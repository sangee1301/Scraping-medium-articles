Category,Title,Authors,Text,Image,Videos,Link,Published_Date

Artificial Intelligence,Media – Medium,"['Ev Williams', 'Dave Pell', 'Hossein Derakhshan', 'Dawn Ennis', 'Stephan Neidenbach', 'Don Day', 'Jessie Singer', 'Tim Grierson']","Media Where the newsroom is the news.

Follow Following",https://cdn-images-1.medium.com/max/1200/1*wLhNmBWoSMvG0kyRGjDIqw@2x.jpeg,[],https://medium.com/topic/media,

Artificial Intelligence,The Inspiration of Anthony Bourdain – Member Feature Stories – Medium,['Christine Byrne'],"One of my first great food memories comes from a trip my family took to Normandy when I was six years old. We hadn’t been sitting for two minutes when I announced to my parents, “I want the escargot.”

Dad: “You know that’s snails?”

Six-year-old me: “Yes! We just learned about them in French class, and I want the escargot!”

My parents went along, although I’m sure they expected I’d take a few bites out of stubbornness, then subtly push the dish of garlic and butter and earthy mollusk aside, hoping no one would call out my misplaced courage.

Actually, though, I ate every snail, then mopped up every bit of briny, herby garlic butter left behind. I still think about those snails and about how excited and proud I was to love them so much.

A decade after those snails, I sat on the living room couch with my dad and watched an episode of No Reservations, Anthony Bourdain’s first food travel show. I, like millions of others, was drawn to the irreverent reverence with which he seemed to approach every food he tried, to his eagerness to try anything, and to his ability to narrate the stories of different foods, cooks, and cultures in an unpretentious way that let them mostly speak for themselves. Until then, I had thought of food and travel writing and television as more marketing than storytelling, but watching No Reservations made it clear that, actually, food was not only a story in and of itself, but also a great way to anchor other stories in something tangible and universally understood. Bourdain wasn’t out to sell an experience or show how good something could be — every episode was about telling the story of things exactly as they are.

Bourdain wasn’t the first to talk about food this way, but he was the first to make me feel like maybe I could talk about food that way, too. Food was an important part of my life growing up, but not in a particularly extraordinary way that I felt would resonate. We lived abroad and traveled often, so I was massively privileged in that there was always something new to eat. I remember eating pâté for the first time on a pebble beach in Cornwall while watching my dad (try to) learn to windsurf. I remember tearing apart a slick piece of roti prata and dipping it into a Styrofoam container of curry sauce on a plastic picnic table in Mersing, Malaysia, before getting on a bum boat to an island where I’d go to summer camp for the first time. I remember my first drink: a Tiger beer at Newton Circus, another hawker center, after the closing night of our high school production of South Pacific. I remember, every year when we’d fly home to New Jersey, eating baked ziti and supermarket sheet cake at Fourth of July barbecues, both or which were exciting and special for me because I only ate them once a year. I remember the first time I ate lunch at a New York City deli and was awed by the enormity of both the sandwiches and the Snapple selection. None of this seemed like a story, though, because I wasn’t sure why anyone else would care.

Years later, as a rising college senior, I spent the summer working as a publishing intern in New York. Weeks in, I realized that my longtime goal of being a book editor was actually, definitely, not what I wanted. To keep the “I graduate in a year and now have no plan” anxiety at bay, I read more books that summer than I ever have. One of them was Anthony Bourdain’s Kitchen Confidential.

Bourdain’s 2000 memoir, as you may know, gets so much of its magic from the sense you get while reading that every story is true. I figured it would fall into the “I never want to go there, but that sure made me think and was fun to watch” category that some of the No Reservations episodes did, and that the stories about hypermasculine kitchen culture and the people who somehow ended up in it would make me laugh, think, and then move on to whatever book was next.

That’s not what happened. The first story the book tells is one of Bourdain as a fourth-grader on a European cruise with his family. He tries vichyssoise, a potato-based French soup, and is taken aback by the fact that it’s cold. “I’d eaten in restaurants before, sure,” he says, “but this was the first food I really noticed. It was the first food I enjoyed and, more important, remembered enjoying.” Reading it made me think of my snails, how adventurous they made me feel, and how they established food as something important and worth discovering. It’s a good, tame story that I could easily relate to, and I bet most people felt the same when reading it.

The thing is, the relatability of the book started and ended with that cold potato soup. The rest of the book — about restaurant kitchens and all the crass, stressful, macho, bonkers shit that happened inside them — took place in a world very, very different from mine. Even coming from Bourdain, whose stories had been making me feel welcome since I first watched him walk around Paris unironically wearing cowboy boots in the first episode of No Reservations, the book felt like something I was looking in on from the outside. Reading it piqued my curiosity in restaurant cooking but made it clear that it wasn’t something for me. The longer the stories sat with me, though, the more they started to feel like a sort of…dare.

I graduated soon after, six months earlier than planned. I was still put off by my intern experience in publishing and totally uninspired by every job option presented to me by career counselors and all the well-meaning adults in my life. (Although it was 2010 and the height of a recession, so calling them “options” is maybe a stretch.) Food writing had crossed my mind, but I didn’t figure it was something I could just jump into. I can’t really explain my sudden decision to go to culinary school — a mix of desperation, an interest in food, a burning need to be interesting and different, and a nagging curiosity about Kitchen Confidential, if I had to put it into words — but in 2010, I moved to New York and spent 10 months at the French Culinary Institute learning how to cook. It remains the most impulsive thing I’ve ever done—and the most significant.

The following two and a half years spent cooking in NYC restaurant kitchens taught me things that culinary school never could have—about cooking, stress, being a woman in a room of mostly men, and how to deal with constantly being under fire without falling apart. It’s hard to explain what it was like to walk into a restaurant kitchen, and I honestly don’t remember it clearly, but I do remember that everything I did was wrong, everywhere I was was in the way, and every time someone said something to me, I had to ask them to explain what they were talking about. It was the most underqualified and out of place I’d ever felt, even though I knew in theory that’s exactly what I was signing up for. (I’d read the book! I intentionally jumped out of my comfort zone!) It wasn’t the useless, undervalued feeling that comes with an entry-level office job; it was the feeling that I needed to apologize for even being there, for being the alien who disrupted a system that everyone else knew how to work in. Weeks went by before I was able to walk into that kitchen without absolute fear; months went by before I was able to actually contribute.

Was restaurant cooking the way Bourdain described? Not really. It was vaguely the same, sure: late nights, weekends, burn scars, characters, industry bars, some yelling, ticket boards that inexplicably but reliably went from empty to full in a matter of minutes every single night.

The actual experience of it was very different from what I’d read, though. Because it wasn’t his experience—it was mine. I was the one cramming four hours’ worth of food prep into two and a half every afternoon. I was the one at the stove, firing seven dishes from three different orders at the same time, in exactly the right order, totally on instinct. I was the one who stayed at the bar three hours too long on a Tuesday and somehow always managed to find my way on the L train. I was the one who felt disconnected from one world but totally plugged into another.

Which made me realize: A great storyteller is one who makes you want to experience stories for yourself. A great story is one that makes you think, “I wonder what it would be like to do that.” I’m not much of a storyteller these days, nor am I still a restaurant cook. I write recipes, and I write stories about how and why people should cook them, but I do so in a way that’s shaped by what I’ve learned: Recipes are like stories, kind of, and the best recipes are ones that people will actually cook. Getting someone to cook a recipe isn’t about presenting them with something they’re already familiar with, necessarily, but about making them think, “I wonder what it would be like to do that.”

It’s no secret that Anthony Bourdain was a great storyteller. I’ll miss following along with his unending curiosity about food and how it shapes us, and the world will miss the way he was able to share that curiosity in a way that was welcoming and inclusive. What I’m most grateful for, though, is that he showed me the inside of a world I’d never given a second thought to—restaurants—and painted a picture that, even though it was totally unrelatable to me, was interesting enough that I felt compelled to experience if for myself. Not many storytellers do their job so well that, after reading their stories, you actually feel moved to go out and live them.

“Food, for me, has always been an adventure,” Bourdain writes in the preface of Kitchen Confidential. For me, too, Chef. Thanks for teaching me that food is something worth exploring and that the exploration is something worth writing about.",https://cdn-images-1.medium.com/max/1200/1*65ru7KtyJDme4kUXz8Sl5Q.jpeg,[],https://medium.com/s/story/the-inspiration-of-anthony-bourdain-8d5679c2acb4?source=grid_home---------0------------------18,

Artificial Intelligence,"Apple has no idea what’s next, so it’s just banging on the same old drum",['Owen Williams'],"Apple has no idea what’s next, so it’s just banging on the same old drum If you want to witness a company that’s simultaneously in its prime and losing control over its own narrative, look no further than WWDC, Apple’s second-most splashy event of the year, designed to offer a glimpse of the future. The annual developer event is a spectacle that I’ve watched live for almost a decade, but this year was different: it showcased a company that’s lost in the woods, playing the same old hits on repeat, in the same old format. Not only was it painful to watch, it demonstrated that Apple doesn’t really have a coherent plan, or understanding, of where it should take its core platform, let alone the ones it’s tried to build around it. It’s fine to have an off year, but what struck me was how… random it felt, and how little insight or forward thinking there was. Apple’s own platform advantages, company culture, and whatever else, seem to be pigeonholing its trajectory, driving it down a path that looks increasingly dated, and leaving me to wonder if the company is self-aware enough to see the shifting tide before it’s lost at sea. Big, slow, yearly

Apple struggled throughout 2017 to ship flagship features it promised at WWDC 2017, including Airplay 2 and iCloud Messages, delivering them quietly just days before this year’s event. Alongside a scandal about performance throttling, a series of major security slip-ups, and hardware that shipped without long-touted features, many have loudly asked what’s causing these issues — and why a company with so many engineers is fundamentally failing to ship. Performance improvements are arguably the biggest focus of iOS 12. They’ll be welcome for many users, along with several additional improvements: streamlined notifications, a new ‘shortcuts’ feature for custom buttons, usage reporting, group FaceTime, AR updates and a number of other minor improvements to create a major release, iOS 12. The company’s other platforms received similar treatment, including macOS. Apple finished dark mode, a feature it half-introduced all the way back in Yosemite, added basic functionality to Finder, threw in a new way to organize your desktop, and boom — there’s your major release, 10.14. None of these things are inherently bad — in fact, people have been complaining about the lack of improvements to things like FaceTime for years — but what’s interesting is Apple’s choice to bundle them together as a way to make them look truly meaningful, rather than just fixing many of these issues sooner, in a point release. I’m aware there’s a slew of tiny other fixes and features I haven’t listed here, but that’s my point: it’s a hodgepodge of things that have been neglected over the years after being debuted once and forgotten about. Here’s the rub: Apple could arguably ship notification improvements to iOS users tomorrow in a point release, iOS 11.5, but it won’t. Combining them provides the illusion of progress. Instead of servicing users and giving them features sooner, on a regular basis, Apple chooses to hold back simple functionality longer, for its bottom line. As Martin Bryant points out, Apple may have a timing problem: Yes, Apple needs to take the time to do ‘boring’ optimisation work on iOS, but why build iOS around these big, annual feature bumps and then disappoint people when the bumps aren’t very big?

Interestingly, the narrative here actually doesn’t make sense anymore, either. Every year, Apple takes the time to point out how dire the state of the competition is: Nobody’s Android phones get updates! Android people don’t get any the latest features! Your phones all suck! The reality is different: Android users, regardless of manufacturer, frequently get them sooner than iOS users do, because Google divorced the operating system and core application suite from one another. Google’s approach to unbundling Android has, for the most part, been quietly successful — in an unexpected way. Instead of shipping monolithic feature updates, Google’s applications are now updated via the Play Store, from the clock app to the calculator and even the camera (unless you’re Samsung). Apple has made a yearly ritual out of jabbing competitors for poor update histories, but conveniently omits the reality that improvements to Google Assistant, the built-in web browser, or even just the OS keyboard will reach billions of users in a matter of hours without needing to update the entire phone. Android’s support libraries mean developers can target older devices, with new features, regardless of whether or not they received the OS update. Meanwhile, if you find a bug in the iOS keyboard, or some weird security flaw in Safari’s web view, you hope it gets fixed in the next version of the operating system. Maybe next year, or the year after that. It depends how bad it is, or if Apple is actively maintaining the feature, as to when it’ll get serviced. Don’t get me wrong, Android has a terrible history of updates that is only now beginning to change, ten years after the fact. Google has made strides with Project Treble, which makes an end-run around the device maker itself, but it’s only in its infancy with new devices picking it up today. That’s not good enough either; but it’s gaining traction and getting things into people’s hands. For each platform update, Apple dangles a carrot. That’s the flagship feature to convince you it’s a Big Update™ worth having immediately. On macOS this year, that’s dark mode, and on iOS, the promise of performance improvements and, god forbid, actually decent notification management. Arguably the most interesting segment out of WWDC happens at the very end of the two-hour keynote: a peek at Project Marzipan, a long-term effort to unify the interface framework developers use to build apps for iOS and macOS, which is expected to ship to everyone in 2019.

From where I sit, this is an impressive, massive project that doesn’t do much more than play defense against Electron’s continued march on Apple’s territory, threatening to kill native application development altogether. Why build anything native at all, when you can write once, and run everywhere? Anti-Electron fans will run rabid at the idea, but as the technology has become more efficient and introduced lower-level API access, it only makes even more business sense. Marzipan is an audacious plan to defend against that by making it easier to build cross-platform apps. It’s a genuinely fascinating play with fewer apparent benefits in the short term over just building an Electron app, which addresses an additional billion users, allows developers to use familiar web technology and is truly write-once-run-everywhere. Over time, Marzipan may win favor with developers, but I’m not convinced it’ll stop web-based technologies swallowing native app development whole, particularly given that both Microsoft and Google have now bet their entire strategies on Progressive Web Applications, and how low the barrier of entry has come as a result of Electron’s success. Marzipan indicates something bigger, of course, such as an impending shift away from Intel chipsets entirely to some sort of custom Apple ARM-based silicon in — shock horror — a productivity form factor. If anything, what will win as a result will be that control, and what it could ship in a end-to-end device: true all-day battery? Always-on LTE with desktop class apps? If so, the message is this: lock in with us, develop for our platforms, and we’ll reward you. Don’t, and you’ll be shut out and stuck on the outside. Hey Siri, where’s the vision?

What’s clearly missing in all of this is a willingness to take risks, or go for the long view on what’s better than the status quo for Apple’s users. Instead of looking at how phone usage is changing and redesigning the nature of iOS, it’s another year of shoehorning new features into a decade-old shell. The new shortcuts feature promises to let users wire up workflows of their dreams, chaining together tasks behind a single button. Yes, this is a great improvement to iOS that addresses a problem without actually improving on the reason anyone needs this in the first place — it’s just glued onto the homescreen that’s responsible for causing the need for it in the first place. Apple could have offered up a way to surface the weather right there, deeply integrated with the lock screen, or calendar events at the top of your home screen along with the icons, but it didn’t. Instead, it slathered what appears to be a UX hack in the shape of a notification, and tries to guess when you want to see it. Google’s own developer conference, just down the street in Mountain View, was held in May and offered a clearer, if poorly highlighted, view of the future: AI is a core part of mobile devices going forward, so we’re beginning to add it everywhere. The Android alternative to Shortcuts, Slices and App Actions, surfaces the device’s best guess at your next action as a deeply integrated interface component, where you can actually see information before actually going further in, or taking an action. Want a button to order a Lyft? Great, here’s a button embedded within the system’s app tray, with the current estimated price of your ride, which orders it right now with a single tap. Much of this data is crunched on device, just like Apple’s audacious claims to privacy brag about as well, but instead of being a UX hack to add buttons that summon help, the information is already right there, on hand, without opening anything, even Assistant. Google and Apple both anticipate a future in which we use our phones less — time well spent is a core part of this driver — and as a result, it appears Google has spent a lot of time thinking about how AI can help get the right information to the user. The result is the exact button they need at the right time, with relevant information, sans the need to actually go away and do something. To facilitate this, Google is willing to rejig the UX of its devices, mess with the sea of icons, and has invested heavily in serendipitous computing with Google Home alongside this, so it can get you there faster regardless of if the phone is in your hand.

Google’s vision of the future of smartphones, mobile operating systems, and the way we’ll interact with devices over the long haul is a coherent, well-told story: get more out of your day, get the devices out of the way. It even has a fantastic page that showcases how its own ecosystem works better, together, than I’ve ever seen explained about Apple’s ecosystem on its own site. As for why all of this happens, I suspect it’s a difference in strategy and approach. Apple’s strategy has long been to monetize its existing cash cows as long as it can by throwing out new stuff to see what sticks and doubling down on that, rather than creating any sort of coherent narrative of what the future actually looks like, operating in secrecy until it somehow lands upon it. Incremental improvement is fine, but there’s a distinct lack of forward-looking, and a whole lot of looking over the fence at what everyone else is doing to bash it instead. Apples, oranges and comparing the two

It’s easy to compare and contrast Google and Apple because they are very different companies, but what they’re both claiming to do is the same: invent the future, whatever that actually might be. Their approaches, however, are increasingly diverging: Apple’s squeezing more out of less, shipping flashy features, and focusing on privacy, while Google and others have pushed further into understanding the user and getting out of their way. Most of this comes down to business model. Apple’s focus on features by piling them together drives more sales of iPhone, which drives reliable revenue on a yearly basis. Google’s is on advertising and relevance to the user, which doesn’t depend on a particular feature or thing to tout, it just needs you to love using its tools (and not mind advertising). Apple’s entire strategy over the last two decades has pivoted around the exploitation of a product line until something new comes along, then rinse and repeat. This is framed around improving your life and often actually does, even if that is by proxy. I’d argue that the company’s vision of the future isn’t to enrich, or drive progress, but to squeeze as much revenue as possible out of slick, well-designed and marketed ideas. The products it builds, the cycles they’re released in and the way that Apple’s entire software cycle works reflects this. An example of the manifestation of this is perhaps HomePod’s requirement to have a locally available iPhone to do anything interesting, leaving it crippled without one, and Animoji’s debut only to be locked away in Messages instead of somewhere like the camera.

Google, a latecomer in the game, has the luxury — and peril — of not depending on phone revenue, so it can risk it all and get weird, since it’s not fundamentally critical to the company’s continued trajectory. Microsoft has done the same, now finding itself the underdog, risked it all and moved to an ‘OS-as-a-service’ model in which it ships features when they’re ready instead of waiting for flashy releases. Apple, on the other hand, begins and ends with the iPhone today, the rest flows from there. It can’t just rip up the foundation on which its revenue exists, and Tim Cook hasn’t shown a flair for doing so. iOS is too valuable to go away and tear down to just reimagine it for fun, so it’s the status quo, with experiments like HomePod and AirPods on the side, where it can get weird and sometimes wonderful. That’s fine, because Apple has plenty of cash lying around, but it’s interesting how limiting the approach can become. As we hurtle toward peak smartphone, the cracks here are beginning to show because Apple don’t have the next big thing yet — that we know of, naturally — and it’s taking a long time to get here. We’re essentially watching the bottom of the metaphorical tube of toothpaste being squeezed, while others are trying to figure out if maybe the tube should work completely differently. AR is potentially the next platform, yes, and it’s clear that Apple is pushing forward on that in a big way, so it’s easy to imagine a scenario in which it makes sense to shift precious resources there instead of focusing on iOS which may wind up unimportant in a year or two. I’m not convinced that in the short term, such as the oft-claimed 2020 launch date of an Apple VR/AR headset, that we’ll be headed there in any meaningful capacity. I mean, Magic Leap, a bajillion dollar company building the future of AR showed off its hardware yesterday on Twitch, quipping that “you better not put it in your pocket or it’ll overheat.” I’m happy to be wrong, and I write this knowing I’ll probably be that guy who very publically crapped on the iPhone at launch later. Apple’s worth a very large amount of money, which is more than enough proof that it’s good at many things, including convincing people to buy a phone every year.",https://cdn-images-1.medium.com/max/1200/1*tIUbwrpHZPbdNPXB569wPQ.png,[],https://medium.com/@ow/apple-has-no-idea-whats-next-so-it-s-just-banging-on-the-same-old-drum-dcfd0179cf80?source=grid_home---------0------------------18,2018-06-07 13:54:23.876000+00:00

Artificial Intelligence,Our Wedding Is Canceled Due to the Following Strongly-Held Beliefs,['Tim Sniffen'],"Hi, everyone. I know you weren’t expecting to see Keith and I out here so soon, but we have some bad news. We’re not getting married today.

Believe me, we were really looking forward to it, but recently — this morning, in fact — we learned our blessed event was in direct conflict with the strongly-held beliefs of many of the people providing our wedding services. And if they’re not happy, we’re not happy.

Let me bring you up to speed.

You may have noticed the empty display table by the reception tent as you filed in. That’s where our wedding cake would have been. For our baker, however, creating a cake to be employed in the marriage of two men would be the moral equivalent of using communion wine to make sangria.

We knew the risks when enlisting Give Us This Beignet, Our Daily Bread as our wedding baker. They’re the best in downtown Aurora, no question — sorry, Wild-Flour! — but their beliefs on same-sex marriage are no secret. We hoped they might get swept up in the joy of the occasion but last night their chief baker Jonah, applying the final bit of piping, had a vision of Billie Jean King physically dragging him away from the gates of Heaven. And if that’s not a sign, I don’t know what is.

I should add, it may not have helped that we requested our little cake figurines be surrounded by an added semi-circle of figurines, in likenesses of the bakery staff, giving us the thumbs-up.

But that’s all done with. They’ve made their wishes clear and we respect them.

Which brings me to the empty vases alongside the pews and the empty centerpiece bowls on the reception tables. We’ve known Joyce Gantz, owner of Rest On My Laurels, for years; I couldn’t imagine this day without her. What I couldn’t know was the war raging within Joyce, fervent Catholic, after she learned of the meat-laden Friday barbecues Keith and I throw for our softball team. Last night, Joyce looked deep within her heart to ask, can I lend my good name to this cursed union?

The dumpster full of imported delphinium behind Joyce’s shop can tell you the answer.

You see, what we’re learning is that these are not just goods and services; they’re not simply the imprints of Keith’s Capital One card and the resulting exchange of goods. Every item at a wedding is nothing less than the avatar of its vendor’s entire belief system. With this in mind, each rose petal my niece Stephanie was prepared to hurl down the aisle might as well have been embossed with JOYCE GANTZ APPLAUDS THEE, SATAN.

What faith-engorged entrepreneur should face such hell?

This is why the rows of steam-trays in the tent are empty, and your choice of beef tenderloin or grilled salmon — or the one plate of tempeh veggie kabob, bless you, Amy! — will never arrive. Because Something Borrowed, Something Cordon Bleu, exceptional wedding caterers and unapologetic druids, could not bear the thought of providing nourishment to a couple willing to rip two thriving Magnolia trees from their backyard last summer. From their email: “Your heretic’s feast will be served when the earth heals from your violence.” By our best guess that wouldn’t have been by 6 p.m.

We also won’t be dancing to Renèe and the Ring-tones. While Rènee was a woman of few beliefs when we booked her, she has since converted to the Egyptian cult of Bastet, and considers the choice to put our cat Banjo to sleep, rather than pay $15,000 for experimental feline jaw surgery, to be “unforgivable wickedness, worthy of disciples of Set.”

I’ve been handed this note: Lane, our photographer, turns out to be more of a Star Wars guy and doesn’t feel right legitimizing such an obviously Star Trek couple.

Blessings on your journey, Lane.

In closing, our apologies. We were so busy coordinating our big day that we forgot to coordinate the sacred truths of all players involved. I’m told many of our vendors will adopt an exhaustive three-week interview process before each sale to keep this from happening again.

We did have a lovely wedding favor created for each of you, which we might as well distribute. It’s a wooden plaque, engraved with the phrase Love Conquers All, hand-crafted by our friend Bryce Charles in the front row. Now, Bryce is something of a Packers fan, and Keith is all about the Bears, but in the spirit of friendly rivalry, we’ve always managed to put aside our differ — wait.

Bryce’s feelings are changing.

They’re moving from loosely-held to nonchalantly-held. They’re not done; from the set of Bryce’s jaw, her feelings have transitioned to intentionally-held, and finally, they’re — yup. They’re strongly-held. Dammit.

Sorry, folks. You’re on your own.",https://cdn-images-1.medium.com/focal/1200/632/50/45/0*fh1vaEnMNoMbHE42,[],https://medium.com/s/story/our-wedding-is-cancelled-due-to-the-following-strongly-held-beliefs-1fa71105660e?source=grid_home---------0------------------18,

Artificial Intelligence,My So-Called (Millennial) Entitlement – Trust Issues – Medium,['Stephanie Georgopulos'],"I am at the San Francisco International Airport some barely recent morning, registering for a travel program called Clear when the automated kiosk assisting me makes a strange request: “Stand still while we scan your irises.” I’ve barely digested this first ask when another takes its place: this time, the kiosk wants my fingerprints. I find this slightly less alarming; I already use those to access my banking app, buy coins for my mobile games, and unlock the phone that hosts all this information in the first place. But my eyeballs — which I had only just learned could be used as ID, and from a machine at the airport, no less — my dude. Those are the windows to my soul! Ever heard of foreplay?

Clear is a private company that prescreens air travelers using biometric authentication. Becoming a member is like ordering the half-soup, half-sandwich version of TSA PreCheck: it works, if all you want is a taste and are willing to pay for it. With Clear, you don’t need your ID to go through security, but you still have to remove your shoes. You get to wait in a shorter line (sometimes), but you still have to take out your laptop. Basically, the Cleared still participate in the most annoying aspects of air travel and pay almost 10 times the PreCheck fee for the privilege.

If the worst has already happened, that means it’s survivable.

How we decided on this valuation of convenience—it’s $179 per year—is not the point, though. My point is that some random startup casually acquired my eye-prints, and some small voice is telling me I should care more than I do. Someone out there definitely cares about this, no doubt. I’m sure at least one other traveler was not sated when a brisk Google search revealed that Clear is based in her hometown and run by a female CEO, ergo it must be a secure and entirely trustworthy business.

But I was sated. It’s the future, right? What’s the worst one could do with my retinal scans? I already gave my social security number to Camel in exchange for a pack of promotional cigarettes one time (or 12). Somewhere in Midtown Manhattan, a market-research firm knows how many condoms I used in May of 2011 (give or take). And when I think about the fact that every hard document I’ve reproduced on a digital copy machine — at work, at the bodega, at the library — is saved on a hard drive somewhere (lots of somewheres, in fact), I feel a sense of hopelessness that, in its own demented way, translates to freedom.

That’s why I unlock my phone with my fingerprint. It’s also why I talk shit in front of Alexa, why I haven’t put tape over my laptop camera, and why I still have a Facebook account. I don’t expect the worst to happen.

Because the worst has already happened. It is happening, and it will continue to happen.

I find this to be an honest, useful framework. If the worst has already happened, that means it’s survivable. And if the worst is a given in the future, too, we know that ignoring it won’t make it go away. There’s opportunity in having nothing to lose. You just need the right attitude.

Or perhaps you need the right conditioning.

Imagine: You’re 11 years old when two teenagers bring guns to their high school and kill 13 people. They injure 21 more. Your sixth-grade humanities teacher explains the inexplicable to your class after lunch period. You have to imagine that this is a first for at least some of your classmates, crying over the national news. It won’t be the last.

When you’re 15, two planes crash into two towers. You know the towers; had toured them on school trips just like all the other famous Manhattan buildings for which you know the names, if not the functions. In fact, you’d visited the towers just one week before the planes hit. There had been a renaissance fair in one of the lobbies.

At 17, your high school economics teacher tells you that social security will run out before you retire. You’ve already been paying taxes for three years. In 2018, you learn that he was exaggerating, thank goodness — by 2034, retirees can expect to receive a whopping 79% of the full benefit they receive today. You will not be of retirement age until the 2050s.

And when you’re 21, the market crashes. You’ve had a bachelor’s degree for three months. It cost $100,000 to earn, all before interest. Your class valedictorian moves back in with her parents, and no, your internship is not hiring. Five years later, the unemployment rate for people your age is almost double the national average.

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

Neuroscience has confirmed that you were making sense of these events with an underdeveloped brain. Along with your emotional maturity and your hormones, it’ll be a work-in-progress until you’re around 25. And the same way the small hurts of being small can still seep into your present — the way your grandmother eyed you with disgust when you went for a second helping — the chipping away of every institution you were raised to believe in can have unintended consequences.

Me: Do you use Touch ID to unlock your phone?

Friend: Ya.

Me: Do you know anything about the technology behind it? Or like, how secure it is?

A beat. A blank stare.

Friend: No?

Me: Same.

My friends do not need to understand the technology behind touch ID any more than they need to understand black holes. They are not convinced that adjusting their social media privacy settings is some sort of moral duty, a symbolic middle finger to Facebook on behalf of all the little guys who understand internet economics to varying degrees, or not at all. Mostly, they were confused as to why any thinking person would have an assumption of security.

“It’s not that I don’t care about being hacked, or about my data being stolen or sold,” one friend tells me. “I assume that vulnerability because there are no physical systems or structures that have succeeded, so why would something that is essentially invisible do a better job than something tangible?”

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

I’ll go: I don’t expect to own a home. I don’t expect to retire well, or at all. I don’t expect anyone to give me anything I haven’t explicitly asked for, and even then. I don’t expect it will ever be affordable to continue my education in any formal way. If a package gets lost in the mail, I don’t expect to see it again. I don’t expect the government or the banks or the universities to do anything that benefits regular people. I don’t expect them to hold each other accountable on our behalf. I don’t expect them to expel abusers from their ranks, or to put my safety over their legacy. I don’t expect to feel safe in large crowds or alone late at night. And I don’t expect that my privacy will be respected, online or in general.

America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

As far as I can tell, security — whether financial, technological, physical, or emotional — is not a thing. You don’t get to decide whether some drunk asshole drinks his drunk ass off and gets behind the wheel. Likewise, you don’t get to decide if the drunk Congress or the drunk banker or all the drunk administrations of all the drunk institutions do what’s right for you. Sometimes they will do the right thing for somebody, but statistically speaking, that somebody is not you.

Sometimes the right thing comes served in a shit sandwich, or one guy does the right thing but it’s later counteracted by the next guy and just so we’re clear, it’s always a guy. Or sometimes, we learn that what we thought was the right thing was actually the wrong thing, in ways we didn’t anticipate, except for those of us who did anticipate it but were not asked or heard because we do not employ lobbyists and because the powers that be can’t listen to us until they sort out whether our bodies are legal or not.

Mark Zuckerberg’s Congressional hearing was probably the biggest mainstreaming of data privacy issues yet, and Facebook, with its many transgressions, made for an appropriate scapegoat. But I want to know why it’s Mark Zuckerberg’s fault that American adults of voting age lack the critical thinking skills to differentiate between fake Russian bot news and The Guardian. I want to know the plan for bringing internet literacy to those who are not digital natives. I want to know why the U.S. government is being celebrated for protecting our egos and baby-proofing the internet instead of telling us the truth: Dirty tricks are less likely to work on people with more education.

What happens when your brand of exceptionalism breeds millions of people who voted a sentient conspiracy theory into office? Where does the fault lie? After all, it’s not Facebook who’s spent decades underpaying teachers and closing schools in low-income neighborhoods. Facebook doesn’t have the jurisdiction to end standardized testing or combat the quiet continuation of white flight. Facebook’s biggest mistake? Profiting off of state-sanctioned dumbness.

We’re only supposed to be dumb enough to believe that the fight is red vs. blue and not top vs. bottom. We’re only supposed to be dumb enough to believe in Democracy the Concept™ without casting a critical eye toward its practical application. This is a dumbness cultivated by and for Washington, and Zuckerberg’s misusing of it for corporate gain almost blew the lid off the entire thing. Commence finger-wagging.

On an episode of his podcast Revisionist History, Malcolm Gladwell argues that we should treat education as a weak-link network, where strengthening the weakest links has the most positive outcome for all. This is in contrast to a strong-link network, where a couple of superstars at the top carry the weaker players on the bottom. He illustrates this dynamic using soccer and basketball. An average soccer team with one star player is less likely to win a match than an above-average team with no star players — soccer is a weak-link sport. Conversely, an NBA team with a superstar or two fares better than a team on which all the players are equally, decently good — basketball is a strong-link sport.

Much to its detriment, America acts like a strong-link country. It is the type of place where electing one mixed-race president means we solved racism. (Imagine if the lesson we took from electing one white man was that all white men who lack upward mobility just need to work harder.) We raise up a few undoubtedly smart and deserving people in each field, send them around the world like brand ambassadors for democracy, poster-adults for how advanced and distinguished and American we are. Meanwhile, most of us back home — 78%, in fact — are living paycheck to paycheck. Is that freedom ringing? We’ll call right back after we pay this phone bill.

These are complex problems. In addition to the 3000ish words here, I have written and cut an additional 4500 trying to make sense of it all. I remain overwhelmed by the number of solutions that contradict one another, the knowns and unknowns, the countless logical ends I haven’t considered. But I eventually found my demented silver lining: America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

While grim on its face, this perspective has pushed me to take inventory of myself, my own power. What can I do right now? Am I solving problems I actually care about, or were these problems unconsciously inherited from another time, problems propagated by those with a vested interest in resolving them with more money, more power, more loopholes? Should I devote my energy to righting a system that, by design, has only consistently benefited one demographic and has yet to even prove itself as a scalable model for a generation that’s tired of the same people making the same decisions on behalf of the most diverse country in the world?

Is that a problem? Because it feels more like an opportunity, to me: a chance to exercise this cache of personal agency I’ve been sitting on, agency I didn’t realize I had or needed as I waited for America to work. It feels like an opportunity to try something else.

More powerful than having nothing to lose is cultivating that which can’t be taken. Grace. Clarity. Purpose. The stuff that isn’t Amazon Prime-able. These are the indoor plants of our being; only you can feed them and grow them and expose them to the light. It’s a lot of responsibility, and the work involved is often unglamorous. Some people think they never have to learn to care for these things because they have the means to outsource what they wish: their plants are alive on paper though they don’t know the how or why of it. And besides, can’t you see they’re a little busy trying to colonize Mars?

A respectable goal, though I might suggest to anyone faced with the choice to try taking on the inner self before jumping ahead to outer space. There’s more to unearth in there than you might think, and we need more people to understand the potential of their own organic material. We need people who appreciate the slow growth of nothing into something, who drink up the sunlight and make the air a little more breathable than before.

Because that’s it, for most of us. That’s how we build power. That’s how we, a generation of janitors for the American dream, put our trust in something real: each other. We stop trying to control the world in our heads and in the headlines, and we start controlling ourselves. We sleep. We go to the doctor. We log off. We talk about our problems. We water our plants. We collect our neighbor’s mail when they’re out of town. We take a deep breath before reacting in anger, and question whether this particular battle is worth our energy. It’s not. Why were we fighting again? We volunteer. We water our plants. We focus on ourselves so we can eventually focus on others — in a real way, in a non-transactional way, in a way that slowly but authentically strengthens our fellow weak links. We don’t wait for permission. We get over ourselves; we stop demanding perfection; we start. We water our plants. And on weekends, we play soccer.",https://cdn-images-1.medium.com/max/1200/1*c5zNxCX34sYmYYO-yRxlbA.png,[],https://medium.com/s/trustissues/my-so-called-millennial-entitlement-9be84343c713?source=grid_home---------0------------------18,

Artificial Intelligence,How to Cope with the End of the World – How to Cope With The End of The World – Medium,['Maria Farrell'],"We All Die, and That’s Okay

My favorite postapocalyptic novel is George R. Stewart’s 1951 Earth Abides. In it, scientist Isherwood Williams (nicknamed Ish) survives a plague and eventually starts a new family and community in the ruins of suburban California. His hope for the future is wholly invested in a child who is intellectually curious, like him, and who might be able to revive some of the old ways and technologies. It’s an observant and reflective novel, full of the “how stuff would probably work” thinking that makes science fiction the true literature of ideas.

Ish starts out as a scientist-savior of humanity, figuring there is just enough time to raise a generation to turn back the clock to before the disaster. But he ultimately has to make his peace with the fact that civilization as he knew it is dead, there will be no heroic rescue, no going back, and the people around him are mostly fine with that.

The 1950s may have been the last decade we could complacently believe the Ecclesiastes (1:4) maxim that “men come and go, but earth abides,” but Stewart’s basic message is correct.

The people who come after us don’t have to do better than us, or think well of us, for them to be essentially okay. And us all throwing a big “let’s blow it all up” hissy fit because we fucked up and we can’t bear to look at it is just teenage nihilism that we need to grow out of already. Coming to terms with what we have done means dumping the egotistical death drive of the mass shooter or far-right politician and gathering the maturity to look our individual and collective deaths straight in the eye and say, “Okay, we get it now. We get it. It’s not about us.”

Have you ever stood in a crowded place like a town square or an airport meet-and-greet and thought, “Every single person here is going to die”? Morbid, eh? More of us should do it.

I live in an early Victorian terraced house in the UK. It’s never been a tenement, so probably a hundred people have called it home in the almost two centuries it’s been standing. Nearly all of them are dead. The people are already born who’ll live there when I’m dead. The head of this country’s anachronistic state has already been born who I’ll never see on the throne and to whom I’ll seem as old as someone born in the 1930s seems to me.

We’re all going to die. The morning will come when those who have loved us put on dark clothes and cry and get on with the rest of their lives, seeing movies we’d have loved, depending on gadgets that now seem to us ridiculously unnecessary. Our deaths matter to us and those who love us, but they don’t fundamentally matter.

Once, while my husband was deployed to Afghanistan, I asked him on the phone if he was doing okay about someone we knew who’d recently been killed. “Oh, you know,” he said, “you know,” and quoted his regiment’s unofficial mantra:

Everything matters. Nothing matters terribly.

The soldier’s death mattered very, very much to him, and (not but) he and others were nonetheless carrying on their shared purpose. Otherwise, what had been the point of any of it?

What will outlive us, individually? Plastic. Perhaps some genes. The bacteria that act as a species-level enabler for everything we are. Some ideas, maybe, or songs, stories, pictures, the memories of us others hold, until they go, memorials like a community flower bed or a named scholarship, for a while, anyway. Less concretely: ways of being, a fitness for the world that those who flourish pass unremarked to their offspring via the epigenetics of love — the sunny inverse of patterns of trauma and abuse transmitted through the body, even unto the third generation. Predation.

And our species? Buildings and bones, maybe. Our nuclear waste and the warning signs we hope people of our deep future, or other species altogether, will decrypt. Snatches of radio-transmitted voices slipping through the vacuum of space. Perhaps some bacterial payload we’ll launch in a decade or so, trying to seed life on other planets, even in other solar systems. Or just the anomalous levels of carbon dioxide and methane in our atmosphere that will reveal, for a time, that complex forms of life were here.

Pride and despair are two sides of the same coin. Our collective denial and despair about the future we have built is preventing us from cracking on and sorting it out. We need to get over ourselves. The world we know will end, in both small and big ways. We ourselves will end. But that doesn’t matter, terribly.

Our mortality is the greatest enabler we have of positive, ongoing change, if only we can face it, if only we can understand that we don’t get to see the end of the movie, because, if what we do works, the movie won’t have to end. We’re not the protagonists. We’re just the foreshadowing. We need to hold the knowledge of our own deaths up to the light and turn it around to see each shining facet, then take the certainty that we are both finite and imperfect deep down inside of us—and put it to work.",https://cdn-images-1.medium.com/max/1200/0*avXWZmh3n3H7a8t8,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world/how-to-cope-with-the-end-of-the-world-2520ef9d3dbc?source=grid_home---------0------------------18,

Artificial Intelligence,How to Cope With The End of The World – Medium,['Maria Farrell'],"COLUMN

How to Cope With The End of The World

There are moments of joy even in times of great despair. Maria Farrell explains how to deal with a darkening world, and how to plan for the end. It might be the end of the world as we know it, but it turns out we feel fine.",https://cdn-images-1.medium.com/max/1200/1*kvqwUuDCsbkAoSfaYXV1vQ@2x.png,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world,

Artificial Intelligence,Chatbots were the next big thing: what happened? – The Startup – Medium,"['Matt Asay', 'Justin Lee']","Chatbots were the next big thing: what happened?

Oh, how the headlines blared:

“…the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”

Chatbots were The Next Big Thing.

Our hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.

And why wouldn’t they be? All the road signs pointed towards insane success.

Messaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!

Plus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.

At the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.

In fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:

“Will a single platform emerge to dominate the chatbot and personal assistant ecosystem?”

One year on, we have an answer to that question.

No.

Because there isn’t even an ecosystem for a platform to dominate.

Fooled by another hype cycle

Chatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.

The age-old hype cycle unfolded in familiar fashion…

Reverential TechCrunch articles were written.

Prophetic thought leaders like Chris Messina chimed in.

Silicon Valley salivated at the prospect of talking to smart automation.

Messenger began to overflow with bots.

Slack went through exponential growth and even launched a fund for bot investment.

Expectations built, built, and then….. It all kind of fizzled out.

The predicted paradim shift didn’t materialize.

And apps are, tellingly, still alive and well.

We look back at our breathless optimism and turn to each other, slightly baffled:

“is that it? THAT was the chatbot revolution we were promised?”

Digit’s Ethan Bloch sums up the general consensus:

“I’m not even sure if we can say ‘chatbots are dead,’ because I don’t even know if they were ever alive.”

According to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.

Text vs. Speech vs. GUI: a potted history

Bots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.

Users had to type commands manually into a machine to get anything done.

Then, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!

Meanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.

Another bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:

… so many different accents, people speaking too fast or too slowly, mumbling, umming and aahing.

Did you say “recognise speech” or “wreck a nice beach”?

The next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:

User: “Hello.”

Agent: “Hello, what’s your name?”

User: “Candy.”

Agent: “Hello, Candy!”

User: “Let’s set the clock.”

Agent: “What is the time?”

User: “The time is 11:00 AM.”

Agent sets the clock to 11:00 AM.

Pretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.

It was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.

Modern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.

Basically, we’re still trying to achieve the same innovations we were 30 years ago.

Here’s where I think we’re going wrong:

Thinking in terms of Bots vs. Apps

An oversized assumption has been that apps are ‘over’, and would be replaced by bots.

By pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.

You might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?

It’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.

Whether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.

Plus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.

A great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.

That’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.

Modern-day apps benefit from decades of research and experimentation. Why would we throw this away?

But, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.

Today’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.

Penny provides chatty advice and alerts alongside a traditional account dashboard and transaction list.

HubSpot Conversations unifies Facebook Messenger, onsite chat, social media, email and other messaging outlets into one shared inbox.

Layer gives developers the tools to create personalized messaging experiences on mobile web and desktop web as well as native apps.

The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.

Bots for the sake of bots

Does my product need a bot? Are existing platforms able to support its functionality? Do I have the patience to build a bot that’s capable of doing what I want it to?

Another problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.

For plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.

Building a bot for the sake of it, letting it loose and hoping for the best will never end well:

The totally necessary Maroon 5 chatbot in action

The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.

The advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.

That’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.

Problems arise when life refuses to fit into those boxes.

According to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.

When we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.

Remember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.

Inaccessibility

A competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.

In an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.

Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)

As Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.

“Consumer interest was never going to materialize until machine intelligence could get anywhere near human intelligence.

User interest depends upon AI that makes talking with a bot worthwhile for consumers.”

And conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.

Today’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.

And in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:

“Should Slack, Facebook, Google, Microsoft, Kik, and others have built their own built-in bots to lead the way?

Should they have gotten more proactive with their bot funds and incubators, hiring mentors to educate participants in the Way of the Bot, or supplying engineering and design resources? Funded Strategic Bot Initiatives at high-profile partners?

In my opinion yes, yes, and yes. When it comes to platforms, developers are the users; and we don’t rely on our users to understand why or how to use our products. We have to show them.”

GUI shouldn’t be dismissed

Once upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information

There’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.

Tapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.

We love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.

Conversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.

Sure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.

Humans like talking to other humans

Aiming for a human dimension in business interactions makes sense.

If there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.

Facebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.

A conversation encompasses so much more than just text.

Humans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.

As HubSpot team pinpointed:

Bots provide a scalable way to interact one-on-one with buyers. Yet, they fail when they don’t deliver an experience as efficient and delightful as the complex, multi-layered conversations people are accustomed to having with other humans on messaging apps.

People aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).

And even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.

And here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.

But is that how humans prefer to interact with machines?

Not necessarily.

At the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.

Where do we go from here?

In a way, those early-adopters weren’t entirely wrong.

People are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.

Not even close.

Computers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.

Computers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.

That’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.

For now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.

But that’s not the whole story.

Yes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.

As Bill Gates once said:

We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. Don’t let yourself be lulled into inaction.

The hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.

I believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.

Messaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.

Developers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.

And I can’t wait to see what happens next.",https://cdn-images-1.medium.com/max/1200/1*-_um8Nai0uer46tni1LETg.jpeg,[],https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=topic_page---8------0----------------,2018-06-05 15:55:36.912000+00:00

Artificial Intelligence,Google’s AutoML will change how businesses use Machine Learning,['George Seif'],"Google’s AutoML will change how businesses use Machine Learning

Google’s AutoML is a new up-and-coming (alpha stage) cloud software suite of Machine Learning tools. It’s based on Google’s state-of-the-art research in image recognition called Neural Architecture Search (NAS). NAS is basically an algorithm that, given your specific dataset, searches for the most optimal neural network to perform a certain task on that dataset. AutoML is then a suite of machine learning tools that will allow one to easily train high-performance deep networks, without requiring the user to have any knowledge of deep learning or AI; all you need is labelled data! Google will use NAS to then find the best network for your specific dataset and task. They’ve already shown how their methods can achieve performance that is far better than that of hand-designed networks.

AutoML totally changes the whole machine learning game because for many applications, specialised skills and knowledge won’t be required. Many companies only need deep networks to do simpler tasks, such as image classification. At that point they don’t need to hire 5 machine learning PhDs; they just need someone who can handle moving around and organising their data.

There’s no doubt that this shift in how “AI” can be used by businesses will create change. But what kind of change are we looking at? Whom will this change benefit? And what will happen to all of the people jumping into the machine learning field? In this post, we’re going to breakdown what Google’s AutoML, and in general the shift towards Software 2.0, means for both businesses and developers in the machine learning field.

More development, less research for businesses

A lot of businesses in the AI space, especially start-ups, are doing relatively simple things in the context of deep learning. Most of their value is coming from their final put-together product. For example, most computer vision start-ups are using some kind of image classification network, which will actually be AutoML’s first tool in the suite. In fact, Google’s NASNet, which achieves the current state-of-the-art in image classification is already publicly available in TensorFlow! Businesses can now skip over this complex experimental-research part of the product pipeline and just use transfer learning for their task. Because there is less experimental-research, more business resources can be spent on product design, development, and the all important data.

Speaking of which…

It becomes more about product

Connecting from the first point, since more time is being spent on product design and development, companies will have faster product iteration. The main value of the company will become less about how great and cutting edge their research is and more about how well their product/technology is engineered. Is it well designed? Easy to use? Is their data pipeline set up in such a way that they can quickly and easily improve their models? These will be the new key questions for optimising their products and being able to iterate faster than their competition. Cutting edge research will also become less of a main driver of increasing the technology’s performance.

Now it’s more like…

Data and resources become critical

Now that research is a less significant part of the equation, how can companies stand out? How do you get ahead of the competition? Of course sales, marketing, and as we just discussed, product design are all very important. But the huge driver of the performance of these deep learning technologies is your data and resources. The more clean and diverse yet task-targeted data you have (i.e both quality and quantity), the more you can improve your models using software tools like AutoML. That means lots of resources for the acquisition and handling of data. All of this partially signifies us moving away from the nitty-gritty of writing tons of code.

It becomes more of…

Software 2.0: Deep learning becomes another tool in the toolbox for most

All you have to do to use Google’s AutoML is upload your labelled data and boom, you’re all set! For people who aren’t super deep (ha ha, pun) into the field, and just want to leverage the power of the technology, this is big. The application of deep learning becomes more accessible. There’s less coding, more using the tool suite. In fact, for most people, deep learning because just another tool in their toolbox. Andrej Karpathy wrote a great article on Software 2.0 and how we’re shifting from writing lots of code to more design and using tools, then letting AI do the rest.

But, considering all of this…

There’s still room for creative science and research

Even though we have these easy-to-use tools, the journey doesn’t just end! When cars were invented, we didn’t just stop making them better even though now they’re quite easy to use. And there’s still many improvements that can be made to improve current AI technologies. AI still isn’t very creative, nor can it reason, or handle complex tasks. It has the crutch of needing a ton of labelled data, which is both expensive and time consuming to acquire. Training still takes a long time to achieve top accuracy. The performance of deep learning models is good for some simple tasks, like classification, but does only fairly well, sometimes even poorly (depending on task complexity), on things like localisation. We don’t yet even fully understand deep networks internally.

All of these things present opportunities for science and research, and in particular for advancing the current AI technologies. On the business side of things, some companies, especially the tech giants (like Google, Microsoft, Facebook, Apple, Amazon) will need to innovate past current tools through science and research in order to compete. All of them can get lots of data and resources, design awesome products, do lots of sales and marketing etc. They could really use something more to set them apart, and that can come from cutting edge innovation.

That leaves us with a final question…

Is all of this good or bad?

Overall, I think this shift in how we create our AI technologies is a good thing. Most businesses will leverage existing machine learning tools, rather than create new ones since they don’t have a need for it. Near-cutting-edge AI becomes accessible to many people, and that means better technologies for all. AI is also quite an “open” field, with major figures like Andrew Ng creating very popular courses to teach people about this important new technology. Making things more accessible helps people transition with the fast-paced tech field.

Such a shift has happened many times before. Programming computers started with assembly level coding! We later moved on to things like C. Many people today consider C too complicated so they use C++. Much of the time, we don’t even need something as complex as C++, so we just use the super high level languages of Python or R! We use the tool that is most appropriate at hand. If you don’t need something super low-level, then you don’t have to use it (e.g C code optimisation, R&D of deep networks from scratch), and can simply use something more high-level and built-in (e.g Python, transfer learning, AI tools).

At the same time, continued efforts in the science and research of AI technologies is critical. We can definitely add tremendous value to the world by engineering new AI-based products. But there comes a point where new science is needed to move forward. Human creativity will always be valuable.

Conclusion

Thanks for reading! I hope you enjoyed this post and learned something new and useful about the current trend in AI technology! This is a partially opinionated piece, so I’d love to hear any responses you may have below!",https://cdn-images-1.medium.com/max/1200/1*g9BzirXxUauRO9rA_tSvnA.jpeg,[],https://towardsdatascience.com/googles-automl-will-change-how-businesses-use-machine-learning-c7d72257aba9?source=topic_page---8------1----------------,2018-05-14 14:27:41.145000+00:00

Artificial Intelligence,Automated Feature Engineering in Python – Towards Data Science,['William Koehrsen'],"First, let’s take a look at our example data. We already saw some of the dataset above, and the complete collection of tables is as follows:

Deep feature synthesis stacks multiple transformation and aggregation operations (which are called feature primitives in the vocab of featuretools) to create features from data spread across many tables. Like most ideas in machine learning, it’s a complex method built on a foundation of simple concepts. By learning one building block at a time, we can form a good understanding of this powerful method.

Fortunately, featuretools is exactly the solution we are looking for. This open-source Python library will automatically create many features from a set of related tables. Featuretools is based on a method known as “ Deep Feature Synthesis ”, which sounds a lot more imposing than it actually is (the name comes from stacking multiple features not because it uses deep learning!).

These operations are not difficult by themselves, but if we have hundreds of variables spread across dozens of tables, this process is not feasible to do by hand. Ideally, we want a solution that can automatically perform transformations and aggregations across multiple tables and combine the resulting data into a single table. Although Pandas is a great resource, there’s only so much data manipulation we want to do by hand! (For more on manual feature engineering check out the excellent Python Data Science Handbook ).

This process involves grouping the loans table by the client, calculating the aggregations, and then merging the resulting data into the client data. Here’s how we would do that in Python using the language of Pandas .

On the other hand, aggregations are performed across tables, and use a one-to-many relationship to group observations and then calculate statistics. For example, if we have another table with information on the loans of clients, where each client may have multiple loans, we can calculate statistics such as the average, maximum, and minimum of loans for each client.

we can create features by finding the month of the joined column or taking the natural log of the income column. These are both transformations because they use information from only one table.

A transformation acts on a single table (thinking in terms of Python, a table is just a Pandas DataFrame ) by creating new features out of one or more of the existing columns. As an example, if we have the table of clients below

The process of constructing features is very time-consuming because each new feature usually requires several steps to build, especially when using information from more than one table. We can group the operations of feature creation into two categories: transformations and aggregations . Let’s look at a few examples to see these concepts in action.

Feature engineering means building additional features out of existing data which is often spread across multiple related tables. Feature engineering requires extracting the relevant information from the data and getting it into a single table which can then be used to train a machine learning model.

If we have a machine learning task, such as predicting whether a client will repay a future loan, we will want to combine all the information about clients into a single table. The tables are related (through the client_id and the loan_id variables) and we could use a series of transformations and aggregations to do this process by hand. However, we will shortly see that we can instead use featuretools to automate the process.

Entities and EntitySets

The first two concepts of featuretools are entities and entitysets. An entity is simply a table (or a DataFrame if you think in Pandas). An EntitySet is a collection of tables and the relationships between them. Think of an entityset as just another Python data structure, with its own methods and attributes.

We can create an empty entityset in featuretools using the following:

import featuretools as ft

# Create new entityset

es = ft.EntitySet(id = 'clients')

Now we have to add entities. Each entity must have an index, which is a column with all unique elements. That is, each value in the index must appear in the table only once. The index in the clients dataframe is the client_id because each client has only one row in this dataframe. We add an entity with an existing index to an entityset using the following syntax:

The loans dataframe also has a unique index, loan_id and the syntax to add this to the entityset is the same as for clients . However, for the payments dataframe, there is no unique index. When we add this entity to the entityset, we need to pass in the parameter make_index = True and specify the name of the index. Also, although featuretools will automatically infer the data type of each column in an entity, we can override this by passing in a dictionary of column types to the parameter variable_types .

For this dataframe, even though missed is an integer, this is not a numeric variable since it can only take on 2 discrete values, so we tell featuretools to treat is as a categorical variable. After adding the dataframes to the entityset, we inspect any of them:

The column types have been correctly inferred with the modification we specified. Next, we need to specify how the tables in the entityset are related.

Table Relationships

The best way to think of a relationship between two tables is the analogy of parent to child. This is a one-to-many relationship: each parent can have multiple children. In the realm of tables, a parent table has one row for every parent, but the child table may have multiple rows corresponding to multiple children of the same parent.

For example, in our dataset, the clients dataframe is a parent of the loans dataframe. Each client has only one row in clients but may have multiple rows in loans . Likewise, loans is the parent of payments because each loan will have multiple payments. The parents are linked to their children by a shared variable. When we perform aggregations, we group the child table by the parent variable and calculate statistics across the children of each parent.

To formalize a relationship in featuretools, we only need to specify the variable that links two tables together. The clients and the loans table are linked via the client_id variable and loans and payments are linked with the loan_id . The syntax for creating a relationship and adding it to the entityset are shown below:

The entityset now contains the three entities (tables) and the relationships that link these entities together. After adding entities and formalizing relationships, our entityset is complete and we are ready to make features.

Feature Primitives

Before we can quite get to deep feature synthesis, we need to understand feature primitives. We already know what these are, but we have just been calling them by different names! These are simply the basic operations that we use to form new features:

Aggregations: operations completed across a parent-to-child (one-to-many) relationship that group by the parent and calculate stats for the children. An example is grouping the loan table by the client_id and finding the maximum loan amount for each client.

table by the and finding the maximum loan amount for each client. Transformations: operations done on a single table to one or more columns. An example is taking the difference between two columns in one table or taking the absolute value of a column.

New features are created in featuretools using these primitives either by themselves or stacking multiple primitives. Below is a list of some of the feature primitives in featuretools (we can also define custom primitives):

Feature Primitives

These primitives can be used by themselves or combined to create features. To make features with specified primitives we use the ft.dfs function (standing for deep feature synthesis). We pass in the entityset , the target_entity , which is the table where we want to add the features, the selected trans_primitives (transformations), and agg_primitives (aggregations):

The result is a dataframe of new features for each client (because we made clients the target_entity ). For example, we have the month each client joined which is a transformation feature primitive:

We also have a number of aggregation primitives such as the average payment amounts for each client:

Even though we specified only a few feature primitives, featuretools created many new features by combining and stacking these primitives.

The complete dataframe has 793 columns of new features!

Deep Feature Synthesis

We now have all the pieces in place to understand deep feature synthesis (dfs). In fact, we already performed dfs in the previous function call! A deep feature is simply a feature made of stacking multiple primitives and dfs is the name of process that makes these features. The depth of a deep feature is the number of primitives required to make the feature.

For example, the MEAN(payments.payment_amount) column is a deep feature with a depth of 1 because it was created using a single aggregation. A feature with a depth of two is LAST(loans(MEAN(payments.payment_amount)) This is made by stacking two aggregations: LAST (most recent) on top of MEAN. This represents the average payment size of the most recent loan for each client.

We can stack features to any depth we want, but in practice, I have never gone beyond a depth of 2. After this point, the features are difficult to interpret, but I encourage anyone interested to try “going deeper”.",https://cdn-images-1.medium.com/max/1200/1*lg3OxWVYDsJFN-snBY7M5w.jpeg,[],https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219?source=topic_page---8------2----------------,2018-06-02 15:01:18.755000+00:00

Artificial Intelligence,My Phone Wants Me to Say ‘Thank You’ – When Robots Rule The World – Medium,['Evan Selinger'],"Sincerely Thankful

Perhaps there’s something infantilizing about our phones “wanting” us to say thanks. It’s hard to draw a firm line between what you would say if only you put in the time to say it versus what you do say after predictive software fills in the blanks. Seeing suggestions is itself a suggestive situation. And so, while Google emphasizes that smart reply is intelligent enough to figure out if you’re more of a “thanks!” than a “thanks.” person, the fact remains that it’s a good bet that some variation of the word will be frequently presented to you.

If being offered a “thanks” seems familiar, it’s because the act resembles what parents do when they try to instill etiquette. Let’s imagine that Lil’ Johnny receives a gift and instinctively wants to run off and play with it. Before this happens, one of his parents admonishes, “Johnny, what do you say?” And so, robotically, Johnny responds, “Thank you.”

At the time of being coached, Lil’ Johnny doesn’t mean what he parrots back. The gesture is insincere, and Johnny offers it to avoid conflict that would further delay what he really wants to do. That’s okay, though. The hope is that, over time, Lil’ Johnny becomes Big Johnny, the type of person who can genuinely experience gratitude and doesn’t simply follow rules like an automaton. The parental admonitions made during childhood are supposed to be like a pair of moral training wheels that kids ultimately outgrow.

Software like smart reply isn’t designed to provide adults with a second round of moral education. But if we mindlessly use such tools on a regular basis so we can quickly move on to do other things—things that we actually care about—our gestures will merely take the form of gratitude while lacking the underlying substance.

True gratitude must be sincere.

To be truly grateful, you have to mean what you say — that is, you must recognize that someone did something for you that deserves to be acknowledged, and you must sincerely want to make the acknowledgment.

Graciousness is a virtue. If an adult passes off insincere gratitude as the sincere variety in situations where people reasonably expect a person’s words and beliefs to align, the person is behaving worse than Lil’ Johnny. Lil’ Johnny is trying to be compliant, not deceptive.

We also shouldn’t lose sight of the fact that people who in engage in rituals like keeping gratitude journals aim to be specific when offering their appreciation. They don’t just say “thanks” or use any of the other minimalist formulations that smart reply offers. Instead, people who are pursuing lives filled with intentionality are concrete about what they are grateful for, as well as why they’re grateful for it. They want to focus on what they have rather than despair or obsesses over what they lack.",https://cdn-images-1.medium.com/focal/1200/632/51/50/1*MpyyWHuRUnanCenqeG3sHA.jpeg,[],https://medium.com/s/when-robots-rule-the-world/my-phone-wants-me-to-say-thank-you-122cc15952a9?source=topic_page---8------3----------------,

Artificial Intelligence,"In 2018, Numbers Lie and Fictions Paint Truth – Eve Weinberg – Medium",['Eve Weinberg'],"In 2018, Numbers Lie and Fictions Paint Truth Why storytelling is our best tool in disambiguating fact from fiction

I’d love to share a few of the lecturers who touched upon this topic and forever changed my understanding of the 2018 landscape of fact, fiction, and storytelling’s role in deciphering one from the other.

This summer, I had the great privilege of attending EyeO (June 3–8 2018). Innumerable topics that encompass the intersection of Art, Technology, and Data were covered, but one common thread has left an imprint on my brain. That is: the Sisyphean 21st century task of disambiguating fact from fiction. That’s right…

PART 1: NUMBERS ARE MALLEABLE

On the first day, we discussed climate science at length. We (a very self aware room of liberal, number-crunching, data-visualization-making, coastal-living, self-ascribed nerds) attempted to break down the problems with human psychology. We looked at the facts, stats, charts, and graphs; then investigated the human power of denial, dissonance, disincentivization, and the hurdles of behavioral change. After 6 hours of discussion, ideation, and reflection, feeling a bit helpless, we ended with questions that I kept with me throughout the next 3 days of lectures:

Why don’t people believe statistics?

Are stories more powerful than numbers?

Why is denial more powerful than behavioral change?

Why do lies travel faster than truth?

…And what should we do about this?

The next day, Amanda Cox enlightened us with her talk These Lines Are The Same. She showed us that data, even in simple bar graphs, can be misinterpreted depending on the viewer’s own bias. She bravely revealed to us that in her department The Upshot at The New York Times they struggle with how to best represent datasets objectively. They experiment in meaningful and educational ways. In one example she showed data from the US unemployment report. The article allows readers to look at the chart with ‘Democratic Goggles’ and ‘Republican Goggles.’

The numbers are the same, but they can easily be bent to the will of anyone with an agenda.

Then she humorously showed us our flaws in clinging to round numbers. She drove the point home with a series of charts, one here showing the likelihood that someone in the ER gets checked for a heart attack, according to their age. As Amanda points out, “nothing radical changes from the age of 39-and-three-quarters and 40, yet here is the data:",https://cdn-images-1.medium.com/max/1200/1*bJ58aYiSmkeNYJY73AQN3w.jpeg,[],https://medium.com/@evejweinberg/in-2018-numbers-lie-and-fictions-paint-truth-ea1f5cdc9abe?source=topic_page---8------0----------------,2018-06-08 22:01:41.763000+00:00

Artificial Intelligence,The Art of Ethereal: Bringing Cellarius to Life – Genesis Thought – Medium,['Mally Anderson'],"The Art of Ethereal: Bringing Cellarius to Life

Whose future is it? Hers, and his, and theirs, and ours.

A sampling of the Cellarius faction portraits from our Ethereal Summit pop-up.

On May 11 and 12, our parent company ConsenSys hosted the third Ethereal Summit at the Knockdown Center in Queens, New York and invited Cellarius to participate, along with many other spokes from our Mesh. The creators of Ethereal wanted to build a different kind of crypto conference. Since this one explored the intersection of blockchain and the arts, we wanted to showcase that aspect of our project and spread the word in an unexpected way. We set up shop in “The Crypt,” a semi-outdoor concrete space with a distinctive patina that felt perfect for the Cellarius blockpunk aesthetic.

The Knockdown Center’s very blockpunk Crypt space. We displayed some not-yet-published art commissions.

We teamed with some artists from a group called Drawn Together NYC: Boris Rasin, Michael Scarola, Derrick Dent, and Rosalind Bunting. Drawn Together’s talented roster of artists creates design concepts, multimedia experiences, and fine art solutions for a wide range of projects and businesses, and they understood what we are going for right away.

The artists of Drawn Together NYC, from left to right: Boris Rasin, Rosalind Bunting, Derrick Dent, and Michael Scarola.

Boris, Michael, and Derrick created custom, in-universe faction portraits of Ethereal attendees. The CX Universe Guide imagines that nation-states and traditional economies will break down after the Cellarius AI seizes control of Earth’s energy sources and communication channels in 2084. In the absence of familiar institutions and technologies, people will begin to form factions according to their allegiance to Cellarius. We wanted to get attendees thinking about their own relationships to technology and start dreaming up characters to explore in the Cellarius universe. So we posed the question: which faction do you think you would be?

Boris drew background art for four different factions:

The 4 faction backgrounds, clockwise from top left: Bucolic, Elite, Ad-Hoc, Homotranscendus.

Bucolic: Bucolics are AI skeptics who reject technology and live on the peripheries of megacities, observing from the outside and farming small pockets of fertile soil. Though their process is completely manual and their harvests are meager, they feel a great satisfaction from working with their own hands, in stark contrast to the highly automated farming processes elsewhere.

Ad-Hoc: Ad-Hocs live off the Cellarius grid and make their own augmentations and tools with scrap pieces they scavenge and rework. Comprised of mostly poor and marginalized groups, they use ingenuity and what little tech they can access to get by.

Elite: The crypto-Elites of the future are pro-Cellarius and experiment with AI and aesthetic enhancements. Living in the highest levels of the megacities, Elites have access to bleeding-edge technology. They are known for having lifespans beyond the normal range of humans, and enjoy the neural boost that comes with AI coupling.

Homotranscendus: During the Reformation, it wasn’t just the home habitat that was transformed forever, but also humankind itself. The campaign was more than just re-imagining the economic machinery of the planet Earth, but also a re-imagining of the of the human brain and body. Through Cellarius-engineered advancements, the next evolution of humanity was born: Homotranscendus. Homotranscendi are fully integrated with AI and no longer depend on their human forms to express consciousness and gather information.

We even got a portrait of ConsenSys’s own Joe Lubin, who wore a custom Cellarius Ethereal t-shirt design during his keynote address (thanks, Joe!). Something tells us that Joe would be a Homotranscendus.

Future Homotranscendus Joe Lubin on Mars.

Reimagining how familiar scenarios from your own life play out in a future setting or speculating about how you might react to a superintelligent AI’s takeover of the world is a great place to start inventing your own ideas in the world of Cellarius. We hope some attendees will be inspired to start making art and stories based on their portraits!

Every single Ethereal portrait, as arranged by our designer, Octavian.

As we’ve mentioned in previous posts, we are also commissioning works from artists we admire to create the first round of content for the Cellarius universe. We decided to commission a mural that would take shape over the two days of the Summit and give attendees a behind-the-scenes look at the process of making a large-scale landscape painting. The design depicts what the Knockdown Center might look like a century from now, in 2118. Visitors to the Crypt got a chance to watch Rosalind transform the canvas from a faint pencil sketch into an impressive and detailed final product:

Rosalind’s “Knockdown Center in 2118” painting took shape over two days.

Rosalind & Boris outlined the sketch first, then Rosalind added color, starting with the future-NYC background.

We hope that the Cellarius platform will allow experienced artists and creators to get directly in touch with their fan bases and share some glimpses of their artistic process, just as Rosalind did with her live painting.

The Drawn Together NYC artists got to learn more about the possibilities of blockchain and decentralization for creatives in the process of chatting with the attendees. Michael noted, “There were so many passionate and interesting people from all over the world that came through. And they had as much fun as we did learning about and playing in the Cellarius world.” Rosalind agreed: “Probably my favorite thing I learnt about over the Summit was how Cellarius involves the creative talents of so many more artists in their company, and loved seeing some of their amazing artwork. Can’t wait to see more!”

We were also excited that the long-term goals of the Cellarius project resonated with the Drawn Together NYC artists. Derrick said, “This was probably the coolest on-site portrait job I’ve ever worked on. I had a great time learning about the Cellarius project and the potential for a sprawling, community-shaped open sci-fi world. It was even cooler to have our portrait work used as an onboarding tool for visitors. People immediately took to creating their own story within this world, and that says a lot about how exciting this could be for folks who are creatively inclined.” We couldn’t have said it better ourselves.

As Boris told us, “The more I spoke to the pop-up team and event attendees about the concept behind this project, the more it occurred to me that this is a game changer. Cellarius and the other projects from ConsenSys are sure to revolutionize our ecosystem in ways we can’t even begin to comprehend. It’s a challenge to explain exactly what this project is, because the underlying platform allows for limitless opportunities of invention, inspiration, and collaboration. Cellarius is whatever its contributors will it to be, and frankly, that’s a fundamentally crazy idea!”

That’s just the point: blockchain enthusiasts can become artists and use storytelling to push the conceptual limits of technology. Artists can use the platform to explore the possibilities of decentralization and blockchain for sharing and protecting their work. We can build it together. Cellarius is whatever our community of contributors wills it to be.",https://cdn-images-1.medium.com/max/1200/1*vL8856P7cdV84CYM_SkF0A.jpeg,[],https://medium.com/genesis-thought/the-art-of-ethereal-bringing-cellarius-to-life-ba4ae31811e7?source=topic_page---8------1----------------,2018-06-08 16:46:47.896000+00:00

Artificial Intelligence,A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what…,['Rowan Trollope'],"A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what happened?” Has gotten some fun responses.

The most popular comment being one that says “not surprised, this was never going to be a big thing”…

The first thing to point out is that people are conflating the specific of a chatbot with the generic “conversational user interface” (CUI) of which a chatbot is a specific modality. The real discussion here is about the CUI.

And the last month has certainly showed us that the CUI has made dramatic strides with Google demonstrating Duplex.

So what happened to the explosion of chatbots people predicted?

Among other things, Developers figured out just how hard it is to make a really good conversational user interface. Product folks were tricked by the trio of Alexa/Siri/Google Assistant into the belief that a conversational interface is easy.

Turns out it’s really hard, requires a ton of data and is highly domain specific.

In other words, training a CUI to be really great at getting sports scores doesn’t translate at all to a chatbot that can help you with a billing problem or ordering a pizza.

Google was careful to point out that Duplex was trained for only two very specific use cases : book a salon or a restaurant appointment.

Tim Tuttle at Mindmeld figured this out and built a company to solve it, but it still required heavy lifting and tons of data specific to the domain.

My belief is that the conversational interface is inevitable.

Technology evolution is exponential not linear. Our tendency is to project the future in a linear fashion, which causes us to overestimate what’s possible in 1 year and underestimate what’s possible in 10 years.

This makes tech progress feel gradual or slow, and then sudden and surprising.

Last week Salesforce’s chief scientist, Richard Socher, spoke publicly about the future of chatbots and asserted that in 5 years we would begin to see this start to pay off.

We are early days on the conversational interface, but as with all tech progress most folks will be disappointed until one year, 5–10 years from now when they’ll be shocked and amazed and wonder how it happened so fast.",https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico,[],https://medium.com/@rowantrollope/chatbots-were-supposed-to-be-the-next-big-thing-what-happened-5a4e416308e1?source=topic_page---8------2----------------,2018-06-08 21:06:45.446000+00:00

Artificial Intelligence,"Beethoven, Picasso, and Artificial Intelligence – Towards Data Science",['Chris Kalahiki'],"Beethoven, Picasso, and Artificial Intelligence

Introduction

When people think of the greatest artists who’ve ever lived, they probably think of names like Beethoven or Picasso. No one would ever think of a computer as a great artist. But what if one day, that was indeed the case. Could computers learn to create incredible drawings like the Mona Lisa? Perhaps one day a robot will be capable of composing the next great symphony. Some experts believe this to be the case. In fact, some of the greatest minds in artificial intelligence are diligently working to develop programs that can create drawing and music independently from humans. The use of artificial intelligence in the field of art has even been picked up by tech giants the likes of Google.

The projects that are included in this paper could have drastic implications in our everyday lives. They may also change the way we view art. They also showcase the incredible advancement that has been made in the field of artificial intelligence. Image recognition is not as far as the research goes. Nor is the ability to generate music in the styling of the great artists of our past. Although these topics will be touched upon, we will focus on several more advanced achievements such as text descriptions being turned into images and generating art and music that is totally original. Each of these projects bring something new and innovative to the table and show us exactly how the art space is a great place to further explore applications of artificial intelligence. We will be discussing problems that have been faced in these projects and how they have been overcome. The future of AI looks bright. Let’s look at what the future may hold. In doing this, we may be able to better understand the impact that artificial intelligence can have in an area that is driven by human creativity.

GAN and Its Evolved Forms

Machines must be educated. They learn from instruction. How do we lead machines away from emulating what already exists, and have them create new techniques? “No creative artist will create art today that tries to emulate the Baroque or Impressionist style, or any other traditional style, unless trying to do so ironically” [4]. This problem isn’t limited to paintings either. Music can be very structured in some respects, but is also a form of art that requires vast creativity. So how do we go about solving such a problem? The first concept we will discuss is something called GAN (Generative Adversarial Networks). GANs, although quite complex, are becoming an outdated model. If artificial intelligence in the art space is to advance, researchers and developers will have to work to find better methods to allow machines to generate art and music. Two of these such methods are presented in the form of Sketch-RNN and CAN (Creative Adversarial Networks). Each of these methods have their advantages over GANs.

First, let’s explore what exactly a GAN is. Below is a small excerpt explaining how a GAN works:

Generative Adversarial Network (GAN) has two sub networks, a generator and a discriminator. The discriminator has access to a set of images (training images). The discriminator tries to discriminate between “real” images (from the training set) and “fake” images generated by the generator. The generator tries to generate images similar to the training set without seeing the images [4].

The more images the generator creates, the closer they get to the images from the training set. The idea is that after a certain number of images are generated, the GAN will create images that are very similar to what we consider art. This is a very impressive accomplishment to say the least. But what if we take it a step further?

Many issues associated with the GAN are simply limitations on what it can do. The GAN is powerful, but can’t do quite as much as we would like. For example, the generator in the model described above will continue to create images closer and closer to the images given to the discriminator that it isn’t producing original art. Could a GAN be trained to draw alongside a user? It’s not likely. The model wouldn’t be able to turn a text-based description of an image into an actual picture either. As impressive as the GAN may be, we would all agree that it can be improved. Each of the shortcoming mentioned have actually been addressed and, to an extent, solved. Let’s look at how this is done.

Sketch-RNN is a recurrent neural network model developed by Google. The goal of Sketch-RNN is to help machines learn to create art in a manner similar to the way a human may learn. It has been used in a Google AI Experiment to be able to sketch alongside a user. While doing so, it can provide the users with suggestions and even complete the user’s sketch when they decide to take a break. Sketch-RNN is exposed to a massive number of sketches provided through a dataset of vector drawings obtained through another Google application that we will discuss later. Each of these sketches are tagged to let the program know what object is in the sketch. The data set represents the sketch as a set of pen strokes. This allows Sketch-RNN to then learn what aspects each sketch of a certain object has in common. If a user begins to draw a cat, Sketch-RNN could then show the user other common features that could be on the cat. This model could have many new creative applications. “The decoder-only model trained on various classes can assist the creative process of an artist by suggesting many possible ways of finishing a sketch” [3]. The Sketch-RNN team even believes that, given a more complex dataset, the applications could be used in an educational sense to teach users how to draw. These applications of Sketch-RNN couldn’t be nearly as easily achieved with GAN alone.

Another method used to improve upon GAN is the Creative Adversarial Network. In their paper regarding adversarial networks generating art, several researchers discuss a new way of generating art through CANs. The idea is that the CAN has two adversary networks. One, the generator, has no access to any art. It has no basis to go off of when generating images. The other network, the discriminator, is trained to classify the images generated as being art or not. When an image is generated, the discriminator gives the generator two pieces of information. The first is whether it believes the generated image comes from the same distributor as the pieces of art it was trained on, and the other being how the discriminator can fit the generated image into one of the categories of art it was taught. This technique is fantastic in that it helps the generator create images that are both emulative of past works of art in the sense that it learns what was good about those images and creative in a sense that it is taught to produce new and different artistic concepts. This is a big difference from GAN creating art that emulated the training images. Eventually, the CAN will learn how to produce only new and innovative artwork.

One final future for the vanilla GAN is StackGAN. StackGAN is a text to photo-realistic image synthesizer that uses stacked generative adversarial networks. Given a text description, the StackGAN is able to create images that are very much related to the given text. This wouldn’t be doable with a normal GAN model as it would be much too difficult to generate photo-realistic images from a text description even with a state-of-the-art training database. This is where StackGAN comes in. It breaks the problem down into 2 parts. “Low-resolution images are generated by our Stage-I GAN. On the top of our Stage-I GAN, we stack Stage-II GAN to generate realistic high-resolution images conditioned on Stage-I results and text descriptions” [7]. It is through the conditioning on Stage-I results and text descriptions that Stage-II GAN can find details that Stage-I GAN may have missed and create higher resolution images. By breaking the problem down into smaller subproblems, the StackGAN can tackle problems that aren’t possible with a regular GAN. On the next page is an image showing the difference between a regular GAN and each step of the StackGAN.

This image came from the StackGAN paper [7].

It is through advancements like these that have been made in recent years that we can continue to push the boundaries of what AI can do. We have just seen three ways to improve upon a concept that was already quite complex and innovative. Each of these advancements have a practical, everyday use. As we continue to improve on artificial intelligence techniques, we will able to do more and more in regard to, not just art and music, but a wide variety of tasks to improve our lives.

DeepBach, Magenta, and NSynth

Images aren’t the only type of art that artificial intelligence can impact though. Its effect on music is being explored as we speak. We will now explore some specific cases and their impact on both music and artificial intelligence. In doing this, we should be able to see how art can do as much for AI as AI does for it. Both fields benefit heavily from the types of projects that we are exploring here.

Could a machine ever be able to create a piece of music the likes of Johann Sebastian Bach? In a project known as DeepBach, several researchers looked to create pieces similar to Bach’s chorales. The beauty of DeepBach is that it “is able to generate coherent musical phrases and provides, for instance, varied reharmonizations of melodies without plagiarism” [6]. What this means it that DeepBach can create music with correct structure and be original. It is just in the style of Bach. It isn’t just a mashup of his works. DeepBach is creating new content. The developers of DeepBach went on to test whether their product could actually fool listeners.

As part of the experiment, over 1,250 people were asked to vote whether pieces presented to them were in fact composed by Bach. The subjects had varying degrees of musical expertise. The results showed that as the model for DeepBach’s complexity increased, the subjects had more and more trouble distinguishing the chorales of Bach from those of DeepBach. This experiment shows us that through the use of artificial intelligence and machine learning, it is quite possible to recreate original works in the likeness of the greats. But is that the limit to what artificial intelligence can do in the field of art and music?

DeepBach has achieved something that would have been unheard of in the not so distant past, but it certainly isn’t the fullest extent of what AI can do to benefit the field of music. What if we want to create new and innovative music? Maybe AI can change the way music is created all together. There must be projects that do more to push the envelope. As a matter of fact, that is exactly what the team behind Magenta look to do.

Magenta is a project being conducted by the Google Brain team and lead by Douglas Eck. Eck has been working for Google since 2010, but that isn’t where his interest in Music began. Eck helped found Brain Music and Sound, an international laboratory for brain, music, and sound research. He was also involved at the McGill Centre for Interdisciplinary Research in Music Media and Technology, and was an Associate Professor in Computer Science at the University of Montreal.

Magenta’s goal is to be “a research project to advance the state of the art in machine intelligence for music and art generation” [2]. It is an open source project that uses TensorFlow. Magenta aims to learn how to generate art and music in a way that is indeed generative. It must go past just emulating existing music. This is distinctly different that projects along the line of DeepBach which set out to emulate existing music in a way that wasn’t plagiarizing existing pieces of music. Eck and company realize that art is about capturing elements of surprise and drawing attention to certain aspects. “This leads to perhaps the biggest challenge: combining generation, attention and surprise to tell a compelling story. So much of machine-generated music and art is good in small chunks, but lacks any sort of long-term narrative arc” [2]. Such a perspective gives computer-generated music more substance, and helps it to become less of a gimmick.

One of the projects the magenta team has developed is called NSynth. The idea behind NSynth is to be able to create new sounds that have never been heard before, but beyond that, to reimagine how music synthesis can be done. Unlike ordinary synthesizers that focus on “a specific arrangement of oscillators or an algorithm for sample playback, such as FM Synthesis or Granular Synthesis” [5], NSynth generates sounds on an individual level. To do this, it uses deep neural networks. Google has even launched an experiment that allows users to really see what NSynth can do by allowing them to fuse together the sounds of existing instruments to create new hybrid sounds that have never been heard before. As an example, users can take two instruments such as a banjo and a tuba, and take parts of each of their sounds to create a totally new instrument. The experiment also allowed users to decide what percentage of each instrument would be used.

Projects like Magenta go above and beyond in showing us the full extent of what artificial intelligence can do in the way of generating music. They explore new applications of artificial intelligence that can generate new ideas independent of humans. It is the closest we have come to machine creativity. Although machines aren’t yet able to truly think and express creativity, they may soon be able to generate new and unique art and music for us to enjoy. Don’t worry though. Eck doesn’t intend to replace artists with AI. Instead he looks to provide artists with tools to create music in an entirely new way.

Deep Dream and Quick, Draw!

As we look ahead to a few more of the ways that AI has been used to accomplish new and innovative ideas in the art space, we look at projects like Quick, Draw! and Deep Dream. These projects showcase amazing progress in the space while pointing out some issues that researchers in AI will have to work out in the years to come.

Quick, Draw! is an application from the Google Creative Lab, trained to recognize quick drawings much like one would see in a game of Pictionary. The program can recognize simple objects such as cats and apples based on common aspects of the many pictures it was given before. Although the program will not get every picture right each time it is used, it continues to learn from the similarities in the picture drawn and the hundreds of pictures before it.

The science behind Quick, Draw! “uses some of the same technology that helps Google Translate recognize your handwriting. To understand handwritings or drawings, you don’t just look at what the person drew. You look at how they actually drew it” [1]. It is presented in the form of a game, with the user drawing a picture of an object chosen by the application. The program then has 20 seconds to recognize the image. In each session, the user is given a total of 6 objects. The images are then stored to the database used to train application. This happens to be the same database we saw earlier in the Sketch-RNN application. This image recognition is a very practical use of artificial intelligence in the realm of art and music. It can do a lot to benefit us in our everyday lives. But this only begins to scratch the surface of what artificial intelligence can do in this field. Although this is very impressive, we might point out that the application doesn’t truly understand what is being drawn. It is just picking up on patterns. In fact, this distinction is part of the gap between simple AI techniques and true artificial general intelligence. Machines that truly understand what the objects in images are don’t appear to be coming in the near future.

Another interesting project in the art space is Google’s Deep Dream project, which uses AI to create new and unique images. Unfortunately, the Deep Dream Generator Team wouldn’t go into too much detail about the technology itself (mostly fearing it would be too long for an email) [8]. They did, however, explain that convolutional neural networks train on the famous ImageNet dataset. Those neural networks are then used to create art-like images. Essentially, Deep Dream takes the styling of one image and uses it to modify another image. The results can be anything from a silly fusion to an artistic masterpiece. This occurs when the program identifies the unique stylings of an image provided by the user and imposes those stylings onto another image that the user provides. What can easily be observed through the use of Deep Dream is that computers aren’t yet capable of truly understanding what they are doing with respect to art. They can be fed complex algorithms to generate images, but don’t fundamentally understand what it is they are generating. For example, a computer may see a knife cutting through an onion and assume the knife and onion are one object. The lack of an ability to truly understand the contents of an image is one dilemma that researchers have yet to solve.

Perhaps as we continue to make advances in artificial intelligence we will be able to have machines that do truly understand what objects are in an image and even the emotions evoked by their music. The only way for this to be achieved is by reaching true artificial general intelligence (AGI). IN the meantime, the Deep Dream team believes that generative models will be able to create some really interesting pieces of art and digital content.

Where Do We Go From Here?

For this section, we will consider where artificial intelligence could be heading in the art space. We will take a look at how AI has impacted the space and in what ways it can continue to do so. We will also look at ways art and music could continue to impact AI in the years to come.

Although I don’t feel that we have completely mastered the ability to emulate the great artists of our past, it is just a matter of time before that problem is solved. The real task to be solved is that of creating new innovations in art and music. We need to work towards creation without emulation. It is quite clear that we are headed in that direction through projects like CAN and Magenta. Artificial general intelligence (AGI) is not the only way to complete this task. As a matter of fact, even those who dispute the possibility of AGI would have a hard time disputing the creation of unique works of art by a machine.

One path that may be taken to further improve art and music through AI is to create more advanced datasets to use in training the complex networks like Sketch-RNN and Deep Dream. AI needs to be trained to be able to perform as expected. That training has a huge impact on the results we get. Shouldn’t we want to train our machines in the most beneficial way possible. Even developing software like Sketch-RNN to use the ImageNet dataset used in Deep Dream could be huge in educating artists on techniques for drawing complex, realistic images. Complex datasets could very well be our answer to more efficient training. Until our machines can think and learn like we do, we will need to be very careful what data is used to train them.

One of the ways that art and music can help to impact AI is by providing another method of Turing Testing machines. For those who dream of creating AGI, what better way to test the machine’s ability that to create something that tests the full extent of human-like creativity? Art is the truest representation of human creativity. That is, in fact, its essence. Although art is probably not the ultimate end game for artificial intelligence, it could be one of the best ways to test the limits of what a machine can do. The day that computers can create original musical composition and create images based on descriptions given by a user could very well be the day that we stop being able to distinguish man from machine.

Conclusion

There are many benefits to using artificial intelligence in the music space. Some of them have already been seen in the projects we have discussed so far. We have seen how artificial intelligence could be used for image recognition as well as their ability to turn our words into fantastic images. We have also seen how AI can be used to synthesize new sounds that have never been heard. We know that artificial intelligence can be used to create art alongside us as well as independently from us. It can be taught to mimic music from the past and can create novel ideas. All of these accomplishments are a part of what will drive AI research into the future. Who knows? Perhaps one day we will achieve artificial general intelligence and machines will be able to understand what is really in the images it is given. Maybe our computers will be able to understand how their art makes us feel. There is a clear path showing us where to go from here. I firmly believe that it is up to us to continue this research and test the limits of what artificial intelligence can do, both in the field of art and in our everyday lives.

References",https://cdn-images-1.medium.com/max/1200/0*pIGHko-OCo1usW2c,[],https://towardsdatascience.com/beethoven-picasso-and-artificial-intelligence-caf644fc72f9?source=topic_page---8------3----------------,2018-06-08 21:34:58.310000+00:00

Artificial Intelligence,The curious case of the vanishing & exploding gradient,['Eniola Alese'],"The curious case of the vanishing & exploding gradient

Understanding why gradients explode or vanish and methods for dealing with the problem.

Photo by SpaceX on Unsplash

In the last post, we introduced a step by step walkthrough of RNN training and how to derive the gradients of the network weights using back propagation and the chain rule. But it turns out that during this training the RNN can suffer greatly from two problems: 1. Vanishing gradients or 2. Exploding gradients.

Why Gradients Explode or Vanish

Recall the many-to-many architecture for text generation shown below and in the introduction to RNN post, lets assume the input sequence to the network is a 20 word sentence: “I grew up in France,…….. I speak French fluently.

We can see from the example above that for the RNN to predict the word “French” which comes at the end of the sequence, it would need information from the word “France”, which occurs further back at the beginning of the sentence. This kind of dependence between sequence data is called long-term dependencies because the distance between the relevant information “France” and the point where it is needed to make a prediction “French” is very wide. Unfortunately, in practice as this distance becomes wider, RNNs have a hard time learning these dependencies because it encounters either a vanishing or exploding gradient problem.

These problems arise during training of a deep network when the gradients are being propagated back in time all the way to the initial layer. The gradients coming from the deeper layers have to go through continuous matrix multiplications because of the the chain rule, and as they approach the earlier layers, if they have small values (<1), they shrink exponentially until they vanish and make it impossible for the model to learn , this is the vanishing gradient problem. While on the other hand if they have large values (>1) they get larger and eventually blow up and crash the model, this is the exploding gradient problem

Dealing with Exploding Gradients",https://cdn-images-1.medium.com/max/1200/0*UCn2LUkacEHQxgZW,[],https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb?source=topic_page---8------5----------------,2018-06-05 22:33:57.437000+00:00

Artificial Intelligence,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------,2018-06-08 22:25:33.341000+00:00

Artificial Intelligence,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------#--responses,2018-06-08 22:25:33.341000+00:00

Artificial Intelligence,How to build a range slider component in React from scratch using only <div> and <span>,['Rajesh Pillai'],"How to build a range slider component in React from scratch using only <div> and <span>

In this article we will build a React range slider component step by step using only <div>. We will enable it with touch support.

What can you do with a piece of about 50 <div’s>?

Build a slider control from scratch. If this sounds interesting, then follow along.

The final output will look like the below animation.

Please do note that I have developed this component as a teaching exercise for my students of ReactJS — Beyond the Basics course on Udemy, so it may have some edge cases (which I will fix as and when encountered).

You could use an HTML5 range control and customize it. But I wanted to take a different approach and build something from scratch. And the result is what you see here.

Our slider component will be composed of the below three elements:

A slider range

The actual slider controls

The current selection range

Defining the state for our component

Let us begin by defining our state. I am only showing you the important part of the code. For the full source code, please refer to the link at the end of the article.

state = {

slots: 24,

start: 0,

end: 10,

labelMode: ""mid"", // mid, long

}

The state contains the following properties.

slots: Total slots to be drawn (in this case I am using it as a time selector, so it will have 24 hour slots)

start: The start value of the selection

end: The end value of the selection

labelMode: Currently unused. But can be used to customize the scale label rendering.

The return part of the render method

Let us now take a look at the return part of the render method. The render() method will be slowly composed of small pieces of functionality.

return (

<div>

<h2>React Slider</h2>

<div className=""example-1"">

<div className=""slider-container"">

<div className=""slider-scale"">

{scale}

</div>

<div className=""slider"">

{slider}

</div>

<div className=""slider-selected-scale"">

{currentScale}

</div>

</div>

</div>

</div>

);

For those reading on mobile, the below image may be handy, as sometimes Medium breaks the code formatting.

If you take a look at the code, there are only three important pieces:

scale variable

slider variable

currentScale variable

The three variables above will be responsible for rendering the correct parts of the overall slider.

Dissecting the render () method

Let us initialize some variables. The scale , slider and currentScale JSX will be created within the for loop defined below.

render () {

let scale = [];

let slider=[];

let currentScale = [];

let minThumb = null;

let maxThumb = null

..... // rest of the code

}

Create the JSX for the ‘scale’ variable

Creating the JSX for the scale variable is quite simple. We just loop through the slots value in the state and push a <div> to the scale array with the required CSS class for styling.

The if condition ensures that we are only printing the label for i = 0, i = 12, or i = 24 (kind of mid range). Please feel free to customize this.

for (let i = 0; i <= this.state.slots;i++) {

let label = """";



if (i == 0 || i == 12 || i == 24) {

label = i;

}



scale.push(

<div

key={i}

className=""slot-scale"">

{label}

</div>

);

Here’s the code in image format:

Create the JSX for the ‘currentScale’ variable

Let us now continue with the same for loop and create the ‘currentScale’ JSX. We are still within the same for loop, so about 24 divs will be created as per the value in this.state.slots value.

The currentScale has a class of ‘slot-scale-selected’.

let currentLabel = """";



if (i === this.state.start || i === this.state.end) {

currentLabel = i;

}



currentScale.push(

<div

key={i}

className=""slot-scale-selected"">

{currentLabel}

</div>

);

The code is pretty similar to the ‘scale’ JSX that we created.

Create the JSX for the ‘slider’ variable

Let us write a function to render the ‘slider’ jsx. The slider needs two thumbs, one for min, and one for max.

Let us first initialize the thumb variable depending on the ‘i’ value. If ‘i’ is the same as this.state.start, then we set the minThumb variable. Else if the value of ‘i’ is the same as this.state.end, then we initialize the maxThumb variable.

if (i === this.state.start) {

minThumb = <this.MinSlider />

} else if (i === this.state.end) {

maxThumb = <this.MaxSlider />

} else {

minThumb = null;

maxThumb = null;

}

Create the JSX for the ‘slider’

The important code piece here is the dragover event. This is required for the HTML drop to work correctly.

let lineClass = ""line"";



if (i >= this.state.start && i < this.state.end) {

lineClass += "" line-selected"";

}

slider.push(

<div

data-slot={i}

onDragOver={this.onDragOver}

onTouchMove = {this.onDragOver}

onTouchEnd = {this.onDrop}

onDrop = {this.onDrop}

key={i}

className=""slot"">

<div data-slot={i} className={lineClass}/>

<span className=""scale-mark""></span>

{minThumb}

{maxThumb}

</div>

);

The slider variable needs two additional pieces of features to represent the min and the max thumb on the slider.

The slider JSX has additional event handlers to deal with handling the drop event/touchend event. We will take a look at the event handlers shortly.

The ‘lineClass’ styles/renders the line on the slider, and the ‘line-selected’ class styles the currently selected range.

Let us now write the MinSlider and MaxSlider function outside the render method.

The MinSlider () function to render the min thumb

Let’s take a look at the code. The important props are the events related to drag and the draggable attribute. The draggable attribute will make this element draggable.

We are also adding the touch event handler. Refer to the link at the bottom of the article to add touch support polyfill for the HTML5 API.

MinSlider=()=> {

return (

<div data-slider=""min""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-min"">

</div>

);

}

The MaxSlider () function to render the min thumb

The MaxSlider is almost the same as the MinSlider except for the data and the className.

MaxSlider=()=> {

return (

<div data-slider=""max""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-max"">

</div>

);

}

The code image is given below for reference.

Event Handling

Let us now look at the drag/touch event handlers defined within our <div> to control the movement of the slider element.

dragover:

The dragover event is required to support the drop zone when using the HTML5 drag/drop API. The only thing we need to do here is to invoke the preventDefault on the event object.

onDragOver = (e) => {

e.preventDefault();

}

dragstart:

The dragstart enables us to store which slider is being dragged. Please note that I am not using the dataTransfer object here, but simply using an instance variable to store this.

onDragStart = (e) => {

let slider = e.target.dataset.slider;

this.sliderType = slider;

}

The value of e.target.dataset.slider is either “min” or “max,” indicating which slider is being dragged.

ondrop:

The ondrop event captures where the thumb is being dropped (on which scale).

This is the important flow in the ondrop event:

Grab the source (whether min/max thumb)

Get the slot (where the drop happens)

Validations

Update the slot (in the state)

Reset the sliderType.

onDrop = (e, target) => {

let source = this.sliderType;

let slot = Number(e.target.dataset.slot);



if (isNaN(slot)) return;



if (source === ""min"") {

if (slot >= this.state.end) return;

this.setState({

start: slot

},()=>{

console.log(this.state);

})

} else if (source === ""max"") {

if (slot <= this.state.start) return;

this.setState({

end: slot

},()=>{

console.log(this.state);

})

}

this.sliderType = null;

}

The complete source code/and demo can be seen here http://jsbin.com/remodat/edit?output

Since I am using HTML5 drag and drop features to add touch, support please add this polyfill reference to your html file.

Todos

Extract the logic to a separate Component class

Test it and and add customization.

History

21-May-2018 — First release

P.S: This component is a result of a very quick coding attempt. This will be refactored.

Promotion: If you would like to support our open source curriculum Mastering Full Stack Engineering in 12 to 20 weeks then here is a special 10$ coupon for medium readers for my upcoming live ReactJS-Beyond the basicscourse on udemy (MEDIUM_500 is the coupon code, which is already tagged in the above URL)",https://cdn-images-1.medium.com/max/1200/1*iSkeoPHBQubtAL4fV4h9xQ.png,[],https://medium.freecodecamp.org/how-to-build-a-range-slider-component-in-react-from-scratch-using-only-div-and-span-d53e1a62c4a3?source=collection_home---6------1----------------,2018-06-08 21:41:33.808000+00:00

Artificial Intelligence,The well-kept secret behind great UX: Usability Testing,['Anant Jain'],"The well-kept secret behind great UX: Usability Testing

Whether you only have a prototype or a full-fledged product, it’s a really good idea to run monthly usability tests. These make sure that whatever you’re working on is usable and the user experience is excellent.

If you’re wondering what you can do to make your usability tests more structured and organized, this guide is for you. Let’s get started!

First off, always keep the two Golden Rules of Usability Testing in mind:

Any testing is better than no testing (with no one!) A little testing earlier is better than a lot of testing later.

In this post, I will introduce you to the kind of lightweight usability testing described in Steve Krug’s books, “Don’t Make Me Think” and “Rocket Surgery Made Easy.” Steve calls this kind of testing “Do-It-Yourself Usability Testing” since it’s supposed to be cheap, easy-to-do and takes just a morning a month.

A quick intro to usability testing

The idea behind this is to:

Find a few participants

Ask them to come in and go through a list of user flows you want to test

Observe the problems they run into

Finally, make a list of issues to fix

Sounds simple enough, but very few of us actually do it. The goal of this post is to make you confident enough to run at least one usability test session this month. I ran my first usability test only a year ago, and I must say it’s actually a lot of fun!

Before we get to the test itself, here are a few things to note:

Reserve one morning a month (say the third Thursday every month) for a round of testing, debriefing, and deciding what to fix. Test with three participants each round. Recruit loosely, and grade on a curve. You don’t need to find someone who fits the exact mould of your ideal user, since most usability problems can be uncovered by testing with just about anyone. If you are part of a big company and have the budget, you can recruit via Craigslist and offer a $50 gift card for an hour of the participant’s time. If you don’t have those kind of resources, don’t worry — you can ask your friends, your existing users, or even go to a café and ask strangers for 15 minutes of their time in exchange for buying them a coffee. If you’re doing this as part of a bigger team, get as many observers as possible to observe the tests in a separate observation room. These will be the designers, engineers, project managers, executives, etc. Or, in case of side projects, it’ll be just be you later in your room!

What happens during the test?

During a usability test, you will record the participant’s voice and their computer screen, and share both these streams live with observers in another room. A typical one-hour test can be broken down into:

Welcome (4 mins): Explain how the test will work so that the participant will know what to expect. The questions (2 mins): Ask the participant a few questions about themselves. This helps put them at ease and gives you an idea of how computer-savvy they are. The Homepage tour (3 mins): Open the Home page of your site, and ask the participant to look around and tell you what they think. This will give you an idea of how easy it is to understand your home page, as well as how familiar the participant is with your domain. The tasks (35 minutes): Watch the participant perform a series of tasks you have prepared for them beforehand. If you’re building a SaaS product and you’re testing out your subscription flow, a typical task could be to find the Pricing page, compare various plans, and Subscribe to one of the plans with a provided test credit card number. Encourage the participant to think out loud as they perform the task (see the video at the end of the post for a sample test.) It’s crucial that you let them work on their own and not ask them any leading questions, or give out any clues or assistance. Probing (5 mins): Ask the participant any questions you may have about anything that happened during the test and about any issues that people in the observation room may have. Also, answer any questions that the participant may have at this point (don’t answer them during the actual tasks since you’re testing how they’ll perform with no one around.) Wrapping Up (5 mins): Thank them for their help, and give them their gift card if you promised one while recruiting them.

The debrief

During the breaks between successive tests, ask the observers to write down the top 3 usability problems that they saw. During the debriefing, focus ruthlessly on deciding to fix the most severe problems first. Here are a few other recommendations:

Keep a separate list of low-hanging fruit. These are the problems you can typically fix with one-line code changes, but have a huge impact on task completion rates. Joel Califa calls them “tiny wins”. Here’s an example:

Resist the impulse to add things — instead, try to tweak your existing design to fix the problem.

to fix the problem. Take “new feature” requests with a grain of salt. Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature.

Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature. Ignore the problems where the user goes astray for a bit but comes back on track by themselves. These are usually not worth investing much time unless you see a pattern across multiple participants.

Good design is a delicate balance, so when fixing a problem, ensure that you aren’t introducing new ones.

Remote testing and unmoderated user testing

Remote testing is very similar to an in-person usability test, except that the participant is at their home/office and you conduct the testing via screen sharing and voice call.

Unmoderated user testing is another way to test, where you specify your website, the tasks you want the users to do, and get back video recordings of people trying to accomplish those tasks. Usertesting.com is the leader in this space, but note that a single 30-minute test costs about $50.

Resources

You can download checklists, interview script, consent form, and a demo video at Steve Krug’s site here: Downloads for Rocket Surgery Made Easy.

Here’s a Usability Test demo video from Google Ventures:

I want to thank you for reading this quick guide. This was originally published as part of the UX Design course on Commonlounge, a platform that has courses with small bite-sized lessons like these on topics ranging from Project Management to Machine Learning that deliver the most value for the time you put in.

You learn by working on real-world projects and getting feedback from industry mentors. You should check it out here!",https://cdn-images-1.medium.com/max/1200/0*UWxJWKKNLXR5c1cm,[],https://medium.freecodecamp.org/the-well-kept-secret-behind-great-ux-usability-testing-b788178a64c3?source=collection_home---6------2----------------,2018-06-08 21:25:31.335000+00:00

Artificial Intelligence,An introduction to part-of-speech tagging and the Hidden Markov Model,['Divya Godayal'],"Let’s go back into the times when we had no language to communicate. The only way we had was sign language. That’s how we usually communicate with our dog at home, right? When we tell him, “We love you, Jimmy,” he responds by wagging his tail. This doesn’t mean he knows what we are actually saying. Instead, his response is simply because he understands the language of emotions and gestures more than words.

We as humans have developed an understanding of a lot of nuances of the natural language more than any animal on this planet. That is why when we say “I LOVE you, honey” vs when we say “Lets make LOVE, honey” we mean different things. Since we understand the basic difference between the two phrases, our responses are very different. It is these very intricacies in natural language understanding that we want to teach to a machine.

What this could mean is when your future robot dog hears “I love you, Jimmy”, he would know LOVE is a Verb. He would also realize that it’s an emotion that we are expressing to which he would respond in a certain way. And maybe when you are telling your partner “Lets make LOVE”, the dog would just stay out of your business 😛.

This is just an example of how teaching a robot to communicate in a language known to us can make things easier.

The primary use case being highlighted in this example is how important it is to understand the difference in the usage of the word LOVE, in different contexts.

Part-of-Speech Tagging

From a very small age, we have been made accustomed to identifying part of speech tags. For example, reading a sentence and being able to identify what words act as nouns, pronouns, verbs, adverbs, and so on. All these are referred to as the part of speech tags.

Let’s look at the Wikipedia definition for them:

In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging or word-category disambiguation, is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context — i.e., its relationship with adjacent and related words in a phrase, sentence, or paragraph. A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.

Identifying part of speech tags is much more complicated than simply mapping words to their part of speech tags. This is because POS tagging is not something that is generic. It is quite possible for a single word to have a different part of speech tag in different sentences based on different contexts. That is why it is impossible to have a generic mapping for POS tags.

As you can see, it is not possible to manually find out different part-of-speech tags for a given corpus. New types of contexts and new words keep coming up in dictionaries in various languages, and manual POS tagging is not scalable in itself. That is why we rely on machine-based POS tagging.

Before proceeding further and looking at how part-of-speech tagging is done, we should look at why POS tagging is necessary and where it can be used.

Why Part-of-Speech tagging?

Part-of-Speech tagging in itself may not be the solution to any particular NLP problem. It is however something that is done as a pre-requisite to simplify a lot of different problems. Let us consider a few applications of POS tagging in various NLP tasks.

Text to Speech Conversion

Let us look at the following sentence:

They refuse to permit us to obtain the refuse permit.

The word refuse is being used twice in this sentence and has two different meanings here. refUSE (/rəˈfyo͞oz/)is a verb meaning “deny,” while REFuse(/ˈrefˌyo͞os/) is a noun meaning “trash” (that is, they are not homophones). Thus, we need to know which word is being used in order to pronounce the text correctly. (For this reason, text-to-speech systems usually perform POS-tagging.)

Have a look at the part-of-speech tags generated for this very sentence by the NLTK package.

>>> text = word_tokenize(""They refuse to permit us to obtain the refuse permit"")

>>> nltk.pos_tag(text)

[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'),

('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]

As we can see from the results provided by the NLTK package, POS tags for both refUSE and REFuse are different. Using these two different POS tags for our text to speech converter can come up with a different set of sounds.

Similarly, let us look at yet another classical application of POS tagging: word sense disambiguation.

Word Sense Disambiguation

Let’s talk about this kid called Peter. Since his mother is a neurological scientist, she didn’t send him to school. His life was devoid of science and math.

One day she conducted an experiment, and made him sit for a math class. Even though he didn’t have any prior subject knowledge, Peter thought he aced his first test. His mother then took an example from the test and published it as below. (Kudos to her!)

Word-sense Disambiguation example — My son Peter’s first Maths problem.

Words often occur in different senses as different parts of speech. For example:

She saw a bear.

Your efforts will bear fruit.

The word bear in the above sentences has completely different senses, but more importantly one is a noun and other is a verb. Rudimentary word sense disambiguation is possible if you can tag words with their POS tags.

Word-sense disambiguation (WSD) is identifying which sense of a word (that is, which meaning) is used in a sentence, when the word has multiple meanings.

Try to think of the multiple meanings for this sentence:

Time flies like an arrow

Here are the various interpretations of the given sentence. The meaning and hence the part-of-speech might vary for each word.

Part-of-speech tags define the meaning of a sentence based on the context

As we can clearly see, there are multiple interpretations possible for the given sentence. Different interpretations yield different kinds of part of speech tags for the words.This information, if available to us, can help us find out the exact version / interpretation of the sentence and then we can proceed from there.

The above example shows us that a single sentence can have three different POS tag sequences assigned to it that are equally likely. That means that it is very important to know what specific meaning is being conveyed by the given sentence whenever it’s appearing. This is word sense disambiguation, as we are trying to find out THE sequence.

These are just two of the numerous applications where we would require POS tagging. There are other applications as well which require POS tagging, like Question Answering, Speech Recognition, Machine Translation, and so on.

Now that we have a basic knowledge of different applications of POS tagging, let us look at how we can go about actually assigning POS tags to all the words in our corpus.

Types of POS taggers

POS-tagging algorithms fall into two distinctive groups:

Rule-Based POS Taggers

Stochastic POS Taggers

E. Brill’s tagger, one of the first and most widely used English POS-taggers, employs rule-based algorithms. Let us first look at a very brief overview of what rule-based tagging is all about.

Rule-Based Tagging

Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods.

Typical rule-based approaches use contextual information to assign tags to unknown or ambiguous words. Disambiguation is done by analyzing the linguistic features of the word, its preceding word, its following word, and other aspects.

For example, if the preceding word is an article, then the word in question must be a noun. This information is coded in the form of rules.

Example of a rule:

If an ambiguous/unknown word X is preceded by a determiner and followed by a noun, tag it as an adjective.

Defining a set of rules manually is an extremely cumbersome process and is not scalable at all. So we need some automatic way of doing this.

The Brill’s tagger is a rule-based tagger that goes through the training data and finds out the set of tagging rules that best define the data and minimize POS tagging errors. The most important point to note here about Brill’s tagger is that the rules are not hand-crafted, but are instead found out using the corpus provided. The only feature engineering required is a set of rule templates that the model can use to come up with new features.

Let’s move ahead now and look at Stochastic POS tagging.

Stochastic Part-of-Speech Tagging

The term ‘stochastic tagger’ can refer to any number of different approaches to the problem of POS tagging. Any model which somehow incorporates frequency or probability may be properly labelled stochastic.

The simplest stochastic taggers disambiguate words based solely on the probability that a word occurs with a particular tag. In other words, the tag encountered most frequently in the training set with the word is the one assigned to an ambiguous instance of that word. The problem with this approach is that while it may yield a valid tag for a given word, it can also yield inadmissible sequences of tags.

An alternative to the word frequency approach is to calculate the probability of a given sequence of tags occurring. This is sometimes referred to as the n-gram approach, referring to the fact that the best tag for a given word is determined by the probability that it occurs with the n previous tags. This approach makes much more sense than the one defined before, because it considers the tags for individual words based on context.

The next level of complexity that can be introduced into a stochastic tagger combines the previous two approaches, using both tag sequence probabilities and word frequency measurements. This is known as the Hidden Markov Model (HMM).

Before proceeding with what is a Hidden Markov Model, let us first look at what is a Markov Model. That will better help understand the meaning of the term Hidden in HMMs.

Markov Model

Say that there are only three kinds of weather conditions, namely

Rainy

Sunny

Cloudy

Now, since our young friend we introduced above, Peter, is a small kid, he loves to play outside. He loves it when the weather is sunny, because all his friends come out to play in the sunny conditions.

He hates the rainy weather for obvious reasons.

Every day, his mother observe the weather in the morning (that is when he usually goes out to play) and like always, Peter comes up to her right after getting up and asks her to tell him what the weather is going to be like. Since she is a responsible parent, she want to answer that question as accurately as possible. But the only thing she has is a set of observations taken over multiple days as to how weather has been.

How does she make a prediction of the weather for today based on what the weather has been for the past N days?

Say you have a sequence. Something like this:

Sunny, Rainy, Cloudy, Cloudy, Sunny, Sunny, Sunny, Rainy

So, the weather for any give day can be in any of the three states.

Let’s say we decide to use a Markov Chain Model to solve this problem. Now using the data that we have, we can construct the following state diagram with the labelled probabilities.",https://cdn-images-1.medium.com/max/1200/1*f6e0uf5PX17pTceYU4rbCA.jpeg,[],https://medium.freecodecamp.org/an-introduction-to-part-of-speech-tagging-and-the-hidden-markov-model-953d45338f24?source=collection_home---6------3----------------,2018-06-08 19:31:14.123000+00:00

Artificial Intelligence,A deep dive into part-of-speech tagging using the Viterbi algorithm,['Sachin Malhotra'],"Welcome back, Caretaker!

In case you’ve forgotten the problem we were trying to tackle in the previous article, let us revise it for you.

So there’s this naughty kid Peter and he’s going to pester his new caretaker, you!

As a caretaker, one of the most important tasks for you is to tuck Peter in bed and make sure he is sound asleep. Once you’ve tucked him in, you want to make sure that he’s actually asleep and not up to some mischief.

You cannot, however, enter the room again, as that would surely wake Peter up. All you can hear are the noises that might come from the room.

Either the room is quiet or there is noise coming from the room. These are your states.

All you have as the caretaker are:

a set of observations, which is basically a sequence containing noise or quiet over time, and

or over time, and A state diagram provided by Peter’s mom — who happens to be a neurological scientist — that contains all the different sets of probabilities that you can use to solve the problem defined below.

The problem

Given the state diagram and a sequence of N observations over time, we need to tell the state of the baby at the current point in time. Mathematically, we have N observations over times t0, t1, t2 .... tN . We want to find out if Peter would be awake or asleep, or rather which state is more probable at time tN+1 .

In case any of this seems like Greek to you, go read the previous article to brush up on the Markov Chain Model, Hidden Markov Models, and Part of Speech Tagging.

The state diagram that Peter’s mom gave you before leaving.

In that previous article, we had briefly modeled the problem of Part of Speech tagging using the Hidden Markov Model.

The problem of Peter being asleep or not is just an example problem taken up for a better understanding of some of the core concepts involved in these two articles. At the core, the articles deal with solving the Part of Speech tagging problem using the Hidden Markov Models.

So, before moving on to the Viterbi Algorithm, let’s first look at a much more detailed explanation of how the tagging problem can be modeled using HMMs.

Generative Models and the Noisy Channel Model

A lot of problems in Natural Language Processing are solved using a supervised learning approach.

Supervised problems in machine learning are defined as follows. We assume training examples (x(1), y(1)) . . . (x(m) , y(m)) , where each example consists of an input x(i) paired with a label y(i) . We use X to refer to the set of possible inputs, and Y to refer to the set of possible labels. Our task is to learn a function f : X → Y that maps any input x to a label f(x).

In tagging problems, each x(i) would be a sequence of words X1 X2 X3 …. Xn(i) , and each y(i) would be a sequence of tags Y1 Y2 Y3 … Yn(i) (we use n(i)to refer to the length of the i’th training example). X would refer to the set of all sequences x1 . . . xn, and Y would be the set of all tag sequences y1 . . . yn. Our task would be to learn a function f : X → Y that maps sentences to tag sequences.

An intuitive approach to get an estimate for this problem is to use conditional probabilities. p(y | x) which is the probability of the output y given an input x. The parameters of the model would be estimated using the training samples. Finally, given an unknown input x we would like to find

f(x) = arg max(p(y | x)) ∀y ∊ Y

This here is the conditional model to solve this generic problem given the training data. Another approach that is mostly adopted in machine learning and natural language processing is to use a generative model.

Rather than directly estimating the conditional distribution p(y|x) , in generative models we instead model the joint probability p(x, y) over all the (x, y) pairs.

We can further decompose the joint probability into simpler values using Bayes’ rule:

p(y) is the prior probability of any input belonging to the label y.

is the prior probability of any input belonging to the label y. p(x | y) is the conditional probability of input x given the label y.

We can use this decomposition and the Bayes rule to determine the conditional probability.

Remember, we wanted to estimate the function

f(x) = arg max( p(y|x) ) ∀y ∊ Y

f(x) = arg max( p(y) * p(x | y) )

The reason we skipped the denominator here is because the probability p(x) remains the same no matter what the output label being considered. And so, from a computational perspective, it is treated as a normalization constant and is normally ignored.

Models that decompose a joint probability into terms p(y) and p(x|y) are often called noisy-channel models. Intuitively, when we see a test example x, we assume that it has been generated in two steps:

first, a label y has been chosen with probability p(y) second, the example x has been generated from the distribution p(x|y). The model p(x|y) can be interpreted as a “channel” which takes a label y as its input, and corrupts it to produce x as its output.

Generative Part of Speech Tagging Model

Let us assume a finite set of words V and a finite sequence of tags K. Then the set S will be the set of all sequence, tags pairs <x1, x2, x3 ... xn, y1, y2, y3, ..., yn> such that n > 0 ∀x ∊ V and ∀y ∊ K .

A generative tagging model is then the one where

2.

Given a generative tagging model, the function that we talked about earlier from input to output becomes

Thus for any given input sequence of words, the output is the highest probability tag sequence from the model. Having defined the generative model, we need to figure out three different things:

How exactly do we define the generative model probability p(<x1, x2, x3 ... xn, y1, y2, y3, ..., yn>) How do we estimate the parameters of the model, and How do we efficiently calculate

Let us look at how we can answer these three questions side by side, once for our example problem and then for the actual problem at hand: part of speech tagging.

Defining the Generative Model

Let us first look at how we can estimate the probability p(x1 .. xn, y1 .. yn) using the HMM.

We can have any N-gram HMM which considers events in the previous window of size N.

The formulas provided hereafter are corresponding to a Trigram Hidden Markov Model.

Trigram Hidden Markov Model

A trigram Hidden Markov Model can be defined using

A finite set of states.

A sequence of observations.

q(s|u, v)

Transition probability defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations.

defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations. e(x|s)

Emission probability defined as the probability of making an observation x given that the state was s.

Then, the generative model probability would be estimated as

As for the baby sleeping problem that we are considering, we will have only two possible states: that the baby is either awake or he is asleep. The caretaker can make only two observations over time. Either there is noise coming in from the room or the room is absolutely quiet. The sequence of observations and states can be represented as follows:

Observations and States over time for the baby sleeping problem

Coming on to the part of speech tagging problem, the states would be represented by the actual tags assigned to the words. The words would be our observations. The reason we say that the tags are our states is because in a Hidden Markov Model, the states are always hidden and all we have are the set of observations that are visible to us. Along similar lines, the sequence of states and observations for the part of speech tagging problem would be

Observations and States over time for the POS tagging problem

Estimating the model’s parameters

We will assume that we have access to some training data. The training data consists of a set of examples where each example is a sequence consisting of the observations, every observation being associated with a state. Given this data, how do we estimate the parameters of the model?

Estimating the model’s parameters is done by reading various counts off of the training corpus we have, and then computing maximum likelihood estimates:

Transition probability and Emission probability for a Trigram HMM

We already know that the first term represents transition probability and the second term represents the emission probability. Let us look at what the four different counts mean in the terms above.

c(u, v, s) represents the trigram count of states u, v and s. Meaning it represents the number of times the three states u, v and s occurred together in that order in the training corpus. c(u, v) following along similar lines as that of the trigram count, this is the bigram count of states u and v given the training corpus. c(s → x) is the number of times in the training set that the state s and observation x are paired with each other. And finally, c(s) is the prior probability of an observation being labelled as the state s.

Let us look at a sample training set for the toy problem first and see the calculations for transition and emission probabilities using the same.

The BLUE markings represent the transition probability, and RED is for emission probability calculations.

Note that since the example problem only has two distinct states and two distinct observations, and given that the training set is very small, the calculations shown below for the example problem are using a bigram HMM instead of a trigram HMM.

Peter’s mother was maintaining a record of observations and states. And thus she even provided you with a training corpus to help you get the transition and emission probabilities.

Transition Probability Example:

Training Corpus

Calculations for Awake appearing after Awake

Emission Probability Example:

Training corpus

Calculations for observing ‘Quiet’ when the state is ‘Awake’

That was quite simple, since the training set was very small. Let us look at a sample training set for our actual problem of part of speech tagging. Here we can consider a trigram HMM, and we will show the calculations accordingly.

We will use the following sentences as a corpus of training data (the notation word/TAG means word tagged with a specific part-of-speech tag).

The training set that we have is a tagged corpus of sentences. Every sentence consists of words tagged with their corresponding part of speech tags. eg:- eat/VB means that the word is “eat” and the part of speech tag in this sentence in this very context is “VB” i.e. Verb Phrase. Let us look at a sample calculation for transition probability and emission probability just like we saw for the baby sleeping problem.

Transition Probability

Let’s say we want to calculate the transition probability q(IN | VB, NN). For this, we see how many times we see a trigram (VB,NN,IN) in the training corpus in that specific order. We then divide it by the total number of times we see the bigram (VB,NN) in the corpus.

Emission Probability

Let’s say we want to find out the emission probability e(an | DT). For this, we see how many times the word “an” is tagged as “DT” in the corpus and divide it by the total number of times we see the tag “DT” in the corpus.

So if you look at these calculations, it shows that calculating the model’s parameters is not computationally expensive. That is, we don’t have to do multiple passes over the training data to calculate these parameters. All we need are a bunch of different counts, and a single pass over the training corpus should provide us with that.

Let’s move on and look at the final step that we need to look at given a generative model. That step is efficiently calculating

We will be looking at the famous Viterbi Algorithm for this calculation.

Finding the most probable sequence — Viterbi Algorithm

Finally, we are going to solve the problem of finding the most likely sequence of labels given a set of observations x1 … xn. That is, we are to find out

The probability here is expressed in terms of the transition and emission probabilities that we learned how to calculate in the previous section of the article. Just to remind you, the formula for the probability of a sequence of labels given a sequence of observations over “n” time steps is

Before looking at an optimized algorithm to solve this problem, let us first look at a simple brute force approach to this problem. Basically, we need to find out the most probable label sequence given a set of observations out of a finite set of possible sequences of labels. Let’s look at the total possible number of sequences for a small example for our example problem and also for a part of speech tagging problem.

Say we have the following set of observations for the example problem.

Noise Quiet Noise

We have two possible labels {Asleep and Awake}. Some of the possible sequence of labels for the observations above are:

Awake Awake Awake

Awake Awake Asleep

Awake Asleep Awake

Awake Asleep Asleep

In all we can have ²³ = 8 possible sequences. This might not seem like very many, but if we increase the number of observations over time, the number of sequences would increase exponentially. This is the case when we only had two possible labels. What if we have more? As is the case with part of speech tagging.

For example, consider the sentence

the dog barks

and assuming that the set of possible tags are {D, N, V}, let us look at some of the possible tag sequences:

D D D

D D N

D D V

D N D

D N N

D N V ... etc

Here, we would have ³³ = 27 possible tag sequences. And as you can see, the sentence was extremely short and the number of tags weren’t very many. In practice, we can have sentences that might be much larger than just three words. Then the number of unique labels at our disposal would also be too high to follow this enumeration approach and find the best possible tag sequence this way.

So the exponential growth in the number of sequences implies that for any reasonable length sentence, the brute force approach would not work out as it would take too much time to execute.

Instead of this brute force approach, we will see that we can find the highest probable tag sequence efficiently using a dynamic programming algorithm known as the Viterbi Algorithm.

Let us first define some terms that would be useful in defining the algorithm itself. We already know that the probability of a label sequence given a set of observations can be defined in terms of the transition probability and the emission probability. Mathematically, it is

Let us look at a truncated version of this which is

and let us call this the cost of a sequence of length k.

So the definition of “r” is simply considering the first k terms off of the definition of probability where k ∊ {1..n} and for any label sequence y1…yk.

Next we have the set S(k, u, v) which is basically the set of all label sequences of length k that end with the bigram (u, v) i.e.

Finally, we define the term π(k, u, v) which is basically the sequence with the maximum cost.

The main idea behind the Viterbi Algorithm is that we can calculate the values of the term π(k, u, v) efficiently in a recursive, memoized fashion. In order to define the algorithm recursively, let us look at the base cases for the recursion.

π(0, *, *) = 1

π(0, u, v) = 0

Since we are considering a trigram HMM, we would be considering all of the trigrams as a part of the execution of the Viterbi Algorithm.

Now, we can start the first trigram window from the first three words of the sentence but then the model would miss out on those trigrams where the first word or the first two words occurred independently. For that reason, we consider two special start symbols as * and so our sentence becomes

* * x1 x2 x3 ...... xn

And the first trigram we consider then would be (*, *, x1) and the second one would be (*, x1, x2).

Now that we have all our terms in place, we can finally look at the recursive definition of the algorithm which is basically the heart of the algorithm.",https://cdn-images-1.medium.com/max/1200/1*x-5ZBtUvlD78BOMuMnMAbg.png,[],https://medium.freecodecamp.org/a-deep-dive-into-part-of-speech-tagging-using-viterbi-algorithm-17c8de32e8bc?source=collection_home---6------4----------------,2018-06-08 19:05:31.518000+00:00

Artificial Intelligence,A quick introduction to OAuth using Passport.js – freeCodeCamp,['Arun Kumar'],"A quick introduction to OAuth using Passport.js

What is OAuth?

OAuth (Open Authorization) is an authorization protocol. A third party application can use it to access user data from a site (like Google or Twitter) without revealing their password. Sites like Quora, Medium, AirBnb and many others offer authentication using OAuth.

OAuth really makes our lives simpler by eliminating the need to remember the password of every account you create on almost any site. You just have to remember your OAuth provider’s main account password.

What is Passport.js?

Passport is a middleware which implements authentication on Express-based web applications. It provides over 500+ strategies. What are these strategies? Strategies are used to authenticate requests. Each strategy has its own npm package (such as passport-twitter, passport-google-oauth20). A strategy must be configured before usage.

Why use Passport.js?

Here are six reasons stating why you should use Passport:

It is lightweight

Easily configurable

Supports persistent sessions

Offers OAuth

Provides separate modules for each strategy

Gives you the ability to implement custom strategies

Let’s build something

To get started, we need to install passport from NPM:

npm install passport

We are going to build a simple app which grants the user access to a secret route only if they log in. I’m going to be using the passport-google-oauth20 strategy in this tutorial. Feel free to use any other strategy you prefer, but make sure to check the docs to see how it is configured.

Before continuing, we need a clientID and clientSecret. To get one, head over to https://console.developers.google.com and create a new project. Then go to Enable APIs and Services and enable the Google+ API. Select the API and click on create credentials.

Fill out the form and use the same callback URL on both the form and on your file. Make sure to read the comments on the code to figure out how everything fits together.

app.js

index.ejs

As you can see, we’ve created a /secret route, and only grant access to it if the user is authenticated. To verify whether the user is authenticated, we’ve created a middleware which checks if the request has the user object in it. Finally, to log out we used the req.logout() method provided by passport to clear the session.

Here are some resources to learn more about passport

Complete Passport.js tutorial series

Conclusion

We only saw one strategy here. There are 500+ more. I highly recommend that you skim through Passport’s official documentation and find out what else they offer. Thank you for taking your time to read this. Feel free to connect with me on LinkedIn, Twitter and GitHub. I wish you good luck!

“Do what is great, written on a computer monitor.” by Martin Shreder on Unsplash

Previous article",https://cdn-images-1.medium.com/max/1200/0*gWsdm7w5PSZNR08L,[],https://medium.freecodecamp.org/a-quick-introduction-to-oauth-using-passport-js-65ea5b621a?source=collection_home---6------5----------------,2018-06-07 22:11:44.925000+00:00

Artificial Intelligence,How to control your randomizer in R – freeCodeCamp,['Michelle Jones'],"What happens when you need a particular type of randomization?

Overview of random number generation in R

R has at least 20 random number generator functions. Each uses a specific probability distribution to create the numbers. All require you to specify the number of random numbers you want (the above image shows 200). All are available in base R — no packages required.

Common random number generator distributions are:

normal (rnorm): default mean of 0 and standard deviation of 1

binomial (rbinom): no defaults, specify the number of trials and the probability of success on each trial

uniform (runif): default minimum value of 0 and maximum value of 1

Of the three above, only the binomial random number generator creates integers.

Why create random numbers?

Problems involving random numbers are very common — there are around 50,000 questions relating to random numbers on Stack Exchange.

But why use them?

Random numbers have many practical applications. They are used in Monte Carlo simulations. They are used in cryptography. They have been used to produce CAPTCHA content. They are used in slot machines. They have also been used for more mundane tasks such as creating a random sort order for an array of ordered data.

Problems with random numbers

Common questions include “are my random numbers actually random?” and “how can I generate non-repeated random numbers?”

Note: the latter decreases randomness, because the population of possible random numbers is decreased by one each time a random number is drawn. The method is appropriate in situations such as lotteries or bingo, where each ticket or ball can only be drawn once.

This problem brings in another problem! The randomly generated, sampling without replacement numbers must be integers. No one has ticket 5.6932 or bingo ball 0.18967.

A practical example of random number problems

Let’s take the example that I have 20 female students of the same age. I have four teaching methods that I want to trial. I only want to trial one teaching method for each student. Easy math— I need five students in each group.

But how do I do this so that each student is randomly assigned?

And how do I make sure that I only have integers produced?

And how do I do all this while using randomly generated numbers without replacement? I don’t want, for example, six students in one group, and four students in another.

First, I need to create some dummy data, in R. Let’s create that list of mock female students.

FemaleStudents <- data.frame(Names=c(""Alice"", ""Betty"", ""Carol"", ""Denise"", ""Erica"", ""Frances"", ""Gina"", ""Helen"", ""Iris"", ""Julie"", ""Katherine"",

""Lisa"", ""Michelle"", ""Ngaire"", ""Olivia"", ""Penelope"", ""Rachel"", ""Sarah"", ""Trudy"", ""Uma""))

Now we have a one-dimensional dataset of our 20 students.

We know that the runif() function doesn’t create integers. Why don’t we round the random numbers so that we only get integers and use this function? We can wrap the random number in a rounding function.

Question 1: why am I using the random uniform distribution and not another one, such as the random normal distribution?

There are five types of rounding functions in R. We will use round() .

So that we get the same results, I will set a seed for the random number generation. Each time we generate random numbers, we will use the same seed. I’ve decided on 5 as the seed. If you do not set a seed, or if you set a seed other than 5, your results will be different than mine.

set.seed(5)

FemaleStudents$Group <- round(runif(20, 1, 5))

Well, that seemed to work. We have each student allocated to a group numbered between 1 and 5.

Let’s double check our allocation.

table(FemaleStudents$Group)

1 2 3 4 5

2 6 5 4 3

Darn. Only one of the five groups has the correct number of students (Group 4). Why did this happen?

We can check the numbers actually output by runif() without rounding, and letting the output print to the console. Here, the output prints because I have not assigned the function to an object (for example, to a data.frame variable).

set.seed(5)

runif(20,1,5)

[1] 1.800858 3.740874 4.667503 2.137598 1.418601 3.804230 3.111840 4.231741 4.826001 1.441812 2.093140 2.962053 2.273616 3.236691 2.050373

[16] 1.807501 2.550103 4.551479 3.219690 4.368718

As we can see, the rounding caused our problem. But if we hadn’t rounded, each student would have been assigned to a different group.

What do we do?

sample()

sample() is now one of my favourite functions in R. Let’s see how it works.

Randomly allocate to equally sized groups (counts matter)

How can we use it to randomly assign our 20 students to four equally sized groups?

What happens if we try sample() normally?

set.seed(5)

FemaleStudents$Sample <- sample(1:5, nrow(FemaleStudents), replace=TRUE)

Question 2: what output did you get when you used table(FemaleStudents$Sample) ?

We can fix this problem by creating a vector of group numbers, and then using sampling without replacement from this vector. The rep command is used to create a range of repeated values. You can use it to repeat each number in the series, as I have used here. Number 1 is repeated four times, then number 2 is repeated four times, and so forth. You can also use it to repeat a sequence of numbers, if you use this code instead: rep(1:5,4)

OurGroups <- rep(1:5, each=4)

set.seed(5)

FemaleStudents$Sample <- sample(OurGroups, nrow(FemaleStudents), replace=FALSE)

We used our vector of numbers ( OurGroups ) to allocate our students to groups. We used sampling without replacement ( replace=FALSE ) from OurGroups because we need to use each value in that vector. We need to remove each value as we use it.

And we get the result we wanted!

table(FemaleStudents$Sample)

1 2 3 4 5

4 4 4 4 4

Question 3: why did I still set a seed?

Another advantage of sample() is that it doesn’t care about type. We can repeat the allocation using a vector of strings. This can be useful if you don’t want to keep referring back to what “1” means.

OurNamedGroups <- rep(c(""Up"", ""Down"", ""Charmed"", ""Strange"", ""Top""), each=4)

set.seed(5)

FemaleStudents$Sample2 <- sample(OurNamedGroups, nrow(FemaleStudents), replace=FALSE)

table(FemaleStudents$Sample2)

Charmed Down Strange Top Up

4 4 4 4 4

Because we used the same seed, we can see that the same student allocation was performed, irrespective of whether we used numeric or character data for the assignment.

table(FemaleStudents$Sample,FemaleStudents$Sample2)



Charmed Down Strange Top Up

1 0 0 0 0 4

2 0 4 0 0 0

3 4 0 0 0 0

4 0 0 4 0 0

5 0 0 0 4 0

Randomly allocate when group size is not restricted

Sometimes we want to randomly allocate to groups, but we don’t have a vector of groups. We are still only allocating each unit (person, sheep, block of cheese) to a single group, and we use completely random allocation.

Let’s say that our school has a new, special library room. It’s been constructed to be soundproof to give students a better studying environment. The chief librarian would like to know about the experiences of students in that room. The only problem is that the room is limited in size. The chief librarian thinks that around four students is a large enough group to provide the initial feedback.

Again, we can use sample() to pick our student groups. In this case, we have “students who will test the room” and “students who won’t test the room”. I’m going to call them “Test” and “Not test”. These labels have been chosen for being 1. short and 2. easily distinguished.

Because we did sampling without replacement earlier, we didn’t specify probabilities of assignment to groups — we simply pulled out an assignment from a vector. Now we are going to use sampling with replacement. With replacement refers to the group, not to the students.

We need to sample with replacement as we only have two groups (“Test”, “Not test”) and 20 students. If we tried to sample without replacement, our code would error.

Our code is very similar:

set.seed(5)

FemaleStudents$Library <- sample(c(""Test"", ""Not test""), nrow(FemaleStudents), replace=TRUE, prob=c(4/20,16/20))

table(FemaleStudents$Library)

Not test Test

15 5

As you can see, we allocated five students to test the room, not four. This type of result is expected when dealing with small samples. However, our allocation of students is completely random. Each student had exactly the same probability of being assigned to test the room. Whether previous students were testers or not had no impact on the allocation of the next student.

Let’s walk through some of that code.

I’ve constructed a new variable in the data.frame to collect the allocation ( Library ).

Instead of dealing with numbers for group names, I’ve used the strings I mentioned earlier. Because I’ve used strings, the c() must wrap the group names ( “Test”, “Not test” ) and each group name is separated by a comma.

Replacement has been set to TRUE .

The probability of assignment to either group must be provided. This is the prob=c(4/20,16/20) part of the sample() function. Again, note how c() is used to contain the probabilities. Also of interest is that the probabilities can be expressed as fractions, rather than decimals.

Hooray for sample()

I use sample() all the time for the work I am doing. The ability to use strings, as well as to restrict numeric output to integers (and define the desired integer range), provides me with more control than trying to use one of the random number functions.

Answers

Answer 1: I used a random uniform distribution because I wanted each value to be equally probable.

Answer 2: I got this output:

1 2 3 4 5

2 7 4 2 5

Answer 3: If we don’t set a seed value, or we use a different one, the allocation of specific students will be different. For example, when the seed is 5, Alice is allocated to group 2. If the seed is 7, Alice is allocated to group 5. Replication is important when code needs to be re-run (for example, in testing).",https://cdn-images-1.medium.com/max/1200/1*aI6mpoboOmJMKqvEU593xA.png,[],https://medium.freecodecamp.org/how-to-control-your-randomizer-in-r-852ae7d8f80c?source=collection_home---6------6----------------,2018-06-07 20:10:57.677000+00:00

Artificial Intelligence,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------,2018-06-07 17:57:40.375000+00:00

Artificial Intelligence,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------#--responses,2018-06-07 17:57:40.375000+00:00

Artificial Intelligence,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------,2018-06-07 15:39:54.084000+00:00

Artificial Intelligence,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------#--responses,2018-06-07 15:39:54.084000+00:00

Artificial Intelligence,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------,2018-06-06 21:43:33.288000+00:00

Artificial Intelligence,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------#--responses,2018-06-06 21:43:33.288000+00:00

Artificial Intelligence,Follow these steps to solve any Dynamic Programming interview problem,['Nikola Otasevic'],"Follow these steps to solve any Dynamic Programming interview problem

Despite having significant experience building software products, many engineers feel jittery at the thought of going through a coding interview that focuses on algorithms. I’ve interviewed hundreds of engineers at Refdash, Google, and at startups I’ve been a part of, and some of the most common questions that make engineers uneasy are the ones that involve Dynamic Programming (DP).

Many tech companies like to ask DP questions in their interviews. While we can debate whether they’re effective in evaluating someone’s ability to perform in an engineering role, DP continues to be an area that trips engineers up on their way to finding a job that they love.

Dynamic Programming — Predictable and Preparable

One of the reasons why I personally believe that DP questions might not be the best way to test engineering ability is that they’re predictable and easy to pattern match. They allow us to filter much more for preparedness as opposed to engineering ability.

These questions typically seem pretty complex on the outside, and might give you an impression that a person who solves them is very good at algorithms. Similarly, people who may not be able to get over some mind-twisting concepts of DP might seem pretty weak in their knowledge of algorithms.

The reality is different, and the biggest factor in their performance is preparedness. So let’s make sure everyone is prepared for it. Once and for all.

7 Steps to solve a Dynamic Programming problem

In the rest of this post, I will go over a recipe that you can follow to figure out if a problem is a “DP problem”, as well as to figure out a solution to such a problem. Specifically, I will go through the following steps:

How to recognize a DP problem Identify problem variables Clearly express the recurrence relation Identify the base cases Decide if you want to implement it iteratively or recursively Add memoization Determine time complexity

Sample DP Problem

For the purpose of having an example for abstractions that I am going to make, let me introduce a sample problem. In each of the sections, I will refer to the problem, but you could also read the sections independently of the problem.

Problem statement:

In this problem, we’re on a crazy jumping ball, trying to stop, while avoiding spikes along the way.

Here are the rules:

1) You’re given a flat runway with a bunch of spikes in it. The runway is represented by a boolean array which indicates if a particular (discrete) spot is clear of spikes. It is True for clear and False for not clear.

Example array representation:

2) You’re given a starting speed S. S is a non-negative integer at any given point, and it indicates how much you will move forward with the next jump.

3) Every time you land on a spot, you can adjust your speed by up to 1 unit before the next jump.

4) You want to safely stop anywhere along the runway (does not need to be at the end of the array). You stop when your speed becomes 0. However, if you land on a spike at any point, your crazy bouncing ball bursts and it’s game over.

The output of your function should be a boolean indicating whether we can safely stop anywhere along the runway.

Step 1: How to recognize a Dynamic Programming problem

First, let’s make it clear that DP is essentially just an optimization technique. DP is a method for solving problems by breaking them down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions. The next time the same subproblem occurs, instead of recomputing its solution, you simply look up the previously computed solution. This saves computation time at the expense of a (hopefully) modest expenditure in storage space.

Recognizing that a problem can be solved using DP is the first and often the most difficult step in solving it. What you want to ask yourself is whether your problem solution can be expressed as a function of solutions to similar smaller problems.

In the case of our example problem, given a point on the runway, a speed, and the runway ahead, we could determine the spots where we could potentially jump next. Furthermore, it seems that whether we can stop from the current point with the current speed depends only on whether we could stop from the point we choose to go to next.

That is a great thing, because by moving forward, we shorten the runway ahead and make our problem smaller. We should be able to repeat this process all the way until we get to a point where it is obvious whether we can stop.

Recognizing a Dynamic Programming problem is often the most difficult step in solving it. Can the problem solution be expressed as a function of solutions to similar smaller problems?

Step 2: Identify problem variables

Now we have established that there is some recursive structure between our subproblems. Next, we need to express the problem in terms of the function parameters and see which of those parameters are changing.

Typically in interviews, you will have one or two changing parameters, but technically this could be any number. A classic example of a one-changing-parameter problem is “determine an n-th Fibonacci number”. Such an example for a two-changing-parameters problem is “Compute edit distance between strings”. If you’re not familiar with these problems, don’t worry about it.

A way to determine the number of changing parameters is to list examples of several subproblems and compare the parameters. Counting the number of changing parameters is valuable to determine the number of subproblems we have to solve. It’s also important in its own right in helping us strengthen the understanding of the recurrence relation from step 1.

In our example, the two parameters that could change for every subproblem are:

Array position (P) Speed (S)

One could say that the runway ahead is changing as well, but that would be redundant considering that the entire non-changing runway and the position (P) carry that information already.

Now, with these 2 changing parameters and other static parameters, we have the complete description of our sub-problems.

Identify the changing parameters and determine the number of subproblems.

Step 3: Clearly express the recurrence relation

This is an important step that many rush through in order to get into coding. Expressing the recurrence relation as clearly as possible will strengthen your problem understanding and make everything else significantly easier.

Once you figure out that the recurrence relation exists and you specify the problems in terms of parameters, this should come as a natural step. How do problems relate to each other? In other words, let’s assume that you have computed the subproblems. How would you compute the main problem?

Here is how we think about it in our sample problem:

Because you can adjust your speed by up to 1 before jumping to the next position, there are only 3 possible speeds, and therefore 3 spots in which we could be next.

More formally, if our speed is S, position P, we could go from (S, P) to:

(S, P + S); # if we do not change the speed (S — 1, P + S — 1); # if we change the speed by -1 (S + 1, P + S + 1); # if we change the speed by +1

If we can find a way to stop in any of the subproblems above, then we can also stop from (S, P). This is because we can transition from (S, P) to any of the above three options.

This is typically a fine level of understanding of the problem (plain English explanation), but you sometimes might want to express the relation mathematically as well. Let’s call a function that we’re trying to compute canStop. Then:

canStop(S, P) = canStop(S, P + S) || canStop(S — 1, P + S — 1) || canStop(S + 1, P + S + 1)

Woohoo, it seems like we have our recurrence relation!

Recurrence relation: Assuming you have computed the subproblems, how would you compute the main problem?

Step 4: Identify the base cases

A base case is a subproblem that doesn’t depend on any other subproblem. In order to find such subproblems, you typically want to try a few examples, see how your problem simplifies into smaller subproblems, and identify at what point it cannot be simplified further.

The reason a problem cannot be simplified further is that one of the parameters would become a value that is not possible given the constraints of the problem.

In our example problem, we have two changing parameters, S and P. Let’s think about what possible values of S and P might not be legal:

P should be within the bounds of the given runway P cannot be such that runway[P] is false because that would mean that we’re standing on a spike S cannot be negative, and a S==0 indicates that we’re done

Sometimes it can be a little challenging to convert assertions that we make about parameters into programmable base cases. This is because, in addition to listing the assertions if you want to make your code look concise and not check for unnecessary conditions, you also need to think about which of these conditions are even possible.

In our example:

P < 0 || P >= length of runway seems like the right thing to do. An alternative could be to consider making P == end of runway a base case. However, it is possible that a problem splits into a subproblem which goes beyond the end of the runway, so we really need to check for inequality. This seems pretty obvious. We can simply check if runway[P] is false. Similar to #1, we could simply check for S < 0 and S == 0. However, here we can reason that it is impossible for S to be < 0 because S decreases by at most 1, so it would have to go through S == 0 case beforehand. Therefore S == 0 is a sufficient base case for the S parameter.

Step 5: Decide if you want to implement it iteratively or recursively

The way we talked about the steps so far might lead you to think that we should implement the problem recursively. However, everything that we’ve talked about so far is completely agnostic to whether you decide to implement the problem recursively or iteratively. In both approaches, you would have to determine the recurrence relation and the base cases.

To decide whether to go iteratively or recursively, you want to carefully think about the trade-offs.

Stack overflow issues are typically a deal breaker and a reason why you would not want to have recursion in a (backend) production system. However, for the purposes of the interview, as long as you mention the trade-offs, you should typically be fine with either of the implementations. You should feel comfortable implementing both.

In our particular problem, I implemented both versions. Here is python code for that:

A recursive solution: (original code snippets can be found here)

An iterative solution: (original code snippets can be found here)

Step 6: Add memoization

Memoization is a technique that is closely associated with DP. It is used for storing the results of expensive function calls and returning the cached result when the same inputs occur again.

Why are we adding memoization to our recursion? We encounter the same subproblems which, without memoization, are computed repeatedly. Those repetitions very often lead to exponential time complexities.

In recursive solutions, adding memoization should feel straightforward. Let’s see why. Remember that memoization is just a cache of the function results. There are times when you want to deviate from this definition in order to squeeze out some minor optimizations, but treating memoization as a function result cache is the most intuitive way to implement it.

This means that you should:

Store your function result into your memory before every return statement Look up the memory for the function result before you start doing any other computation

Here is the code from above with added memoization (added lines are highlighted): (original code snippets can be found here)

In order to illustrate the effectiveness of memoization and different approaches, let’s do some quick tests. I will stress test all three methods that we have seen so far. Here is the set up:

I created a runway of length 1000 with spikes in random places (I chose to have a probability of a spike being in any given spot to be 20%) initSpeed = 30 I ran all functions 10 times and measured the average time of execution

Here are the results (in seconds):

You can see that the pure recursive approach takes about 500x more time than the iterative approach and about 1300x more time than the recursive approach with memoization. Note that this discrepancy would grow rapidly with the length of the runway. I encourage you to try running it yourself.

Step 7: Determine Time complexity

There are some simple rules that can make computing time complexity of a dynamic programming problem much easier. Here are two steps that you need to do:

Count the number of states — this will depend on the number of changing parameters in your problem Think about the work done per each state. In other words, if everything else but one state has been computed, how much work do you have to do to compute that last state?

In our example problem, the number of states is |P| * |S|, where

P is the set of all positions (|P| indicates the number of elements in P)

S is the set of all speeds

The work done per each state is O(1) in this problem because, given all other states, we simply have to look at 3 subproblems to determine the resulting state.

As we noted in the code before, |S| is limited by length of the runway (|P|), so we could say that the number of states is |P|² and because work done per each state is O(1), then the total time complexity is O(|P|²).

However, it seems that |S| can be further limited, because if it were really |P|, it is very clear that stopping would not be possible because you would have to jump the length of the entire runway on the first move.

So let’s see how we can put a tighter bound on |S|. Let’s call maximum speed S. Assume that we’re starting from position 0. How quickly could we stop if we were trying to stop as soon as possible and if we ignore potential spikes?

In the first iteration, we would have to come at least to the point (S-1), by adjusting our speed at zero by -1. From there we would at a minimum go by (S-2) steps forward, and so on.

For a runway of length L, the following has to hold:

=> (S-1) + (S-2) + (S-3) + ….+ 1 < L

=> S*(S-1) / 2 < L

=> S < sqrt(2L + 1)

That is the maximum speed that we could possibly have on a runway of a length L. If we had a speed higher than that, we could not stop even theoretically, irrespective of the position of the spikes.

That means that the total time complexity depends only on the length of the runway L in the following form:

O(L * sqrt(L)) which is better than O(L²)

O(L * sqrt(L)) is the upper bound on the time complexity

Awesome, you made it through! :)

The 7 steps that we went through should give you a framework for systematically solving any dynamic programming problem. I highly recommend practicing this approach on a few more problems to perfect your approach.

Here are some next steps that you can take

Extend the sample problem by trying to find a path to a stopping point. We solved a problem that tells you whether you can stop, but what if you wanted to also know the steps to take in order to stop eventually along the runway? How would you modify the existing implementation to do that? If you want to solidify your understanding of memoization, and understand that it is just a function result cache, you should read about decorators in Python or similar concepts in other languages. Think about how they would allow you to implement memoization in general for any function that you want to memoize. Work on more DP problems by following the steps we went through. You can always find a bunch of them online (ex. LeetCode or GeeksForGeeks). As you practice, keep in mind one thing: learn ideas, don’t learn problems. The number of ideas is significantly smaller and it’s an easier space to conquer which will also serve you much better.

When you feel like you’ve conquered these ideas, check out Refdash where you are interviewed by a senior engineer and get a detailed feedback on your coding, algorithms, and system design.",https://cdn-images-1.medium.com/max/1200/0*DpsbrfUM89M_LHKY.jpg,[],https://medium.freecodecamp.org/follow-these-steps-to-solve-any-dynamic-programming-interview-problem-cc98e508cd0e?source=collection_home---6------11----------------,2018-06-06 19:32:36.335000+00:00

Artificial Intelligence,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------,2018-06-06 17:23:02.015000+00:00

Artificial Intelligence,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------#--responses,2018-06-06 17:23:02.015000+00:00

Artificial Intelligence,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------,2018-06-06 16:42:46.938000+00:00

Artificial Intelligence,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------#--responses,2018-06-06 16:42:46.938000+00:00

Artificial Intelligence,How to process textual data using TF-IDF in Python – freeCodeCamp,[],"How to process textual data using TF-IDF in Python

Computers are good with numbers, but not that much with textual data. One of the most widely used techniques to process textual data is TF-IDF. In this article, we will learn how it works and what are its features.

From our intuition, we think that the words which appear more often should have a greater weight in textual data analysis, but that’s not always the case. Words such as “the”, “will”, and “you” — called stopwords — appear the most in a corpus of text, but are of very little significance. Instead, the words which are rare are the ones that actually help in distinguishing between the data, and carry more weight.

An introduction to TF-IDF

TF-IDF stands for “Term Frequenct — Inverse Data Frequency”. First, we will learn what this term means mathematically.

Term Frequency (tf): gives us the frequency of the word in each document in the corpus. It is the ratio of number of times the word appears in a document compared to the total number of words in that document. It increases as the number of occurrences of that word within the document increases. Each document has its own tf.

Inverse Data Frequency (idf): used to calculate the weight of rare words across all documents in the corpus. The words that occur rarely in the corpus have a high IDF score. It is given by the equation below.

Combining these two we come up with the TF-IDF score (w) for a word in a document in the corpus. It is the product of tf and idf:

Let’s take an example to get a clearer understanding.

Sentence 1 : The car is driven on the road.

Sentence 2: The truck is driven on the highway.

In this example, each sentence is a separate document.

We will now calculate the TF-IDF for the above two documents, which represent our corpus.

From the above table, we can see that TF-IDF of common words was zero, which shows they are not significant. On the other hand, the TF-IDF of “car” , “truck”, “road”, and “highway” are non-zero. These words have more significance.

Using Python to calculate TF-IDF

Lets now code TF-IDF in Python from scratch. After that, we will see how we can use sklearn to automate the process.",https://cdn-images-1.medium.com/max/1200/1*JTk6iVMiZCQCr8duiaKlHQ.png,[],https://medium.freecodecamp.org/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3?source=collection_home---6------15----------------,2018-06-06 16:07:18.115000+00:00

Artificial Intelligence,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------,2018-06-06 01:10:32.658000+00:00

Artificial Intelligence,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------#--responses,2018-06-06 01:10:32.658000+00:00

Artificial Intelligence,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------,2018-06-06 00:59:12.072000+00:00

Artificial Intelligence,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------,2018-06-06 00:20:56.870000+00:00

Artificial Intelligence,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------#--responses,2018-06-06 00:20:56.870000+00:00

Artificial Intelligence,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------,2018-06-05 20:08:25.488000+00:00

Artificial Intelligence,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------#--responses,2018-06-05 20:08:25.488000+00:00

Artificial Intelligence,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------,2018-06-05 16:44:13.144000+00:00

Artificial Intelligence,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------#--responses,2018-06-05 16:44:13.144000+00:00

Artificial Intelligence,A deeply detailed but never definitive guide to mobile development architecture,['Jose Berardo Cunha'],"A deeply detailed but never definitive guide to mobile development architecture

Native, Web, PWA, hybrid, Cross-Compiled… what is “the best” way to develop for Android and iOS platforms? What looks reasonable? And how are you supposed to choose among the options? In this article, I’ll lay it all out so you can make an informed decision.

First things first, let me provide you with a bit of context. I am an IT senior consultant, and the idea of putting together this guide was born from discussions with one of our clients about what could be the best approach for them. Yes, just for them. And we realized that we did not have a well-defined strategy, a solid and reliable foundation, to help us come up with the right answer.

And you know what? I could not find such a guide easily anywhere on the Internet, either. Although there are several articles about this topic, none of those I came across were reasonably complete. Unfortunately the majority overlook a lot of concepts or, even worse, are essentially wrong.

Now, I’d like to take a wider look. And while I’m potentially helping someone make their own decisions, I’m also asking around the community for more thoughts on the subject.

This guide has two parts:

Mobile Development Architectural Tiers (this) How to make your decision

It's also available on YouTube as a series of 10 videos and as a free course on Udemy. There, you’ll find the same written material as here, the same videos from the YouTube series, as well as quizzes to fix all the topics and a final certification.

So let’s get started.

Introduction

When it comes to mobile platforms, it's arguable that there are just two big players: Android and iOS. Other technologies like Tizen, Blackberry, or Windows Phone are either dead or have been around for a while and have no prospects of reaching any significative market share.

A quick look at this massive duopoly might make you think that developers do not have many options when creating mobile apps. This idea can't be further from the truth, though. You can quickly spot a fistful of programming languages being used out there: C/C++, Java, Kotlin, Objective-C, Swift, JavaScript, TypeScript, C#, Dart, Ruby, and I'm pretty sure I’ve missed a few more.

The same is true of mobile development frameworks. Unless you are not a developer, or have somehow been unaware of new technologies for the last 10 years, you’ve probably heard about Cordova/PhoneGap, React Native, Xamarin, Ionic, Nativescript, or Flutter, just to name a few cross-platform solutions for mobile apps.

So let’s look at all these pieces of the architecture and break things down a bit.

TL;DR

There's no clear winner. All approaches have pros and cons, and might be either the best fit or the worst fit for your next project. In this guide, I'm classifying many different solutions into various tiers according to the distance their architectures are from the native platform.

Native Apps

To start, let's go straight to the metal. Our first architectural tier is Native Apps.

Native Apps Tier — Where you develop for each specific platform (it might be even more specific when considering NDK)

This is the tier where you must be aware of the idiosyncrasies of each platform. It’s not my intention to dig into them, I just want to mention a few things in a bit of context.

You can watch this first part on Youtube.

iOS

Starting on the iOS side, just because it's simpler, there's only Apple ruling the world. Originally, developers needed to learn Objective-C, a proprietary object-oriented variation of C with some inspiration from SmallTalk (and an insanely long-named API).

In 2014, Apple announced Swift, a multi-paradigm language, which was a lot easier than its predecessor. It's still possible to deal with Objective-C legacy code, but Swift has reached high maturity levels. So, if you're planning to learn how to natively develop for iOS, Swift is definitely where you should start.

Android

On the Android side, there are a number of different manufacturers. The vast majority of them rely upon ARM processors. But generally speaking, Android apps lay on virtual machine instances (instances of ART) to help deal with potential underlying specificities (not without many amazing tricks).

That's why, originally, the language of choice was Java. It’s not only been the most popular language in the World for almost two decades (with a few position swaps with C), but it’s also notable for its Java Virtual Machine (JVM). This empowered developers to compile their code down to an intermediate bytecode that could be read and run by the JVM.

With the Android Native Development Kit (NDK), it's also possible to develop critical parts of the app directly in native code, writing in C/C++. In this case, you have to be aware of underlying platform quirks.

Kotlin is a language unveiled by JetBrains in 2011. When it first came out, despite its flexibility and conciseness, it wasn't more than yet another JVM language with more successful competitors like Scala, Clojure, or Groovy. However, after its first major release in 2016, it rapidly started to stand out from the crowd, especially after Google announced that it would be officially supported on the Android platform at Google I/O 2017.

Kotlin is becoming Google's first class language (currently Kotlin and Java — in this order — are used throughout Android's official documentation). A total Java replacement is expected even more so now that the US Federal Appeals Court has ruled on the endless lawsuit filed by Oracle accusing Google of violating Java copyrights.

Native components

Developing in this tier, you can also leverage all native APIs and, in particular, the native components. This saves your app from having to reinvent the wheel.

I've published a video demo of how to create a simple project on Xcode (iOS) and Android Studio. If you want to check it out:

Demo of iOS and Android basic projects.

Native Apps advantages

Best performance and top user engagement

Bleeding edge native features

Notably good IDEs Android Studio / Xcode

Modern high-level languages Kotlin / Swift

Very low-level approach with NDK

Native Apps disadvantages

Two codebases to maintain

Require installation (except Android Instant Apps)

Hard to analyze SEO

Very expensive to get users to download the app

Web Apps

On the other side of the spectrum, we have Web Apps. Web Apps are essentially apps run by the browser. You don't write code targeting the platform, but rather any browser running on top of it.

Web Apps Tier — clearly on top of a browser bar targeting a beast sitting in between Android and iOS.

In this tier you’ll find an insane number of contenders jumping at each other's throats. But they all use an arsenal consisting of the same weapons: HTML, CSS, and Javascript.

Web frameworks and libraries, even when leveraging CSS pre-compilers like LESS or SASS, even Javascript pre-compiled languages like TypeScript, CoffeeScript or Flow, even symbiosis like JSX or Elm, leaving alone tools like Babel used to transpile everything to Javascript with different configurable levels of conformance with ECMAScript yearly specifications (ES6 / ES7 / ES8, or if you prefer ES2015 / ES2016 / ES2017 / ES2018).

At the end of the day, they all are HTML, CSS, and JavaScript rendered and run by the browser. There's no direct access to native APIs like camera, vibration, battery status, or file system, but some of them can be achieved via Web API's:

The big issue with Web APIs is their maturity level. Many of them are not supported by some browsers. There are differences in implementations, especially across mobile browsers.

Web App advantages

Shared code between platforms and desktop browsers

Do not require previous installations, just navigate and use

Tons of frameworks and libraries to go with them

Best for SEO

Web App disadvantages

Lower performance

Hard to get a native user experience

Require an internet connection

Not available on official app stores

API not as mature and reliable as native API

Frameworks and Web components

Angular, React, and Vue are probably the most popular web frameworks as of 2018. To be precise, however, React is considered just a library due to its flexible and less opinionated nature. Angular, on the other hand, is a strongly opinionated framework. Vue lives at some point in between them.

Angular vs React vs Vue

Angular, originally called AngularJS, was presented to the world in 2010 by Google. It quickly started to shine, due to its inversion of paradigms in comparison with other libraries from that time (like jQuery, the most popular back then). Instead of directly talking to HTML elements to manipulate the UI state, with AngularJS, templates were magically updated whenever the JavaScript model was updated.

As AngularJS became more and more popular, it also grew in purpose. It turned into a complete and opinionated framework that was one of the first that took SPAs (Single Page Apps) seriously. This growth (in both aspects) was responsible for some API bloats and performance issues.

React was created by Facebook to solve their own needs on the presentation layer. It introduced many aspects that suddenly became very popular, like virtual DOM, one-way data flow (originally named Flux, especially popular through an implementation library called Redux), and a mixture of HTML and JavaScript called JSX.

Only in 2016, after long debates and unexpected big changes, Google launched version two of its popular web framework. They called it Angular, instead of AngularJS. But, as many people already called the first version “Angular” (without the ""JS"" suffix), people started calling the new version Angular 2. That turned into a naming problem, as Google also announced that it would release new major versions every 6 months.

In my opinion, that was a mammoth mistake. I've seen this before (with Struts vs Struts 2/WebWork, for example). They have a massively popular product that appears to have reached its plateau, and it has started to be more criticized than praised. If Google decides to rebuild it from the ground up, they should never, by any means, just change its major version. How will people trust that they will not repeat it every new major version release? Version two is supposed to present breaking changes, but it doesn't mean it can be totally revamped.

Angular is a spectacular web framework, and I really feel passionate about it. However, it's a completely new beast. It does not have much to do with AngularJS. Even Vue, which is another amazing framework (probably one of the most pleasant to work with, by the way) looks more similar to AngularJS from a bird's-eye view. I believe this caused a significant movement away from Angular and contributed substantially to React's popularity.

Vue is the only one of the three most popular web frameworks that is not backed by a big company. It was actually started by a former Google developer. Due to its formidable simplicity and tiny footprint, it got attention from a massive and enthusiastic community.

Although there are more complete solutions, they all work on top of the concept of web components. There's an open specification about them currently in progress in W3C, and some interesting implementations like Polymer, Stencil and X-Tag.

In the third video of the series, I don't spend too much time discussing frameworks but discuss web component libraries:

The Web Apps tier is discussed in Part 3 of the series

Mobile Apps vs Web Apps

I’m not sure if you’ve noticed, but the order of tiers I'm presenting here follows what I think is the easiest path to learn all approaches. I started from the Native Tier, the most genuinely mobile development. Then I decided to fly directly to the other extreme to present the Web Tier, which is the tier that has been available since the first smartphones.

Only now, after elaborating on a comparison between the two edges of my diagram, will I start talking about many of the cross-platform approaches to build mobile apps.

There's a long debate between Mobile Apps vs Web Apps. Everything I say about Mobile Apps is not exclusive to the Native Tier. It is also applicable to all cross-platform tiers I present later on.

The user behavior dilemma

Users spend more time on Mobile Apps (87%) than on Mobile Websites (13%)

According to a Comscore survey in 2017, a user's fidelity to a mobile app is way more relevant than it is to mobile websites. According to an aligned article on Forbes, this is usually because of convenience (for example, home screen buttons, widgets, top notifications), speed (for example, smoother interfaces, almost instant start ups), and stored settings (for example, offline content).

Mobile Websites reach more people (8.9M monthly unique visitors against 3.3M of Mobile Apps)

On the other hand, in the same Comscore data, we learn that customers can be reached more easily from mobile websites, as they are not as much tied to their few apps of preference. If you compare the most popular websites versus the most downloaded apps, it's estimated that an average of 8.9 million unique web visitors per month access the top 1000 websites. That's almost three times more than the average unique users of the top 1000 most downloaded apps.

Distribution (Web App) x Engagement (Mobile App)

That's all about distribution vs engagement. Your web app has a higher chance of being accessed, as users are more likely to try new things when navigating through their mobile browsers. But Mobile Apps have been proven to be more engaging, and catch the users attention for much longer periods.

Now that you understand the dilemma, let's have a look at Progressive Web Apps. This is an approach so tied to the Web Apps tier that I classify it as just an addendum to Web Apps. But it's a big disruptor and a serious candidate for the most prominent new and cool thing in web and mobile development.

Progressive Web Apps

Progressive Web Apps (PWAs) are a set of tools used to give Web App users the same experience they are accustomed to when they run Mobile Apps. This means that Web Apps can leverage the potentially higher levels of distribution with more decent levels of engagement.

Progressive Web Apps addendum to Web Apps tier

Google defined three main qualifications for PWAs: they must be Reliable, Fast, and Engaging.

Features called Service Workers and the App Shell are the foundation of Progressive Web Apps. They were created to promote apps’ reliability as they are now designed to work regardless of the device’s connection status. That includes offline mode, as well as poor connections. They also provide significant perceived performance boost, as apps launch using locally cached data, which eliminates delays for synchronous content downloads.

You could consider reliability an indirect vector of engagement. Users are not affected while commuting by train, for example. They can stay engaged.

The same applies to speed. According to Google:

53% of users will abandon a site if it takes longer than 3 seconds to load!

However, being exclusively reliable and fast on load doesn't necessarily guarantee high engagement. PWAs leverage mobile-related features that used to be exclusive to mobile apps, like an “Add to Home Screen” option and Push Notifications.

When it comes to to the “Add to Home Screen” feature, you might notice that Apple has had a similar feature since the very first iPhone. Some people even argue that Progressive Web Apps are Google's fancy new name for an original Apple idea.

And you really can’t completely disagree. Some ideas are actually cycling. They come, go away, and then come back with a new name and some enhancements (for instance, Service Workers), so they can finally stick around.

On the other hand, it’s hard to completely agree. Steve Jobs’ speech about Web 2.0 + AJAX and the memorable announcement of the iPhone back in WWDC 2007 are not convincing enough to call him as the father, or even the prophet, of PWAs.

To be fair, the Add to Home Screen capability on iPhone has been nothing more than a subtle, almost hidden, feature to generate desktop icons that just start up Web Apps in fullscreen mode. It has all the burden of HTTP request-response cycles and no clear path around caches.

PWAs start from the right point. They explore how previous installations of Web Apps aren’t necessary without losing the client-side bootstrap of Mobile Apps. This means that everything a user needs for their first interaction following startup might be locally cached (read: App Shell) and kept available as soon as they hit “Add to Home Screen.”

Moving onto another well-known characteristic of PWAs, let’s talk about the super engaging (or re-engaging) feature of the Mobile Apps world: Push Notifications. They are alert-style messages that appear on the top notification bar / area, as well as on lock screens. They have the power of pulling users back to your app once they receive the notification.

To reinforce the appeal of PWAs, Google has been pulling all modern Web APIs under the PWA umbrella. So expect to see things like Payment Requests, Credential Management, WebVR, Sensors, WebAssembly, and WebRTC in the context of Progressive Web Apps. But these feature are not necessarily tied to PWAs, and some were even born before the term PWA was coined.

PWA and Apple

Apple, on the other hand, announced their first solid milestones towards PWAs only in March 2018. Although there are still some limitations, the progress is appreciable. Some of the limitations might be related to the fact that Safari has fallen behind its competitors. Others could be attributed to Apple's philosophy of tight control.

Still, Apple has a more profitable App Store than Google. Apple's asserts that more criteria on app publications brings more overall reliability, and PWAs are bound to hurt the App Store's revenue. This suggests that some limitations that seem to be intentionally imposed (like 50Mb of PWA maximum cache size) will cost more to be revoked.

Unfortunately PWAs are not perfect

Web solutions and, on different levels, all cross-platform solutions struggle to attain the excellence and comprehensiveness of Native Apps. Every new feature, and every detail particular to Android or iOS makes that native feel harder and harder to access as you distance your app from the native tier.

Overall, PWAs fix some issues in the Web Apps tier. But there are other issues that can’t be fixed by a solution working on top of a browser.

What PWAs fix

More “native” experience

Faster load times

Do not require an internet connection

Force web developers to be aware of situations where there’s no connection as well as a bad connection

Incorporate features from Mobile Apps like Push Notifications, Geolocation, or Speech Recognition

What they don’t

Inherent slowness

Not available on app stores (just yet)

Still not fully supported by all browsers

Still lack mobile features like NFC, Ambient Light, Geofencing

Also lack support for peculiarities of Android or iOS like PiP, smart app banners, launch screen widgets, and 3D touch

In the video below, I do a brief overview of PWAs.

Progressive Web Apps are introduced in the Part 4 of the series

Hybrid Apps

At this level, we begin to dive into the Mobile App world. We’ll start from the most distant tier: Hybrid Apps.

The term Hybrid is also commonly applied to all cross-platform solutions. Here, however, I’m restricting it to Apps that work inside mobile components, called WebViews.

The Hybrid Apps tier. Below the browser's line but on top of WebViews

In the demos in the second video, my purpose for adding WebView as the Hello World example was to make clear that there's a native component for each platform that is able to perform like an actual browser.

Cordova/PhoneGap

Solutions like Cordova/PhoneGap close the gap (sorry for the uninspired pun) between Web and Mobile Apps. They provide tools to package developer's HTML, JavaScript, and CSS code (as well as any extra assets like images or videos) and transform them into Mobile Apps (yes, real Android or iOS apps). These apps have their WebView exclusively to interpret and run the original web code, starting with the “index.html” file in the app’s main folder (normally called “www”). They also bridge the JavaScript code to native APIs through plugins which are partially implemented in JavaScript and partially in a native language.

So, let's make things clearer. Hybrid Apps are able to access native APIs (instead of Web APIs), but they are enclosed by the WebView. A button with Cordova must be an HTML button rendered by a WebView instead of a mobile native button.

This is the magical tier that allows companies to port their Web Apps to Mobile Apps to be shipped by app stores. So any web framework is allowed here.

Ionic

Frameworks like Ionic wrap Cordova into their own solutions. With Ionic, you don't need to use Cordova’s command line interface (CLI), because all of its commands are wrapped by the Ionic CLI.

Recently, the Ionic team decided to take the reins of the entire stack of Hybrid Apps. So they launched a proposed replacement for Cordova called Capacitor. Capacitor has support for Cordova plugins, and can also be used by a non-Ionic project.

You can watch me going through a Cordova Hello World sample in the fifth video of the series:

Hybrid Apps are in Part 5 of the series.

Hybrid Apps advantages

They are essentially web apps that are shippable to official app stores

Can be used along with any JavaScript framework / library

The code is still highly shareable across platforms

Access to native features (for instance, camera, accelerometer, contact list)

Hybrid Apps disadvantages

Struggle with performance issues and memory consumption, as web views are responsible for rendering everything on screen

Have to mimic all native UI components on top of a single web view

Harder to be accepted and published on App Store

Usually take longer to have native features available for these environments

Web Native

Web Native is a relatively new and often misunderstood tier. That's where Web Apps meet native components. Although Appcelerator (Axway) Titanium has been around a long time, there are some relatively new competitors that justify making this a completely separate category of mobile apps.

Web Native Apps don't need WebView as they talk directly to other native components

As you can see above, there's no web view to render and run your application. So, how is your JavaScript executed? Is it compiled? Well, if you consider transpilation (compilation from one language to another — for example TypeScript to JavaScript), bundling, minification, mangling, and obfuscation all together as a compilation, yes JavaScript is compiled.

But the problem is, this doesn't make your JavaScript something directly understood by Android or iOS operational systems. And, in theory, there's no native component that only serves as a JavaScript engine without the bloat of the HTML layout engine.

The strategy is to ship JavaScript engines (normally V8 for Android and JavaScriptCore for iOS) along with your code. Although they have small footprints and are very fast, they are something external that must be provided by your app.

On the other hand, this approach tends to have better UI performance, as all the components are the same (or are based on the same thing for React Native, for example) as the ones used by Native Apps.

Web Native Apps advantages

Reach both platforms with one single codebase

Roughly the same performance as native apps, as they also deal with native UI components

Tweaks are necessary, but the code is still shareable with web development

Web Native Apps disadvantages

Even with one single codebase, the developer must be aware of native components

Steeper learning curve than Hybrid / Web Apps for web developers, especially when it comes to layout

React Native

In part 6 of the series, I do a quick Hello World in React Native. This shows, on Android Studio's Layout Inspector, what components were rendered in the emulator. I compare with the previous examples, ensuring that there's no WebView whatsoever.

Web Native Apps presentation with focus on React Native in Part 6 of the series.

Nativescript

Another amazing framework that I've been particularly interested in over the last two years (I have a course on Udemy about it — in Portuguese), is Nativescript. It’s similar to React Native but is not tied to the React world (there's an unofficial integration, Nativescript-Preact, though).

With Nativescript, you can develop using vanilla JavaScript, TypeScript, Angular and, more recently, Vue. Of course you can use other frameworks, but those are the ones officially supported. It’s fairly well documented too, by the way.

Nativescript has tools like Nativescript Sidekick and Nativescript Playground, as well as project structures based on templates that can be provided by the community. This should help you in project creation, giving you the ability to start, deploy, test, and run on simulators on the cloud and iPhone devices even when you are not developing using a Mac.

In the seventh part of the series, I do a Hello World using Sidekick along with another project started from the CLI and a WhatsApp clone template I created for learning purposes.

Web Native Apps with Nativescript in Part 7 of the series.

It's important to have a look at the Layout Inspector when your app is running on an Android emulator. With Nativescript, it shows the native components (again, no WebView), and direct instances of common Android classes like TextView. This is different than React Native, which has its own classes to wrap the native components.

That's probably why Nativescript claims that there’s no delay between when a new feature is available on iOS and Android and when you can use it in a Nativescript project. For example, they posted on their blog an AR project on the same day iOS 11 was officially released with the new ARKit API.

Weex

Another framework worth mentioning in this category is Weex. It's a project developed by Alibaba, and is currently incubated at Apache Sofware Foundation (ASF). It uses common HTML tags like <div> and CSS commands inside <style> tags to call native components instead. From their documentation:

Although components in Weex look like HTML tags, you are not able to use all of them. Instead, you can only use the built-in components and your custom components.

Cross Compiled

At this level, it’s time to jump off the Web bandwagon. This is the closest tier to native development, but has the advantage of using one single codebase to target Android and iOS.

Development tiers now complete with Cross Compiled Apps

RubyMotion and Xamarin

There are solutions like RubyMotion. This is a way to write mobile apps using Ruby and compile directly to the targeted platform (as it was created using any ""native"" language).

Another option is Xamarin, where you write in C#, compile to an intermediate bytecode, and deploy your app along with an instance of the Mono common language runtime. This approach has the same drawback as Web Native (where V8 and JavaScriptCore are delivered by your app), but can also rely upon JIT compilations to optimize the app at runtime.

Flutter

Last but not least, I'd like to bring up Flutter. It’s Google's newest cool initiative for mobile development. It fits in the Cross Compiled tier because you write apps using the Dart language and compile them down to the native platform.

Flutter has innovated in some aspects. Probably the most outstanding one is the fact that it provides its own set of components.

What? Own set of components?

Yes, Flutter provides a number of different components so you can completely skip the ones from the platform. It has generic components as well as Material Design components for Android, and Cupertino components for iOS.

Rather than .Net virtual machine (as Xamarin) or JavaScript engines (as Web Native frameworks), with Flutter your app will deliver the components you decide to use.

Are they native components?

Yes, they are. Your app is native, too. Everything is compiled to the native architecture. However, bear in mind they are not the pre-existing native components.

What's the point of that?

Well, in my opinion, this solution is clever and audacious. I've been waiting to talk about advantages and disadvantages, but as it's just one particular technology, let me address them now.

One of the biggest challenges for Web Native and Cross Compiled solutions (remember, above Native but below the WebView in our tiers) is how to deal with native components. For example, an important problem is how to lay them out. That's because they were not created to be used by those external resources. Also, they were not created with a counterpart in the other platform in mind. The Android NavBar doesn't work like iOS UINavBar, for example.

With Flutter, components are created with cross-platform always in mind. So let's have a look at the pros and cons of the Cross Compiled Apps tier:

Cross Compiled Apps advantages

Reach both platforms with one single language

Roughly the same performance as native apps, as they also deal with native UI components

Cross Compiled Apps disadvantages

Slightly delayed support for the latest platform updates

Code not shareable with web development

Even with one single codebase, the developer must be aware of native components

PS: With Flutter, you’ll provide your own set of widgets along with your app's code

Mobile Apps runtime architecture",https://cdn-images-1.medium.com/max/1200/1*kHze88HBCkKt8Tw4MESC9Q.png,[],https://medium.freecodecamp.org/a-deeply-detailed-but-never-definitive-guide-to-mobile-development-architecture-6b01ce3b1528?source=collection_home---6------21----------------,2018-06-05 16:34:24.241000+00:00

Artificial Intelligence,A coffee-break introduction to time complexity of algorithms,['Vicky Lai'],"A coffee-break introduction to time complexity of algorithms

Just like writing your very first for loop, understanding time complexity is an integral milestone to learning how to write efficient complex programs. Think of it as having a superpower that allows you to know exactly what type of program might be the most efficient in a particular situation — before even running a single line of code.

The fundamental concepts of complexity analysis are well worth studying. You’ll be able to better understand how the code you’re writing will interact with the program’s input, and as a result, you’ll spend a lot less wasted time writing slow and problematic code.

It won’t take long to go over all you need to know in order to start writing more efficient programs — in fact, we can do it in about fifteen minutes. You can go grab a coffee right now (or tea, if that’s your thing) and I’ll take you through it before your coffee break is over. Go ahead, I’ll wait.

All set? Let’s do it!

What is “time complexity” anyway?

The time complexity of an algorithm is an approximation of how long that algorithm will take to process some input. It describes the efficiency of the algorithm by the magnitude of its operations. This is different than the number of times an operation repeats. I’ll expand on that later. Generally, the fewer operations the algorithm has, the faster it will be.

We write about time complexity using Big O notation, which looks something like O(n). There’s rather a lot of math involved in its formal definition, but informally we can say that Big O notation gives us our algorithm’s approximate run time in the worst case, or in other words, its upper bound. It is inherently relative and comparative.

We’re describing the algorithm’s efficiency relative to the increasing size of its input data, n. If the input is a string, then n is the length of the string. If it’s a list of integers, n is the length of the list.

It’s easiest to picture what Big O notation represents with a graph:

Lines made with the very excellent Desmos graph calculator. You can play with this graph here.

Here are the main important points to remember as you read the rest of this article:

Time complexity is an approximation

An algorithm’s time complexity approximates its worst case run time

Determining time complexity

There are different classes of complexity that we can use to quickly understand an algorithm. I’ll illustrate some of these classes using nested loops and other examples.

Polynomial time complexity

A polynomial, from the Greek poly meaning “many,” and Latin nomen meaning “name,” describes an expression comprised of constant variables, and addition, multiplication, and exponentiation to a non-negative integer power. That’s a super math-y way to say that it contains variables usually denoted by letters, and symbols that look like these:

The below classes describe polynomial algorithms. Some have food examples.

Constant

A constant time algorithm doesn’t change its running time in response to the input data. No matter the size of the data it receives, the algorithm takes the same amount of time to run. We denote this as a time complexity of O(1).

Here’s one example of a constant algorithm that takes the first item in a slice.

func takeCupcake(cupcakes []int) int {

return cupcakes[0]

}

Choice of flavours are: vanilla cupcake, strawberry cupcake, mint chocolate cupcake, lemon cupcake, and “wibbly wobbly, timey wimey” cupcake.

With this contant-time algorithm, no matter how many cupcakes are on offer, you just get the first one. Oh well. Flavours are overrated anyway.

Linear

The running duration of a linear algorithm is constant. It will process the input in n number of operations. This is often the best possible (most efficient) case for time complexity where all the data must be examined.

Here’s an example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

}

Here’s another example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// double dip chip

}

}

It doesn’t matter whether the code inside the loop executes once, twice, or any number of times. Both these loops process the input by a constant factor of n, and thus can be described as linear.

Don’t double dip in a shared bowl.

Quadratic

Now here’s an example of code with time complexity of O(n2):

func pizzaDelivery(pizzas int) {

for pizza := 0; pizza <= pizzas; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

Because there are two nested loops, or nested linear operations, the algorithm process the input n2times.

Cubic

Extending on the previous example, this code with three nested loops has time complexity of O(n3):

func pizzaDelivery(boxesDelivered int) {

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

}

Seriously though, who delivers unsliced pizza??

Logarithmic

A logarithmic algorithm is one that reduces the size of the input at every step. We denote this time complexity as O(log n), where log, the logarithm function, is this shape:

One example of this is a binary search algorithm that finds the position of an element within a sorted array. Here’s how it would work, assuming we’re trying to find the element x:

If x matches the middle element m of the array, return the position of m. If x doesn’t match m, see if m is larger or smaller than x. If larger, discard all array items greater than m. If smaller, discard all array items smaller than m. Continue by repeating steps 1 and 2 on the remaining array until x is found.

I find the clearest analogy for understanding binary search is imagining the process of locating a book in a bookstore aisle. If the books are organized by author’s last name and you want to find “Terry Pratchett,” you know you need to look for the “P” section.

You can approach the shelf at any point along the aisle and look at the author’s last name there. If you’re looking at a book by Neil Gaiman, you know you can ignore all the rest of the books to your left, since no letters that come before “G” in the alphabet happen to be “P.” You would then move down the aisle to the right any amount, and repeat this process until you’ve found the Terry Pratchett section, which should be rather sizable if you’re at any decent bookstore, because wow did he write a lot of books.

Quasilinear

Often seen with sorting algorithms, the time complexity O(n log n) can describe a data structure where each operation takes O(log n) time. One example of this is quick sort, a divide-and-conquer algorithm.

Quick sort works by dividing up an unsorted array into smaller chunks that are easier to process. It sorts the sub-arrays, and thus the whole array. Think about it like trying to put a deck of cards in order. It’s faster if you split up the cards and get five friends to help you.

Non-polynomial time complexity

The below classes of algorithms are non-polynomial.

Factorial

An algorithm with time complexity O(n!) often iterates through all permutations of the input elements. One common example is a brute-force search, seen in the traveling salesman problem. It tries to find the least costly path between a number of points by enumerating all possible permutations and finding the ones with the lowest cost.

Exponential

An exponential algorithm often also iterates through all subsets of the input elements. It is denoted O(2n) and is often seen in brute-force algorithms. It is similar to factorial time except in its rate of growth, which, as you may not be surprised to hear, is exponential. The larger the data set, the more steep the curve becomes.

In cryptography, a brute-force attack may systematically check all possible elements of a password by iterating through subsets. Using an exponential algorithm to do this, it becomes incredibly resource-expensive to brute-force crack a long password versus a shorter one. This is one reason that a long password is considered more secure than a shorter one.

There are further time complexity classes less commonly seen that I won’t cover here, but you can read about these and find examples in this handy table.

Recursion time complexity

As I described in my article explaining recursion using apple pie, a recursive function calls itself under specified conditions. Its time complexity depends on how many times the function is called and the time complexity of a single function call. In other words, it’s the product of the number of times the function runs and a single execution’s time complexity.

Here’s a recursive function that eats pies until no pies are left:

func eatPies(pies int) int {

if pies == 0 {

return pies

}

return eatPies(pies - 1)

}

The time complexity of a single execution is constant. No matter how many pies are input, the program will do the same thing: check to see if the input is 0. If so, return, and if not, call itself with one fewer pie.

The initial number of pies could be any number, and we need to process all of them, so we can describe the input as n. Thus, the time complexity of this recursive function is the product O(n).

This function’s return value is zero, plus some indigestion.

Worst case time complexity

So far, we’ve talked about the time complexity of a few nested loops and some code examples. Most algorithms, however, are built from many combinations of these. How do we determine the time complexity of an algorithm containing many of these elements strung together?

Easy. We can describe the total time complexity of the algorithm by finding the largest complexity among all of its parts. This is because the slowest part of the code is the bottleneck, and time complexity is concerned with describing the worst case for the algorithm’s run time.

Say we have a program for an office party. If our program looks like this:

package main



import ""fmt""



func takeCupcake(cupcakes []int) int {

fmt.Println(""Have cupcake number"",cupcakes[0])

return cupcakes[0]

}



func eatChips(bowlOfChips int) {

fmt.Println(""Have some chips!"")

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

fmt.Println(""No more chips."")

}



func pizzaDelivery(boxesDelivered int) {

fmt.Println(""Pizza is here!"")

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

fmt.Println(""Pizza is gone."")

}



func eatPies(pies int) int {

if pies == 0 {

fmt.Println(""Someone ate all the pies!"")

return pies

}

fmt.Println(""Eating pie..."")

return eatPies(pies - 1)

}



func main() {

takeCupcake([]int{1, 2, 3})

eatChips(23)

pizzaDelivery(3)

eatPies(3)

fmt.Println(""Food gone. Back to work!"")

}

We can describe the time complexity of all the code by the complexity of its most complex part. This program is made up of functions we’ve already seen, with the following time complexity classes:

To describe the time complexity of the entire office party program, we choose the worst case. This program would have the time complexity O(n3).

Here’s the office party soundtrack, just for fun.

Have cupcake number 1

Have some chips!

No more chips.

Pizza is here!

Pizza is gone.

Eating pie...

Eating pie...

Eating pie...

Someone ate all the pies!

Food gone. Back to work!

P vs NP, NP-complete, and NP-hard

You may come across these terms in your explorations of time complexity. Informally, P (for Polynomial time), is a class of problems that is quick to solve. NP, for Nondeterministic Polynomial time, is a class of problems where the answer can be quickly verified in polynomial time. NP encompasses P, but also another class of problems called NP-complete, for which no fast solution is known. Outside of NP, but still including NP-complete, is yet another class called NP-hard, which includes problems that no one has been able to verifiably solve with polynomial algorithms.

P vs NP Euler diagram, by Behnam Esfahbod, CC BY-SA 3.0

P versus NP is an unsolved, open question in computer science.

Anyway, you don’t generally need to know about NP and NP-hard problems to begin taking advantage of understanding time complexity. They’re a whole other Pandora’s box.

Approximate the efficiency of an algorithm before you write the code

So far, we’ve identified some different time complexity classes and how we might determine which one an algorithm falls into. So how does this help us before we’ve written any code to evaluate?

By combining a little knowledge of time complexity with an awareness of the size of our input data, we can take a guess at an efficient algorithm for processing our data within a given time constraint. We can base our estimation on the fact that a modern computer can perform some hundreds of millions of operations in a second. The following table from the Competitive Programmer’s Handbook offers some estimates on required time complexity to process the respective input size in a time limit of one second.

Keep in mind that time complexity is an approximation, and not a guarantee. We can save a lot of time and effort by immediately ruling out algorithm designs that are unlikely to suit our constraints, but we must also consider that Big O notation doesn’t account for constant factors. Here’s some code to illustrate.

The following two algorithms both have O(n) time complexity.

func makeCoffee(scoops int) {

for scoop := 0; scoop <= scoops; scoop++ {

// add instant coffee

}

}

func makeStrongCoffee(scoops int) {

for scoop := 0; scoop <= 3*scoops; scoop++ {

// add instant coffee

}

}

The first function makes a cup of coffee with the number of scoops we ask for. The second function also makes a cup of coffee, but it triples the number of scoops we ask for. To see an illustrative example, let’s ask both these functions for a cup of coffee with a million scoops.

Here’s the output of the Go test:

Benchmark_makeCoffee-4 1000000000 0.29 ns/op

Benchmark_makeStrongCoffee-4 1000000000 0.86 ns/op

Our first function, makeCoffee , completed in an average 0.29 nanoseconds. Our second function, makeStrongCoffee , completed in an average of 0.86 nanoseconds. While those may both seem like pretty small numbers, consider that the stronger coffee took nearly three times longer to make. This should make sense intuitively, since we asked it to triple the scoops. Big O notation alone wouldn’t tell you this, since the constant factor of the tripled scoops isn’t accounted for.

Improve time complexity of existing code

Becoming familiar with time complexity gives us the opportunity to write code, or refactor code, to be more efficient. To illustrate, I’ll give a concrete example of one way we can refactor a bit of code to improve its time complexity.

Let’s say a bunch of people at the office want some pie. Some people want pie more than others. The amount that everyone wants some pie is represented by an int > 0:

diners := []int{2, 88, 87, 16, 42, 10, 34, 1, 43, 56}

Unfortunately, we’re bootstrapped and there are only three forks to go around. Since we’re a cooperative bunch, the three people who want pie the most will receive the forks to eat it with. Even though they’ve all agreed on this, no one seems to want to sort themselves out and line up in an orderly fashion, so we’ll have to make do with everybody jumbled about.

Without sorting the list of diners, return the three largest integers in the slice.

Here’s a function that solves this problem and has O(n2) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// loop over three forks

for i := 1; i <= 3; i++ {

// variables to keep track of the highest integer and where it is

var max, maxIndex int

// loop over the diners slice

for n := range diners {

// if this integer is higher than max, update max and maxIndex

if diners[n] > max {

max = diners[n]

maxIndex = n

}

}

// remove the highest integer from the diners slice for the next loop

diners = append(diners[:maxIndex], diners[maxIndex+1:]...)

// keep track of who gets a fork

withForks = append(withForks, max)

}

return withForks

}

This program works, and eventually returns diners [88 87 56] . Everyone gets a little impatient while it’s running though, since it takes rather a long time (about 120 nanoseconds) just to hand out three forks, and the pie’s getting cold. How could we improve it?

By thinking about our approach in a slightly different way, we can refactor this program to have O(n) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// create variables for each fork

var first, second, third int

// loop over the diners

for i := range diners {

// assign the forks

if diners[i] > first {

third = second

second = first

first = diners[i]

} else if diners[i] > second {

third = second

second = diners[i]

} else if diners[i] > third {

third = diners[i]

}

}

// list the final result of who gets a fork

withForks = append(withForks, first, second, third)

return withForks

}

Here’s how the new program works:

Initially, diner 2 (the first in the list) is assigned the first fork. The other forks remain unassigned.

Then, diner 88 is assigned the first fork instead. Diner 2 gets the second one.

Diner 87 isn’t greater than first which is currently 88 , but it is greater than 2 who has the second fork. So, the second fork goes to 87 . Diner 2 gets the third fork.

Continuing in this violent and rapid fork exchange, diner 16 is then assigned the third fork instead of 2 , and so on.

We can add a print statement in the loop to see how the fork assignments play out:

0 0 0

2 0 0

88 2 0

88 87 2

88 87 16

88 87 42

88 87 42

88 87 42

88 87 42

88 87 43

[88 87 56]

This program is much faster, and the whole epic struggle for fork domination is over in 47 nanoseconds.

As you can see, with a little change in perspective and some refactoring, we’ve made this simple bit of code faster and more efficient.

Well, it looks like our fifteen minute coffee break is up! I hope I’ve given you a comprehensive introduction to calculating time complexity. Time to get back to work, hopefully applying your new knowledge to write more effective code! Or maybe just sound smart at your next office party. :)

Sources

“If I have seen further it is by standing on the shoulders of Giants.” –Isaac Newton, 1675",https://cdn-images-1.medium.com/max/1200/1*_YsSsyFQ5sgS8F0kiZ1USA.png,[],https://medium.freecodecamp.org/a-coffee-break-introduction-to-time-complexity-of-algorithms-64df7dd8338e?source=collection_home---6------24----------------,2018-06-04 23:44:40.970000+00:00

Machine Learning,Media – Medium,"['Ev Williams', 'Dave Pell', 'Hossein Derakhshan', 'Dawn Ennis', 'Don Day', 'Jessie Singer', 'Tim Grierson', 'Melissa Chu']","Media Where the newsroom is the news.

Follow Following",https://cdn-images-1.medium.com/max/1200/1*wLhNmBWoSMvG0kyRGjDIqw@2x.jpeg,[],https://medium.com/topic/media,

Machine Learning,The Inspiration of Anthony Bourdain – Member Feature Stories – Medium,['Christine Byrne'],"One of my first great food memories comes from a trip my family took to Normandy when I was six years old. We hadn’t been sitting for two minutes when I announced to my parents, “I want the escargot.”

Dad: “You know that’s snails?”

Six-year-old me: “Yes! We just learned about them in French class, and I want the escargot!”

My parents went along, although I’m sure they expected I’d take a few bites out of stubbornness, then subtly push the dish of garlic and butter and earthy mollusk aside, hoping no one would call out my misplaced courage.

Actually, though, I ate every snail, then mopped up every bit of briny, herby garlic butter left behind. I still think about those snails and about how excited and proud I was to love them so much.

A decade after those snails, I sat on the living room couch with my dad and watched an episode of No Reservations, Anthony Bourdain’s first food travel show. I, like millions of others, was drawn to the irreverent reverence with which he seemed to approach every food he tried, to his eagerness to try anything, and to his ability to narrate the stories of different foods, cooks, and cultures in an unpretentious way that let them mostly speak for themselves. Until then, I had thought of food and travel writing and television as more marketing than storytelling, but watching No Reservations made it clear that, actually, food was not only a story in and of itself, but also a great way to anchor other stories in something tangible and universally understood. Bourdain wasn’t out to sell an experience or show how good something could be — every episode was about telling the story of things exactly as they are.

Bourdain wasn’t the first to talk about food this way, but he was the first to make me feel like maybe I could talk about food that way, too. Food was an important part of my life growing up, but not in a particularly extraordinary way that I felt would resonate. We lived abroad and traveled often, so I was massively privileged in that there was always something new to eat. I remember eating pâté for the first time on a pebble beach in Cornwall while watching my dad (try to) learn to windsurf. I remember tearing apart a slick piece of roti prata and dipping it into a Styrofoam container of curry sauce on a plastic picnic table in Mersing, Malaysia, before getting on a bum boat to an island where I’d go to summer camp for the first time. I remember my first drink: a Tiger beer at Newton Circus, another hawker center, after the closing night of our high school production of South Pacific. I remember, every year when we’d fly home to New Jersey, eating baked ziti and supermarket sheet cake at Fourth of July barbecues, both or which were exciting and special for me because I only ate them once a year. I remember the first time I ate lunch at a New York City deli and was awed by the enormity of both the sandwiches and the Snapple selection. None of this seemed like a story, though, because I wasn’t sure why anyone else would care.

Years later, as a rising college senior, I spent the summer working as a publishing intern in New York. Weeks in, I realized that my longtime goal of being a book editor was actually, definitely, not what I wanted. To keep the “I graduate in a year and now have no plan” anxiety at bay, I read more books that summer than I ever have. One of them was Anthony Bourdain’s Kitchen Confidential.

Bourdain’s 2000 memoir, as you may know, gets so much of its magic from the sense you get while reading that every story is true. I figured it would fall into the “I never want to go there, but that sure made me think and was fun to watch” category that some of the No Reservations episodes did, and that the stories about hypermasculine kitchen culture and the people who somehow ended up in it would make me laugh, think, and then move on to whatever book was next.

That’s not what happened. The first story the book tells is one of Bourdain as a fourth-grader on a European cruise with his family. He tries vichyssoise, a potato-based French soup, and is taken aback by the fact that it’s cold. “I’d eaten in restaurants before, sure,” he says, “but this was the first food I really noticed. It was the first food I enjoyed and, more important, remembered enjoying.” Reading it made me think of my snails, how adventurous they made me feel, and how they established food as something important and worth discovering. It’s a good, tame story that I could easily relate to, and I bet most people felt the same when reading it.

The thing is, the relatability of the book started and ended with that cold potato soup. The rest of the book — about restaurant kitchens and all the crass, stressful, macho, bonkers shit that happened inside them — took place in a world very, very different from mine. Even coming from Bourdain, whose stories had been making me feel welcome since I first watched him walk around Paris unironically wearing cowboy boots in the first episode of No Reservations, the book felt like something I was looking in on from the outside. Reading it piqued my curiosity in restaurant cooking but made it clear that it wasn’t something for me. The longer the stories sat with me, though, the more they started to feel like a sort of…dare.

I graduated soon after, six months earlier than planned. I was still put off by my intern experience in publishing and totally uninspired by every job option presented to me by career counselors and all the well-meaning adults in my life. (Although it was 2010 and the height of a recession, so calling them “options” is maybe a stretch.) Food writing had crossed my mind, but I didn’t figure it was something I could just jump into. I can’t really explain my sudden decision to go to culinary school — a mix of desperation, an interest in food, a burning need to be interesting and different, and a nagging curiosity about Kitchen Confidential, if I had to put it into words — but in 2010, I moved to New York and spent 10 months at the French Culinary Institute learning how to cook. It remains the most impulsive thing I’ve ever done—and the most significant.

The following two and a half years spent cooking in NYC restaurant kitchens taught me things that culinary school never could have—about cooking, stress, being a woman in a room of mostly men, and how to deal with constantly being under fire without falling apart. It’s hard to explain what it was like to walk into a restaurant kitchen, and I honestly don’t remember it clearly, but I do remember that everything I did was wrong, everywhere I was was in the way, and every time someone said something to me, I had to ask them to explain what they were talking about. It was the most underqualified and out of place I’d ever felt, even though I knew in theory that’s exactly what I was signing up for. (I’d read the book! I intentionally jumped out of my comfort zone!) It wasn’t the useless, undervalued feeling that comes with an entry-level office job; it was the feeling that I needed to apologize for even being there, for being the alien who disrupted a system that everyone else knew how to work in. Weeks went by before I was able to walk into that kitchen without absolute fear; months went by before I was able to actually contribute.

Was restaurant cooking the way Bourdain described? Not really. It was vaguely the same, sure: late nights, weekends, burn scars, characters, industry bars, some yelling, ticket boards that inexplicably but reliably went from empty to full in a matter of minutes every single night.

The actual experience of it was very different from what I’d read, though. Because it wasn’t his experience—it was mine. I was the one cramming four hours’ worth of food prep into two and a half every afternoon. I was the one at the stove, firing seven dishes from three different orders at the same time, in exactly the right order, totally on instinct. I was the one who stayed at the bar three hours too long on a Tuesday and somehow always managed to find my way on the L train. I was the one who felt disconnected from one world but totally plugged into another.

Which made me realize: A great storyteller is one who makes you want to experience stories for yourself. A great story is one that makes you think, “I wonder what it would be like to do that.” I’m not much of a storyteller these days, nor am I still a restaurant cook. I write recipes, and I write stories about how and why people should cook them, but I do so in a way that’s shaped by what I’ve learned: Recipes are like stories, kind of, and the best recipes are ones that people will actually cook. Getting someone to cook a recipe isn’t about presenting them with something they’re already familiar with, necessarily, but about making them think, “I wonder what it would be like to do that.”

It’s no secret that Anthony Bourdain was a great storyteller. I’ll miss following along with his unending curiosity about food and how it shapes us, and the world will miss the way he was able to share that curiosity in a way that was welcoming and inclusive. What I’m most grateful for, though, is that he showed me the inside of a world I’d never given a second thought to—restaurants—and painted a picture that, even though it was totally unrelatable to me, was interesting enough that I felt compelled to experience if for myself. Not many storytellers do their job so well that, after reading their stories, you actually feel moved to go out and live them.

“Food, for me, has always been an adventure,” Bourdain writes in the preface of Kitchen Confidential. For me, too, Chef. Thanks for teaching me that food is something worth exploring and that the exploration is something worth writing about.",https://cdn-images-1.medium.com/max/1200/1*65ru7KtyJDme4kUXz8Sl5Q.jpeg,[],https://medium.com/s/story/the-inspiration-of-anthony-bourdain-8d5679c2acb4?source=grid_home---------0------------------18,

Machine Learning,"Apple has no idea what’s next, so it’s just banging on the same old drum",['Owen Williams'],"Apple has no idea what’s next, so it’s just banging on the same old drum If you want to witness a company that’s simultaneously in its prime and losing control over its own narrative, look no further than WWDC, Apple’s second-most splashy event of the year, designed to offer a glimpse of the future. The annual developer event is a spectacle that I’ve watched live for almost a decade, but this year was different: it showcased a company that’s lost in the woods, playing the same old hits on repeat, in the same old format. Not only was it painful to watch, it demonstrated that Apple doesn’t really have a coherent plan, or understanding, of where it should take its core platform, let alone the ones it’s tried to build around it. It’s fine to have an off year, but what struck me was how… random it felt, and how little insight or forward thinking there was. Apple’s own platform advantages, company culture, and whatever else, seem to be pigeonholing its trajectory, driving it down a path that looks increasingly dated, and leaving me to wonder if the company is self-aware enough to see the shifting tide before it’s lost at sea. Big, slow, yearly

Apple struggled throughout 2017 to ship flagship features it promised at WWDC 2017, including Airplay 2 and iCloud Messages, delivering them quietly just days before this year’s event. Alongside a scandal about performance throttling, a series of major security slip-ups, and hardware that shipped without long-touted features, many have loudly asked what’s causing these issues — and why a company with so many engineers is fundamentally failing to ship. Performance improvements are arguably the biggest focus of iOS 12. They’ll be welcome for many users, along with several additional improvements: streamlined notifications, a new ‘shortcuts’ feature for custom buttons, usage reporting, group FaceTime, AR updates and a number of other minor improvements to create a major release, iOS 12. The company’s other platforms received similar treatment, including macOS. Apple finished dark mode, a feature it half-introduced all the way back in Yosemite, added basic functionality to Finder, threw in a new way to organize your desktop, and boom — there’s your major release, 10.14. None of these things are inherently bad — in fact, people have been complaining about the lack of improvements to things like FaceTime for years — but what’s interesting is Apple’s choice to bundle them together as a way to make them look truly meaningful, rather than just fixing many of these issues sooner, in a point release. I’m aware there’s a slew of tiny other fixes and features I haven’t listed here, but that’s my point: it’s a hodgepodge of things that have been neglected over the years after being debuted once and forgotten about. Here’s the rub: Apple could arguably ship notification improvements to iOS users tomorrow in a point release, iOS 11.5, but it won’t. Combining them provides the illusion of progress. Instead of servicing users and giving them features sooner, on a regular basis, Apple chooses to hold back simple functionality longer, for its bottom line. As Martin Bryant points out, Apple may have a timing problem: Yes, Apple needs to take the time to do ‘boring’ optimisation work on iOS, but why build iOS around these big, annual feature bumps and then disappoint people when the bumps aren’t very big?

Interestingly, the narrative here actually doesn’t make sense anymore, either. Every year, Apple takes the time to point out how dire the state of the competition is: Nobody’s Android phones get updates! Android people don’t get any the latest features! Your phones all suck! The reality is different: Android users, regardless of manufacturer, frequently get them sooner than iOS users do, because Google divorced the operating system and core application suite from one another. Google’s approach to unbundling Android has, for the most part, been quietly successful — in an unexpected way. Instead of shipping monolithic feature updates, Google’s applications are now updated via the Play Store, from the clock app to the calculator and even the camera (unless you’re Samsung). Apple has made a yearly ritual out of jabbing competitors for poor update histories, but conveniently omits the reality that improvements to Google Assistant, the built-in web browser, or even just the OS keyboard will reach billions of users in a matter of hours without needing to update the entire phone. Android’s support libraries mean developers can target older devices, with new features, regardless of whether or not they received the OS update. Meanwhile, if you find a bug in the iOS keyboard, or some weird security flaw in Safari’s web view, you hope it gets fixed in the next version of the operating system. Maybe next year, or the year after that. It depends how bad it is, or if Apple is actively maintaining the feature, as to when it’ll get serviced. Don’t get me wrong, Android has a terrible history of updates that is only now beginning to change, ten years after the fact. Google has made strides with Project Treble, which makes an end-run around the device maker itself, but it’s only in its infancy with new devices picking it up today. That’s not good enough either; but it’s gaining traction and getting things into people’s hands. For each platform update, Apple dangles a carrot. That’s the flagship feature to convince you it’s a Big Update™ worth having immediately. On macOS this year, that’s dark mode, and on iOS, the promise of performance improvements and, god forbid, actually decent notification management. Arguably the most interesting segment out of WWDC happens at the very end of the two-hour keynote: a peek at Project Marzipan, a long-term effort to unify the interface framework developers use to build apps for iOS and macOS, which is expected to ship to everyone in 2019.

From where I sit, this is an impressive, massive project that doesn’t do much more than play defense against Electron’s continued march on Apple’s territory, threatening to kill native application development altogether. Why build anything native at all, when you can write once, and run everywhere? Anti-Electron fans will run rabid at the idea, but as the technology has become more efficient and introduced lower-level API access, it only makes even more business sense. Marzipan is an audacious plan to defend against that by making it easier to build cross-platform apps. It’s a genuinely fascinating play with fewer apparent benefits in the short term over just building an Electron app, which addresses an additional billion users, allows developers to use familiar web technology and is truly write-once-run-everywhere. Over time, Marzipan may win favor with developers, but I’m not convinced it’ll stop web-based technologies swallowing native app development whole, particularly given that both Microsoft and Google have now bet their entire strategies on Progressive Web Applications, and how low the barrier of entry has come as a result of Electron’s success. Marzipan indicates something bigger, of course, such as an impending shift away from Intel chipsets entirely to some sort of custom Apple ARM-based silicon in — shock horror — a productivity form factor. If anything, what will win as a result will be that control, and what it could ship in a end-to-end device: true all-day battery? Always-on LTE with desktop class apps? If so, the message is this: lock in with us, develop for our platforms, and we’ll reward you. Don’t, and you’ll be shut out and stuck on the outside. Hey Siri, where’s the vision?

What’s clearly missing in all of this is a willingness to take risks, or go for the long view on what’s better than the status quo for Apple’s users. Instead of looking at how phone usage is changing and redesigning the nature of iOS, it’s another year of shoehorning new features into a decade-old shell. The new shortcuts feature promises to let users wire up workflows of their dreams, chaining together tasks behind a single button. Yes, this is a great improvement to iOS that addresses a problem without actually improving on the reason anyone needs this in the first place — it’s just glued onto the homescreen that’s responsible for causing the need for it in the first place. Apple could have offered up a way to surface the weather right there, deeply integrated with the lock screen, or calendar events at the top of your home screen along with the icons, but it didn’t. Instead, it slathered what appears to be a UX hack in the shape of a notification, and tries to guess when you want to see it. Google’s own developer conference, just down the street in Mountain View, was held in May and offered a clearer, if poorly highlighted, view of the future: AI is a core part of mobile devices going forward, so we’re beginning to add it everywhere. The Android alternative to Shortcuts, Slices and App Actions, surfaces the device’s best guess at your next action as a deeply integrated interface component, where you can actually see information before actually going further in, or taking an action. Want a button to order a Lyft? Great, here’s a button embedded within the system’s app tray, with the current estimated price of your ride, which orders it right now with a single tap. Much of this data is crunched on device, just like Apple’s audacious claims to privacy brag about as well, but instead of being a UX hack to add buttons that summon help, the information is already right there, on hand, without opening anything, even Assistant. Google and Apple both anticipate a future in which we use our phones less — time well spent is a core part of this driver — and as a result, it appears Google has spent a lot of time thinking about how AI can help get the right information to the user. The result is the exact button they need at the right time, with relevant information, sans the need to actually go away and do something. To facilitate this, Google is willing to rejig the UX of its devices, mess with the sea of icons, and has invested heavily in serendipitous computing with Google Home alongside this, so it can get you there faster regardless of if the phone is in your hand.

Google’s vision of the future of smartphones, mobile operating systems, and the way we’ll interact with devices over the long haul is a coherent, well-told story: get more out of your day, get the devices out of the way. It even has a fantastic page that showcases how its own ecosystem works better, together, than I’ve ever seen explained about Apple’s ecosystem on its own site. As for why all of this happens, I suspect it’s a difference in strategy and approach. Apple’s strategy has long been to monetize its existing cash cows as long as it can by throwing out new stuff to see what sticks and doubling down on that, rather than creating any sort of coherent narrative of what the future actually looks like, operating in secrecy until it somehow lands upon it. Incremental improvement is fine, but there’s a distinct lack of forward-looking, and a whole lot of looking over the fence at what everyone else is doing to bash it instead. Apples, oranges and comparing the two

It’s easy to compare and contrast Google and Apple because they are very different companies, but what they’re both claiming to do is the same: invent the future, whatever that actually might be. Their approaches, however, are increasingly diverging: Apple’s squeezing more out of less, shipping flashy features, and focusing on privacy, while Google and others have pushed further into understanding the user and getting out of their way. Most of this comes down to business model. Apple’s focus on features by piling them together drives more sales of iPhone, which drives reliable revenue on a yearly basis. Google’s is on advertising and relevance to the user, which doesn’t depend on a particular feature or thing to tout, it just needs you to love using its tools (and not mind advertising). Apple’s entire strategy over the last two decades has pivoted around the exploitation of a product line until something new comes along, then rinse and repeat. This is framed around improving your life and often actually does, even if that is by proxy. I’d argue that the company’s vision of the future isn’t to enrich, or drive progress, but to squeeze as much revenue as possible out of slick, well-designed and marketed ideas. The products it builds, the cycles they’re released in and the way that Apple’s entire software cycle works reflects this. An example of the manifestation of this is perhaps HomePod’s requirement to have a locally available iPhone to do anything interesting, leaving it crippled without one, and Animoji’s debut only to be locked away in Messages instead of somewhere like the camera.

Google, a latecomer in the game, has the luxury — and peril — of not depending on phone revenue, so it can risk it all and get weird, since it’s not fundamentally critical to the company’s continued trajectory. Microsoft has done the same, now finding itself the underdog, risked it all and moved to an ‘OS-as-a-service’ model in which it ships features when they’re ready instead of waiting for flashy releases. Apple, on the other hand, begins and ends with the iPhone today, the rest flows from there. It can’t just rip up the foundation on which its revenue exists, and Tim Cook hasn’t shown a flair for doing so. iOS is too valuable to go away and tear down to just reimagine it for fun, so it’s the status quo, with experiments like HomePod and AirPods on the side, where it can get weird and sometimes wonderful. That’s fine, because Apple has plenty of cash lying around, but it’s interesting how limiting the approach can become. As we hurtle toward peak smartphone, the cracks here are beginning to show because Apple don’t have the next big thing yet — that we know of, naturally — and it’s taking a long time to get here. We’re essentially watching the bottom of the metaphorical tube of toothpaste being squeezed, while others are trying to figure out if maybe the tube should work completely differently. AR is potentially the next platform, yes, and it’s clear that Apple is pushing forward on that in a big way, so it’s easy to imagine a scenario in which it makes sense to shift precious resources there instead of focusing on iOS which may wind up unimportant in a year or two. I’m not convinced that in the short term, such as the oft-claimed 2020 launch date of an Apple VR/AR headset, that we’ll be headed there in any meaningful capacity. I mean, Magic Leap, a bajillion dollar company building the future of AR showed off its hardware yesterday on Twitch, quipping that “you better not put it in your pocket or it’ll overheat.” I’m happy to be wrong, and I write this knowing I’ll probably be that guy who very publically crapped on the iPhone at launch later. Apple’s worth a very large amount of money, which is more than enough proof that it’s good at many things, including convincing people to buy a phone every year.",https://cdn-images-1.medium.com/max/1200/1*tIUbwrpHZPbdNPXB569wPQ.png,[],https://medium.com/@ow/apple-has-no-idea-whats-next-so-it-s-just-banging-on-the-same-old-drum-dcfd0179cf80?source=grid_home---------0------------------18,2018-06-07 13:54:23.876000+00:00

Machine Learning,Our Wedding Is Canceled Due to the Following Strongly-Held Beliefs,['Tim Sniffen'],"Hi, everyone. I know you weren’t expecting to see Keith and I out here so soon, but we have some bad news. We’re not getting married today.

Believe me, we were really looking forward to it, but recently — this morning, in fact — we learned our blessed event was in direct conflict with the strongly-held beliefs of many of the people providing our wedding services. And if they’re not happy, we’re not happy.

Let me bring you up to speed.

You may have noticed the empty display table by the reception tent as you filed in. That’s where our wedding cake would have been. For our baker, however, creating a cake to be employed in the marriage of two men would be the moral equivalent of using communion wine to make sangria.

We knew the risks when enlisting Give Us This Beignet, Our Daily Bread as our wedding baker. They’re the best in downtown Aurora, no question — sorry, Wild-Flour! — but their beliefs on same-sex marriage are no secret. We hoped they might get swept up in the joy of the occasion but last night their chief baker Jonah, applying the final bit of piping, had a vision of Billie Jean King physically dragging him away from the gates of Heaven. And if that’s not a sign, I don’t know what is.

I should add, it may not have helped that we requested our little cake figurines be surrounded by an added semi-circle of figurines, in likenesses of the bakery staff, giving us the thumbs-up.

But that’s all done with. They’ve made their wishes clear and we respect them.

Which brings me to the empty vases alongside the pews and the empty centerpiece bowls on the reception tables. We’ve known Joyce Gantz, owner of Rest On My Laurels, for years; I couldn’t imagine this day without her. What I couldn’t know was the war raging within Joyce, fervent Catholic, after she learned of the meat-laden Friday barbecues Keith and I throw for our softball team. Last night, Joyce looked deep within her heart to ask, can I lend my good name to this cursed union?

The dumpster full of imported delphinium behind Joyce’s shop can tell you the answer.

You see, what we’re learning is that these are not just goods and services; they’re not simply the imprints of Keith’s Capital One card and the resulting exchange of goods. Every item at a wedding is nothing less than the avatar of its vendor’s entire belief system. With this in mind, each rose petal my niece Stephanie was prepared to hurl down the aisle might as well have been embossed with JOYCE GANTZ APPLAUDS THEE, SATAN.

What faith-engorged entrepreneur should face such hell?

This is why the rows of steam-trays in the tent are empty, and your choice of beef tenderloin or grilled salmon — or the one plate of tempeh veggie kabob, bless you, Amy! — will never arrive. Because Something Borrowed, Something Cordon Bleu, exceptional wedding caterers and unapologetic druids, could not bear the thought of providing nourishment to a couple willing to rip two thriving Magnolia trees from their backyard last summer. From their email: “Your heretic’s feast will be served when the earth heals from your violence.” By our best guess that wouldn’t have been by 6 p.m.

We also won’t be dancing to Renèe and the Ring-tones. While Rènee was a woman of few beliefs when we booked her, she has since converted to the Egyptian cult of Bastet, and considers the choice to put our cat Banjo to sleep, rather than pay $15,000 for experimental feline jaw surgery, to be “unforgivable wickedness, worthy of disciples of Set.”

I’ve been handed this note: Lane, our photographer, turns out to be more of a Star Wars guy and doesn’t feel right legitimizing such an obviously Star Trek couple.

Blessings on your journey, Lane.

In closing, our apologies. We were so busy coordinating our big day that we forgot to coordinate the sacred truths of all players involved. I’m told many of our vendors will adopt an exhaustive three-week interview process before each sale to keep this from happening again.

We did have a lovely wedding favor created for each of you, which we might as well distribute. It’s a wooden plaque, engraved with the phrase Love Conquers All, hand-crafted by our friend Bryce Charles in the front row. Now, Bryce is something of a Packers fan, and Keith is all about the Bears, but in the spirit of friendly rivalry, we’ve always managed to put aside our differ — wait.

Bryce’s feelings are changing.

They’re moving from loosely-held to nonchalantly-held. They’re not done; from the set of Bryce’s jaw, her feelings have transitioned to intentionally-held, and finally, they’re — yup. They’re strongly-held. Dammit.

Sorry, folks. You’re on your own.",https://cdn-images-1.medium.com/focal/1200/632/50/45/0*fh1vaEnMNoMbHE42,[],https://medium.com/s/story/our-wedding-is-cancelled-due-to-the-following-strongly-held-beliefs-1fa71105660e?source=grid_home---------0------------------18,

Machine Learning,My So-Called (Millennial) Entitlement – Trust Issues – Medium,['Stephanie Georgopulos'],"I am at the San Francisco International Airport some barely recent morning, registering for a travel program called Clear when the automated kiosk assisting me makes a strange request: “Stand still while we scan your irises.” I’ve barely digested this first ask when another takes its place: this time, the kiosk wants my fingerprints. I find this slightly less alarming; I already use those to access my banking app, buy coins for my mobile games, and unlock the phone that hosts all this information in the first place. But my eyeballs — which I had only just learned could be used as ID, and from a machine at the airport, no less — my dude. Those are the windows to my soul! Ever heard of foreplay?

Clear is a private company that prescreens air travelers using biometric authentication. Becoming a member is like ordering the half-soup, half-sandwich version of TSA PreCheck: it works, if all you want is a taste and are willing to pay for it. With Clear, you don’t need your ID to go through security, but you still have to remove your shoes. You get to wait in a shorter line (sometimes), but you still have to take out your laptop. Basically, the Cleared still participate in the most annoying aspects of air travel and pay almost 10 times the PreCheck fee for the privilege.

If the worst has already happened, that means it’s survivable.

How we decided on this valuation of convenience—it’s $179 per year—is not the point, though. My point is that some random startup casually acquired my eye-prints, and some small voice is telling me I should care more than I do. Someone out there definitely cares about this, no doubt. I’m sure at least one other traveler was not sated when a brisk Google search revealed that Clear is based in her hometown and run by a female CEO, ergo it must be a secure and entirely trustworthy business.

But I was sated. It’s the future, right? What’s the worst one could do with my retinal scans? I already gave my social security number to Camel in exchange for a pack of promotional cigarettes one time (or 12). Somewhere in Midtown Manhattan, a market-research firm knows how many condoms I used in May of 2011 (give or take). And when I think about the fact that every hard document I’ve reproduced on a digital copy machine — at work, at the bodega, at the library — is saved on a hard drive somewhere (lots of somewheres, in fact), I feel a sense of hopelessness that, in its own demented way, translates to freedom.

That’s why I unlock my phone with my fingerprint. It’s also why I talk shit in front of Alexa, why I haven’t put tape over my laptop camera, and why I still have a Facebook account. I don’t expect the worst to happen.

Because the worst has already happened. It is happening, and it will continue to happen.

I find this to be an honest, useful framework. If the worst has already happened, that means it’s survivable. And if the worst is a given in the future, too, we know that ignoring it won’t make it go away. There’s opportunity in having nothing to lose. You just need the right attitude.

Or perhaps you need the right conditioning.

Imagine: You’re 11 years old when two teenagers bring guns to their high school and kill 13 people. They injure 21 more. Your sixth-grade humanities teacher explains the inexplicable to your class after lunch period. You have to imagine that this is a first for at least some of your classmates, crying over the national news. It won’t be the last.

When you’re 15, two planes crash into two towers. You know the towers; had toured them on school trips just like all the other famous Manhattan buildings for which you know the names, if not the functions. In fact, you’d visited the towers just one week before the planes hit. There had been a renaissance fair in one of the lobbies.

At 17, your high school economics teacher tells you that social security will run out before you retire. You’ve already been paying taxes for three years. In 2018, you learn that he was exaggerating, thank goodness — by 2034, retirees can expect to receive a whopping 79% of the full benefit they receive today. You will not be of retirement age until the 2050s.

And when you’re 21, the market crashes. You’ve had a bachelor’s degree for three months. It cost $100,000 to earn, all before interest. Your class valedictorian moves back in with her parents, and no, your internship is not hiring. Five years later, the unemployment rate for people your age is almost double the national average.

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

Neuroscience has confirmed that you were making sense of these events with an underdeveloped brain. Along with your emotional maturity and your hormones, it’ll be a work-in-progress until you’re around 25. And the same way the small hurts of being small can still seep into your present — the way your grandmother eyed you with disgust when you went for a second helping — the chipping away of every institution you were raised to believe in can have unintended consequences.

Me: Do you use Touch ID to unlock your phone?

Friend: Ya.

Me: Do you know anything about the technology behind it? Or like, how secure it is?

A beat. A blank stare.

Friend: No?

Me: Same.

My friends do not need to understand the technology behind touch ID any more than they need to understand black holes. They are not convinced that adjusting their social media privacy settings is some sort of moral duty, a symbolic middle finger to Facebook on behalf of all the little guys who understand internet economics to varying degrees, or not at all. Mostly, they were confused as to why any thinking person would have an assumption of security.

“It’s not that I don’t care about being hacked, or about my data being stolen or sold,” one friend tells me. “I assume that vulnerability because there are no physical systems or structures that have succeeded, so why would something that is essentially invisible do a better job than something tangible?”

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

I’ll go: I don’t expect to own a home. I don’t expect to retire well, or at all. I don’t expect anyone to give me anything I haven’t explicitly asked for, and even then. I don’t expect it will ever be affordable to continue my education in any formal way. If a package gets lost in the mail, I don’t expect to see it again. I don’t expect the government or the banks or the universities to do anything that benefits regular people. I don’t expect them to hold each other accountable on our behalf. I don’t expect them to expel abusers from their ranks, or to put my safety over their legacy. I don’t expect to feel safe in large crowds or alone late at night. And I don’t expect that my privacy will be respected, online or in general.

America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

As far as I can tell, security — whether financial, technological, physical, or emotional — is not a thing. You don’t get to decide whether some drunk asshole drinks his drunk ass off and gets behind the wheel. Likewise, you don’t get to decide if the drunk Congress or the drunk banker or all the drunk administrations of all the drunk institutions do what’s right for you. Sometimes they will do the right thing for somebody, but statistically speaking, that somebody is not you.

Sometimes the right thing comes served in a shit sandwich, or one guy does the right thing but it’s later counteracted by the next guy and just so we’re clear, it’s always a guy. Or sometimes, we learn that what we thought was the right thing was actually the wrong thing, in ways we didn’t anticipate, except for those of us who did anticipate it but were not asked or heard because we do not employ lobbyists and because the powers that be can’t listen to us until they sort out whether our bodies are legal or not.

Mark Zuckerberg’s Congressional hearing was probably the biggest mainstreaming of data privacy issues yet, and Facebook, with its many transgressions, made for an appropriate scapegoat. But I want to know why it’s Mark Zuckerberg’s fault that American adults of voting age lack the critical thinking skills to differentiate between fake Russian bot news and The Guardian. I want to know the plan for bringing internet literacy to those who are not digital natives. I want to know why the U.S. government is being celebrated for protecting our egos and baby-proofing the internet instead of telling us the truth: Dirty tricks are less likely to work on people with more education.

What happens when your brand of exceptionalism breeds millions of people who voted a sentient conspiracy theory into office? Where does the fault lie? After all, it’s not Facebook who’s spent decades underpaying teachers and closing schools in low-income neighborhoods. Facebook doesn’t have the jurisdiction to end standardized testing or combat the quiet continuation of white flight. Facebook’s biggest mistake? Profiting off of state-sanctioned dumbness.

We’re only supposed to be dumb enough to believe that the fight is red vs. blue and not top vs. bottom. We’re only supposed to be dumb enough to believe in Democracy the Concept™ without casting a critical eye toward its practical application. This is a dumbness cultivated by and for Washington, and Zuckerberg’s misusing of it for corporate gain almost blew the lid off the entire thing. Commence finger-wagging.

On an episode of his podcast Revisionist History, Malcolm Gladwell argues that we should treat education as a weak-link network, where strengthening the weakest links has the most positive outcome for all. This is in contrast to a strong-link network, where a couple of superstars at the top carry the weaker players on the bottom. He illustrates this dynamic using soccer and basketball. An average soccer team with one star player is less likely to win a match than an above-average team with no star players — soccer is a weak-link sport. Conversely, an NBA team with a superstar or two fares better than a team on which all the players are equally, decently good — basketball is a strong-link sport.

Much to its detriment, America acts like a strong-link country. It is the type of place where electing one mixed-race president means we solved racism. (Imagine if the lesson we took from electing one white man was that all white men who lack upward mobility just need to work harder.) We raise up a few undoubtedly smart and deserving people in each field, send them around the world like brand ambassadors for democracy, poster-adults for how advanced and distinguished and American we are. Meanwhile, most of us back home — 78%, in fact — are living paycheck to paycheck. Is that freedom ringing? We’ll call right back after we pay this phone bill.

These are complex problems. In addition to the 3000ish words here, I have written and cut an additional 4500 trying to make sense of it all. I remain overwhelmed by the number of solutions that contradict one another, the knowns and unknowns, the countless logical ends I haven’t considered. But I eventually found my demented silver lining: America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

While grim on its face, this perspective has pushed me to take inventory of myself, my own power. What can I do right now? Am I solving problems I actually care about, or were these problems unconsciously inherited from another time, problems propagated by those with a vested interest in resolving them with more money, more power, more loopholes? Should I devote my energy to righting a system that, by design, has only consistently benefited one demographic and has yet to even prove itself as a scalable model for a generation that’s tired of the same people making the same decisions on behalf of the most diverse country in the world?

Is that a problem? Because it feels more like an opportunity, to me: a chance to exercise this cache of personal agency I’ve been sitting on, agency I didn’t realize I had or needed as I waited for America to work. It feels like an opportunity to try something else.

More powerful than having nothing to lose is cultivating that which can’t be taken. Grace. Clarity. Purpose. The stuff that isn’t Amazon Prime-able. These are the indoor plants of our being; only you can feed them and grow them and expose them to the light. It’s a lot of responsibility, and the work involved is often unglamorous. Some people think they never have to learn to care for these things because they have the means to outsource what they wish: their plants are alive on paper though they don’t know the how or why of it. And besides, can’t you see they’re a little busy trying to colonize Mars?

A respectable goal, though I might suggest to anyone faced with the choice to try taking on the inner self before jumping ahead to outer space. There’s more to unearth in there than you might think, and we need more people to understand the potential of their own organic material. We need people who appreciate the slow growth of nothing into something, who drink up the sunlight and make the air a little more breathable than before.

Because that’s it, for most of us. That’s how we build power. That’s how we, a generation of janitors for the American dream, put our trust in something real: each other. We stop trying to control the world in our heads and in the headlines, and we start controlling ourselves. We sleep. We go to the doctor. We log off. We talk about our problems. We water our plants. We collect our neighbor’s mail when they’re out of town. We take a deep breath before reacting in anger, and question whether this particular battle is worth our energy. It’s not. Why were we fighting again? We volunteer. We water our plants. We focus on ourselves so we can eventually focus on others — in a real way, in a non-transactional way, in a way that slowly but authentically strengthens our fellow weak links. We don’t wait for permission. We get over ourselves; we stop demanding perfection; we start. We water our plants. And on weekends, we play soccer.",https://cdn-images-1.medium.com/max/1200/1*c5zNxCX34sYmYYO-yRxlbA.png,[],https://medium.com/s/trustissues/my-so-called-millennial-entitlement-9be84343c713?source=grid_home---------0------------------18,

Machine Learning,How to Cope with the End of the World – How to Cope With The End of The World – Medium,['Maria Farrell'],"We All Die, and That’s Okay

My favorite postapocalyptic novel is George R. Stewart’s 1951 Earth Abides. In it, scientist Isherwood Williams (nicknamed Ish) survives a plague and eventually starts a new family and community in the ruins of suburban California. His hope for the future is wholly invested in a child who is intellectually curious, like him, and who might be able to revive some of the old ways and technologies. It’s an observant and reflective novel, full of the “how stuff would probably work” thinking that makes science fiction the true literature of ideas.

Ish starts out as a scientist-savior of humanity, figuring there is just enough time to raise a generation to turn back the clock to before the disaster. But he ultimately has to make his peace with the fact that civilization as he knew it is dead, there will be no heroic rescue, no going back, and the people around him are mostly fine with that.

The 1950s may have been the last decade we could complacently believe the Ecclesiastes (1:4) maxim that “men come and go, but earth abides,” but Stewart’s basic message is correct.

The people who come after us don’t have to do better than us, or think well of us, for them to be essentially okay. And us all throwing a big “let’s blow it all up” hissy fit because we fucked up and we can’t bear to look at it is just teenage nihilism that we need to grow out of already. Coming to terms with what we have done means dumping the egotistical death drive of the mass shooter or far-right politician and gathering the maturity to look our individual and collective deaths straight in the eye and say, “Okay, we get it now. We get it. It’s not about us.”

Have you ever stood in a crowded place like a town square or an airport meet-and-greet and thought, “Every single person here is going to die”? Morbid, eh? More of us should do it.

I live in an early Victorian terraced house in the UK. It’s never been a tenement, so probably a hundred people have called it home in the almost two centuries it’s been standing. Nearly all of them are dead. The people are already born who’ll live there when I’m dead. The head of this country’s anachronistic state has already been born who I’ll never see on the throne and to whom I’ll seem as old as someone born in the 1930s seems to me.

We’re all going to die. The morning will come when those who have loved us put on dark clothes and cry and get on with the rest of their lives, seeing movies we’d have loved, depending on gadgets that now seem to us ridiculously unnecessary. Our deaths matter to us and those who love us, but they don’t fundamentally matter.

Once, while my husband was deployed to Afghanistan, I asked him on the phone if he was doing okay about someone we knew who’d recently been killed. “Oh, you know,” he said, “you know,” and quoted his regiment’s unofficial mantra:

Everything matters. Nothing matters terribly.

The soldier’s death mattered very, very much to him, and (not but) he and others were nonetheless carrying on their shared purpose. Otherwise, what had been the point of any of it?

What will outlive us, individually? Plastic. Perhaps some genes. The bacteria that act as a species-level enabler for everything we are. Some ideas, maybe, or songs, stories, pictures, the memories of us others hold, until they go, memorials like a community flower bed or a named scholarship, for a while, anyway. Less concretely: ways of being, a fitness for the world that those who flourish pass unremarked to their offspring via the epigenetics of love — the sunny inverse of patterns of trauma and abuse transmitted through the body, even unto the third generation. Predation.

And our species? Buildings and bones, maybe. Our nuclear waste and the warning signs we hope people of our deep future, or other species altogether, will decrypt. Snatches of radio-transmitted voices slipping through the vacuum of space. Perhaps some bacterial payload we’ll launch in a decade or so, trying to seed life on other planets, even in other solar systems. Or just the anomalous levels of carbon dioxide and methane in our atmosphere that will reveal, for a time, that complex forms of life were here.

Pride and despair are two sides of the same coin. Our collective denial and despair about the future we have built is preventing us from cracking on and sorting it out. We need to get over ourselves. The world we know will end, in both small and big ways. We ourselves will end. But that doesn’t matter, terribly.

Our mortality is the greatest enabler we have of positive, ongoing change, if only we can face it, if only we can understand that we don’t get to see the end of the movie, because, if what we do works, the movie won’t have to end. We’re not the protagonists. We’re just the foreshadowing. We need to hold the knowledge of our own deaths up to the light and turn it around to see each shining facet, then take the certainty that we are both finite and imperfect deep down inside of us—and put it to work.",https://cdn-images-1.medium.com/max/1200/0*avXWZmh3n3H7a8t8,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world/how-to-cope-with-the-end-of-the-world-2520ef9d3dbc?source=grid_home---------0------------------18,

Machine Learning,How to Cope With The End of The World – Medium,['Maria Farrell'],"COLUMN

How to Cope With The End of The World

There are moments of joy even in times of great despair. Maria Farrell explains how to deal with a darkening world, and how to plan for the end. It might be the end of the world as we know it, but it turns out we feel fine.",https://cdn-images-1.medium.com/max/1200/1*kvqwUuDCsbkAoSfaYXV1vQ@2x.png,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world,

Machine Learning,Chatbots were the next big thing: what happened? – The Startup – Medium,"['Matt Asay', 'Justin Lee']","Chatbots were the next big thing: what happened?

Oh, how the headlines blared:

“…the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”

Chatbots were The Next Big Thing.

Our hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.

And why wouldn’t they be? All the road signs pointed towards insane success.

Messaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!

Plus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.

At the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.

In fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:

“Will a single platform emerge to dominate the chatbot and personal assistant ecosystem?”

One year on, we have an answer to that question.

No.

Because there isn’t even an ecosystem for a platform to dominate.

Fooled by another hype cycle

Chatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.

The age-old hype cycle unfolded in familiar fashion…

Reverential TechCrunch articles were written.

Prophetic thought leaders like Chris Messina chimed in.

Silicon Valley salivated at the prospect of talking to smart automation.

Messenger began to overflow with bots.

Slack went through exponential growth and even launched a fund for bot investment.

Expectations built, built, and then….. It all kind of fizzled out.

The predicted paradim shift didn’t materialize.

And apps are, tellingly, still alive and well.

We look back at our breathless optimism and turn to each other, slightly baffled:

“is that it? THAT was the chatbot revolution we were promised?”

Digit’s Ethan Bloch sums up the general consensus:

“I’m not even sure if we can say ‘chatbots are dead,’ because I don’t even know if they were ever alive.”

According to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.

Text vs. Speech vs. GUI: a potted history

Bots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.

Users had to type commands manually into a machine to get anything done.

Then, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!

Meanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.

Another bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:

… so many different accents, people speaking too fast or too slowly, mumbling, umming and aahing.

Did you say “recognise speech” or “wreck a nice beach”?

The next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:

User: “Hello.”

Agent: “Hello, what’s your name?”

User: “Candy.”

Agent: “Hello, Candy!”

User: “Let’s set the clock.”

Agent: “What is the time?”

User: “The time is 11:00 AM.”

Agent sets the clock to 11:00 AM.

Pretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.

It was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.

Modern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.

Basically, we’re still trying to achieve the same innovations we were 30 years ago.

Here’s where I think we’re going wrong:

Thinking in terms of Bots vs. Apps

An oversized assumption has been that apps are ‘over’, and would be replaced by bots.

By pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.

You might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?

It’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.

Whether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.

Plus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.

A great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.

That’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.

Modern-day apps benefit from decades of research and experimentation. Why would we throw this away?

But, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.

Today’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.

Penny provides chatty advice and alerts alongside a traditional account dashboard and transaction list.

HubSpot Conversations unifies Facebook Messenger, onsite chat, social media, email and other messaging outlets into one shared inbox.

Layer gives developers the tools to create personalized messaging experiences on mobile web and desktop web as well as native apps.

The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.

Bots for the sake of bots

Does my product need a bot? Are existing platforms able to support its functionality? Do I have the patience to build a bot that’s capable of doing what I want it to?

Another problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.

For plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.

Building a bot for the sake of it, letting it loose and hoping for the best will never end well:

The totally necessary Maroon 5 chatbot in action

The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.

The advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.

That’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.

Problems arise when life refuses to fit into those boxes.

According to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.

When we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.

Remember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.

Inaccessibility

A competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.

In an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.

Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)

As Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.

“Consumer interest was never going to materialize until machine intelligence could get anywhere near human intelligence.

User interest depends upon AI that makes talking with a bot worthwhile for consumers.”

And conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.

Today’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.

And in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:

“Should Slack, Facebook, Google, Microsoft, Kik, and others have built their own built-in bots to lead the way?

Should they have gotten more proactive with their bot funds and incubators, hiring mentors to educate participants in the Way of the Bot, or supplying engineering and design resources? Funded Strategic Bot Initiatives at high-profile partners?

In my opinion yes, yes, and yes. When it comes to platforms, developers are the users; and we don’t rely on our users to understand why or how to use our products. We have to show them.”

GUI shouldn’t be dismissed

Once upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information

There’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.

Tapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.

We love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.

Conversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.

Sure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.

Humans like talking to other humans

Aiming for a human dimension in business interactions makes sense.

If there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.

Facebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.

A conversation encompasses so much more than just text.

Humans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.

As HubSpot team pinpointed:

Bots provide a scalable way to interact one-on-one with buyers. Yet, they fail when they don’t deliver an experience as efficient and delightful as the complex, multi-layered conversations people are accustomed to having with other humans on messaging apps.

People aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).

And even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.

And here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.

But is that how humans prefer to interact with machines?

Not necessarily.

At the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.

Where do we go from here?

In a way, those early-adopters weren’t entirely wrong.

People are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.

Not even close.

Computers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.

Computers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.

That’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.

For now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.

But that’s not the whole story.

Yes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.

As Bill Gates once said:

We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. Don’t let yourself be lulled into inaction.

The hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.

I believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.

Messaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.

Developers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.

And I can’t wait to see what happens next.",https://cdn-images-1.medium.com/max/1200/1*-_um8Nai0uer46tni1LETg.jpeg,[],https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=topic_page---8------0----------------,2018-06-05 15:55:36.912000+00:00

Machine Learning,Google’s AutoML will change how businesses use Machine Learning,['George Seif'],"Google’s AutoML will change how businesses use Machine Learning

Google’s AutoML is a new up-and-coming (alpha stage) cloud software suite of Machine Learning tools. It’s based on Google’s state-of-the-art research in image recognition called Neural Architecture Search (NAS). NAS is basically an algorithm that, given your specific dataset, searches for the most optimal neural network to perform a certain task on that dataset. AutoML is then a suite of machine learning tools that will allow one to easily train high-performance deep networks, without requiring the user to have any knowledge of deep learning or AI; all you need is labelled data! Google will use NAS to then find the best network for your specific dataset and task. They’ve already shown how their methods can achieve performance that is far better than that of hand-designed networks.

AutoML totally changes the whole machine learning game because for many applications, specialised skills and knowledge won’t be required. Many companies only need deep networks to do simpler tasks, such as image classification. At that point they don’t need to hire 5 machine learning PhDs; they just need someone who can handle moving around and organising their data.

There’s no doubt that this shift in how “AI” can be used by businesses will create change. But what kind of change are we looking at? Whom will this change benefit? And what will happen to all of the people jumping into the machine learning field? In this post, we’re going to breakdown what Google’s AutoML, and in general the shift towards Software 2.0, means for both businesses and developers in the machine learning field.

More development, less research for businesses

A lot of businesses in the AI space, especially start-ups, are doing relatively simple things in the context of deep learning. Most of their value is coming from their final put-together product. For example, most computer vision start-ups are using some kind of image classification network, which will actually be AutoML’s first tool in the suite. In fact, Google’s NASNet, which achieves the current state-of-the-art in image classification is already publicly available in TensorFlow! Businesses can now skip over this complex experimental-research part of the product pipeline and just use transfer learning for their task. Because there is less experimental-research, more business resources can be spent on product design, development, and the all important data.

Speaking of which…

It becomes more about product

Connecting from the first point, since more time is being spent on product design and development, companies will have faster product iteration. The main value of the company will become less about how great and cutting edge their research is and more about how well their product/technology is engineered. Is it well designed? Easy to use? Is their data pipeline set up in such a way that they can quickly and easily improve their models? These will be the new key questions for optimising their products and being able to iterate faster than their competition. Cutting edge research will also become less of a main driver of increasing the technology’s performance.

Now it’s more like…

Data and resources become critical

Now that research is a less significant part of the equation, how can companies stand out? How do you get ahead of the competition? Of course sales, marketing, and as we just discussed, product design are all very important. But the huge driver of the performance of these deep learning technologies is your data and resources. The more clean and diverse yet task-targeted data you have (i.e both quality and quantity), the more you can improve your models using software tools like AutoML. That means lots of resources for the acquisition and handling of data. All of this partially signifies us moving away from the nitty-gritty of writing tons of code.

It becomes more of…

Software 2.0: Deep learning becomes another tool in the toolbox for most

All you have to do to use Google’s AutoML is upload your labelled data and boom, you’re all set! For people who aren’t super deep (ha ha, pun) into the field, and just want to leverage the power of the technology, this is big. The application of deep learning becomes more accessible. There’s less coding, more using the tool suite. In fact, for most people, deep learning because just another tool in their toolbox. Andrej Karpathy wrote a great article on Software 2.0 and how we’re shifting from writing lots of code to more design and using tools, then letting AI do the rest.

But, considering all of this…

There’s still room for creative science and research

Even though we have these easy-to-use tools, the journey doesn’t just end! When cars were invented, we didn’t just stop making them better even though now they’re quite easy to use. And there’s still many improvements that can be made to improve current AI technologies. AI still isn’t very creative, nor can it reason, or handle complex tasks. It has the crutch of needing a ton of labelled data, which is both expensive and time consuming to acquire. Training still takes a long time to achieve top accuracy. The performance of deep learning models is good for some simple tasks, like classification, but does only fairly well, sometimes even poorly (depending on task complexity), on things like localisation. We don’t yet even fully understand deep networks internally.

All of these things present opportunities for science and research, and in particular for advancing the current AI technologies. On the business side of things, some companies, especially the tech giants (like Google, Microsoft, Facebook, Apple, Amazon) will need to innovate past current tools through science and research in order to compete. All of them can get lots of data and resources, design awesome products, do lots of sales and marketing etc. They could really use something more to set them apart, and that can come from cutting edge innovation.

That leaves us with a final question…

Is all of this good or bad?

Overall, I think this shift in how we create our AI technologies is a good thing. Most businesses will leverage existing machine learning tools, rather than create new ones since they don’t have a need for it. Near-cutting-edge AI becomes accessible to many people, and that means better technologies for all. AI is also quite an “open” field, with major figures like Andrew Ng creating very popular courses to teach people about this important new technology. Making things more accessible helps people transition with the fast-paced tech field.

Such a shift has happened many times before. Programming computers started with assembly level coding! We later moved on to things like C. Many people today consider C too complicated so they use C++. Much of the time, we don’t even need something as complex as C++, so we just use the super high level languages of Python or R! We use the tool that is most appropriate at hand. If you don’t need something super low-level, then you don’t have to use it (e.g C code optimisation, R&D of deep networks from scratch), and can simply use something more high-level and built-in (e.g Python, transfer learning, AI tools).

At the same time, continued efforts in the science and research of AI technologies is critical. We can definitely add tremendous value to the world by engineering new AI-based products. But there comes a point where new science is needed to move forward. Human creativity will always be valuable.

Conclusion

Thanks for reading! I hope you enjoyed this post and learned something new and useful about the current trend in AI technology! This is a partially opinionated piece, so I’d love to hear any responses you may have below!",https://cdn-images-1.medium.com/max/1200/1*g9BzirXxUauRO9rA_tSvnA.jpeg,[],https://towardsdatascience.com/googles-automl-will-change-how-businesses-use-machine-learning-c7d72257aba9?source=topic_page---8------1----------------,2018-05-14 14:27:41.145000+00:00

Machine Learning,Automated Feature Engineering in Python – Towards Data Science,['William Koehrsen'],"First, let’s take a look at our example data. We already saw some of the dataset above, and the complete collection of tables is as follows:

Deep feature synthesis stacks multiple transformation and aggregation operations (which are called feature primitives in the vocab of featuretools) to create features from data spread across many tables. Like most ideas in machine learning, it’s a complex method built on a foundation of simple concepts. By learning one building block at a time, we can form a good understanding of this powerful method.

Fortunately, featuretools is exactly the solution we are looking for. This open-source Python library will automatically create many features from a set of related tables. Featuretools is based on a method known as “ Deep Feature Synthesis ”, which sounds a lot more imposing than it actually is (the name comes from stacking multiple features not because it uses deep learning!).

These operations are not difficult by themselves, but if we have hundreds of variables spread across dozens of tables, this process is not feasible to do by hand. Ideally, we want a solution that can automatically perform transformations and aggregations across multiple tables and combine the resulting data into a single table. Although Pandas is a great resource, there’s only so much data manipulation we want to do by hand! (For more on manual feature engineering check out the excellent Python Data Science Handbook ).

This process involves grouping the loans table by the client, calculating the aggregations, and then merging the resulting data into the client data. Here’s how we would do that in Python using the language of Pandas .

On the other hand, aggregations are performed across tables, and use a one-to-many relationship to group observations and then calculate statistics. For example, if we have another table with information on the loans of clients, where each client may have multiple loans, we can calculate statistics such as the average, maximum, and minimum of loans for each client.

we can create features by finding the month of the joined column or taking the natural log of the income column. These are both transformations because they use information from only one table.

A transformation acts on a single table (thinking in terms of Python, a table is just a Pandas DataFrame ) by creating new features out of one or more of the existing columns. As an example, if we have the table of clients below

The process of constructing features is very time-consuming because each new feature usually requires several steps to build, especially when using information from more than one table. We can group the operations of feature creation into two categories: transformations and aggregations . Let’s look at a few examples to see these concepts in action.

Feature engineering means building additional features out of existing data which is often spread across multiple related tables. Feature engineering requires extracting the relevant information from the data and getting it into a single table which can then be used to train a machine learning model.

If we have a machine learning task, such as predicting whether a client will repay a future loan, we will want to combine all the information about clients into a single table. The tables are related (through the client_id and the loan_id variables) and we could use a series of transformations and aggregations to do this process by hand. However, we will shortly see that we can instead use featuretools to automate the process.

Entities and EntitySets

The first two concepts of featuretools are entities and entitysets. An entity is simply a table (or a DataFrame if you think in Pandas). An EntitySet is a collection of tables and the relationships between them. Think of an entityset as just another Python data structure, with its own methods and attributes.

We can create an empty entityset in featuretools using the following:

import featuretools as ft

# Create new entityset

es = ft.EntitySet(id = 'clients')

Now we have to add entities. Each entity must have an index, which is a column with all unique elements. That is, each value in the index must appear in the table only once. The index in the clients dataframe is the client_id because each client has only one row in this dataframe. We add an entity with an existing index to an entityset using the following syntax:

The loans dataframe also has a unique index, loan_id and the syntax to add this to the entityset is the same as for clients . However, for the payments dataframe, there is no unique index. When we add this entity to the entityset, we need to pass in the parameter make_index = True and specify the name of the index. Also, although featuretools will automatically infer the data type of each column in an entity, we can override this by passing in a dictionary of column types to the parameter variable_types .

For this dataframe, even though missed is an integer, this is not a numeric variable since it can only take on 2 discrete values, so we tell featuretools to treat is as a categorical variable. After adding the dataframes to the entityset, we inspect any of them:

The column types have been correctly inferred with the modification we specified. Next, we need to specify how the tables in the entityset are related.

Table Relationships

The best way to think of a relationship between two tables is the analogy of parent to child. This is a one-to-many relationship: each parent can have multiple children. In the realm of tables, a parent table has one row for every parent, but the child table may have multiple rows corresponding to multiple children of the same parent.

For example, in our dataset, the clients dataframe is a parent of the loans dataframe. Each client has only one row in clients but may have multiple rows in loans . Likewise, loans is the parent of payments because each loan will have multiple payments. The parents are linked to their children by a shared variable. When we perform aggregations, we group the child table by the parent variable and calculate statistics across the children of each parent.

To formalize a relationship in featuretools, we only need to specify the variable that links two tables together. The clients and the loans table are linked via the client_id variable and loans and payments are linked with the loan_id . The syntax for creating a relationship and adding it to the entityset are shown below:

The entityset now contains the three entities (tables) and the relationships that link these entities together. After adding entities and formalizing relationships, our entityset is complete and we are ready to make features.

Feature Primitives

Before we can quite get to deep feature synthesis, we need to understand feature primitives. We already know what these are, but we have just been calling them by different names! These are simply the basic operations that we use to form new features:

Aggregations: operations completed across a parent-to-child (one-to-many) relationship that group by the parent and calculate stats for the children. An example is grouping the loan table by the client_id and finding the maximum loan amount for each client.

table by the and finding the maximum loan amount for each client. Transformations: operations done on a single table to one or more columns. An example is taking the difference between two columns in one table or taking the absolute value of a column.

New features are created in featuretools using these primitives either by themselves or stacking multiple primitives. Below is a list of some of the feature primitives in featuretools (we can also define custom primitives):

Feature Primitives

These primitives can be used by themselves or combined to create features. To make features with specified primitives we use the ft.dfs function (standing for deep feature synthesis). We pass in the entityset , the target_entity , which is the table where we want to add the features, the selected trans_primitives (transformations), and agg_primitives (aggregations):

The result is a dataframe of new features for each client (because we made clients the target_entity ). For example, we have the month each client joined which is a transformation feature primitive:

We also have a number of aggregation primitives such as the average payment amounts for each client:

Even though we specified only a few feature primitives, featuretools created many new features by combining and stacking these primitives.

The complete dataframe has 793 columns of new features!

Deep Feature Synthesis

We now have all the pieces in place to understand deep feature synthesis (dfs). In fact, we already performed dfs in the previous function call! A deep feature is simply a feature made of stacking multiple primitives and dfs is the name of process that makes these features. The depth of a deep feature is the number of primitives required to make the feature.

For example, the MEAN(payments.payment_amount) column is a deep feature with a depth of 1 because it was created using a single aggregation. A feature with a depth of two is LAST(loans(MEAN(payments.payment_amount)) This is made by stacking two aggregations: LAST (most recent) on top of MEAN. This represents the average payment size of the most recent loan for each client.

We can stack features to any depth we want, but in practice, I have never gone beyond a depth of 2. After this point, the features are difficult to interpret, but I encourage anyone interested to try “going deeper”.",https://cdn-images-1.medium.com/max/1200/1*lg3OxWVYDsJFN-snBY7M5w.jpeg,[],https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219?source=topic_page---8------2----------------,2018-06-02 15:01:18.755000+00:00

Machine Learning,My Phone Wants Me to Say ‘Thank You’ – When Robots Rule The World – Medium,['Evan Selinger'],"Sincerely Thankful

Perhaps there’s something infantilizing about our phones “wanting” us to say thanks. It’s hard to draw a firm line between what you would say if only you put in the time to say it versus what you do say after predictive software fills in the blanks. Seeing suggestions is itself a suggestive situation. And so, while Google emphasizes that smart reply is intelligent enough to figure out if you’re more of a “thanks!” than a “thanks.” person, the fact remains that it’s a good bet that some variation of the word will be frequently presented to you.

If being offered a “thanks” seems familiar, it’s because the act resembles what parents do when they try to instill etiquette. Let’s imagine that Lil’ Johnny receives a gift and instinctively wants to run off and play with it. Before this happens, one of his parents admonishes, “Johnny, what do you say?” And so, robotically, Johnny responds, “Thank you.”

At the time of being coached, Lil’ Johnny doesn’t mean what he parrots back. The gesture is insincere, and Johnny offers it to avoid conflict that would further delay what he really wants to do. That’s okay, though. The hope is that, over time, Lil’ Johnny becomes Big Johnny, the type of person who can genuinely experience gratitude and doesn’t simply follow rules like an automaton. The parental admonitions made during childhood are supposed to be like a pair of moral training wheels that kids ultimately outgrow.

Software like smart reply isn’t designed to provide adults with a second round of moral education. But if we mindlessly use such tools on a regular basis so we can quickly move on to do other things—things that we actually care about—our gestures will merely take the form of gratitude while lacking the underlying substance.

True gratitude must be sincere.

To be truly grateful, you have to mean what you say — that is, you must recognize that someone did something for you that deserves to be acknowledged, and you must sincerely want to make the acknowledgment.

Graciousness is a virtue. If an adult passes off insincere gratitude as the sincere variety in situations where people reasonably expect a person’s words and beliefs to align, the person is behaving worse than Lil’ Johnny. Lil’ Johnny is trying to be compliant, not deceptive.

We also shouldn’t lose sight of the fact that people who in engage in rituals like keeping gratitude journals aim to be specific when offering their appreciation. They don’t just say “thanks” or use any of the other minimalist formulations that smart reply offers. Instead, people who are pursuing lives filled with intentionality are concrete about what they are grateful for, as well as why they’re grateful for it. They want to focus on what they have rather than despair or obsesses over what they lack.",https://cdn-images-1.medium.com/focal/1200/632/51/50/1*MpyyWHuRUnanCenqeG3sHA.jpeg,[],https://medium.com/s/when-robots-rule-the-world/my-phone-wants-me-to-say-thank-you-122cc15952a9?source=topic_page---8------3----------------,

Machine Learning,"In 2018, Numbers Lie and Fictions Paint Truth – Eve Weinberg – Medium",['Eve Weinberg'],"In 2018, Numbers Lie and Fictions Paint Truth Why storytelling is our best tool in disambiguating fact from fiction

I’d love to share a few of the lecturers who touched upon this topic and forever changed my understanding of the 2018 landscape of fact, fiction, and storytelling’s role in deciphering one from the other.

This summer, I had the great privilege of attending EyeO (June 3–8 2018). Innumerable topics that encompass the intersection of Art, Technology, and Data were covered, but one common thread has left an imprint on my brain. That is: the Sisyphean 21st century task of disambiguating fact from fiction. That’s right…

PART 1: NUMBERS ARE MALLEABLE

On the first day, we discussed climate science at length. We (a very self aware room of liberal, number-crunching, data-visualization-making, coastal-living, self-ascribed nerds) attempted to break down the problems with human psychology. We looked at the facts, stats, charts, and graphs; then investigated the human power of denial, dissonance, disincentivization, and the hurdles of behavioral change. After 6 hours of discussion, ideation, and reflection, feeling a bit helpless, we ended with questions that I kept with me throughout the next 3 days of lectures:

Why don’t people believe statistics?

Are stories more powerful than numbers?

Why is denial more powerful than behavioral change?

Why do lies travel faster than truth?

…And what should we do about this?

The next day, Amanda Cox enlightened us with her talk These Lines Are The Same. She showed us that data, even in simple bar graphs, can be misinterpreted depending on the viewer’s own bias. She bravely revealed to us that in her department The Upshot at The New York Times they struggle with how to best represent datasets objectively. They experiment in meaningful and educational ways. In one example she showed data from the US unemployment report. The article allows readers to look at the chart with ‘Democratic Goggles’ and ‘Republican Goggles.’

The numbers are the same, but they can easily be bent to the will of anyone with an agenda.

Then she humorously showed us our flaws in clinging to round numbers. She drove the point home with a series of charts, one here showing the likelihood that someone in the ER gets checked for a heart attack, according to their age. As Amanda points out, “nothing radical changes from the age of 39-and-three-quarters and 40, yet here is the data:",https://cdn-images-1.medium.com/max/1200/1*bJ58aYiSmkeNYJY73AQN3w.jpeg,[],https://medium.com/@evejweinberg/in-2018-numbers-lie-and-fictions-paint-truth-ea1f5cdc9abe?source=topic_page---8------0----------------,2018-06-08 22:01:41.763000+00:00

Machine Learning,The Art of Ethereal: Bringing Cellarius to Life – Genesis Thought – Medium,['Mally Anderson'],"The Art of Ethereal: Bringing Cellarius to Life

Whose future is it? Hers, and his, and theirs, and ours.

A sampling of the Cellarius faction portraits from our Ethereal Summit pop-up.

On May 11 and 12, our parent company ConsenSys hosted the third Ethereal Summit at the Knockdown Center in Queens, New York and invited Cellarius to participate, along with many other spokes from our Mesh. The creators of Ethereal wanted to build a different kind of crypto conference. Since this one explored the intersection of blockchain and the arts, we wanted to showcase that aspect of our project and spread the word in an unexpected way. We set up shop in “The Crypt,” a semi-outdoor concrete space with a distinctive patina that felt perfect for the Cellarius blockpunk aesthetic.

The Knockdown Center’s very blockpunk Crypt space. We displayed some not-yet-published art commissions.

We teamed with some artists from a group called Drawn Together NYC: Boris Rasin, Michael Scarola, Derrick Dent, and Rosalind Bunting. Drawn Together’s talented roster of artists creates design concepts, multimedia experiences, and fine art solutions for a wide range of projects and businesses, and they understood what we are going for right away.

The artists of Drawn Together NYC, from left to right: Boris Rasin, Rosalind Bunting, Derrick Dent, and Michael Scarola.

Boris, Michael, and Derrick created custom, in-universe faction portraits of Ethereal attendees. The CX Universe Guide imagines that nation-states and traditional economies will break down after the Cellarius AI seizes control of Earth’s energy sources and communication channels in 2084. In the absence of familiar institutions and technologies, people will begin to form factions according to their allegiance to Cellarius. We wanted to get attendees thinking about their own relationships to technology and start dreaming up characters to explore in the Cellarius universe. So we posed the question: which faction do you think you would be?

Boris drew background art for four different factions:

The 4 faction backgrounds, clockwise from top left: Bucolic, Elite, Ad-Hoc, Homotranscendus.

Bucolic: Bucolics are AI skeptics who reject technology and live on the peripheries of megacities, observing from the outside and farming small pockets of fertile soil. Though their process is completely manual and their harvests are meager, they feel a great satisfaction from working with their own hands, in stark contrast to the highly automated farming processes elsewhere.

Ad-Hoc: Ad-Hocs live off the Cellarius grid and make their own augmentations and tools with scrap pieces they scavenge and rework. Comprised of mostly poor and marginalized groups, they use ingenuity and what little tech they can access to get by.

Elite: The crypto-Elites of the future are pro-Cellarius and experiment with AI and aesthetic enhancements. Living in the highest levels of the megacities, Elites have access to bleeding-edge technology. They are known for having lifespans beyond the normal range of humans, and enjoy the neural boost that comes with AI coupling.

Homotranscendus: During the Reformation, it wasn’t just the home habitat that was transformed forever, but also humankind itself. The campaign was more than just re-imagining the economic machinery of the planet Earth, but also a re-imagining of the of the human brain and body. Through Cellarius-engineered advancements, the next evolution of humanity was born: Homotranscendus. Homotranscendi are fully integrated with AI and no longer depend on their human forms to express consciousness and gather information.

We even got a portrait of ConsenSys’s own Joe Lubin, who wore a custom Cellarius Ethereal t-shirt design during his keynote address (thanks, Joe!). Something tells us that Joe would be a Homotranscendus.

Future Homotranscendus Joe Lubin on Mars.

Reimagining how familiar scenarios from your own life play out in a future setting or speculating about how you might react to a superintelligent AI’s takeover of the world is a great place to start inventing your own ideas in the world of Cellarius. We hope some attendees will be inspired to start making art and stories based on their portraits!

Every single Ethereal portrait, as arranged by our designer, Octavian.

As we’ve mentioned in previous posts, we are also commissioning works from artists we admire to create the first round of content for the Cellarius universe. We decided to commission a mural that would take shape over the two days of the Summit and give attendees a behind-the-scenes look at the process of making a large-scale landscape painting. The design depicts what the Knockdown Center might look like a century from now, in 2118. Visitors to the Crypt got a chance to watch Rosalind transform the canvas from a faint pencil sketch into an impressive and detailed final product:

Rosalind’s “Knockdown Center in 2118” painting took shape over two days.

Rosalind & Boris outlined the sketch first, then Rosalind added color, starting with the future-NYC background.

We hope that the Cellarius platform will allow experienced artists and creators to get directly in touch with their fan bases and share some glimpses of their artistic process, just as Rosalind did with her live painting.

The Drawn Together NYC artists got to learn more about the possibilities of blockchain and decentralization for creatives in the process of chatting with the attendees. Michael noted, “There were so many passionate and interesting people from all over the world that came through. And they had as much fun as we did learning about and playing in the Cellarius world.” Rosalind agreed: “Probably my favorite thing I learnt about over the Summit was how Cellarius involves the creative talents of so many more artists in their company, and loved seeing some of their amazing artwork. Can’t wait to see more!”

We were also excited that the long-term goals of the Cellarius project resonated with the Drawn Together NYC artists. Derrick said, “This was probably the coolest on-site portrait job I’ve ever worked on. I had a great time learning about the Cellarius project and the potential for a sprawling, community-shaped open sci-fi world. It was even cooler to have our portrait work used as an onboarding tool for visitors. People immediately took to creating their own story within this world, and that says a lot about how exciting this could be for folks who are creatively inclined.” We couldn’t have said it better ourselves.

As Boris told us, “The more I spoke to the pop-up team and event attendees about the concept behind this project, the more it occurred to me that this is a game changer. Cellarius and the other projects from ConsenSys are sure to revolutionize our ecosystem in ways we can’t even begin to comprehend. It’s a challenge to explain exactly what this project is, because the underlying platform allows for limitless opportunities of invention, inspiration, and collaboration. Cellarius is whatever its contributors will it to be, and frankly, that’s a fundamentally crazy idea!”

That’s just the point: blockchain enthusiasts can become artists and use storytelling to push the conceptual limits of technology. Artists can use the platform to explore the possibilities of decentralization and blockchain for sharing and protecting their work. We can build it together. Cellarius is whatever our community of contributors wills it to be.",https://cdn-images-1.medium.com/max/1200/1*vL8856P7cdV84CYM_SkF0A.jpeg,[],https://medium.com/genesis-thought/the-art-of-ethereal-bringing-cellarius-to-life-ba4ae31811e7?source=topic_page---8------1----------------,2018-06-08 16:46:47.896000+00:00

Machine Learning,The curious case of the vanishing & exploding gradient,['Eniola Alese'],"The curious case of the vanishing & exploding gradient

Understanding why gradients explode or vanish and methods for dealing with the problem.

Photo by SpaceX on Unsplash

In the last post, we introduced a step by step walkthrough of RNN training and how to derive the gradients of the network weights using back propagation and the chain rule. But it turns out that during this training the RNN can suffer greatly from two problems: 1. Vanishing gradients or 2. Exploding gradients.

Why Gradients Explode or Vanish

Recall the many-to-many architecture for text generation shown below and in the introduction to RNN post, lets assume the input sequence to the network is a 20 word sentence: “I grew up in France,…….. I speak French fluently.

We can see from the example above that for the RNN to predict the word “French” which comes at the end of the sequence, it would need information from the word “France”, which occurs further back at the beginning of the sentence. This kind of dependence between sequence data is called long-term dependencies because the distance between the relevant information “France” and the point where it is needed to make a prediction “French” is very wide. Unfortunately, in practice as this distance becomes wider, RNNs have a hard time learning these dependencies because it encounters either a vanishing or exploding gradient problem.

These problems arise during training of a deep network when the gradients are being propagated back in time all the way to the initial layer. The gradients coming from the deeper layers have to go through continuous matrix multiplications because of the the chain rule, and as they approach the earlier layers, if they have small values (<1), they shrink exponentially until they vanish and make it impossible for the model to learn , this is the vanishing gradient problem. While on the other hand if they have large values (>1) they get larger and eventually blow up and crash the model, this is the exploding gradient problem

Dealing with Exploding Gradients",https://cdn-images-1.medium.com/max/1200/0*UCn2LUkacEHQxgZW,[],https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb?source=topic_page---8------3----------------,2018-06-05 22:33:57.437000+00:00

Machine Learning,How to ensure the safety of Self-Driving Cars: Part 2/5,['Jason Marks'],"How to ensure the safety of Self-Driving Cars: Part 2/5

There’s an ongoing battle between LiDAR, Automotive Radar, and Cameras (and a few others too) for the title of the self-driving car’s “eyes:”

Figure 1: McKinsey&Company Evaluation of Autonomous Vehicle Sensors

Figure 2: National Instruments Visual of ADAS Sensors

But self-driving car do more than just “see” the world. The cars also are equipped with sensors onboard that can tell the vehicle more about the surrounding world and itself. These sensors tell how fast the car is moving; the G-force acceleration experienced by the vehicle in forward-back, side-to-side, and up-and-down directions; the current steering angle; and lots more. It is a combination of these perception systems (camera, LiDAR, Radar) and sensor systems (GPS, IMU, Wheel Speed, etc) that make up the inputs to the “sense” block of the self-driving car AV stack.

Part 2: How well can a self-driving car sense the world?

Often included in the “sense” block of the AV Stack is the integration of all of the sensors, which let’s the vehicle make determinations about the environment. Examples include “there’s a pedestrian coming out of the bushes on the left side at 3 mph towards the vehicle,” or “it’s nighttime and raining,” or even “the vehicle is driving up a 10% hill while turning at a 3-degree angle.” The integration of sensors together is called “sensor fusion,” and the determination of what is going on in the environment is called many things, but commonly referred to as “Scene Understanding.”

There is a huge industry focus on developing this layer of the AV Stack. Engineers want the car to be able to see and understand the world with the “intelligence” of humans. Some of the most brilliant people are working on software algorithms that fall under the “Artificial Intelligence,” “Machine Learning,” and “Deep Learning” buckets to allow the car understand what it sees:

So, with all of these sensors and algorithms, how can we be sure that everything’s working correctly? We break each component or some grouping of the components into their inputs and outputs and verify they are doing what they were intended to do. We run tons of tests to get a bunch of data, and then run statistics on that data to prove with some confidence, that the component or group functions correctly.

Below we will break down each of the components and determine how we verify them.

Cameras

Most camera testing is done at the company that makes the camera. A camera is fundamentally a sensor that grabs a bunch of color points in space and arranges them into an image, often referred to as an image array. This image array is converted into a digital signal and is passed along to the hardware that does sensor fusion and scene understanding. Camera technology is fairly mature, and the processes for verifying that the camera converts the right picture to digital lines is well understood, so it should not be an area of concern for autonomous vehicles.

LiDAR

LiDAR systems for autonomous vehicles are relatively new, with the first player, Velodyne, only really demonstrating this capability in 2005 at the first DARPA Grand Challenge. LiDAR technology is quickly evolving, with the goal to make the LiDAR sensor economical and compact. With this technology shift, companies making LiDAR systems are having to adjust the ways they verify their systems.

LiDAR is a laser-light point-and-shoot methodology for sensing the world. A transmitter spits out a bit of light, waits for that light to bounce off an object, and since it knows how fast light travels, can determine how far away that object is by determining the time that’s passed between sending out that light and receiving it. LiDAR units can broaden their field of view by using a bunch of lasers that spin around in a circle, or more recently, as a stationary bunch of lasers that spread out along a field of view, called “Solid State LiDAR.” After all the light is received, the LiDAR system sends an array of direction and distance information back to the hardware for sensor fusion and scene understanding, referred to as a “point cloud.”

In order to verify the LiDAR system acts appropriately, an engineer can setup an artificial scene with predetermined objects a known distance away and verify the results of the LiDAR. More advanced test methodologies involve having another light source feed in light to the LiDAR being tested with a time-based pattern that represents a known field of view, and then the Engineer can compare the results of the LiDAR with the known, simulated environment. This type of testing is called “Hardware in the Loop” since there is a test system that simulates a known stimulus to the hardware under test, and the feedback from that hardware goes back to the test system, making a “loop.”

There are many more ways engineers verify the correct functionality of the LiDAR system, including stress testing the unit at various weather conditions, and ensuring that it functions appropriately with different electrical signals going to and from the unit. In all, this is can be a very involved procedure, and engineers picking LiDAR systems for their self-driving cars should do their research before selecting a unit. Suppliers will provide data on the life expectancy, accuracy, and failure expectations of their units, but engineers putting LiDAR systems in vehicles must perform their own safety tests as well.

Radar

Radar has been around forever. It is similar to LiDAR in that it is a “point-and-shoot” technology, but uses radio, or electromagnetic, waves to do this. Radar lends itself well to long-distance object detection but is not typically very precise.

So how do you test this thing? Well, it’s just like LiDAR, but since the RADAR technology is less expensive and better understood, some companies are already creating tools for this purpose:

Again, engineers need to work with Radar suppliers to make sure they stringently test their devices and that those engineers again retest the unit once it’s onboard their vehicle.

Vehicle Sensors

Vehicle sensors have been built into cars for quite some time, but only since 1993 did the International Organization of Standardization (ISO) determine that the way a sensor talks to a car will be through a digital 2-wire protocol developed by Robert Bosch Gmbh called the “CAN Bus:”

Figure 5: CAN Bus, CSS Electronics

Sensors that sit on the CAN bus are plentiful. They include accelerometers, Internal Measurement Units (IMUs), Vehicle speed sensors, wheel sensors, joint angle sensors, tire pressure, and many, many more. The ISO (ISO 11898) standard is what ensures that the makers of these sensors are verifying their sensors before they ship to a customer.

If you’re retrofitting a vehicle for automation, you’ll need to plug into that CAN bus and make sure you’re able to decipher the signals and send your own. After all, the vehicle must read these signals to operate appropriately. In a “Drive By Wire” (DBW) vehicle, there are no manual, only digital, connections between the accelerator, brake, or steering wheel and the engine and wheels. The CAN bus is what communicates the intentions of the driver to the vehicle.

If you’re building an autonomous vehicle from the ground up, you’ll need to ensure the appropriate selection and mounting of sensors. This must also be verified by driving the vehicle or simulating a drive with HIL testing, and then analyzing the results from the sensors. Same goes for any additional sensors added to an existing vehicle.

What if one of the sensors is off?

Here’s where the engineers again need to step in. Their algorithms onboard the sense layer must do a sanity check of the sensors at some predetermined interval. Adjustments should be made if necessary. There should also be some redundancy in the sensors.

If one of the sensors malfunctions or disconnects, or if your vehicle is struck and a camera moves, what happens? Well, if the system “self-calibrates,” its sensors, this should catch some of these issues. Otherwise, the system may just need to send a command to the rest of the software stack that a sensor is malfunctioning, and the rest of the AV stack can decide what to do.

Engineers need to make sure that the decision on how to handle a malfunctioning sensor is correct. Like how LiDAR is tested, an engineer can send simulated signals to the sensor fusion hardware that represent a failure of a sensor and see how the system responds (HIL). Even before that happens though, the engineer can send simulated data in software to the segment of code on a development environment to see how that code responds. This method of testing is called “Software-in-the Loop” or SIL, testing because the program that’s testing the code sends data to the software being tested and gets a response back, again making a “loop.”

All these tests are run under various conditions and a ton of data is produced. That data is categorized, labeled, and analyzed to provide a statistical determination about how well the vehicle recognized the sensor failure and how it responded.

Scene Understanding: Static or Semi-Static Objects

Ah more software running on hardware to test! The software for scene understanding can be quite complex and can even be a “black box” to many engineers developing it. Regardless, it is up to these engineers to be sure that it’s objectively safe.

An engineer testing scene understanding will verify the software at many times during development. They can even split parts of the scene, such as first checking “is there an object” then “what is that object” and even then “what does that mean for me?”

Thousands of simulations with images, LiDAR data, and Radar data can be fed in software to the scene understanding to check that the scene is correct. Often, this requires a set of “Training data” where the result is already well known (that’s a dog). A bunch of data is then analyzed, and again a statistical probability that the scene understanding was correct is provided.

Engineers can take this one step further by simulating camera, LiDAR, and Radar signals to the sensors on the vehicle and testing if the scene understanding system got the scene correct. This is the HIL approach.

To test scene understanding, engineers need tons of images and point clouds. A single one of these images takes up significant space, so a car operating in real-time would fill 4 TB of data in an hour and a half, equivalent to 250 Million pages of paper, or 83 days of watching DVDs straight (source).

Figure 6: Intel Car Data (Source)

As you can imagine, managing all this data for testing a vehicle is a big challenge. But engineers are working through this and can provide stats on just how good their scene understanding algorithms are. This should inspire the public.

Scene Understanding: Dynamic and Real-Time Objects

This is just like static objects, but now you need multiple back-to-back images and point cloud information to understand how objects are moving in space. So not only do you need to correctly identify objects, you need to know how they’re moving and where they will likely be next based on physics and reasoning. This can be especially challenging.

Just like for static data, engineers must simulate environments that are dynamic with SIL and HIL and prove the scene understanding made the right prediction. You now need series of images over time and you need to test this quite stringently, because head-on-collisions with another moving body can be deadly.

Luckily, engineers are figuring this one out too, but they need more and more data. For some of these challenges, the algorithms that engineers use are not fully mature, but there’s daily progress on that front. This is one the public should be keenly aware of.

Scene Understanding: Vehicle-Road Scenario

OK, so now you’re confident the robot “driver” of the vehicle sees the road correctly. What else does it need to do? Well, it needs to figure out the scenario of the car in space at any given time. You as a driver do this all the time. You can easily tell if you’re going up or down a hill, if you’re in a turn or going straight, or if the roads are covered in snow or clear. More complex things you may pick up on are being sucked into the back of your chair, or forced towards the windshield, or swaying off to the side based on the Gs the vehicle is imparting on you.

A vehicle can figure out all these thing by sensor fusion. It can read the linear acceleration from the IMU and tell the angle of the car and how fast it’s pitching forward/back, rolling side-to-side, or yawing through a turn.

Figure 7: SAE Axis System

A combination of perception and acceleration information can tell the inclination or bank of the road, even dips and crests. Perception and wheel speed vs vehicle speed allows the vehicle to guess the coefficient of friction between the road and tires (albeit, this one can be quite challenging).

Since we trust the sensors already, we test the ability to understand the road by simulating data to the software that represents certain road conditions (SIL), by sending simulated signals to the sensors that represents road conditions (HIL), and even by putting the vehicle on a jig, called a chassis dynamometer, and verifying the results the system spits out:

Figure 8: Meidensha Chassis Dyno (Source)

For this one, there is no ISO standard, and the Society of Automotive Engineers (SAE) have not recommended an approach to take to guarantee that the vehicle knows itself. Many autonomous vehicle companies are relying on only the perception and GPS map information to provide this information. Vehicle makers will need to get better at this in the future to ensure the safety of the vehicles, and this will be especially evident when we discuss path planning.

The Hardware that hosts the Stack

There’s another ongoing battle about the appropriate hardware to host all this software described above. Some of the many players in the game are the CPU, GPU, FPGA, ASIC, TPU, IPU, MCU, etc. They have their tradeoffs, and some of them can be loosely described by this image:

Figure 9: Silicon Alternatives (Source)

In today’s (2018) world of self-driving-car prototypes, we see most cars built using a combination of CPUs and GPUs. Though in the future, this will likely be some combination of the hardware contenders:

Figure 10, 11, 12: Adrian Colyer (Source)

So, what needs to be tested in hardware? Well, in the images above, you see a metric called “Latency” and a metric called “Power.” Latency is how long it took to for the software on the hardware to make a decision. You want to minimize this. “Power” is how much electrical energy it took to make that decision. You want to minimize this as well, because more power consumption means you can drive the car less distance, whether it’s a gas or electric vehicle. Certain decisions are higher priority than others, as we’ll also discuss in Part 3 and Part 4. For example, you need to know if there’s an emergency scenario immediately, but you may only need to check on the temperature of the outside air every couple of seconds, since temperature changes much more slowly.

You test both latency and power by giving the hardware a “load,” or some task to do while you watch it perform. You measure how much voltage and current that task consumes, and you multiply them together to get Power. You also benchmark how long it took each task to complete and you log that too.

Latency can be a double-edged sword though. You may have two pieces of hardware where one runs much faster than the other 90% of the time, but 10% of the time runs slower. The other piece of hardware always runs at the exact same time through all tests. The amount of variation in latency is called determinism. What you need for a mission-critical task is a low-latency, deterministic system. You can offload non-mission-critical items to things with higher latency and/or non-deterministic systems, ideally that consume the minimal power possible.

So, an engineer must make the right decision on the hardware selection and test it themselves to make sure they get the response they need while consuming the smallest amount of power. Lots of data again!

Conclusion

So where does this leave us? Well, it should be clear that some combination of SIL, HIL, and real-world testing is required to make sure the sensing system works appropriately. It should be also clear that to do this requires massive amounts of data, a ton of time, and a bunch of tools to help the engineers navigate all this. Some of the tests are standardized, others are not. For us to be sure the vehicle senses the world correctly, we’re going to rely on this process improving over time where each element is objectively better than a human driver.",https://cdn-images-1.medium.com/max/1200/1*ebuUG7HWL0v594-yDp46Kg.jpeg,[],https://medium.com/@olley_io/how-to-ensure-the-safety-of-self-driving-cars-part-2-5-b4eafb067534?source=topic_page---8------4----------------,2018-06-05 18:25:54.142000+00:00

Machine Learning,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------,2018-06-08 22:25:33.341000+00:00

Machine Learning,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------#--responses,2018-06-08 22:25:33.341000+00:00

Machine Learning,How to build a range slider component in React from scratch using only <div> and <span>,['Rajesh Pillai'],"How to build a range slider component in React from scratch using only <div> and <span>

In this article we will build a React range slider component step by step using only <div>. We will enable it with touch support.

What can you do with a piece of about 50 <div’s>?

Build a slider control from scratch. If this sounds interesting, then follow along.

The final output will look like the below animation.

Please do note that I have developed this component as a teaching exercise for my students of ReactJS — Beyond the Basics course on Udemy, so it may have some edge cases (which I will fix as and when encountered).

You could use an HTML5 range control and customize it. But I wanted to take a different approach and build something from scratch. And the result is what you see here.

Our slider component will be composed of the below three elements:

A slider range

The actual slider controls

The current selection range

Defining the state for our component

Let us begin by defining our state. I am only showing you the important part of the code. For the full source code, please refer to the link at the end of the article.

state = {

slots: 24,

start: 0,

end: 10,

labelMode: ""mid"", // mid, long

}

The state contains the following properties.

slots: Total slots to be drawn (in this case I am using it as a time selector, so it will have 24 hour slots)

start: The start value of the selection

end: The end value of the selection

labelMode: Currently unused. But can be used to customize the scale label rendering.

The return part of the render method

Let us now take a look at the return part of the render method. The render() method will be slowly composed of small pieces of functionality.

return (

<div>

<h2>React Slider</h2>

<div className=""example-1"">

<div className=""slider-container"">

<div className=""slider-scale"">

{scale}

</div>

<div className=""slider"">

{slider}

</div>

<div className=""slider-selected-scale"">

{currentScale}

</div>

</div>

</div>

</div>

);

For those reading on mobile, the below image may be handy, as sometimes Medium breaks the code formatting.

If you take a look at the code, there are only three important pieces:

scale variable

slider variable

currentScale variable

The three variables above will be responsible for rendering the correct parts of the overall slider.

Dissecting the render () method

Let us initialize some variables. The scale , slider and currentScale JSX will be created within the for loop defined below.

render () {

let scale = [];

let slider=[];

let currentScale = [];

let minThumb = null;

let maxThumb = null

..... // rest of the code

}

Create the JSX for the ‘scale’ variable

Creating the JSX for the scale variable is quite simple. We just loop through the slots value in the state and push a <div> to the scale array with the required CSS class for styling.

The if condition ensures that we are only printing the label for i = 0, i = 12, or i = 24 (kind of mid range). Please feel free to customize this.

for (let i = 0; i <= this.state.slots;i++) {

let label = """";



if (i == 0 || i == 12 || i == 24) {

label = i;

}



scale.push(

<div

key={i}

className=""slot-scale"">

{label}

</div>

);

Here’s the code in image format:

Create the JSX for the ‘currentScale’ variable

Let us now continue with the same for loop and create the ‘currentScale’ JSX. We are still within the same for loop, so about 24 divs will be created as per the value in this.state.slots value.

The currentScale has a class of ‘slot-scale-selected’.

let currentLabel = """";



if (i === this.state.start || i === this.state.end) {

currentLabel = i;

}



currentScale.push(

<div

key={i}

className=""slot-scale-selected"">

{currentLabel}

</div>

);

The code is pretty similar to the ‘scale’ JSX that we created.

Create the JSX for the ‘slider’ variable

Let us write a function to render the ‘slider’ jsx. The slider needs two thumbs, one for min, and one for max.

Let us first initialize the thumb variable depending on the ‘i’ value. If ‘i’ is the same as this.state.start, then we set the minThumb variable. Else if the value of ‘i’ is the same as this.state.end, then we initialize the maxThumb variable.

if (i === this.state.start) {

minThumb = <this.MinSlider />

} else if (i === this.state.end) {

maxThumb = <this.MaxSlider />

} else {

minThumb = null;

maxThumb = null;

}

Create the JSX for the ‘slider’

The important code piece here is the dragover event. This is required for the HTML drop to work correctly.

let lineClass = ""line"";



if (i >= this.state.start && i < this.state.end) {

lineClass += "" line-selected"";

}

slider.push(

<div

data-slot={i}

onDragOver={this.onDragOver}

onTouchMove = {this.onDragOver}

onTouchEnd = {this.onDrop}

onDrop = {this.onDrop}

key={i}

className=""slot"">

<div data-slot={i} className={lineClass}/>

<span className=""scale-mark""></span>

{minThumb}

{maxThumb}

</div>

);

The slider variable needs two additional pieces of features to represent the min and the max thumb on the slider.

The slider JSX has additional event handlers to deal with handling the drop event/touchend event. We will take a look at the event handlers shortly.

The ‘lineClass’ styles/renders the line on the slider, and the ‘line-selected’ class styles the currently selected range.

Let us now write the MinSlider and MaxSlider function outside the render method.

The MinSlider () function to render the min thumb

Let’s take a look at the code. The important props are the events related to drag and the draggable attribute. The draggable attribute will make this element draggable.

We are also adding the touch event handler. Refer to the link at the bottom of the article to add touch support polyfill for the HTML5 API.

MinSlider=()=> {

return (

<div data-slider=""min""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-min"">

</div>

);

}

The MaxSlider () function to render the min thumb

The MaxSlider is almost the same as the MinSlider except for the data and the className.

MaxSlider=()=> {

return (

<div data-slider=""max""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-max"">

</div>

);

}

The code image is given below for reference.

Event Handling

Let us now look at the drag/touch event handlers defined within our <div> to control the movement of the slider element.

dragover:

The dragover event is required to support the drop zone when using the HTML5 drag/drop API. The only thing we need to do here is to invoke the preventDefault on the event object.

onDragOver = (e) => {

e.preventDefault();

}

dragstart:

The dragstart enables us to store which slider is being dragged. Please note that I am not using the dataTransfer object here, but simply using an instance variable to store this.

onDragStart = (e) => {

let slider = e.target.dataset.slider;

this.sliderType = slider;

}

The value of e.target.dataset.slider is either “min” or “max,” indicating which slider is being dragged.

ondrop:

The ondrop event captures where the thumb is being dropped (on which scale).

This is the important flow in the ondrop event:

Grab the source (whether min/max thumb)

Get the slot (where the drop happens)

Validations

Update the slot (in the state)

Reset the sliderType.

onDrop = (e, target) => {

let source = this.sliderType;

let slot = Number(e.target.dataset.slot);



if (isNaN(slot)) return;



if (source === ""min"") {

if (slot >= this.state.end) return;

this.setState({

start: slot

},()=>{

console.log(this.state);

})

} else if (source === ""max"") {

if (slot <= this.state.start) return;

this.setState({

end: slot

},()=>{

console.log(this.state);

})

}

this.sliderType = null;

}

The complete source code/and demo can be seen here http://jsbin.com/remodat/edit?output

Since I am using HTML5 drag and drop features to add touch, support please add this polyfill reference to your html file.

Todos

Extract the logic to a separate Component class

Test it and and add customization.

History

21-May-2018 — First release

P.S: This component is a result of a very quick coding attempt. This will be refactored.

Promotion: If you would like to support our open source curriculum Mastering Full Stack Engineering in 12 to 20 weeks then here is a special 10$ coupon for medium readers for my upcoming live ReactJS-Beyond the basicscourse on udemy (MEDIUM_500 is the coupon code, which is already tagged in the above URL)",https://cdn-images-1.medium.com/max/1200/1*iSkeoPHBQubtAL4fV4h9xQ.png,[],https://medium.freecodecamp.org/how-to-build-a-range-slider-component-in-react-from-scratch-using-only-div-and-span-d53e1a62c4a3?source=collection_home---6------1----------------,2018-06-08 21:41:33.808000+00:00

Machine Learning,The well-kept secret behind great UX: Usability Testing,['Anant Jain'],"The well-kept secret behind great UX: Usability Testing

Whether you only have a prototype or a full-fledged product, it’s a really good idea to run monthly usability tests. These make sure that whatever you’re working on is usable and the user experience is excellent.

If you’re wondering what you can do to make your usability tests more structured and organized, this guide is for you. Let’s get started!

First off, always keep the two Golden Rules of Usability Testing in mind:

Any testing is better than no testing (with no one!) A little testing earlier is better than a lot of testing later.

In this post, I will introduce you to the kind of lightweight usability testing described in Steve Krug’s books, “Don’t Make Me Think” and “Rocket Surgery Made Easy.” Steve calls this kind of testing “Do-It-Yourself Usability Testing” since it’s supposed to be cheap, easy-to-do and takes just a morning a month.

A quick intro to usability testing

The idea behind this is to:

Find a few participants

Ask them to come in and go through a list of user flows you want to test

Observe the problems they run into

Finally, make a list of issues to fix

Sounds simple enough, but very few of us actually do it. The goal of this post is to make you confident enough to run at least one usability test session this month. I ran my first usability test only a year ago, and I must say it’s actually a lot of fun!

Before we get to the test itself, here are a few things to note:

Reserve one morning a month (say the third Thursday every month) for a round of testing, debriefing, and deciding what to fix. Test with three participants each round. Recruit loosely, and grade on a curve. You don’t need to find someone who fits the exact mould of your ideal user, since most usability problems can be uncovered by testing with just about anyone. If you are part of a big company and have the budget, you can recruit via Craigslist and offer a $50 gift card for an hour of the participant’s time. If you don’t have those kind of resources, don’t worry — you can ask your friends, your existing users, or even go to a café and ask strangers for 15 minutes of their time in exchange for buying them a coffee. If you’re doing this as part of a bigger team, get as many observers as possible to observe the tests in a separate observation room. These will be the designers, engineers, project managers, executives, etc. Or, in case of side projects, it’ll be just be you later in your room!

What happens during the test?

During a usability test, you will record the participant’s voice and their computer screen, and share both these streams live with observers in another room. A typical one-hour test can be broken down into:

Welcome (4 mins): Explain how the test will work so that the participant will know what to expect. The questions (2 mins): Ask the participant a few questions about themselves. This helps put them at ease and gives you an idea of how computer-savvy they are. The Homepage tour (3 mins): Open the Home page of your site, and ask the participant to look around and tell you what they think. This will give you an idea of how easy it is to understand your home page, as well as how familiar the participant is with your domain. The tasks (35 minutes): Watch the participant perform a series of tasks you have prepared for them beforehand. If you’re building a SaaS product and you’re testing out your subscription flow, a typical task could be to find the Pricing page, compare various plans, and Subscribe to one of the plans with a provided test credit card number. Encourage the participant to think out loud as they perform the task (see the video at the end of the post for a sample test.) It’s crucial that you let them work on their own and not ask them any leading questions, or give out any clues or assistance. Probing (5 mins): Ask the participant any questions you may have about anything that happened during the test and about any issues that people in the observation room may have. Also, answer any questions that the participant may have at this point (don’t answer them during the actual tasks since you’re testing how they’ll perform with no one around.) Wrapping Up (5 mins): Thank them for their help, and give them their gift card if you promised one while recruiting them.

The debrief

During the breaks between successive tests, ask the observers to write down the top 3 usability problems that they saw. During the debriefing, focus ruthlessly on deciding to fix the most severe problems first. Here are a few other recommendations:

Keep a separate list of low-hanging fruit. These are the problems you can typically fix with one-line code changes, but have a huge impact on task completion rates. Joel Califa calls them “tiny wins”. Here’s an example:

Resist the impulse to add things — instead, try to tweak your existing design to fix the problem.

to fix the problem. Take “new feature” requests with a grain of salt. Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature.

Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature. Ignore the problems where the user goes astray for a bit but comes back on track by themselves. These are usually not worth investing much time unless you see a pattern across multiple participants.

Good design is a delicate balance, so when fixing a problem, ensure that you aren’t introducing new ones.

Remote testing and unmoderated user testing

Remote testing is very similar to an in-person usability test, except that the participant is at their home/office and you conduct the testing via screen sharing and voice call.

Unmoderated user testing is another way to test, where you specify your website, the tasks you want the users to do, and get back video recordings of people trying to accomplish those tasks. Usertesting.com is the leader in this space, but note that a single 30-minute test costs about $50.

Resources

You can download checklists, interview script, consent form, and a demo video at Steve Krug’s site here: Downloads for Rocket Surgery Made Easy.

Here’s a Usability Test demo video from Google Ventures:

I want to thank you for reading this quick guide. This was originally published as part of the UX Design course on Commonlounge, a platform that has courses with small bite-sized lessons like these on topics ranging from Project Management to Machine Learning that deliver the most value for the time you put in.

You learn by working on real-world projects and getting feedback from industry mentors. You should check it out here!",https://cdn-images-1.medium.com/max/1200/0*UWxJWKKNLXR5c1cm,[],https://medium.freecodecamp.org/the-well-kept-secret-behind-great-ux-usability-testing-b788178a64c3?source=collection_home---6------2----------------,2018-06-08 21:25:31.335000+00:00

Machine Learning,An introduction to part-of-speech tagging and the Hidden Markov Model,['Divya Godayal'],"Let’s go back into the times when we had no language to communicate. The only way we had was sign language. That’s how we usually communicate with our dog at home, right? When we tell him, “We love you, Jimmy,” he responds by wagging his tail. This doesn’t mean he knows what we are actually saying. Instead, his response is simply because he understands the language of emotions and gestures more than words.

We as humans have developed an understanding of a lot of nuances of the natural language more than any animal on this planet. That is why when we say “I LOVE you, honey” vs when we say “Lets make LOVE, honey” we mean different things. Since we understand the basic difference between the two phrases, our responses are very different. It is these very intricacies in natural language understanding that we want to teach to a machine.

What this could mean is when your future robot dog hears “I love you, Jimmy”, he would know LOVE is a Verb. He would also realize that it’s an emotion that we are expressing to which he would respond in a certain way. And maybe when you are telling your partner “Lets make LOVE”, the dog would just stay out of your business 😛.

This is just an example of how teaching a robot to communicate in a language known to us can make things easier.

The primary use case being highlighted in this example is how important it is to understand the difference in the usage of the word LOVE, in different contexts.

Part-of-Speech Tagging

From a very small age, we have been made accustomed to identifying part of speech tags. For example, reading a sentence and being able to identify what words act as nouns, pronouns, verbs, adverbs, and so on. All these are referred to as the part of speech tags.

Let’s look at the Wikipedia definition for them:

In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging or word-category disambiguation, is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context — i.e., its relationship with adjacent and related words in a phrase, sentence, or paragraph. A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.

Identifying part of speech tags is much more complicated than simply mapping words to their part of speech tags. This is because POS tagging is not something that is generic. It is quite possible for a single word to have a different part of speech tag in different sentences based on different contexts. That is why it is impossible to have a generic mapping for POS tags.

As you can see, it is not possible to manually find out different part-of-speech tags for a given corpus. New types of contexts and new words keep coming up in dictionaries in various languages, and manual POS tagging is not scalable in itself. That is why we rely on machine-based POS tagging.

Before proceeding further and looking at how part-of-speech tagging is done, we should look at why POS tagging is necessary and where it can be used.

Why Part-of-Speech tagging?

Part-of-Speech tagging in itself may not be the solution to any particular NLP problem. It is however something that is done as a pre-requisite to simplify a lot of different problems. Let us consider a few applications of POS tagging in various NLP tasks.

Text to Speech Conversion

Let us look at the following sentence:

They refuse to permit us to obtain the refuse permit.

The word refuse is being used twice in this sentence and has two different meanings here. refUSE (/rəˈfyo͞oz/)is a verb meaning “deny,” while REFuse(/ˈrefˌyo͞os/) is a noun meaning “trash” (that is, they are not homophones). Thus, we need to know which word is being used in order to pronounce the text correctly. (For this reason, text-to-speech systems usually perform POS-tagging.)

Have a look at the part-of-speech tags generated for this very sentence by the NLTK package.

>>> text = word_tokenize(""They refuse to permit us to obtain the refuse permit"")

>>> nltk.pos_tag(text)

[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'),

('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]

As we can see from the results provided by the NLTK package, POS tags for both refUSE and REFuse are different. Using these two different POS tags for our text to speech converter can come up with a different set of sounds.

Similarly, let us look at yet another classical application of POS tagging: word sense disambiguation.

Word Sense Disambiguation

Let’s talk about this kid called Peter. Since his mother is a neurological scientist, she didn’t send him to school. His life was devoid of science and math.

One day she conducted an experiment, and made him sit for a math class. Even though he didn’t have any prior subject knowledge, Peter thought he aced his first test. His mother then took an example from the test and published it as below. (Kudos to her!)

Word-sense Disambiguation example — My son Peter’s first Maths problem.

Words often occur in different senses as different parts of speech. For example:

She saw a bear.

Your efforts will bear fruit.

The word bear in the above sentences has completely different senses, but more importantly one is a noun and other is a verb. Rudimentary word sense disambiguation is possible if you can tag words with their POS tags.

Word-sense disambiguation (WSD) is identifying which sense of a word (that is, which meaning) is used in a sentence, when the word has multiple meanings.

Try to think of the multiple meanings for this sentence:

Time flies like an arrow

Here are the various interpretations of the given sentence. The meaning and hence the part-of-speech might vary for each word.

Part-of-speech tags define the meaning of a sentence based on the context

As we can clearly see, there are multiple interpretations possible for the given sentence. Different interpretations yield different kinds of part of speech tags for the words.This information, if available to us, can help us find out the exact version / interpretation of the sentence and then we can proceed from there.

The above example shows us that a single sentence can have three different POS tag sequences assigned to it that are equally likely. That means that it is very important to know what specific meaning is being conveyed by the given sentence whenever it’s appearing. This is word sense disambiguation, as we are trying to find out THE sequence.

These are just two of the numerous applications where we would require POS tagging. There are other applications as well which require POS tagging, like Question Answering, Speech Recognition, Machine Translation, and so on.

Now that we have a basic knowledge of different applications of POS tagging, let us look at how we can go about actually assigning POS tags to all the words in our corpus.

Types of POS taggers

POS-tagging algorithms fall into two distinctive groups:

Rule-Based POS Taggers

Stochastic POS Taggers

E. Brill’s tagger, one of the first and most widely used English POS-taggers, employs rule-based algorithms. Let us first look at a very brief overview of what rule-based tagging is all about.

Rule-Based Tagging

Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods.

Typical rule-based approaches use contextual information to assign tags to unknown or ambiguous words. Disambiguation is done by analyzing the linguistic features of the word, its preceding word, its following word, and other aspects.

For example, if the preceding word is an article, then the word in question must be a noun. This information is coded in the form of rules.

Example of a rule:

If an ambiguous/unknown word X is preceded by a determiner and followed by a noun, tag it as an adjective.

Defining a set of rules manually is an extremely cumbersome process and is not scalable at all. So we need some automatic way of doing this.

The Brill’s tagger is a rule-based tagger that goes through the training data and finds out the set of tagging rules that best define the data and minimize POS tagging errors. The most important point to note here about Brill’s tagger is that the rules are not hand-crafted, but are instead found out using the corpus provided. The only feature engineering required is a set of rule templates that the model can use to come up with new features.

Let’s move ahead now and look at Stochastic POS tagging.

Stochastic Part-of-Speech Tagging

The term ‘stochastic tagger’ can refer to any number of different approaches to the problem of POS tagging. Any model which somehow incorporates frequency or probability may be properly labelled stochastic.

The simplest stochastic taggers disambiguate words based solely on the probability that a word occurs with a particular tag. In other words, the tag encountered most frequently in the training set with the word is the one assigned to an ambiguous instance of that word. The problem with this approach is that while it may yield a valid tag for a given word, it can also yield inadmissible sequences of tags.

An alternative to the word frequency approach is to calculate the probability of a given sequence of tags occurring. This is sometimes referred to as the n-gram approach, referring to the fact that the best tag for a given word is determined by the probability that it occurs with the n previous tags. This approach makes much more sense than the one defined before, because it considers the tags for individual words based on context.

The next level of complexity that can be introduced into a stochastic tagger combines the previous two approaches, using both tag sequence probabilities and word frequency measurements. This is known as the Hidden Markov Model (HMM).

Before proceeding with what is a Hidden Markov Model, let us first look at what is a Markov Model. That will better help understand the meaning of the term Hidden in HMMs.

Markov Model

Say that there are only three kinds of weather conditions, namely

Rainy

Sunny

Cloudy

Now, since our young friend we introduced above, Peter, is a small kid, he loves to play outside. He loves it when the weather is sunny, because all his friends come out to play in the sunny conditions.

He hates the rainy weather for obvious reasons.

Every day, his mother observe the weather in the morning (that is when he usually goes out to play) and like always, Peter comes up to her right after getting up and asks her to tell him what the weather is going to be like. Since she is a responsible parent, she want to answer that question as accurately as possible. But the only thing she has is a set of observations taken over multiple days as to how weather has been.

How does she make a prediction of the weather for today based on what the weather has been for the past N days?

Say you have a sequence. Something like this:

Sunny, Rainy, Cloudy, Cloudy, Sunny, Sunny, Sunny, Rainy

So, the weather for any give day can be in any of the three states.

Let’s say we decide to use a Markov Chain Model to solve this problem. Now using the data that we have, we can construct the following state diagram with the labelled probabilities.",https://cdn-images-1.medium.com/max/1200/1*f6e0uf5PX17pTceYU4rbCA.jpeg,[],https://medium.freecodecamp.org/an-introduction-to-part-of-speech-tagging-and-the-hidden-markov-model-953d45338f24?source=collection_home---6------3----------------,2018-06-08 19:31:14.123000+00:00

Machine Learning,A deep dive into part-of-speech tagging using the Viterbi algorithm,['Sachin Malhotra'],"Welcome back, Caretaker!

In case you’ve forgotten the problem we were trying to tackle in the previous article, let us revise it for you.

So there’s this naughty kid Peter and he’s going to pester his new caretaker, you!

As a caretaker, one of the most important tasks for you is to tuck Peter in bed and make sure he is sound asleep. Once you’ve tucked him in, you want to make sure that he’s actually asleep and not up to some mischief.

You cannot, however, enter the room again, as that would surely wake Peter up. All you can hear are the noises that might come from the room.

Either the room is quiet or there is noise coming from the room. These are your states.

All you have as the caretaker are:

a set of observations, which is basically a sequence containing noise or quiet over time, and

or over time, and A state diagram provided by Peter’s mom — who happens to be a neurological scientist — that contains all the different sets of probabilities that you can use to solve the problem defined below.

The problem

Given the state diagram and a sequence of N observations over time, we need to tell the state of the baby at the current point in time. Mathematically, we have N observations over times t0, t1, t2 .... tN . We want to find out if Peter would be awake or asleep, or rather which state is more probable at time tN+1 .

In case any of this seems like Greek to you, go read the previous article to brush up on the Markov Chain Model, Hidden Markov Models, and Part of Speech Tagging.

The state diagram that Peter’s mom gave you before leaving.

In that previous article, we had briefly modeled the problem of Part of Speech tagging using the Hidden Markov Model.

The problem of Peter being asleep or not is just an example problem taken up for a better understanding of some of the core concepts involved in these two articles. At the core, the articles deal with solving the Part of Speech tagging problem using the Hidden Markov Models.

So, before moving on to the Viterbi Algorithm, let’s first look at a much more detailed explanation of how the tagging problem can be modeled using HMMs.

Generative Models and the Noisy Channel Model

A lot of problems in Natural Language Processing are solved using a supervised learning approach.

Supervised problems in machine learning are defined as follows. We assume training examples (x(1), y(1)) . . . (x(m) , y(m)) , where each example consists of an input x(i) paired with a label y(i) . We use X to refer to the set of possible inputs, and Y to refer to the set of possible labels. Our task is to learn a function f : X → Y that maps any input x to a label f(x).

In tagging problems, each x(i) would be a sequence of words X1 X2 X3 …. Xn(i) , and each y(i) would be a sequence of tags Y1 Y2 Y3 … Yn(i) (we use n(i)to refer to the length of the i’th training example). X would refer to the set of all sequences x1 . . . xn, and Y would be the set of all tag sequences y1 . . . yn. Our task would be to learn a function f : X → Y that maps sentences to tag sequences.

An intuitive approach to get an estimate for this problem is to use conditional probabilities. p(y | x) which is the probability of the output y given an input x. The parameters of the model would be estimated using the training samples. Finally, given an unknown input x we would like to find

f(x) = arg max(p(y | x)) ∀y ∊ Y

This here is the conditional model to solve this generic problem given the training data. Another approach that is mostly adopted in machine learning and natural language processing is to use a generative model.

Rather than directly estimating the conditional distribution p(y|x) , in generative models we instead model the joint probability p(x, y) over all the (x, y) pairs.

We can further decompose the joint probability into simpler values using Bayes’ rule:

p(y) is the prior probability of any input belonging to the label y.

is the prior probability of any input belonging to the label y. p(x | y) is the conditional probability of input x given the label y.

We can use this decomposition and the Bayes rule to determine the conditional probability.

Remember, we wanted to estimate the function

f(x) = arg max( p(y|x) ) ∀y ∊ Y

f(x) = arg max( p(y) * p(x | y) )

The reason we skipped the denominator here is because the probability p(x) remains the same no matter what the output label being considered. And so, from a computational perspective, it is treated as a normalization constant and is normally ignored.

Models that decompose a joint probability into terms p(y) and p(x|y) are often called noisy-channel models. Intuitively, when we see a test example x, we assume that it has been generated in two steps:

first, a label y has been chosen with probability p(y) second, the example x has been generated from the distribution p(x|y). The model p(x|y) can be interpreted as a “channel” which takes a label y as its input, and corrupts it to produce x as its output.

Generative Part of Speech Tagging Model

Let us assume a finite set of words V and a finite sequence of tags K. Then the set S will be the set of all sequence, tags pairs <x1, x2, x3 ... xn, y1, y2, y3, ..., yn> such that n > 0 ∀x ∊ V and ∀y ∊ K .

A generative tagging model is then the one where

2.

Given a generative tagging model, the function that we talked about earlier from input to output becomes

Thus for any given input sequence of words, the output is the highest probability tag sequence from the model. Having defined the generative model, we need to figure out three different things:

How exactly do we define the generative model probability p(<x1, x2, x3 ... xn, y1, y2, y3, ..., yn>) How do we estimate the parameters of the model, and How do we efficiently calculate

Let us look at how we can answer these three questions side by side, once for our example problem and then for the actual problem at hand: part of speech tagging.

Defining the Generative Model

Let us first look at how we can estimate the probability p(x1 .. xn, y1 .. yn) using the HMM.

We can have any N-gram HMM which considers events in the previous window of size N.

The formulas provided hereafter are corresponding to a Trigram Hidden Markov Model.

Trigram Hidden Markov Model

A trigram Hidden Markov Model can be defined using

A finite set of states.

A sequence of observations.

q(s|u, v)

Transition probability defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations.

defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations. e(x|s)

Emission probability defined as the probability of making an observation x given that the state was s.

Then, the generative model probability would be estimated as

As for the baby sleeping problem that we are considering, we will have only two possible states: that the baby is either awake or he is asleep. The caretaker can make only two observations over time. Either there is noise coming in from the room or the room is absolutely quiet. The sequence of observations and states can be represented as follows:

Observations and States over time for the baby sleeping problem

Coming on to the part of speech tagging problem, the states would be represented by the actual tags assigned to the words. The words would be our observations. The reason we say that the tags are our states is because in a Hidden Markov Model, the states are always hidden and all we have are the set of observations that are visible to us. Along similar lines, the sequence of states and observations for the part of speech tagging problem would be

Observations and States over time for the POS tagging problem

Estimating the model’s parameters

We will assume that we have access to some training data. The training data consists of a set of examples where each example is a sequence consisting of the observations, every observation being associated with a state. Given this data, how do we estimate the parameters of the model?

Estimating the model’s parameters is done by reading various counts off of the training corpus we have, and then computing maximum likelihood estimates:

Transition probability and Emission probability for a Trigram HMM

We already know that the first term represents transition probability and the second term represents the emission probability. Let us look at what the four different counts mean in the terms above.

c(u, v, s) represents the trigram count of states u, v and s. Meaning it represents the number of times the three states u, v and s occurred together in that order in the training corpus. c(u, v) following along similar lines as that of the trigram count, this is the bigram count of states u and v given the training corpus. c(s → x) is the number of times in the training set that the state s and observation x are paired with each other. And finally, c(s) is the prior probability of an observation being labelled as the state s.

Let us look at a sample training set for the toy problem first and see the calculations for transition and emission probabilities using the same.

The BLUE markings represent the transition probability, and RED is for emission probability calculations.

Note that since the example problem only has two distinct states and two distinct observations, and given that the training set is very small, the calculations shown below for the example problem are using a bigram HMM instead of a trigram HMM.

Peter’s mother was maintaining a record of observations and states. And thus she even provided you with a training corpus to help you get the transition and emission probabilities.

Transition Probability Example:

Training Corpus

Calculations for Awake appearing after Awake

Emission Probability Example:

Training corpus

Calculations for observing ‘Quiet’ when the state is ‘Awake’

That was quite simple, since the training set was very small. Let us look at a sample training set for our actual problem of part of speech tagging. Here we can consider a trigram HMM, and we will show the calculations accordingly.

We will use the following sentences as a corpus of training data (the notation word/TAG means word tagged with a specific part-of-speech tag).

The training set that we have is a tagged corpus of sentences. Every sentence consists of words tagged with their corresponding part of speech tags. eg:- eat/VB means that the word is “eat” and the part of speech tag in this sentence in this very context is “VB” i.e. Verb Phrase. Let us look at a sample calculation for transition probability and emission probability just like we saw for the baby sleeping problem.

Transition Probability

Let’s say we want to calculate the transition probability q(IN | VB, NN). For this, we see how many times we see a trigram (VB,NN,IN) in the training corpus in that specific order. We then divide it by the total number of times we see the bigram (VB,NN) in the corpus.

Emission Probability

Let’s say we want to find out the emission probability e(an | DT). For this, we see how many times the word “an” is tagged as “DT” in the corpus and divide it by the total number of times we see the tag “DT” in the corpus.

So if you look at these calculations, it shows that calculating the model’s parameters is not computationally expensive. That is, we don’t have to do multiple passes over the training data to calculate these parameters. All we need are a bunch of different counts, and a single pass over the training corpus should provide us with that.

Let’s move on and look at the final step that we need to look at given a generative model. That step is efficiently calculating

We will be looking at the famous Viterbi Algorithm for this calculation.

Finding the most probable sequence — Viterbi Algorithm

Finally, we are going to solve the problem of finding the most likely sequence of labels given a set of observations x1 … xn. That is, we are to find out

The probability here is expressed in terms of the transition and emission probabilities that we learned how to calculate in the previous section of the article. Just to remind you, the formula for the probability of a sequence of labels given a sequence of observations over “n” time steps is

Before looking at an optimized algorithm to solve this problem, let us first look at a simple brute force approach to this problem. Basically, we need to find out the most probable label sequence given a set of observations out of a finite set of possible sequences of labels. Let’s look at the total possible number of sequences for a small example for our example problem and also for a part of speech tagging problem.

Say we have the following set of observations for the example problem.

Noise Quiet Noise

We have two possible labels {Asleep and Awake}. Some of the possible sequence of labels for the observations above are:

Awake Awake Awake

Awake Awake Asleep

Awake Asleep Awake

Awake Asleep Asleep

In all we can have ²³ = 8 possible sequences. This might not seem like very many, but if we increase the number of observations over time, the number of sequences would increase exponentially. This is the case when we only had two possible labels. What if we have more? As is the case with part of speech tagging.

For example, consider the sentence

the dog barks

and assuming that the set of possible tags are {D, N, V}, let us look at some of the possible tag sequences:

D D D

D D N

D D V

D N D

D N N

D N V ... etc

Here, we would have ³³ = 27 possible tag sequences. And as you can see, the sentence was extremely short and the number of tags weren’t very many. In practice, we can have sentences that might be much larger than just three words. Then the number of unique labels at our disposal would also be too high to follow this enumeration approach and find the best possible tag sequence this way.

So the exponential growth in the number of sequences implies that for any reasonable length sentence, the brute force approach would not work out as it would take too much time to execute.

Instead of this brute force approach, we will see that we can find the highest probable tag sequence efficiently using a dynamic programming algorithm known as the Viterbi Algorithm.

Let us first define some terms that would be useful in defining the algorithm itself. We already know that the probability of a label sequence given a set of observations can be defined in terms of the transition probability and the emission probability. Mathematically, it is

Let us look at a truncated version of this which is

and let us call this the cost of a sequence of length k.

So the definition of “r” is simply considering the first k terms off of the definition of probability where k ∊ {1..n} and for any label sequence y1…yk.

Next we have the set S(k, u, v) which is basically the set of all label sequences of length k that end with the bigram (u, v) i.e.

Finally, we define the term π(k, u, v) which is basically the sequence with the maximum cost.

The main idea behind the Viterbi Algorithm is that we can calculate the values of the term π(k, u, v) efficiently in a recursive, memoized fashion. In order to define the algorithm recursively, let us look at the base cases for the recursion.

π(0, *, *) = 1

π(0, u, v) = 0

Since we are considering a trigram HMM, we would be considering all of the trigrams as a part of the execution of the Viterbi Algorithm.

Now, we can start the first trigram window from the first three words of the sentence but then the model would miss out on those trigrams where the first word or the first two words occurred independently. For that reason, we consider two special start symbols as * and so our sentence becomes

* * x1 x2 x3 ...... xn

And the first trigram we consider then would be (*, *, x1) and the second one would be (*, x1, x2).

Now that we have all our terms in place, we can finally look at the recursive definition of the algorithm which is basically the heart of the algorithm.",https://cdn-images-1.medium.com/max/1200/1*x-5ZBtUvlD78BOMuMnMAbg.png,[],https://medium.freecodecamp.org/a-deep-dive-into-part-of-speech-tagging-using-viterbi-algorithm-17c8de32e8bc?source=collection_home---6------4----------------,2018-06-08 19:05:31.518000+00:00

Machine Learning,How to control your randomizer in R – freeCodeCamp,['Michelle Jones'],"What happens when you need a particular type of randomization?

Overview of random number generation in R

R has at least 20 random number generator functions. Each uses a specific probability distribution to create the numbers. All require you to specify the number of random numbers you want (the above image shows 200). All are available in base R — no packages required.

Common random number generator distributions are:

normal (rnorm): default mean of 0 and standard deviation of 1

binomial (rbinom): no defaults, specify the number of trials and the probability of success on each trial

uniform (runif): default minimum value of 0 and maximum value of 1

Of the three above, only the binomial random number generator creates integers.

Why create random numbers?

Problems involving random numbers are very common — there are around 50,000 questions relating to random numbers on Stack Exchange.

But why use them?

Random numbers have many practical applications. They are used in Monte Carlo simulations. They are used in cryptography. They have been used to produce CAPTCHA content. They are used in slot machines. They have also been used for more mundane tasks such as creating a random sort order for an array of ordered data.

Problems with random numbers

Common questions include “are my random numbers actually random?” and “how can I generate non-repeated random numbers?”

Note: the latter decreases randomness, because the population of possible random numbers is decreased by one each time a random number is drawn. The method is appropriate in situations such as lotteries or bingo, where each ticket or ball can only be drawn once.

This problem brings in another problem! The randomly generated, sampling without replacement numbers must be integers. No one has ticket 5.6932 or bingo ball 0.18967.

A practical example of random number problems

Let’s take the example that I have 20 female students of the same age. I have four teaching methods that I want to trial. I only want to trial one teaching method for each student. Easy math— I need five students in each group.

But how do I do this so that each student is randomly assigned?

And how do I make sure that I only have integers produced?

And how do I do all this while using randomly generated numbers without replacement? I don’t want, for example, six students in one group, and four students in another.

First, I need to create some dummy data, in R. Let’s create that list of mock female students.

FemaleStudents <- data.frame(Names=c(""Alice"", ""Betty"", ""Carol"", ""Denise"", ""Erica"", ""Frances"", ""Gina"", ""Helen"", ""Iris"", ""Julie"", ""Katherine"",

""Lisa"", ""Michelle"", ""Ngaire"", ""Olivia"", ""Penelope"", ""Rachel"", ""Sarah"", ""Trudy"", ""Uma""))

Now we have a one-dimensional dataset of our 20 students.

We know that the runif() function doesn’t create integers. Why don’t we round the random numbers so that we only get integers and use this function? We can wrap the random number in a rounding function.

Question 1: why am I using the random uniform distribution and not another one, such as the random normal distribution?

There are five types of rounding functions in R. We will use round() .

So that we get the same results, I will set a seed for the random number generation. Each time we generate random numbers, we will use the same seed. I’ve decided on 5 as the seed. If you do not set a seed, or if you set a seed other than 5, your results will be different than mine.

set.seed(5)

FemaleStudents$Group <- round(runif(20, 1, 5))

Well, that seemed to work. We have each student allocated to a group numbered between 1 and 5.

Let’s double check our allocation.

table(FemaleStudents$Group)

1 2 3 4 5

2 6 5 4 3

Darn. Only one of the five groups has the correct number of students (Group 4). Why did this happen?

We can check the numbers actually output by runif() without rounding, and letting the output print to the console. Here, the output prints because I have not assigned the function to an object (for example, to a data.frame variable).

set.seed(5)

runif(20,1,5)

[1] 1.800858 3.740874 4.667503 2.137598 1.418601 3.804230 3.111840 4.231741 4.826001 1.441812 2.093140 2.962053 2.273616 3.236691 2.050373

[16] 1.807501 2.550103 4.551479 3.219690 4.368718

As we can see, the rounding caused our problem. But if we hadn’t rounded, each student would have been assigned to a different group.

What do we do?

sample()

sample() is now one of my favourite functions in R. Let’s see how it works.

Randomly allocate to equally sized groups (counts matter)

How can we use it to randomly assign our 20 students to four equally sized groups?

What happens if we try sample() normally?

set.seed(5)

FemaleStudents$Sample <- sample(1:5, nrow(FemaleStudents), replace=TRUE)

Question 2: what output did you get when you used table(FemaleStudents$Sample) ?

We can fix this problem by creating a vector of group numbers, and then using sampling without replacement from this vector. The rep command is used to create a range of repeated values. You can use it to repeat each number in the series, as I have used here. Number 1 is repeated four times, then number 2 is repeated four times, and so forth. You can also use it to repeat a sequence of numbers, if you use this code instead: rep(1:5,4)

OurGroups <- rep(1:5, each=4)

set.seed(5)

FemaleStudents$Sample <- sample(OurGroups, nrow(FemaleStudents), replace=FALSE)

We used our vector of numbers ( OurGroups ) to allocate our students to groups. We used sampling without replacement ( replace=FALSE ) from OurGroups because we need to use each value in that vector. We need to remove each value as we use it.

And we get the result we wanted!

table(FemaleStudents$Sample)

1 2 3 4 5

4 4 4 4 4

Question 3: why did I still set a seed?

Another advantage of sample() is that it doesn’t care about type. We can repeat the allocation using a vector of strings. This can be useful if you don’t want to keep referring back to what “1” means.

OurNamedGroups <- rep(c(""Up"", ""Down"", ""Charmed"", ""Strange"", ""Top""), each=4)

set.seed(5)

FemaleStudents$Sample2 <- sample(OurNamedGroups, nrow(FemaleStudents), replace=FALSE)

table(FemaleStudents$Sample2)

Charmed Down Strange Top Up

4 4 4 4 4

Because we used the same seed, we can see that the same student allocation was performed, irrespective of whether we used numeric or character data for the assignment.

table(FemaleStudents$Sample,FemaleStudents$Sample2)



Charmed Down Strange Top Up

1 0 0 0 0 4

2 0 4 0 0 0

3 4 0 0 0 0

4 0 0 4 0 0

5 0 0 0 4 0

Randomly allocate when group size is not restricted

Sometimes we want to randomly allocate to groups, but we don’t have a vector of groups. We are still only allocating each unit (person, sheep, block of cheese) to a single group, and we use completely random allocation.

Let’s say that our school has a new, special library room. It’s been constructed to be soundproof to give students a better studying environment. The chief librarian would like to know about the experiences of students in that room. The only problem is that the room is limited in size. The chief librarian thinks that around four students is a large enough group to provide the initial feedback.

Again, we can use sample() to pick our student groups. In this case, we have “students who will test the room” and “students who won’t test the room”. I’m going to call them “Test” and “Not test”. These labels have been chosen for being 1. short and 2. easily distinguished.

Because we did sampling without replacement earlier, we didn’t specify probabilities of assignment to groups — we simply pulled out an assignment from a vector. Now we are going to use sampling with replacement. With replacement refers to the group, not to the students.

We need to sample with replacement as we only have two groups (“Test”, “Not test”) and 20 students. If we tried to sample without replacement, our code would error.

Our code is very similar:

set.seed(5)

FemaleStudents$Library <- sample(c(""Test"", ""Not test""), nrow(FemaleStudents), replace=TRUE, prob=c(4/20,16/20))

table(FemaleStudents$Library)

Not test Test

15 5

As you can see, we allocated five students to test the room, not four. This type of result is expected when dealing with small samples. However, our allocation of students is completely random. Each student had exactly the same probability of being assigned to test the room. Whether previous students were testers or not had no impact on the allocation of the next student.

Let’s walk through some of that code.

I’ve constructed a new variable in the data.frame to collect the allocation ( Library ).

Instead of dealing with numbers for group names, I’ve used the strings I mentioned earlier. Because I’ve used strings, the c() must wrap the group names ( “Test”, “Not test” ) and each group name is separated by a comma.

Replacement has been set to TRUE .

The probability of assignment to either group must be provided. This is the prob=c(4/20,16/20) part of the sample() function. Again, note how c() is used to contain the probabilities. Also of interest is that the probabilities can be expressed as fractions, rather than decimals.

Hooray for sample()

I use sample() all the time for the work I am doing. The ability to use strings, as well as to restrict numeric output to integers (and define the desired integer range), provides me with more control than trying to use one of the random number functions.

Answers

Answer 1: I used a random uniform distribution because I wanted each value to be equally probable.

Answer 2: I got this output:

1 2 3 4 5

2 7 4 2 5

Answer 3: If we don’t set a seed value, or we use a different one, the allocation of specific students will be different. For example, when the seed is 5, Alice is allocated to group 2. If the seed is 7, Alice is allocated to group 5. Replication is important when code needs to be re-run (for example, in testing).",https://cdn-images-1.medium.com/max/1200/1*aI6mpoboOmJMKqvEU593xA.png,[],https://medium.freecodecamp.org/how-to-control-your-randomizer-in-r-852ae7d8f80c?source=collection_home---6------6----------------,2018-06-07 20:10:57.677000+00:00

Machine Learning,How to style your webpage or markdown like a Medium article — or however you want,[],"View the respective pages at: https://github.com/ryandav/link-formatter/ and https://ryandav.github.io/link-formatter/

Get started with Sass at https://sass-lang.com/guide",https://cdn-images-1.medium.com/max/1200/1*L8PQs8ubyxZVIr1EC-cZ6Q.png,[],https://medium.freecodecamp.org/style-webpage-or-markdown-like-medium-article-using-html-css-sass-bootstrap-c6f9e64c0955?source=collection_home---6------7----------------,2018-06-07 19:32:27.295000+00:00

Machine Learning,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------,2018-06-07 17:57:40.375000+00:00

Machine Learning,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------#--responses,2018-06-07 17:57:40.375000+00:00

Machine Learning,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------,2018-06-07 15:39:54.084000+00:00

Machine Learning,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------#--responses,2018-06-07 15:39:54.084000+00:00

Machine Learning,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------#--responses,2018-06-06 21:43:33.288000+00:00

Machine Learning,Follow these steps to solve any Dynamic Programming interview problem,['Nikola Otasevic'],"Follow these steps to solve any Dynamic Programming interview problem

Despite having significant experience building software products, many engineers feel jittery at the thought of going through a coding interview that focuses on algorithms. I’ve interviewed hundreds of engineers at Refdash, Google, and at startups I’ve been a part of, and some of the most common questions that make engineers uneasy are the ones that involve Dynamic Programming (DP).

Many tech companies like to ask DP questions in their interviews. While we can debate whether they’re effective in evaluating someone’s ability to perform in an engineering role, DP continues to be an area that trips engineers up on their way to finding a job that they love.

Dynamic Programming — Predictable and Preparable

One of the reasons why I personally believe that DP questions might not be the best way to test engineering ability is that they’re predictable and easy to pattern match. They allow us to filter much more for preparedness as opposed to engineering ability.

These questions typically seem pretty complex on the outside, and might give you an impression that a person who solves them is very good at algorithms. Similarly, people who may not be able to get over some mind-twisting concepts of DP might seem pretty weak in their knowledge of algorithms.

The reality is different, and the biggest factor in their performance is preparedness. So let’s make sure everyone is prepared for it. Once and for all.

7 Steps to solve a Dynamic Programming problem

In the rest of this post, I will go over a recipe that you can follow to figure out if a problem is a “DP problem”, as well as to figure out a solution to such a problem. Specifically, I will go through the following steps:

How to recognize a DP problem Identify problem variables Clearly express the recurrence relation Identify the base cases Decide if you want to implement it iteratively or recursively Add memoization Determine time complexity

Sample DP Problem

For the purpose of having an example for abstractions that I am going to make, let me introduce a sample problem. In each of the sections, I will refer to the problem, but you could also read the sections independently of the problem.

Problem statement:

In this problem, we’re on a crazy jumping ball, trying to stop, while avoiding spikes along the way.

Here are the rules:

1) You’re given a flat runway with a bunch of spikes in it. The runway is represented by a boolean array which indicates if a particular (discrete) spot is clear of spikes. It is True for clear and False for not clear.

Example array representation:

2) You’re given a starting speed S. S is a non-negative integer at any given point, and it indicates how much you will move forward with the next jump.

3) Every time you land on a spot, you can adjust your speed by up to 1 unit before the next jump.

4) You want to safely stop anywhere along the runway (does not need to be at the end of the array). You stop when your speed becomes 0. However, if you land on a spike at any point, your crazy bouncing ball bursts and it’s game over.

The output of your function should be a boolean indicating whether we can safely stop anywhere along the runway.

Step 1: How to recognize a Dynamic Programming problem

First, let’s make it clear that DP is essentially just an optimization technique. DP is a method for solving problems by breaking them down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions. The next time the same subproblem occurs, instead of recomputing its solution, you simply look up the previously computed solution. This saves computation time at the expense of a (hopefully) modest expenditure in storage space.

Recognizing that a problem can be solved using DP is the first and often the most difficult step in solving it. What you want to ask yourself is whether your problem solution can be expressed as a function of solutions to similar smaller problems.

In the case of our example problem, given a point on the runway, a speed, and the runway ahead, we could determine the spots where we could potentially jump next. Furthermore, it seems that whether we can stop from the current point with the current speed depends only on whether we could stop from the point we choose to go to next.

That is a great thing, because by moving forward, we shorten the runway ahead and make our problem smaller. We should be able to repeat this process all the way until we get to a point where it is obvious whether we can stop.

Recognizing a Dynamic Programming problem is often the most difficult step in solving it. Can the problem solution be expressed as a function of solutions to similar smaller problems?

Step 2: Identify problem variables

Now we have established that there is some recursive structure between our subproblems. Next, we need to express the problem in terms of the function parameters and see which of those parameters are changing.

Typically in interviews, you will have one or two changing parameters, but technically this could be any number. A classic example of a one-changing-parameter problem is “determine an n-th Fibonacci number”. Such an example for a two-changing-parameters problem is “Compute edit distance between strings”. If you’re not familiar with these problems, don’t worry about it.

A way to determine the number of changing parameters is to list examples of several subproblems and compare the parameters. Counting the number of changing parameters is valuable to determine the number of subproblems we have to solve. It’s also important in its own right in helping us strengthen the understanding of the recurrence relation from step 1.

In our example, the two parameters that could change for every subproblem are:

Array position (P) Speed (S)

One could say that the runway ahead is changing as well, but that would be redundant considering that the entire non-changing runway and the position (P) carry that information already.

Now, with these 2 changing parameters and other static parameters, we have the complete description of our sub-problems.

Identify the changing parameters and determine the number of subproblems.

Step 3: Clearly express the recurrence relation

This is an important step that many rush through in order to get into coding. Expressing the recurrence relation as clearly as possible will strengthen your problem understanding and make everything else significantly easier.

Once you figure out that the recurrence relation exists and you specify the problems in terms of parameters, this should come as a natural step. How do problems relate to each other? In other words, let’s assume that you have computed the subproblems. How would you compute the main problem?

Here is how we think about it in our sample problem:

Because you can adjust your speed by up to 1 before jumping to the next position, there are only 3 possible speeds, and therefore 3 spots in which we could be next.

More formally, if our speed is S, position P, we could go from (S, P) to:

(S, P + S); # if we do not change the speed (S — 1, P + S — 1); # if we change the speed by -1 (S + 1, P + S + 1); # if we change the speed by +1

If we can find a way to stop in any of the subproblems above, then we can also stop from (S, P). This is because we can transition from (S, P) to any of the above three options.

This is typically a fine level of understanding of the problem (plain English explanation), but you sometimes might want to express the relation mathematically as well. Let’s call a function that we’re trying to compute canStop. Then:

canStop(S, P) = canStop(S, P + S) || canStop(S — 1, P + S — 1) || canStop(S + 1, P + S + 1)

Woohoo, it seems like we have our recurrence relation!

Recurrence relation: Assuming you have computed the subproblems, how would you compute the main problem?

Step 4: Identify the base cases

A base case is a subproblem that doesn’t depend on any other subproblem. In order to find such subproblems, you typically want to try a few examples, see how your problem simplifies into smaller subproblems, and identify at what point it cannot be simplified further.

The reason a problem cannot be simplified further is that one of the parameters would become a value that is not possible given the constraints of the problem.

In our example problem, we have two changing parameters, S and P. Let’s think about what possible values of S and P might not be legal:

P should be within the bounds of the given runway P cannot be such that runway[P] is false because that would mean that we’re standing on a spike S cannot be negative, and a S==0 indicates that we’re done

Sometimes it can be a little challenging to convert assertions that we make about parameters into programmable base cases. This is because, in addition to listing the assertions if you want to make your code look concise and not check for unnecessary conditions, you also need to think about which of these conditions are even possible.

In our example:

P < 0 || P >= length of runway seems like the right thing to do. An alternative could be to consider making P == end of runway a base case. However, it is possible that a problem splits into a subproblem which goes beyond the end of the runway, so we really need to check for inequality. This seems pretty obvious. We can simply check if runway[P] is false. Similar to #1, we could simply check for S < 0 and S == 0. However, here we can reason that it is impossible for S to be < 0 because S decreases by at most 1, so it would have to go through S == 0 case beforehand. Therefore S == 0 is a sufficient base case for the S parameter.

Step 5: Decide if you want to implement it iteratively or recursively

The way we talked about the steps so far might lead you to think that we should implement the problem recursively. However, everything that we’ve talked about so far is completely agnostic to whether you decide to implement the problem recursively or iteratively. In both approaches, you would have to determine the recurrence relation and the base cases.

To decide whether to go iteratively or recursively, you want to carefully think about the trade-offs.

Stack overflow issues are typically a deal breaker and a reason why you would not want to have recursion in a (backend) production system. However, for the purposes of the interview, as long as you mention the trade-offs, you should typically be fine with either of the implementations. You should feel comfortable implementing both.

In our particular problem, I implemented both versions. Here is python code for that:

A recursive solution: (original code snippets can be found here)

An iterative solution: (original code snippets can be found here)

Step 6: Add memoization

Memoization is a technique that is closely associated with DP. It is used for storing the results of expensive function calls and returning the cached result when the same inputs occur again.

Why are we adding memoization to our recursion? We encounter the same subproblems which, without memoization, are computed repeatedly. Those repetitions very often lead to exponential time complexities.

In recursive solutions, adding memoization should feel straightforward. Let’s see why. Remember that memoization is just a cache of the function results. There are times when you want to deviate from this definition in order to squeeze out some minor optimizations, but treating memoization as a function result cache is the most intuitive way to implement it.

This means that you should:

Store your function result into your memory before every return statement Look up the memory for the function result before you start doing any other computation

Here is the code from above with added memoization (added lines are highlighted): (original code snippets can be found here)

In order to illustrate the effectiveness of memoization and different approaches, let’s do some quick tests. I will stress test all three methods that we have seen so far. Here is the set up:

I created a runway of length 1000 with spikes in random places (I chose to have a probability of a spike being in any given spot to be 20%) initSpeed = 30 I ran all functions 10 times and measured the average time of execution

Here are the results (in seconds):

You can see that the pure recursive approach takes about 500x more time than the iterative approach and about 1300x more time than the recursive approach with memoization. Note that this discrepancy would grow rapidly with the length of the runway. I encourage you to try running it yourself.

Step 7: Determine Time complexity

There are some simple rules that can make computing time complexity of a dynamic programming problem much easier. Here are two steps that you need to do:

Count the number of states — this will depend on the number of changing parameters in your problem Think about the work done per each state. In other words, if everything else but one state has been computed, how much work do you have to do to compute that last state?

In our example problem, the number of states is |P| * |S|, where

P is the set of all positions (|P| indicates the number of elements in P)

S is the set of all speeds

The work done per each state is O(1) in this problem because, given all other states, we simply have to look at 3 subproblems to determine the resulting state.

As we noted in the code before, |S| is limited by length of the runway (|P|), so we could say that the number of states is |P|² and because work done per each state is O(1), then the total time complexity is O(|P|²).

However, it seems that |S| can be further limited, because if it were really |P|, it is very clear that stopping would not be possible because you would have to jump the length of the entire runway on the first move.

So let’s see how we can put a tighter bound on |S|. Let’s call maximum speed S. Assume that we’re starting from position 0. How quickly could we stop if we were trying to stop as soon as possible and if we ignore potential spikes?

In the first iteration, we would have to come at least to the point (S-1), by adjusting our speed at zero by -1. From there we would at a minimum go by (S-2) steps forward, and so on.

For a runway of length L, the following has to hold:

=> (S-1) + (S-2) + (S-3) + ….+ 1 < L

=> S*(S-1) / 2 < L

=> S < sqrt(2L + 1)

That is the maximum speed that we could possibly have on a runway of a length L. If we had a speed higher than that, we could not stop even theoretically, irrespective of the position of the spikes.

That means that the total time complexity depends only on the length of the runway L in the following form:

O(L * sqrt(L)) which is better than O(L²)

O(L * sqrt(L)) is the upper bound on the time complexity

Awesome, you made it through! :)

The 7 steps that we went through should give you a framework for systematically solving any dynamic programming problem. I highly recommend practicing this approach on a few more problems to perfect your approach.

Here are some next steps that you can take

Extend the sample problem by trying to find a path to a stopping point. We solved a problem that tells you whether you can stop, but what if you wanted to also know the steps to take in order to stop eventually along the runway? How would you modify the existing implementation to do that? If you want to solidify your understanding of memoization, and understand that it is just a function result cache, you should read about decorators in Python or similar concepts in other languages. Think about how they would allow you to implement memoization in general for any function that you want to memoize. Work on more DP problems by following the steps we went through. You can always find a bunch of them online (ex. LeetCode or GeeksForGeeks). As you practice, keep in mind one thing: learn ideas, don’t learn problems. The number of ideas is significantly smaller and it’s an easier space to conquer which will also serve you much better.

When you feel like you’ve conquered these ideas, check out Refdash where you are interviewed by a senior engineer and get a detailed feedback on your coding, algorithms, and system design.",https://cdn-images-1.medium.com/max/1200/0*DpsbrfUM89M_LHKY.jpg,[],https://medium.freecodecamp.org/follow-these-steps-to-solve-any-dynamic-programming-interview-problem-cc98e508cd0e?source=collection_home---6------11----------------,2018-06-06 19:32:36.335000+00:00

Machine Learning,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------,2018-06-06 17:23:02.015000+00:00

Machine Learning,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------#--responses,2018-06-06 17:23:02.015000+00:00

Machine Learning,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------,2018-06-06 16:42:46.938000+00:00

Machine Learning,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------#--responses,2018-06-06 16:42:46.938000+00:00

Machine Learning,How to process textual data using TF-IDF in Python – freeCodeCamp,[],"How to process textual data using TF-IDF in Python

Computers are good with numbers, but not that much with textual data. One of the most widely used techniques to process textual data is TF-IDF. In this article, we will learn how it works and what are its features.

From our intuition, we think that the words which appear more often should have a greater weight in textual data analysis, but that’s not always the case. Words such as “the”, “will”, and “you” — called stopwords — appear the most in a corpus of text, but are of very little significance. Instead, the words which are rare are the ones that actually help in distinguishing between the data, and carry more weight.

An introduction to TF-IDF

TF-IDF stands for “Term Frequenct — Inverse Data Frequency”. First, we will learn what this term means mathematically.

Term Frequency (tf): gives us the frequency of the word in each document in the corpus. It is the ratio of number of times the word appears in a document compared to the total number of words in that document. It increases as the number of occurrences of that word within the document increases. Each document has its own tf.

Inverse Data Frequency (idf): used to calculate the weight of rare words across all documents in the corpus. The words that occur rarely in the corpus have a high IDF score. It is given by the equation below.

Combining these two we come up with the TF-IDF score (w) for a word in a document in the corpus. It is the product of tf and idf:

Let’s take an example to get a clearer understanding.

Sentence 1 : The car is driven on the road.

Sentence 2: The truck is driven on the highway.

In this example, each sentence is a separate document.

We will now calculate the TF-IDF for the above two documents, which represent our corpus.

From the above table, we can see that TF-IDF of common words was zero, which shows they are not significant. On the other hand, the TF-IDF of “car” , “truck”, “road”, and “highway” are non-zero. These words have more significance.

Using Python to calculate TF-IDF

Lets now code TF-IDF in Python from scratch. After that, we will see how we can use sklearn to automate the process.",https://cdn-images-1.medium.com/max/1200/1*JTk6iVMiZCQCr8duiaKlHQ.png,[],https://medium.freecodecamp.org/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3?source=collection_home---6------15----------------,2018-06-06 16:07:18.115000+00:00

Machine Learning,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------,2018-06-06 01:10:32.658000+00:00

Machine Learning,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------#--responses,2018-06-06 01:10:32.658000+00:00

Machine Learning,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------,2018-06-06 00:59:12.072000+00:00

Machine Learning,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------#--responses,2018-06-06 00:59:12.072000+00:00

Machine Learning,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------,2018-06-06 00:20:56.870000+00:00

Machine Learning,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------#--responses,2018-06-06 00:20:56.870000+00:00

Machine Learning,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------,2018-06-05 20:08:25.488000+00:00

Machine Learning,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------#--responses,2018-06-05 20:08:25.488000+00:00

Machine Learning,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------,2018-06-05 16:44:13.144000+00:00

Machine Learning,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------#--responses,2018-06-05 16:44:13.144000+00:00

Machine Learning,A deeply detailed but never definitive guide to mobile development architecture,['Jose Berardo Cunha'],"A deeply detailed but never definitive guide to mobile development architecture

Native, Web, PWA, hybrid, Cross-Compiled… what is “the best” way to develop for Android and iOS platforms? What looks reasonable? And how are you supposed to choose among the options? In this article, I’ll lay it all out so you can make an informed decision.

First things first, let me provide you with a bit of context. I am an IT senior consultant, and the idea of putting together this guide was born from discussions with one of our clients about what could be the best approach for them. Yes, just for them. And we realized that we did not have a well-defined strategy, a solid and reliable foundation, to help us come up with the right answer.

And you know what? I could not find such a guide easily anywhere on the Internet, either. Although there are several articles about this topic, none of those I came across were reasonably complete. Unfortunately the majority overlook a lot of concepts or, even worse, are essentially wrong.

Now, I’d like to take a wider look. And while I’m potentially helping someone make their own decisions, I’m also asking around the community for more thoughts on the subject.

This guide has two parts:

Mobile Development Architectural Tiers (this) How to make your decision

It's also available on YouTube as a series of 10 videos and as a free course on Udemy. There, you’ll find the same written material as here, the same videos from the YouTube series, as well as quizzes to fix all the topics and a final certification.

So let’s get started.

Introduction

When it comes to mobile platforms, it's arguable that there are just two big players: Android and iOS. Other technologies like Tizen, Blackberry, or Windows Phone are either dead or have been around for a while and have no prospects of reaching any significative market share.

A quick look at this massive duopoly might make you think that developers do not have many options when creating mobile apps. This idea can't be further from the truth, though. You can quickly spot a fistful of programming languages being used out there: C/C++, Java, Kotlin, Objective-C, Swift, JavaScript, TypeScript, C#, Dart, Ruby, and I'm pretty sure I’ve missed a few more.

The same is true of mobile development frameworks. Unless you are not a developer, or have somehow been unaware of new technologies for the last 10 years, you’ve probably heard about Cordova/PhoneGap, React Native, Xamarin, Ionic, Nativescript, or Flutter, just to name a few cross-platform solutions for mobile apps.

So let’s look at all these pieces of the architecture and break things down a bit.

TL;DR

There's no clear winner. All approaches have pros and cons, and might be either the best fit or the worst fit for your next project. In this guide, I'm classifying many different solutions into various tiers according to the distance their architectures are from the native platform.

Native Apps

To start, let's go straight to the metal. Our first architectural tier is Native Apps.

Native Apps Tier — Where you develop for each specific platform (it might be even more specific when considering NDK)

This is the tier where you must be aware of the idiosyncrasies of each platform. It’s not my intention to dig into them, I just want to mention a few things in a bit of context.

You can watch this first part on Youtube.

iOS

Starting on the iOS side, just because it's simpler, there's only Apple ruling the world. Originally, developers needed to learn Objective-C, a proprietary object-oriented variation of C with some inspiration from SmallTalk (and an insanely long-named API).

In 2014, Apple announced Swift, a multi-paradigm language, which was a lot easier than its predecessor. It's still possible to deal with Objective-C legacy code, but Swift has reached high maturity levels. So, if you're planning to learn how to natively develop for iOS, Swift is definitely where you should start.

Android

On the Android side, there are a number of different manufacturers. The vast majority of them rely upon ARM processors. But generally speaking, Android apps lay on virtual machine instances (instances of ART) to help deal with potential underlying specificities (not without many amazing tricks).

That's why, originally, the language of choice was Java. It’s not only been the most popular language in the World for almost two decades (with a few position swaps with C), but it’s also notable for its Java Virtual Machine (JVM). This empowered developers to compile their code down to an intermediate bytecode that could be read and run by the JVM.

With the Android Native Development Kit (NDK), it's also possible to develop critical parts of the app directly in native code, writing in C/C++. In this case, you have to be aware of underlying platform quirks.

Kotlin is a language unveiled by JetBrains in 2011. When it first came out, despite its flexibility and conciseness, it wasn't more than yet another JVM language with more successful competitors like Scala, Clojure, or Groovy. However, after its first major release in 2016, it rapidly started to stand out from the crowd, especially after Google announced that it would be officially supported on the Android platform at Google I/O 2017.

Kotlin is becoming Google's first class language (currently Kotlin and Java — in this order — are used throughout Android's official documentation). A total Java replacement is expected even more so now that the US Federal Appeals Court has ruled on the endless lawsuit filed by Oracle accusing Google of violating Java copyrights.

Native components

Developing in this tier, you can also leverage all native APIs and, in particular, the native components. This saves your app from having to reinvent the wheel.

I've published a video demo of how to create a simple project on Xcode (iOS) and Android Studio. If you want to check it out:

Demo of iOS and Android basic projects.

Native Apps advantages

Best performance and top user engagement

Bleeding edge native features

Notably good IDEs Android Studio / Xcode

Modern high-level languages Kotlin / Swift

Very low-level approach with NDK

Native Apps disadvantages

Two codebases to maintain

Require installation (except Android Instant Apps)

Hard to analyze SEO

Very expensive to get users to download the app

Web Apps

On the other side of the spectrum, we have Web Apps. Web Apps are essentially apps run by the browser. You don't write code targeting the platform, but rather any browser running on top of it.

Web Apps Tier — clearly on top of a browser bar targeting a beast sitting in between Android and iOS.

In this tier you’ll find an insane number of contenders jumping at each other's throats. But they all use an arsenal consisting of the same weapons: HTML, CSS, and Javascript.

Web frameworks and libraries, even when leveraging CSS pre-compilers like LESS or SASS, even Javascript pre-compiled languages like TypeScript, CoffeeScript or Flow, even symbiosis like JSX or Elm, leaving alone tools like Babel used to transpile everything to Javascript with different configurable levels of conformance with ECMAScript yearly specifications (ES6 / ES7 / ES8, or if you prefer ES2015 / ES2016 / ES2017 / ES2018).

At the end of the day, they all are HTML, CSS, and JavaScript rendered and run by the browser. There's no direct access to native APIs like camera, vibration, battery status, or file system, but some of them can be achieved via Web API's:

The big issue with Web APIs is their maturity level. Many of them are not supported by some browsers. There are differences in implementations, especially across mobile browsers.

Web App advantages

Shared code between platforms and desktop browsers

Do not require previous installations, just navigate and use

Tons of frameworks and libraries to go with them

Best for SEO

Web App disadvantages

Lower performance

Hard to get a native user experience

Require an internet connection

Not available on official app stores

API not as mature and reliable as native API

Frameworks and Web components

Angular, React, and Vue are probably the most popular web frameworks as of 2018. To be precise, however, React is considered just a library due to its flexible and less opinionated nature. Angular, on the other hand, is a strongly opinionated framework. Vue lives at some point in between them.

Angular vs React vs Vue

Angular, originally called AngularJS, was presented to the world in 2010 by Google. It quickly started to shine, due to its inversion of paradigms in comparison with other libraries from that time (like jQuery, the most popular back then). Instead of directly talking to HTML elements to manipulate the UI state, with AngularJS, templates were magically updated whenever the JavaScript model was updated.

As AngularJS became more and more popular, it also grew in purpose. It turned into a complete and opinionated framework that was one of the first that took SPAs (Single Page Apps) seriously. This growth (in both aspects) was responsible for some API bloats and performance issues.

React was created by Facebook to solve their own needs on the presentation layer. It introduced many aspects that suddenly became very popular, like virtual DOM, one-way data flow (originally named Flux, especially popular through an implementation library called Redux), and a mixture of HTML and JavaScript called JSX.

Only in 2016, after long debates and unexpected big changes, Google launched version two of its popular web framework. They called it Angular, instead of AngularJS. But, as many people already called the first version “Angular” (without the ""JS"" suffix), people started calling the new version Angular 2. That turned into a naming problem, as Google also announced that it would release new major versions every 6 months.

In my opinion, that was a mammoth mistake. I've seen this before (with Struts vs Struts 2/WebWork, for example). They have a massively popular product that appears to have reached its plateau, and it has started to be more criticized than praised. If Google decides to rebuild it from the ground up, they should never, by any means, just change its major version. How will people trust that they will not repeat it every new major version release? Version two is supposed to present breaking changes, but it doesn't mean it can be totally revamped.

Angular is a spectacular web framework, and I really feel passionate about it. However, it's a completely new beast. It does not have much to do with AngularJS. Even Vue, which is another amazing framework (probably one of the most pleasant to work with, by the way) looks more similar to AngularJS from a bird's-eye view. I believe this caused a significant movement away from Angular and contributed substantially to React's popularity.

Vue is the only one of the three most popular web frameworks that is not backed by a big company. It was actually started by a former Google developer. Due to its formidable simplicity and tiny footprint, it got attention from a massive and enthusiastic community.

Although there are more complete solutions, they all work on top of the concept of web components. There's an open specification about them currently in progress in W3C, and some interesting implementations like Polymer, Stencil and X-Tag.

In the third video of the series, I don't spend too much time discussing frameworks but discuss web component libraries:

The Web Apps tier is discussed in Part 3 of the series

Mobile Apps vs Web Apps

I’m not sure if you’ve noticed, but the order of tiers I'm presenting here follows what I think is the easiest path to learn all approaches. I started from the Native Tier, the most genuinely mobile development. Then I decided to fly directly to the other extreme to present the Web Tier, which is the tier that has been available since the first smartphones.

Only now, after elaborating on a comparison between the two edges of my diagram, will I start talking about many of the cross-platform approaches to build mobile apps.

There's a long debate between Mobile Apps vs Web Apps. Everything I say about Mobile Apps is not exclusive to the Native Tier. It is also applicable to all cross-platform tiers I present later on.

The user behavior dilemma

Users spend more time on Mobile Apps (87%) than on Mobile Websites (13%)

According to a Comscore survey in 2017, a user's fidelity to a mobile app is way more relevant than it is to mobile websites. According to an aligned article on Forbes, this is usually because of convenience (for example, home screen buttons, widgets, top notifications), speed (for example, smoother interfaces, almost instant start ups), and stored settings (for example, offline content).

Mobile Websites reach more people (8.9M monthly unique visitors against 3.3M of Mobile Apps)

On the other hand, in the same Comscore data, we learn that customers can be reached more easily from mobile websites, as they are not as much tied to their few apps of preference. If you compare the most popular websites versus the most downloaded apps, it's estimated that an average of 8.9 million unique web visitors per month access the top 1000 websites. That's almost three times more than the average unique users of the top 1000 most downloaded apps.

Distribution (Web App) x Engagement (Mobile App)

That's all about distribution vs engagement. Your web app has a higher chance of being accessed, as users are more likely to try new things when navigating through their mobile browsers. But Mobile Apps have been proven to be more engaging, and catch the users attention for much longer periods.

Now that you understand the dilemma, let's have a look at Progressive Web Apps. This is an approach so tied to the Web Apps tier that I classify it as just an addendum to Web Apps. But it's a big disruptor and a serious candidate for the most prominent new and cool thing in web and mobile development.

Progressive Web Apps

Progressive Web Apps (PWAs) are a set of tools used to give Web App users the same experience they are accustomed to when they run Mobile Apps. This means that Web Apps can leverage the potentially higher levels of distribution with more decent levels of engagement.

Progressive Web Apps addendum to Web Apps tier

Google defined three main qualifications for PWAs: they must be Reliable, Fast, and Engaging.

Features called Service Workers and the App Shell are the foundation of Progressive Web Apps. They were created to promote apps’ reliability as they are now designed to work regardless of the device’s connection status. That includes offline mode, as well as poor connections. They also provide significant perceived performance boost, as apps launch using locally cached data, which eliminates delays for synchronous content downloads.

You could consider reliability an indirect vector of engagement. Users are not affected while commuting by train, for example. They can stay engaged.

The same applies to speed. According to Google:

53% of users will abandon a site if it takes longer than 3 seconds to load!

However, being exclusively reliable and fast on load doesn't necessarily guarantee high engagement. PWAs leverage mobile-related features that used to be exclusive to mobile apps, like an “Add to Home Screen” option and Push Notifications.

When it comes to to the “Add to Home Screen” feature, you might notice that Apple has had a similar feature since the very first iPhone. Some people even argue that Progressive Web Apps are Google's fancy new name for an original Apple idea.

And you really can’t completely disagree. Some ideas are actually cycling. They come, go away, and then come back with a new name and some enhancements (for instance, Service Workers), so they can finally stick around.

On the other hand, it’s hard to completely agree. Steve Jobs’ speech about Web 2.0 + AJAX and the memorable announcement of the iPhone back in WWDC 2007 are not convincing enough to call him as the father, or even the prophet, of PWAs.

To be fair, the Add to Home Screen capability on iPhone has been nothing more than a subtle, almost hidden, feature to generate desktop icons that just start up Web Apps in fullscreen mode. It has all the burden of HTTP request-response cycles and no clear path around caches.

PWAs start from the right point. They explore how previous installations of Web Apps aren’t necessary without losing the client-side bootstrap of Mobile Apps. This means that everything a user needs for their first interaction following startup might be locally cached (read: App Shell) and kept available as soon as they hit “Add to Home Screen.”

Moving onto another well-known characteristic of PWAs, let’s talk about the super engaging (or re-engaging) feature of the Mobile Apps world: Push Notifications. They are alert-style messages that appear on the top notification bar / area, as well as on lock screens. They have the power of pulling users back to your app once they receive the notification.

To reinforce the appeal of PWAs, Google has been pulling all modern Web APIs under the PWA umbrella. So expect to see things like Payment Requests, Credential Management, WebVR, Sensors, WebAssembly, and WebRTC in the context of Progressive Web Apps. But these feature are not necessarily tied to PWAs, and some were even born before the term PWA was coined.

PWA and Apple

Apple, on the other hand, announced their first solid milestones towards PWAs only in March 2018. Although there are still some limitations, the progress is appreciable. Some of the limitations might be related to the fact that Safari has fallen behind its competitors. Others could be attributed to Apple's philosophy of tight control.

Still, Apple has a more profitable App Store than Google. Apple's asserts that more criteria on app publications brings more overall reliability, and PWAs are bound to hurt the App Store's revenue. This suggests that some limitations that seem to be intentionally imposed (like 50Mb of PWA maximum cache size) will cost more to be revoked.

Unfortunately PWAs are not perfect

Web solutions and, on different levels, all cross-platform solutions struggle to attain the excellence and comprehensiveness of Native Apps. Every new feature, and every detail particular to Android or iOS makes that native feel harder and harder to access as you distance your app from the native tier.

Overall, PWAs fix some issues in the Web Apps tier. But there are other issues that can’t be fixed by a solution working on top of a browser.

What PWAs fix

More “native” experience

Faster load times

Do not require an internet connection

Force web developers to be aware of situations where there’s no connection as well as a bad connection

Incorporate features from Mobile Apps like Push Notifications, Geolocation, or Speech Recognition

What they don’t

Inherent slowness

Not available on app stores (just yet)

Still not fully supported by all browsers

Still lack mobile features like NFC, Ambient Light, Geofencing

Also lack support for peculiarities of Android or iOS like PiP, smart app banners, launch screen widgets, and 3D touch

In the video below, I do a brief overview of PWAs.

Progressive Web Apps are introduced in the Part 4 of the series

Hybrid Apps

At this level, we begin to dive into the Mobile App world. We’ll start from the most distant tier: Hybrid Apps.

The term Hybrid is also commonly applied to all cross-platform solutions. Here, however, I’m restricting it to Apps that work inside mobile components, called WebViews.

The Hybrid Apps tier. Below the browser's line but on top of WebViews

In the demos in the second video, my purpose for adding WebView as the Hello World example was to make clear that there's a native component for each platform that is able to perform like an actual browser.

Cordova/PhoneGap

Solutions like Cordova/PhoneGap close the gap (sorry for the uninspired pun) between Web and Mobile Apps. They provide tools to package developer's HTML, JavaScript, and CSS code (as well as any extra assets like images or videos) and transform them into Mobile Apps (yes, real Android or iOS apps). These apps have their WebView exclusively to interpret and run the original web code, starting with the “index.html” file in the app’s main folder (normally called “www”). They also bridge the JavaScript code to native APIs through plugins which are partially implemented in JavaScript and partially in a native language.

So, let's make things clearer. Hybrid Apps are able to access native APIs (instead of Web APIs), but they are enclosed by the WebView. A button with Cordova must be an HTML button rendered by a WebView instead of a mobile native button.

This is the magical tier that allows companies to port their Web Apps to Mobile Apps to be shipped by app stores. So any web framework is allowed here.

Ionic

Frameworks like Ionic wrap Cordova into their own solutions. With Ionic, you don't need to use Cordova’s command line interface (CLI), because all of its commands are wrapped by the Ionic CLI.

Recently, the Ionic team decided to take the reins of the entire stack of Hybrid Apps. So they launched a proposed replacement for Cordova called Capacitor. Capacitor has support for Cordova plugins, and can also be used by a non-Ionic project.

You can watch me going through a Cordova Hello World sample in the fifth video of the series:

Hybrid Apps are in Part 5 of the series.

Hybrid Apps advantages

They are essentially web apps that are shippable to official app stores

Can be used along with any JavaScript framework / library

The code is still highly shareable across platforms

Access to native features (for instance, camera, accelerometer, contact list)

Hybrid Apps disadvantages

Struggle with performance issues and memory consumption, as web views are responsible for rendering everything on screen

Have to mimic all native UI components on top of a single web view

Harder to be accepted and published on App Store

Usually take longer to have native features available for these environments

Web Native

Web Native is a relatively new and often misunderstood tier. That's where Web Apps meet native components. Although Appcelerator (Axway) Titanium has been around a long time, there are some relatively new competitors that justify making this a completely separate category of mobile apps.

Web Native Apps don't need WebView as they talk directly to other native components

As you can see above, there's no web view to render and run your application. So, how is your JavaScript executed? Is it compiled? Well, if you consider transpilation (compilation from one language to another — for example TypeScript to JavaScript), bundling, minification, mangling, and obfuscation all together as a compilation, yes JavaScript is compiled.

But the problem is, this doesn't make your JavaScript something directly understood by Android or iOS operational systems. And, in theory, there's no native component that only serves as a JavaScript engine without the bloat of the HTML layout engine.

The strategy is to ship JavaScript engines (normally V8 for Android and JavaScriptCore for iOS) along with your code. Although they have small footprints and are very fast, they are something external that must be provided by your app.

On the other hand, this approach tends to have better UI performance, as all the components are the same (or are based on the same thing for React Native, for example) as the ones used by Native Apps.

Web Native Apps advantages

Reach both platforms with one single codebase

Roughly the same performance as native apps, as they also deal with native UI components

Tweaks are necessary, but the code is still shareable with web development

Web Native Apps disadvantages

Even with one single codebase, the developer must be aware of native components

Steeper learning curve than Hybrid / Web Apps for web developers, especially when it comes to layout

React Native

In part 6 of the series, I do a quick Hello World in React Native. This shows, on Android Studio's Layout Inspector, what components were rendered in the emulator. I compare with the previous examples, ensuring that there's no WebView whatsoever.

Web Native Apps presentation with focus on React Native in Part 6 of the series.

Nativescript

Another amazing framework that I've been particularly interested in over the last two years (I have a course on Udemy about it — in Portuguese), is Nativescript. It’s similar to React Native but is not tied to the React world (there's an unofficial integration, Nativescript-Preact, though).

With Nativescript, you can develop using vanilla JavaScript, TypeScript, Angular and, more recently, Vue. Of course you can use other frameworks, but those are the ones officially supported. It’s fairly well documented too, by the way.

Nativescript has tools like Nativescript Sidekick and Nativescript Playground, as well as project structures based on templates that can be provided by the community. This should help you in project creation, giving you the ability to start, deploy, test, and run on simulators on the cloud and iPhone devices even when you are not developing using a Mac.

In the seventh part of the series, I do a Hello World using Sidekick along with another project started from the CLI and a WhatsApp clone template I created for learning purposes.

Web Native Apps with Nativescript in Part 7 of the series.

It's important to have a look at the Layout Inspector when your app is running on an Android emulator. With Nativescript, it shows the native components (again, no WebView), and direct instances of common Android classes like TextView. This is different than React Native, which has its own classes to wrap the native components.

That's probably why Nativescript claims that there’s no delay between when a new feature is available on iOS and Android and when you can use it in a Nativescript project. For example, they posted on their blog an AR project on the same day iOS 11 was officially released with the new ARKit API.

Weex

Another framework worth mentioning in this category is Weex. It's a project developed by Alibaba, and is currently incubated at Apache Sofware Foundation (ASF). It uses common HTML tags like <div> and CSS commands inside <style> tags to call native components instead. From their documentation:

Although components in Weex look like HTML tags, you are not able to use all of them. Instead, you can only use the built-in components and your custom components.

Cross Compiled

At this level, it’s time to jump off the Web bandwagon. This is the closest tier to native development, but has the advantage of using one single codebase to target Android and iOS.

Development tiers now complete with Cross Compiled Apps

RubyMotion and Xamarin

There are solutions like RubyMotion. This is a way to write mobile apps using Ruby and compile directly to the targeted platform (as it was created using any ""native"" language).

Another option is Xamarin, where you write in C#, compile to an intermediate bytecode, and deploy your app along with an instance of the Mono common language runtime. This approach has the same drawback as Web Native (where V8 and JavaScriptCore are delivered by your app), but can also rely upon JIT compilations to optimize the app at runtime.

Flutter

Last but not least, I'd like to bring up Flutter. It’s Google's newest cool initiative for mobile development. It fits in the Cross Compiled tier because you write apps using the Dart language and compile them down to the native platform.

Flutter has innovated in some aspects. Probably the most outstanding one is the fact that it provides its own set of components.

What? Own set of components?

Yes, Flutter provides a number of different components so you can completely skip the ones from the platform. It has generic components as well as Material Design components for Android, and Cupertino components for iOS.

Rather than .Net virtual machine (as Xamarin) or JavaScript engines (as Web Native frameworks), with Flutter your app will deliver the components you decide to use.

Are they native components?

Yes, they are. Your app is native, too. Everything is compiled to the native architecture. However, bear in mind they are not the pre-existing native components.

What's the point of that?

Well, in my opinion, this solution is clever and audacious. I've been waiting to talk about advantages and disadvantages, but as it's just one particular technology, let me address them now.

One of the biggest challenges for Web Native and Cross Compiled solutions (remember, above Native but below the WebView in our tiers) is how to deal with native components. For example, an important problem is how to lay them out. That's because they were not created to be used by those external resources. Also, they were not created with a counterpart in the other platform in mind. The Android NavBar doesn't work like iOS UINavBar, for example.

With Flutter, components are created with cross-platform always in mind. So let's have a look at the pros and cons of the Cross Compiled Apps tier:

Cross Compiled Apps advantages

Reach both platforms with one single language

Roughly the same performance as native apps, as they also deal with native UI components

Cross Compiled Apps disadvantages

Slightly delayed support for the latest platform updates

Code not shareable with web development

Even with one single codebase, the developer must be aware of native components

PS: With Flutter, you’ll provide your own set of widgets along with your app's code

Mobile Apps runtime architecture",https://cdn-images-1.medium.com/max/1200/1*kHze88HBCkKt8Tw4MESC9Q.png,[],https://medium.freecodecamp.org/a-deeply-detailed-but-never-definitive-guide-to-mobile-development-architecture-6b01ce3b1528?source=collection_home---6------21----------------,2018-06-05 16:34:24.241000+00:00

Machine Learning,How to deliver a React Native app to the client – freeCodeCamp,[],"How to deliver a React Native app to the client

If you have written some React Native apps, you’ve probably noticed that the process of beta-release version generation requires many repeatable steps. This happens especially for multi-platform apps.

Let’s look at sample action steps you need to perform to deliver the beta version app to the client or tester:

Download the proper branch from the repository

Android:

Insert the APK signing key into the ./android/app/ directory

directory Build the release version

Send the app, for example via e-mail

iOS:

Launch Xcode

Change the scheme to Release

Change the jsCodeLocation value to a static main.jsbundle file path

value to a static file path Archive

Upload the app to TestFlight

As you can see, the above list contains a large number of repeatable steps. Since they are repeatable, we can automate them, right?

Possible solutions

There are several solutions for automating beta release version generation and delivering the app to the client.

Visual Studio App Center

The first solution that came to our minds at Brainhub was the use of the Visual Studio App Center. A project built by Microsoft seems to be really attractive — in addition to building the app in the cloud (free 240 minutes / month of building) and distribution among testers and the client, it also provides a platform for testing apps on many real devices, giving access to reports and screenshots of every step of the process.

However, it quickly turned out that this was not the appropriate solution for our particular project. VS App Center has limited configuration abilities, and the app’s code needs to be downloaded from the Git repository hosted on GitHub, Bitbucket, or VSTS. Due to the fact that we use GitLab, we had to rule out this solution (but it could work for your project).

HockeyApp (with Fastlane)

The next option was to use HockeyApp — a tool for app distribution and collecting crash reports and users’ feedback. The service was initially created for distribution of iOS apps using the ‘ad hoc’ method (outside of App Store), but currently it works for Android also.

HockeyApp works well as a delivery platform of software testing versions, but does not give the functionality of building the app. However, we can also use Fastlane — a tool for mobile app building process automation built by fabric.io.

Preparations

Before you start building and deploying the app, you should prepare the environment. This section describes the steps you should take first.

Automatic jsCodeLocation change

React Native documentation says that you should change jsCodeLocation to the static js bundle for the iOS release version in AppDelegate.m file. But there’s no need to do that manually every time you release the app — you can use the #ifdef DEBUG macro to do it automatically. Just replace the line containing jsCodeLocation = … with the following code.

#ifdef DEBUG

// DEV

jsCodeLocation = [[RCTBundleURLProvider sharedSettings] jsBundleURLForBundleRoot:@”index” fallbackResource:nil];

#else

// PROD

jsCodeLocation = [[NSBundle mainBundle] URLForResource:@”main” withExtension:@”jsbundle”];

#endif

Ignore helper files

During the process of building the app, there will be some helper files created. There’s no need to commit them to the repository, so just add them to the following “.gitignore” file.

# Deployment

*.cer

*.jsbundle

*.jsbundle.meta

*dSYM.zip

*.keystore

*.mobileprovision

fastlane/report.xml

APK signing key

To release an Android app, you need a signing key. To learn more about this process, look here.

When you have your key generated, move it to the “android/app” directory and remember to add *.keystore to “.gitignore”.

Fastlane + HockeyApp + Testflight

You will learn how to automatically generate an app written in React Native for Android and iOS platforms, and send it to HockeyApp (Android) and Testflight (iOS).

First, let’s install Fastlane. Make sure you have the newest version of Xcode command line tools installed.

xcode-select — install

Install Fastlane.

[sudo] gem install fastlane -NV` or `brew cask install fastlane`

Init Fastlane.

fastlane init

The command above will create the “fastlane” directory in current directory with a file called “Fastfile” that contains the Fastlane configuration.

Appfile

In the “fastlane” directory, create a file called “Appfile”, which stores data that is used across all fastlane tools, for example AppleID. It is required for the iOS build and deployment to Testflight.

Add your AppleID to “Appfile”.

Fastfile

Your beta release Fastfile might look like this.

# More documentation about how to customize your build

# can be found here:

# https://docs.fastlane.tools

# fastlane_version “2.68.0”

# Fastfile actions accept additional configuration, but

# don’t worry, fastlane will prompt you for required

# info which you can add here later

platform :ios do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

get_certificates

get_provisioning_profile(

app_identifier: “org.you.yourProject”

)

# build your iOS app

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

# TestFlight

pilot()

end

end

platform :android do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

# build the release variant

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

# upload to HockeyApp

hockey(

api_token: “YOUR_TOKEN”

)

end

end

Let’s analyze our “Fastfile” step-by-step.

The code block below will be executed after typing fastlane ios beta into the console.

platform :ios do

lane :beta do

# …

end

end

For Android , type fastlane android beta .

platform :android do

lane :beta do

# …

end

end

Ensure that the current branch is master and perform git pull to sync with the remote repository.

ensure_git_branch(

branch: “master”

)

git_pull

iOS only

Let’s increment the build number (works for iOS only). The application that is being sent to Testflight has to have a higher build number than the previous version.

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

Testflight and Ad Hoc distribution require the proper certificate and provisioning profile. There are several methods of signing apps:

match

cert and sigh

Xcode’s code signing feature

manually

In this article, cert and sigh was used. For further reading about codesigning using Fastlane, visit this site.

get_certificates

get_provisioning_profile( app_identifier: “org.you.yourProject” )

Next, there is the step of building the iOS version where we pass the params such as project path, scheme , and export_method . Export_method contains one of the following values: app-store , ad-hoc , package , enterprise , development , or developer-id .

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

The last step for iOS is sending the app to Testflight.

pilot()

Android only

Now let’s look at the Android version. There are two gradle steps: cleaning, and building the release version.

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

Now you can send the generated app to HockeyApp.

hockey(

api_token: “YOUR_TOKEN”

)

If you don’t add some required parameter, for example no iTunes Connect user in Fastfile, Fastlane will ask you for that data in the console.

HockeyApp Configuration

After signing up and signing in to HockeyApp, you will see the blue “New App” button.",https://cdn-images-1.medium.com/max/1200/1*153T3TpCccNK7hs11oRNpA.png,[],https://medium.freecodecamp.org/how-to-deliver-a-react-native-app-to-the-client-e58421e7272e?source=collection_home---6------22----------------,2018-06-05 01:26:27.937000+00:00

Machine Learning,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------,2018-06-05 00:59:03.212000+00:00

Machine Learning,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------#--responses,2018-06-05 00:59:03.212000+00:00

Machine Learning,A coffee-break introduction to time complexity of algorithms,['Vicky Lai'],"A coffee-break introduction to time complexity of algorithms

Just like writing your very first for loop, understanding time complexity is an integral milestone to learning how to write efficient complex programs. Think of it as having a superpower that allows you to know exactly what type of program might be the most efficient in a particular situation — before even running a single line of code.

The fundamental concepts of complexity analysis are well worth studying. You’ll be able to better understand how the code you’re writing will interact with the program’s input, and as a result, you’ll spend a lot less wasted time writing slow and problematic code.

It won’t take long to go over all you need to know in order to start writing more efficient programs — in fact, we can do it in about fifteen minutes. You can go grab a coffee right now (or tea, if that’s your thing) and I’ll take you through it before your coffee break is over. Go ahead, I’ll wait.

All set? Let’s do it!

What is “time complexity” anyway?

The time complexity of an algorithm is an approximation of how long that algorithm will take to process some input. It describes the efficiency of the algorithm by the magnitude of its operations. This is different than the number of times an operation repeats. I’ll expand on that later. Generally, the fewer operations the algorithm has, the faster it will be.

We write about time complexity using Big O notation, which looks something like O(n). There’s rather a lot of math involved in its formal definition, but informally we can say that Big O notation gives us our algorithm’s approximate run time in the worst case, or in other words, its upper bound. It is inherently relative and comparative.

We’re describing the algorithm’s efficiency relative to the increasing size of its input data, n. If the input is a string, then n is the length of the string. If it’s a list of integers, n is the length of the list.

It’s easiest to picture what Big O notation represents with a graph:

Lines made with the very excellent Desmos graph calculator. You can play with this graph here.

Here are the main important points to remember as you read the rest of this article:

Time complexity is an approximation

An algorithm’s time complexity approximates its worst case run time

Determining time complexity

There are different classes of complexity that we can use to quickly understand an algorithm. I’ll illustrate some of these classes using nested loops and other examples.

Polynomial time complexity

A polynomial, from the Greek poly meaning “many,” and Latin nomen meaning “name,” describes an expression comprised of constant variables, and addition, multiplication, and exponentiation to a non-negative integer power. That’s a super math-y way to say that it contains variables usually denoted by letters, and symbols that look like these:

The below classes describe polynomial algorithms. Some have food examples.

Constant

A constant time algorithm doesn’t change its running time in response to the input data. No matter the size of the data it receives, the algorithm takes the same amount of time to run. We denote this as a time complexity of O(1).

Here’s one example of a constant algorithm that takes the first item in a slice.

func takeCupcake(cupcakes []int) int {

return cupcakes[0]

}

Choice of flavours are: vanilla cupcake, strawberry cupcake, mint chocolate cupcake, lemon cupcake, and “wibbly wobbly, timey wimey” cupcake.

With this contant-time algorithm, no matter how many cupcakes are on offer, you just get the first one. Oh well. Flavours are overrated anyway.

Linear

The running duration of a linear algorithm is constant. It will process the input in n number of operations. This is often the best possible (most efficient) case for time complexity where all the data must be examined.

Here’s an example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

}

Here’s another example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// double dip chip

}

}

It doesn’t matter whether the code inside the loop executes once, twice, or any number of times. Both these loops process the input by a constant factor of n, and thus can be described as linear.

Don’t double dip in a shared bowl.

Quadratic

Now here’s an example of code with time complexity of O(n2):

func pizzaDelivery(pizzas int) {

for pizza := 0; pizza <= pizzas; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

Because there are two nested loops, or nested linear operations, the algorithm process the input n2times.

Cubic

Extending on the previous example, this code with three nested loops has time complexity of O(n3):

func pizzaDelivery(boxesDelivered int) {

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

}

Seriously though, who delivers unsliced pizza??

Logarithmic

A logarithmic algorithm is one that reduces the size of the input at every step. We denote this time complexity as O(log n), where log, the logarithm function, is this shape:

One example of this is a binary search algorithm that finds the position of an element within a sorted array. Here’s how it would work, assuming we’re trying to find the element x:

If x matches the middle element m of the array, return the position of m. If x doesn’t match m, see if m is larger or smaller than x. If larger, discard all array items greater than m. If smaller, discard all array items smaller than m. Continue by repeating steps 1 and 2 on the remaining array until x is found.

I find the clearest analogy for understanding binary search is imagining the process of locating a book in a bookstore aisle. If the books are organized by author’s last name and you want to find “Terry Pratchett,” you know you need to look for the “P” section.

You can approach the shelf at any point along the aisle and look at the author’s last name there. If you’re looking at a book by Neil Gaiman, you know you can ignore all the rest of the books to your left, since no letters that come before “G” in the alphabet happen to be “P.” You would then move down the aisle to the right any amount, and repeat this process until you’ve found the Terry Pratchett section, which should be rather sizable if you’re at any decent bookstore, because wow did he write a lot of books.

Quasilinear

Often seen with sorting algorithms, the time complexity O(n log n) can describe a data structure where each operation takes O(log n) time. One example of this is quick sort, a divide-and-conquer algorithm.

Quick sort works by dividing up an unsorted array into smaller chunks that are easier to process. It sorts the sub-arrays, and thus the whole array. Think about it like trying to put a deck of cards in order. It’s faster if you split up the cards and get five friends to help you.

Non-polynomial time complexity

The below classes of algorithms are non-polynomial.

Factorial

An algorithm with time complexity O(n!) often iterates through all permutations of the input elements. One common example is a brute-force search, seen in the traveling salesman problem. It tries to find the least costly path between a number of points by enumerating all possible permutations and finding the ones with the lowest cost.

Exponential

An exponential algorithm often also iterates through all subsets of the input elements. It is denoted O(2n) and is often seen in brute-force algorithms. It is similar to factorial time except in its rate of growth, which, as you may not be surprised to hear, is exponential. The larger the data set, the more steep the curve becomes.

In cryptography, a brute-force attack may systematically check all possible elements of a password by iterating through subsets. Using an exponential algorithm to do this, it becomes incredibly resource-expensive to brute-force crack a long password versus a shorter one. This is one reason that a long password is considered more secure than a shorter one.

There are further time complexity classes less commonly seen that I won’t cover here, but you can read about these and find examples in this handy table.

Recursion time complexity

As I described in my article explaining recursion using apple pie, a recursive function calls itself under specified conditions. Its time complexity depends on how many times the function is called and the time complexity of a single function call. In other words, it’s the product of the number of times the function runs and a single execution’s time complexity.

Here’s a recursive function that eats pies until no pies are left:

func eatPies(pies int) int {

if pies == 0 {

return pies

}

return eatPies(pies - 1)

}

The time complexity of a single execution is constant. No matter how many pies are input, the program will do the same thing: check to see if the input is 0. If so, return, and if not, call itself with one fewer pie.

The initial number of pies could be any number, and we need to process all of them, so we can describe the input as n. Thus, the time complexity of this recursive function is the product O(n).

This function’s return value is zero, plus some indigestion.

Worst case time complexity

So far, we’ve talked about the time complexity of a few nested loops and some code examples. Most algorithms, however, are built from many combinations of these. How do we determine the time complexity of an algorithm containing many of these elements strung together?

Easy. We can describe the total time complexity of the algorithm by finding the largest complexity among all of its parts. This is because the slowest part of the code is the bottleneck, and time complexity is concerned with describing the worst case for the algorithm’s run time.

Say we have a program for an office party. If our program looks like this:

package main



import ""fmt""



func takeCupcake(cupcakes []int) int {

fmt.Println(""Have cupcake number"",cupcakes[0])

return cupcakes[0]

}



func eatChips(bowlOfChips int) {

fmt.Println(""Have some chips!"")

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

fmt.Println(""No more chips."")

}



func pizzaDelivery(boxesDelivered int) {

fmt.Println(""Pizza is here!"")

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

fmt.Println(""Pizza is gone."")

}



func eatPies(pies int) int {

if pies == 0 {

fmt.Println(""Someone ate all the pies!"")

return pies

}

fmt.Println(""Eating pie..."")

return eatPies(pies - 1)

}



func main() {

takeCupcake([]int{1, 2, 3})

eatChips(23)

pizzaDelivery(3)

eatPies(3)

fmt.Println(""Food gone. Back to work!"")

}

We can describe the time complexity of all the code by the complexity of its most complex part. This program is made up of functions we’ve already seen, with the following time complexity classes:

To describe the time complexity of the entire office party program, we choose the worst case. This program would have the time complexity O(n3).

Here’s the office party soundtrack, just for fun.

Have cupcake number 1

Have some chips!

No more chips.

Pizza is here!

Pizza is gone.

Eating pie...

Eating pie...

Eating pie...

Someone ate all the pies!

Food gone. Back to work!

P vs NP, NP-complete, and NP-hard

You may come across these terms in your explorations of time complexity. Informally, P (for Polynomial time), is a class of problems that is quick to solve. NP, for Nondeterministic Polynomial time, is a class of problems where the answer can be quickly verified in polynomial time. NP encompasses P, but also another class of problems called NP-complete, for which no fast solution is known. Outside of NP, but still including NP-complete, is yet another class called NP-hard, which includes problems that no one has been able to verifiably solve with polynomial algorithms.

P vs NP Euler diagram, by Behnam Esfahbod, CC BY-SA 3.0

P versus NP is an unsolved, open question in computer science.

Anyway, you don’t generally need to know about NP and NP-hard problems to begin taking advantage of understanding time complexity. They’re a whole other Pandora’s box.

Approximate the efficiency of an algorithm before you write the code

So far, we’ve identified some different time complexity classes and how we might determine which one an algorithm falls into. So how does this help us before we’ve written any code to evaluate?

By combining a little knowledge of time complexity with an awareness of the size of our input data, we can take a guess at an efficient algorithm for processing our data within a given time constraint. We can base our estimation on the fact that a modern computer can perform some hundreds of millions of operations in a second. The following table from the Competitive Programmer’s Handbook offers some estimates on required time complexity to process the respective input size in a time limit of one second.

Keep in mind that time complexity is an approximation, and not a guarantee. We can save a lot of time and effort by immediately ruling out algorithm designs that are unlikely to suit our constraints, but we must also consider that Big O notation doesn’t account for constant factors. Here’s some code to illustrate.

The following two algorithms both have O(n) time complexity.

func makeCoffee(scoops int) {

for scoop := 0; scoop <= scoops; scoop++ {

// add instant coffee

}

}

func makeStrongCoffee(scoops int) {

for scoop := 0; scoop <= 3*scoops; scoop++ {

// add instant coffee

}

}

The first function makes a cup of coffee with the number of scoops we ask for. The second function also makes a cup of coffee, but it triples the number of scoops we ask for. To see an illustrative example, let’s ask both these functions for a cup of coffee with a million scoops.

Here’s the output of the Go test:

Benchmark_makeCoffee-4 1000000000 0.29 ns/op

Benchmark_makeStrongCoffee-4 1000000000 0.86 ns/op

Our first function, makeCoffee , completed in an average 0.29 nanoseconds. Our second function, makeStrongCoffee , completed in an average of 0.86 nanoseconds. While those may both seem like pretty small numbers, consider that the stronger coffee took nearly three times longer to make. This should make sense intuitively, since we asked it to triple the scoops. Big O notation alone wouldn’t tell you this, since the constant factor of the tripled scoops isn’t accounted for.

Improve time complexity of existing code

Becoming familiar with time complexity gives us the opportunity to write code, or refactor code, to be more efficient. To illustrate, I’ll give a concrete example of one way we can refactor a bit of code to improve its time complexity.

Let’s say a bunch of people at the office want some pie. Some people want pie more than others. The amount that everyone wants some pie is represented by an int > 0:

diners := []int{2, 88, 87, 16, 42, 10, 34, 1, 43, 56}

Unfortunately, we’re bootstrapped and there are only three forks to go around. Since we’re a cooperative bunch, the three people who want pie the most will receive the forks to eat it with. Even though they’ve all agreed on this, no one seems to want to sort themselves out and line up in an orderly fashion, so we’ll have to make do with everybody jumbled about.

Without sorting the list of diners, return the three largest integers in the slice.

Here’s a function that solves this problem and has O(n2) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// loop over three forks

for i := 1; i <= 3; i++ {

// variables to keep track of the highest integer and where it is

var max, maxIndex int

// loop over the diners slice

for n := range diners {

// if this integer is higher than max, update max and maxIndex

if diners[n] > max {

max = diners[n]

maxIndex = n

}

}

// remove the highest integer from the diners slice for the next loop

diners = append(diners[:maxIndex], diners[maxIndex+1:]...)

// keep track of who gets a fork

withForks = append(withForks, max)

}

return withForks

}

This program works, and eventually returns diners [88 87 56] . Everyone gets a little impatient while it’s running though, since it takes rather a long time (about 120 nanoseconds) just to hand out three forks, and the pie’s getting cold. How could we improve it?

By thinking about our approach in a slightly different way, we can refactor this program to have O(n) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// create variables for each fork

var first, second, third int

// loop over the diners

for i := range diners {

// assign the forks

if diners[i] > first {

third = second

second = first

first = diners[i]

} else if diners[i] > second {

third = second

second = diners[i]

} else if diners[i] > third {

third = diners[i]

}

}

// list the final result of who gets a fork

withForks = append(withForks, first, second, third)

return withForks

}

Here’s how the new program works:

Initially, diner 2 (the first in the list) is assigned the first fork. The other forks remain unassigned.

Then, diner 88 is assigned the first fork instead. Diner 2 gets the second one.

Diner 87 isn’t greater than first which is currently 88 , but it is greater than 2 who has the second fork. So, the second fork goes to 87 . Diner 2 gets the third fork.

Continuing in this violent and rapid fork exchange, diner 16 is then assigned the third fork instead of 2 , and so on.

We can add a print statement in the loop to see how the fork assignments play out:

0 0 0

2 0 0

88 2 0

88 87 2

88 87 16

88 87 42

88 87 42

88 87 42

88 87 42

88 87 43

[88 87 56]

This program is much faster, and the whole epic struggle for fork domination is over in 47 nanoseconds.

As you can see, with a little change in perspective and some refactoring, we’ve made this simple bit of code faster and more efficient.

Well, it looks like our fifteen minute coffee break is up! I hope I’ve given you a comprehensive introduction to calculating time complexity. Time to get back to work, hopefully applying your new knowledge to write more effective code! Or maybe just sound smart at your next office party. :)

Sources

“If I have seen further it is by standing on the shoulders of Giants.” –Isaac Newton, 1675",https://cdn-images-1.medium.com/max/1200/1*_YsSsyFQ5sgS8F0kiZ1USA.png,[],https://medium.freecodecamp.org/a-coffee-break-introduction-to-time-complexity-of-algorithms-64df7dd8338e?source=collection_home---6------24----------------,2018-06-04 23:44:40.970000+00:00

Deep Learning,Media – Medium,"['Ev Williams', 'Dave Pell', 'Hossein Derakhshan', 'Dawn Ennis', 'Stephan Neidenbach', 'Don Day', 'Jessie Singer', 'Tim Grierson']","Media Where the newsroom is the news.

Follow Following",https://cdn-images-1.medium.com/max/1200/1*wLhNmBWoSMvG0kyRGjDIqw@2x.jpeg,[],https://medium.com/topic/media,

Deep Learning,The Inspiration of Anthony Bourdain – Member Feature Stories – Medium,['Christine Byrne'],"One of my first great food memories comes from a trip my family took to Normandy when I was six years old. We hadn’t been sitting for two minutes when I announced to my parents, “I want the escargot.”

Dad: “You know that’s snails?”

Six-year-old me: “Yes! We just learned about them in French class, and I want the escargot!”

My parents went along, although I’m sure they expected I’d take a few bites out of stubbornness, then subtly push the dish of garlic and butter and earthy mollusk aside, hoping no one would call out my misplaced courage.

Actually, though, I ate every snail, then mopped up every bit of briny, herby garlic butter left behind. I still think about those snails and about how excited and proud I was to love them so much.

A decade after those snails, I sat on the living room couch with my dad and watched an episode of No Reservations, Anthony Bourdain’s first food travel show. I, like millions of others, was drawn to the irreverent reverence with which he seemed to approach every food he tried, to his eagerness to try anything, and to his ability to narrate the stories of different foods, cooks, and cultures in an unpretentious way that let them mostly speak for themselves. Until then, I had thought of food and travel writing and television as more marketing than storytelling, but watching No Reservations made it clear that, actually, food was not only a story in and of itself, but also a great way to anchor other stories in something tangible and universally understood. Bourdain wasn’t out to sell an experience or show how good something could be — every episode was about telling the story of things exactly as they are.

Bourdain wasn’t the first to talk about food this way, but he was the first to make me feel like maybe I could talk about food that way, too. Food was an important part of my life growing up, but not in a particularly extraordinary way that I felt would resonate. We lived abroad and traveled often, so I was massively privileged in that there was always something new to eat. I remember eating pâté for the first time on a pebble beach in Cornwall while watching my dad (try to) learn to windsurf. I remember tearing apart a slick piece of roti prata and dipping it into a Styrofoam container of curry sauce on a plastic picnic table in Mersing, Malaysia, before getting on a bum boat to an island where I’d go to summer camp for the first time. I remember my first drink: a Tiger beer at Newton Circus, another hawker center, after the closing night of our high school production of South Pacific. I remember, every year when we’d fly home to New Jersey, eating baked ziti and supermarket sheet cake at Fourth of July barbecues, both or which were exciting and special for me because I only ate them once a year. I remember the first time I ate lunch at a New York City deli and was awed by the enormity of both the sandwiches and the Snapple selection. None of this seemed like a story, though, because I wasn’t sure why anyone else would care.

Years later, as a rising college senior, I spent the summer working as a publishing intern in New York. Weeks in, I realized that my longtime goal of being a book editor was actually, definitely, not what I wanted. To keep the “I graduate in a year and now have no plan” anxiety at bay, I read more books that summer than I ever have. One of them was Anthony Bourdain’s Kitchen Confidential.

Bourdain’s 2000 memoir, as you may know, gets so much of its magic from the sense you get while reading that every story is true. I figured it would fall into the “I never want to go there, but that sure made me think and was fun to watch” category that some of the No Reservations episodes did, and that the stories about hypermasculine kitchen culture and the people who somehow ended up in it would make me laugh, think, and then move on to whatever book was next.

That’s not what happened. The first story the book tells is one of Bourdain as a fourth-grader on a European cruise with his family. He tries vichyssoise, a potato-based French soup, and is taken aback by the fact that it’s cold. “I’d eaten in restaurants before, sure,” he says, “but this was the first food I really noticed. It was the first food I enjoyed and, more important, remembered enjoying.” Reading it made me think of my snails, how adventurous they made me feel, and how they established food as something important and worth discovering. It’s a good, tame story that I could easily relate to, and I bet most people felt the same when reading it.

The thing is, the relatability of the book started and ended with that cold potato soup. The rest of the book — about restaurant kitchens and all the crass, stressful, macho, bonkers shit that happened inside them — took place in a world very, very different from mine. Even coming from Bourdain, whose stories had been making me feel welcome since I first watched him walk around Paris unironically wearing cowboy boots in the first episode of No Reservations, the book felt like something I was looking in on from the outside. Reading it piqued my curiosity in restaurant cooking but made it clear that it wasn’t something for me. The longer the stories sat with me, though, the more they started to feel like a sort of…dare.

I graduated soon after, six months earlier than planned. I was still put off by my intern experience in publishing and totally uninspired by every job option presented to me by career counselors and all the well-meaning adults in my life. (Although it was 2010 and the height of a recession, so calling them “options” is maybe a stretch.) Food writing had crossed my mind, but I didn’t figure it was something I could just jump into. I can’t really explain my sudden decision to go to culinary school — a mix of desperation, an interest in food, a burning need to be interesting and different, and a nagging curiosity about Kitchen Confidential, if I had to put it into words — but in 2010, I moved to New York and spent 10 months at the French Culinary Institute learning how to cook. It remains the most impulsive thing I’ve ever done—and the most significant.

The following two and a half years spent cooking in NYC restaurant kitchens taught me things that culinary school never could have—about cooking, stress, being a woman in a room of mostly men, and how to deal with constantly being under fire without falling apart. It’s hard to explain what it was like to walk into a restaurant kitchen, and I honestly don’t remember it clearly, but I do remember that everything I did was wrong, everywhere I was was in the way, and every time someone said something to me, I had to ask them to explain what they were talking about. It was the most underqualified and out of place I’d ever felt, even though I knew in theory that’s exactly what I was signing up for. (I’d read the book! I intentionally jumped out of my comfort zone!) It wasn’t the useless, undervalued feeling that comes with an entry-level office job; it was the feeling that I needed to apologize for even being there, for being the alien who disrupted a system that everyone else knew how to work in. Weeks went by before I was able to walk into that kitchen without absolute fear; months went by before I was able to actually contribute.

Was restaurant cooking the way Bourdain described? Not really. It was vaguely the same, sure: late nights, weekends, burn scars, characters, industry bars, some yelling, ticket boards that inexplicably but reliably went from empty to full in a matter of minutes every single night.

The actual experience of it was very different from what I’d read, though. Because it wasn’t his experience—it was mine. I was the one cramming four hours’ worth of food prep into two and a half every afternoon. I was the one at the stove, firing seven dishes from three different orders at the same time, in exactly the right order, totally on instinct. I was the one who stayed at the bar three hours too long on a Tuesday and somehow always managed to find my way on the L train. I was the one who felt disconnected from one world but totally plugged into another.

Which made me realize: A great storyteller is one who makes you want to experience stories for yourself. A great story is one that makes you think, “I wonder what it would be like to do that.” I’m not much of a storyteller these days, nor am I still a restaurant cook. I write recipes, and I write stories about how and why people should cook them, but I do so in a way that’s shaped by what I’ve learned: Recipes are like stories, kind of, and the best recipes are ones that people will actually cook. Getting someone to cook a recipe isn’t about presenting them with something they’re already familiar with, necessarily, but about making them think, “I wonder what it would be like to do that.”

It’s no secret that Anthony Bourdain was a great storyteller. I’ll miss following along with his unending curiosity about food and how it shapes us, and the world will miss the way he was able to share that curiosity in a way that was welcoming and inclusive. What I’m most grateful for, though, is that he showed me the inside of a world I’d never given a second thought to—restaurants—and painted a picture that, even though it was totally unrelatable to me, was interesting enough that I felt compelled to experience if for myself. Not many storytellers do their job so well that, after reading their stories, you actually feel moved to go out and live them.

“Food, for me, has always been an adventure,” Bourdain writes in the preface of Kitchen Confidential. For me, too, Chef. Thanks for teaching me that food is something worth exploring and that the exploration is something worth writing about.",https://cdn-images-1.medium.com/max/1200/1*65ru7KtyJDme4kUXz8Sl5Q.jpeg,[],https://medium.com/s/story/the-inspiration-of-anthony-bourdain-8d5679c2acb4?source=grid_home---------0------------------18,

Deep Learning,"Apple has no idea what’s next, so it’s just banging on the same old drum",['Owen Williams'],"Apple has no idea what’s next, so it’s just banging on the same old drum If you want to witness a company that’s simultaneously in its prime and losing control over its own narrative, look no further than WWDC, Apple’s second-most splashy event of the year, designed to offer a glimpse of the future. The annual developer event is a spectacle that I’ve watched live for almost a decade, but this year was different: it showcased a company that’s lost in the woods, playing the same old hits on repeat, in the same old format. Not only was it painful to watch, it demonstrated that Apple doesn’t really have a coherent plan, or understanding, of where it should take its core platform, let alone the ones it’s tried to build around it. It’s fine to have an off year, but what struck me was how… random it felt, and how little insight or forward thinking there was. Apple’s own platform advantages, company culture, and whatever else, seem to be pigeonholing its trajectory, driving it down a path that looks increasingly dated, and leaving me to wonder if the company is self-aware enough to see the shifting tide before it’s lost at sea. Big, slow, yearly

Apple struggled throughout 2017 to ship flagship features it promised at WWDC 2017, including Airplay 2 and iCloud Messages, delivering them quietly just days before this year’s event. Alongside a scandal about performance throttling, a series of major security slip-ups, and hardware that shipped without long-touted features, many have loudly asked what’s causing these issues — and why a company with so many engineers is fundamentally failing to ship. Performance improvements are arguably the biggest focus of iOS 12. They’ll be welcome for many users, along with several additional improvements: streamlined notifications, a new ‘shortcuts’ feature for custom buttons, usage reporting, group FaceTime, AR updates and a number of other minor improvements to create a major release, iOS 12. The company’s other platforms received similar treatment, including macOS. Apple finished dark mode, a feature it half-introduced all the way back in Yosemite, added basic functionality to Finder, threw in a new way to organize your desktop, and boom — there’s your major release, 10.14. None of these things are inherently bad — in fact, people have been complaining about the lack of improvements to things like FaceTime for years — but what’s interesting is Apple’s choice to bundle them together as a way to make them look truly meaningful, rather than just fixing many of these issues sooner, in a point release. I’m aware there’s a slew of tiny other fixes and features I haven’t listed here, but that’s my point: it’s a hodgepodge of things that have been neglected over the years after being debuted once and forgotten about. Here’s the rub: Apple could arguably ship notification improvements to iOS users tomorrow in a point release, iOS 11.5, but it won’t. Combining them provides the illusion of progress. Instead of servicing users and giving them features sooner, on a regular basis, Apple chooses to hold back simple functionality longer, for its bottom line. As Martin Bryant points out, Apple may have a timing problem: Yes, Apple needs to take the time to do ‘boring’ optimisation work on iOS, but why build iOS around these big, annual feature bumps and then disappoint people when the bumps aren’t very big?

Interestingly, the narrative here actually doesn’t make sense anymore, either. Every year, Apple takes the time to point out how dire the state of the competition is: Nobody’s Android phones get updates! Android people don’t get any the latest features! Your phones all suck! The reality is different: Android users, regardless of manufacturer, frequently get them sooner than iOS users do, because Google divorced the operating system and core application suite from one another. Google’s approach to unbundling Android has, for the most part, been quietly successful — in an unexpected way. Instead of shipping monolithic feature updates, Google’s applications are now updated via the Play Store, from the clock app to the calculator and even the camera (unless you’re Samsung). Apple has made a yearly ritual out of jabbing competitors for poor update histories, but conveniently omits the reality that improvements to Google Assistant, the built-in web browser, or even just the OS keyboard will reach billions of users in a matter of hours without needing to update the entire phone. Android’s support libraries mean developers can target older devices, with new features, regardless of whether or not they received the OS update. Meanwhile, if you find a bug in the iOS keyboard, or some weird security flaw in Safari’s web view, you hope it gets fixed in the next version of the operating system. Maybe next year, or the year after that. It depends how bad it is, or if Apple is actively maintaining the feature, as to when it’ll get serviced. Don’t get me wrong, Android has a terrible history of updates that is only now beginning to change, ten years after the fact. Google has made strides with Project Treble, which makes an end-run around the device maker itself, but it’s only in its infancy with new devices picking it up today. That’s not good enough either; but it’s gaining traction and getting things into people’s hands. For each platform update, Apple dangles a carrot. That’s the flagship feature to convince you it’s a Big Update™ worth having immediately. On macOS this year, that’s dark mode, and on iOS, the promise of performance improvements and, god forbid, actually decent notification management. Arguably the most interesting segment out of WWDC happens at the very end of the two-hour keynote: a peek at Project Marzipan, a long-term effort to unify the interface framework developers use to build apps for iOS and macOS, which is expected to ship to everyone in 2019.

From where I sit, this is an impressive, massive project that doesn’t do much more than play defense against Electron’s continued march on Apple’s territory, threatening to kill native application development altogether. Why build anything native at all, when you can write once, and run everywhere? Anti-Electron fans will run rabid at the idea, but as the technology has become more efficient and introduced lower-level API access, it only makes even more business sense. Marzipan is an audacious plan to defend against that by making it easier to build cross-platform apps. It’s a genuinely fascinating play with fewer apparent benefits in the short term over just building an Electron app, which addresses an additional billion users, allows developers to use familiar web technology and is truly write-once-run-everywhere. Over time, Marzipan may win favor with developers, but I’m not convinced it’ll stop web-based technologies swallowing native app development whole, particularly given that both Microsoft and Google have now bet their entire strategies on Progressive Web Applications, and how low the barrier of entry has come as a result of Electron’s success. Marzipan indicates something bigger, of course, such as an impending shift away from Intel chipsets entirely to some sort of custom Apple ARM-based silicon in — shock horror — a productivity form factor. If anything, what will win as a result will be that control, and what it could ship in a end-to-end device: true all-day battery? Always-on LTE with desktop class apps? If so, the message is this: lock in with us, develop for our platforms, and we’ll reward you. Don’t, and you’ll be shut out and stuck on the outside. Hey Siri, where’s the vision?

What’s clearly missing in all of this is a willingness to take risks, or go for the long view on what’s better than the status quo for Apple’s users. Instead of looking at how phone usage is changing and redesigning the nature of iOS, it’s another year of shoehorning new features into a decade-old shell. The new shortcuts feature promises to let users wire up workflows of their dreams, chaining together tasks behind a single button. Yes, this is a great improvement to iOS that addresses a problem without actually improving on the reason anyone needs this in the first place — it’s just glued onto the homescreen that’s responsible for causing the need for it in the first place. Apple could have offered up a way to surface the weather right there, deeply integrated with the lock screen, or calendar events at the top of your home screen along with the icons, but it didn’t. Instead, it slathered what appears to be a UX hack in the shape of a notification, and tries to guess when you want to see it. Google’s own developer conference, just down the street in Mountain View, was held in May and offered a clearer, if poorly highlighted, view of the future: AI is a core part of mobile devices going forward, so we’re beginning to add it everywhere. The Android alternative to Shortcuts, Slices and App Actions, surfaces the device’s best guess at your next action as a deeply integrated interface component, where you can actually see information before actually going further in, or taking an action. Want a button to order a Lyft? Great, here’s a button embedded within the system’s app tray, with the current estimated price of your ride, which orders it right now with a single tap. Much of this data is crunched on device, just like Apple’s audacious claims to privacy brag about as well, but instead of being a UX hack to add buttons that summon help, the information is already right there, on hand, without opening anything, even Assistant. Google and Apple both anticipate a future in which we use our phones less — time well spent is a core part of this driver — and as a result, it appears Google has spent a lot of time thinking about how AI can help get the right information to the user. The result is the exact button they need at the right time, with relevant information, sans the need to actually go away and do something. To facilitate this, Google is willing to rejig the UX of its devices, mess with the sea of icons, and has invested heavily in serendipitous computing with Google Home alongside this, so it can get you there faster regardless of if the phone is in your hand.

Google’s vision of the future of smartphones, mobile operating systems, and the way we’ll interact with devices over the long haul is a coherent, well-told story: get more out of your day, get the devices out of the way. It even has a fantastic page that showcases how its own ecosystem works better, together, than I’ve ever seen explained about Apple’s ecosystem on its own site. As for why all of this happens, I suspect it’s a difference in strategy and approach. Apple’s strategy has long been to monetize its existing cash cows as long as it can by throwing out new stuff to see what sticks and doubling down on that, rather than creating any sort of coherent narrative of what the future actually looks like, operating in secrecy until it somehow lands upon it. Incremental improvement is fine, but there’s a distinct lack of forward-looking, and a whole lot of looking over the fence at what everyone else is doing to bash it instead. Apples, oranges and comparing the two

It’s easy to compare and contrast Google and Apple because they are very different companies, but what they’re both claiming to do is the same: invent the future, whatever that actually might be. Their approaches, however, are increasingly diverging: Apple’s squeezing more out of less, shipping flashy features, and focusing on privacy, while Google and others have pushed further into understanding the user and getting out of their way. Most of this comes down to business model. Apple’s focus on features by piling them together drives more sales of iPhone, which drives reliable revenue on a yearly basis. Google’s is on advertising and relevance to the user, which doesn’t depend on a particular feature or thing to tout, it just needs you to love using its tools (and not mind advertising). Apple’s entire strategy over the last two decades has pivoted around the exploitation of a product line until something new comes along, then rinse and repeat. This is framed around improving your life and often actually does, even if that is by proxy. I’d argue that the company’s vision of the future isn’t to enrich, or drive progress, but to squeeze as much revenue as possible out of slick, well-designed and marketed ideas. The products it builds, the cycles they’re released in and the way that Apple’s entire software cycle works reflects this. An example of the manifestation of this is perhaps HomePod’s requirement to have a locally available iPhone to do anything interesting, leaving it crippled without one, and Animoji’s debut only to be locked away in Messages instead of somewhere like the camera.

Google, a latecomer in the game, has the luxury — and peril — of not depending on phone revenue, so it can risk it all and get weird, since it’s not fundamentally critical to the company’s continued trajectory. Microsoft has done the same, now finding itself the underdog, risked it all and moved to an ‘OS-as-a-service’ model in which it ships features when they’re ready instead of waiting for flashy releases. Apple, on the other hand, begins and ends with the iPhone today, the rest flows from there. It can’t just rip up the foundation on which its revenue exists, and Tim Cook hasn’t shown a flair for doing so. iOS is too valuable to go away and tear down to just reimagine it for fun, so it’s the status quo, with experiments like HomePod and AirPods on the side, where it can get weird and sometimes wonderful. That’s fine, because Apple has plenty of cash lying around, but it’s interesting how limiting the approach can become. As we hurtle toward peak smartphone, the cracks here are beginning to show because Apple don’t have the next big thing yet — that we know of, naturally — and it’s taking a long time to get here. We’re essentially watching the bottom of the metaphorical tube of toothpaste being squeezed, while others are trying to figure out if maybe the tube should work completely differently. AR is potentially the next platform, yes, and it’s clear that Apple is pushing forward on that in a big way, so it’s easy to imagine a scenario in which it makes sense to shift precious resources there instead of focusing on iOS which may wind up unimportant in a year or two. I’m not convinced that in the short term, such as the oft-claimed 2020 launch date of an Apple VR/AR headset, that we’ll be headed there in any meaningful capacity. I mean, Magic Leap, a bajillion dollar company building the future of AR showed off its hardware yesterday on Twitch, quipping that “you better not put it in your pocket or it’ll overheat.” I’m happy to be wrong, and I write this knowing I’ll probably be that guy who very publically crapped on the iPhone at launch later. Apple’s worth a very large amount of money, which is more than enough proof that it’s good at many things, including convincing people to buy a phone every year.",https://cdn-images-1.medium.com/max/1200/1*tIUbwrpHZPbdNPXB569wPQ.png,[],https://medium.com/@ow/apple-has-no-idea-whats-next-so-it-s-just-banging-on-the-same-old-drum-dcfd0179cf80?source=grid_home---------0------------------18,2018-06-07 13:54:23.876000+00:00

Deep Learning,Our Wedding Is Canceled Due to the Following Strongly-Held Beliefs,['Tim Sniffen'],"Hi, everyone. I know you weren’t expecting to see Keith and I out here so soon, but we have some bad news. We’re not getting married today.

Believe me, we were really looking forward to it, but recently — this morning, in fact — we learned our blessed event was in direct conflict with the strongly-held beliefs of many of the people providing our wedding services. And if they’re not happy, we’re not happy.

Let me bring you up to speed.

You may have noticed the empty display table by the reception tent as you filed in. That’s where our wedding cake would have been. For our baker, however, creating a cake to be employed in the marriage of two men would be the moral equivalent of using communion wine to make sangria.

We knew the risks when enlisting Give Us This Beignet, Our Daily Bread as our wedding baker. They’re the best in downtown Aurora, no question — sorry, Wild-Flour! — but their beliefs on same-sex marriage are no secret. We hoped they might get swept up in the joy of the occasion but last night their chief baker Jonah, applying the final bit of piping, had a vision of Billie Jean King physically dragging him away from the gates of Heaven. And if that’s not a sign, I don’t know what is.

I should add, it may not have helped that we requested our little cake figurines be surrounded by an added semi-circle of figurines, in likenesses of the bakery staff, giving us the thumbs-up.

But that’s all done with. They’ve made their wishes clear and we respect them.

Which brings me to the empty vases alongside the pews and the empty centerpiece bowls on the reception tables. We’ve known Joyce Gantz, owner of Rest On My Laurels, for years; I couldn’t imagine this day without her. What I couldn’t know was the war raging within Joyce, fervent Catholic, after she learned of the meat-laden Friday barbecues Keith and I throw for our softball team. Last night, Joyce looked deep within her heart to ask, can I lend my good name to this cursed union?

The dumpster full of imported delphinium behind Joyce’s shop can tell you the answer.

You see, what we’re learning is that these are not just goods and services; they’re not simply the imprints of Keith’s Capital One card and the resulting exchange of goods. Every item at a wedding is nothing less than the avatar of its vendor’s entire belief system. With this in mind, each rose petal my niece Stephanie was prepared to hurl down the aisle might as well have been embossed with JOYCE GANTZ APPLAUDS THEE, SATAN.

What faith-engorged entrepreneur should face such hell?

This is why the rows of steam-trays in the tent are empty, and your choice of beef tenderloin or grilled salmon — or the one plate of tempeh veggie kabob, bless you, Amy! — will never arrive. Because Something Borrowed, Something Cordon Bleu, exceptional wedding caterers and unapologetic druids, could not bear the thought of providing nourishment to a couple willing to rip two thriving Magnolia trees from their backyard last summer. From their email: “Your heretic’s feast will be served when the earth heals from your violence.” By our best guess that wouldn’t have been by 6 p.m.

We also won’t be dancing to Renèe and the Ring-tones. While Rènee was a woman of few beliefs when we booked her, she has since converted to the Egyptian cult of Bastet, and considers the choice to put our cat Banjo to sleep, rather than pay $15,000 for experimental feline jaw surgery, to be “unforgivable wickedness, worthy of disciples of Set.”

I’ve been handed this note: Lane, our photographer, turns out to be more of a Star Wars guy and doesn’t feel right legitimizing such an obviously Star Trek couple.

Blessings on your journey, Lane.

In closing, our apologies. We were so busy coordinating our big day that we forgot to coordinate the sacred truths of all players involved. I’m told many of our vendors will adopt an exhaustive three-week interview process before each sale to keep this from happening again.

We did have a lovely wedding favor created for each of you, which we might as well distribute. It’s a wooden plaque, engraved with the phrase Love Conquers All, hand-crafted by our friend Bryce Charles in the front row. Now, Bryce is something of a Packers fan, and Keith is all about the Bears, but in the spirit of friendly rivalry, we’ve always managed to put aside our differ — wait.

Bryce’s feelings are changing.

They’re moving from loosely-held to nonchalantly-held. They’re not done; from the set of Bryce’s jaw, her feelings have transitioned to intentionally-held, and finally, they’re — yup. They’re strongly-held. Dammit.

Sorry, folks. You’re on your own.",https://cdn-images-1.medium.com/focal/1200/632/50/45/0*fh1vaEnMNoMbHE42,[],https://medium.com/s/story/our-wedding-is-cancelled-due-to-the-following-strongly-held-beliefs-1fa71105660e?source=grid_home---------0------------------18,

Deep Learning,My So-Called (Millennial) Entitlement – Trust Issues – Medium,['Stephanie Georgopulos'],"I am at the San Francisco International Airport some barely recent morning, registering for a travel program called Clear when the automated kiosk assisting me makes a strange request: “Stand still while we scan your irises.” I’ve barely digested this first ask when another takes its place: this time, the kiosk wants my fingerprints. I find this slightly less alarming; I already use those to access my banking app, buy coins for my mobile games, and unlock the phone that hosts all this information in the first place. But my eyeballs — which I had only just learned could be used as ID, and from a machine at the airport, no less — my dude. Those are the windows to my soul! Ever heard of foreplay?

Clear is a private company that prescreens air travelers using biometric authentication. Becoming a member is like ordering the half-soup, half-sandwich version of TSA PreCheck: it works, if all you want is a taste and are willing to pay for it. With Clear, you don’t need your ID to go through security, but you still have to remove your shoes. You get to wait in a shorter line (sometimes), but you still have to take out your laptop. Basically, the Cleared still participate in the most annoying aspects of air travel and pay almost 10 times the PreCheck fee for the privilege.

If the worst has already happened, that means it’s survivable.

How we decided on this valuation of convenience—it’s $179 per year—is not the point, though. My point is that some random startup casually acquired my eye-prints, and some small voice is telling me I should care more than I do. Someone out there definitely cares about this, no doubt. I’m sure at least one other traveler was not sated when a brisk Google search revealed that Clear is based in her hometown and run by a female CEO, ergo it must be a secure and entirely trustworthy business.

But I was sated. It’s the future, right? What’s the worst one could do with my retinal scans? I already gave my social security number to Camel in exchange for a pack of promotional cigarettes one time (or 12). Somewhere in Midtown Manhattan, a market-research firm knows how many condoms I used in May of 2011 (give or take). And when I think about the fact that every hard document I’ve reproduced on a digital copy machine — at work, at the bodega, at the library — is saved on a hard drive somewhere (lots of somewheres, in fact), I feel a sense of hopelessness that, in its own demented way, translates to freedom.

That’s why I unlock my phone with my fingerprint. It’s also why I talk shit in front of Alexa, why I haven’t put tape over my laptop camera, and why I still have a Facebook account. I don’t expect the worst to happen.

Because the worst has already happened. It is happening, and it will continue to happen.

I find this to be an honest, useful framework. If the worst has already happened, that means it’s survivable. And if the worst is a given in the future, too, we know that ignoring it won’t make it go away. There’s opportunity in having nothing to lose. You just need the right attitude.

Or perhaps you need the right conditioning.

Imagine: You’re 11 years old when two teenagers bring guns to their high school and kill 13 people. They injure 21 more. Your sixth-grade humanities teacher explains the inexplicable to your class after lunch period. You have to imagine that this is a first for at least some of your classmates, crying over the national news. It won’t be the last.

When you’re 15, two planes crash into two towers. You know the towers; had toured them on school trips just like all the other famous Manhattan buildings for which you know the names, if not the functions. In fact, you’d visited the towers just one week before the planes hit. There had been a renaissance fair in one of the lobbies.

At 17, your high school economics teacher tells you that social security will run out before you retire. You’ve already been paying taxes for three years. In 2018, you learn that he was exaggerating, thank goodness — by 2034, retirees can expect to receive a whopping 79% of the full benefit they receive today. You will not be of retirement age until the 2050s.

And when you’re 21, the market crashes. You’ve had a bachelor’s degree for three months. It cost $100,000 to earn, all before interest. Your class valedictorian moves back in with her parents, and no, your internship is not hiring. Five years later, the unemployment rate for people your age is almost double the national average.

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

Neuroscience has confirmed that you were making sense of these events with an underdeveloped brain. Along with your emotional maturity and your hormones, it’ll be a work-in-progress until you’re around 25. And the same way the small hurts of being small can still seep into your present — the way your grandmother eyed you with disgust when you went for a second helping — the chipping away of every institution you were raised to believe in can have unintended consequences.

Me: Do you use Touch ID to unlock your phone?

Friend: Ya.

Me: Do you know anything about the technology behind it? Or like, how secure it is?

A beat. A blank stare.

Friend: No?

Me: Same.

My friends do not need to understand the technology behind touch ID any more than they need to understand black holes. They are not convinced that adjusting their social media privacy settings is some sort of moral duty, a symbolic middle finger to Facebook on behalf of all the little guys who understand internet economics to varying degrees, or not at all. Mostly, they were confused as to why any thinking person would have an assumption of security.

“It’s not that I don’t care about being hacked, or about my data being stolen or sold,” one friend tells me. “I assume that vulnerability because there are no physical systems or structures that have succeeded, so why would something that is essentially invisible do a better job than something tangible?”

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

I’ll go: I don’t expect to own a home. I don’t expect to retire well, or at all. I don’t expect anyone to give me anything I haven’t explicitly asked for, and even then. I don’t expect it will ever be affordable to continue my education in any formal way. If a package gets lost in the mail, I don’t expect to see it again. I don’t expect the government or the banks or the universities to do anything that benefits regular people. I don’t expect them to hold each other accountable on our behalf. I don’t expect them to expel abusers from their ranks, or to put my safety over their legacy. I don’t expect to feel safe in large crowds or alone late at night. And I don’t expect that my privacy will be respected, online or in general.

America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

As far as I can tell, security — whether financial, technological, physical, or emotional — is not a thing. You don’t get to decide whether some drunk asshole drinks his drunk ass off and gets behind the wheel. Likewise, you don’t get to decide if the drunk Congress or the drunk banker or all the drunk administrations of all the drunk institutions do what’s right for you. Sometimes they will do the right thing for somebody, but statistically speaking, that somebody is not you.

Sometimes the right thing comes served in a shit sandwich, or one guy does the right thing but it’s later counteracted by the next guy and just so we’re clear, it’s always a guy. Or sometimes, we learn that what we thought was the right thing was actually the wrong thing, in ways we didn’t anticipate, except for those of us who did anticipate it but were not asked or heard because we do not employ lobbyists and because the powers that be can’t listen to us until they sort out whether our bodies are legal or not.

Mark Zuckerberg’s Congressional hearing was probably the biggest mainstreaming of data privacy issues yet, and Facebook, with its many transgressions, made for an appropriate scapegoat. But I want to know why it’s Mark Zuckerberg’s fault that American adults of voting age lack the critical thinking skills to differentiate between fake Russian bot news and The Guardian. I want to know the plan for bringing internet literacy to those who are not digital natives. I want to know why the U.S. government is being celebrated for protecting our egos and baby-proofing the internet instead of telling us the truth: Dirty tricks are less likely to work on people with more education.

What happens when your brand of exceptionalism breeds millions of people who voted a sentient conspiracy theory into office? Where does the fault lie? After all, it’s not Facebook who’s spent decades underpaying teachers and closing schools in low-income neighborhoods. Facebook doesn’t have the jurisdiction to end standardized testing or combat the quiet continuation of white flight. Facebook’s biggest mistake? Profiting off of state-sanctioned dumbness.

We’re only supposed to be dumb enough to believe that the fight is red vs. blue and not top vs. bottom. We’re only supposed to be dumb enough to believe in Democracy the Concept™ without casting a critical eye toward its practical application. This is a dumbness cultivated by and for Washington, and Zuckerberg’s misusing of it for corporate gain almost blew the lid off the entire thing. Commence finger-wagging.

On an episode of his podcast Revisionist History, Malcolm Gladwell argues that we should treat education as a weak-link network, where strengthening the weakest links has the most positive outcome for all. This is in contrast to a strong-link network, where a couple of superstars at the top carry the weaker players on the bottom. He illustrates this dynamic using soccer and basketball. An average soccer team with one star player is less likely to win a match than an above-average team with no star players — soccer is a weak-link sport. Conversely, an NBA team with a superstar or two fares better than a team on which all the players are equally, decently good — basketball is a strong-link sport.

Much to its detriment, America acts like a strong-link country. It is the type of place where electing one mixed-race president means we solved racism. (Imagine if the lesson we took from electing one white man was that all white men who lack upward mobility just need to work harder.) We raise up a few undoubtedly smart and deserving people in each field, send them around the world like brand ambassadors for democracy, poster-adults for how advanced and distinguished and American we are. Meanwhile, most of us back home — 78%, in fact — are living paycheck to paycheck. Is that freedom ringing? We’ll call right back after we pay this phone bill.

These are complex problems. In addition to the 3000ish words here, I have written and cut an additional 4500 trying to make sense of it all. I remain overwhelmed by the number of solutions that contradict one another, the knowns and unknowns, the countless logical ends I haven’t considered. But I eventually found my demented silver lining: America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

While grim on its face, this perspective has pushed me to take inventory of myself, my own power. What can I do right now? Am I solving problems I actually care about, or were these problems unconsciously inherited from another time, problems propagated by those with a vested interest in resolving them with more money, more power, more loopholes? Should I devote my energy to righting a system that, by design, has only consistently benefited one demographic and has yet to even prove itself as a scalable model for a generation that’s tired of the same people making the same decisions on behalf of the most diverse country in the world?

Is that a problem? Because it feels more like an opportunity, to me: a chance to exercise this cache of personal agency I’ve been sitting on, agency I didn’t realize I had or needed as I waited for America to work. It feels like an opportunity to try something else.

More powerful than having nothing to lose is cultivating that which can’t be taken. Grace. Clarity. Purpose. The stuff that isn’t Amazon Prime-able. These are the indoor plants of our being; only you can feed them and grow them and expose them to the light. It’s a lot of responsibility, and the work involved is often unglamorous. Some people think they never have to learn to care for these things because they have the means to outsource what they wish: their plants are alive on paper though they don’t know the how or why of it. And besides, can’t you see they’re a little busy trying to colonize Mars?

A respectable goal, though I might suggest to anyone faced with the choice to try taking on the inner self before jumping ahead to outer space. There’s more to unearth in there than you might think, and we need more people to understand the potential of their own organic material. We need people who appreciate the slow growth of nothing into something, who drink up the sunlight and make the air a little more breathable than before.

Because that’s it, for most of us. That’s how we build power. That’s how we, a generation of janitors for the American dream, put our trust in something real: each other. We stop trying to control the world in our heads and in the headlines, and we start controlling ourselves. We sleep. We go to the doctor. We log off. We talk about our problems. We water our plants. We collect our neighbor’s mail when they’re out of town. We take a deep breath before reacting in anger, and question whether this particular battle is worth our energy. It’s not. Why were we fighting again? We volunteer. We water our plants. We focus on ourselves so we can eventually focus on others — in a real way, in a non-transactional way, in a way that slowly but authentically strengthens our fellow weak links. We don’t wait for permission. We get over ourselves; we stop demanding perfection; we start. We water our plants. And on weekends, we play soccer.",https://cdn-images-1.medium.com/max/1200/1*c5zNxCX34sYmYYO-yRxlbA.png,[],https://medium.com/s/trustissues/my-so-called-millennial-entitlement-9be84343c713?source=grid_home---------0------------------18,

Deep Learning,How to Cope with the End of the World – How to Cope With The End of The World – Medium,['Maria Farrell'],"We All Die, and That’s Okay

My favorite postapocalyptic novel is George R. Stewart’s 1951 Earth Abides. In it, scientist Isherwood Williams (nicknamed Ish) survives a plague and eventually starts a new family and community in the ruins of suburban California. His hope for the future is wholly invested in a child who is intellectually curious, like him, and who might be able to revive some of the old ways and technologies. It’s an observant and reflective novel, full of the “how stuff would probably work” thinking that makes science fiction the true literature of ideas.

Ish starts out as a scientist-savior of humanity, figuring there is just enough time to raise a generation to turn back the clock to before the disaster. But he ultimately has to make his peace with the fact that civilization as he knew it is dead, there will be no heroic rescue, no going back, and the people around him are mostly fine with that.

The 1950s may have been the last decade we could complacently believe the Ecclesiastes (1:4) maxim that “men come and go, but earth abides,” but Stewart’s basic message is correct.

The people who come after us don’t have to do better than us, or think well of us, for them to be essentially okay. And us all throwing a big “let’s blow it all up” hissy fit because we fucked up and we can’t bear to look at it is just teenage nihilism that we need to grow out of already. Coming to terms with what we have done means dumping the egotistical death drive of the mass shooter or far-right politician and gathering the maturity to look our individual and collective deaths straight in the eye and say, “Okay, we get it now. We get it. It’s not about us.”

Have you ever stood in a crowded place like a town square or an airport meet-and-greet and thought, “Every single person here is going to die”? Morbid, eh? More of us should do it.

I live in an early Victorian terraced house in the UK. It’s never been a tenement, so probably a hundred people have called it home in the almost two centuries it’s been standing. Nearly all of them are dead. The people are already born who’ll live there when I’m dead. The head of this country’s anachronistic state has already been born who I’ll never see on the throne and to whom I’ll seem as old as someone born in the 1930s seems to me.

We’re all going to die. The morning will come when those who have loved us put on dark clothes and cry and get on with the rest of their lives, seeing movies we’d have loved, depending on gadgets that now seem to us ridiculously unnecessary. Our deaths matter to us and those who love us, but they don’t fundamentally matter.

Once, while my husband was deployed to Afghanistan, I asked him on the phone if he was doing okay about someone we knew who’d recently been killed. “Oh, you know,” he said, “you know,” and quoted his regiment’s unofficial mantra:

Everything matters. Nothing matters terribly.

The soldier’s death mattered very, very much to him, and (not but) he and others were nonetheless carrying on their shared purpose. Otherwise, what had been the point of any of it?

What will outlive us, individually? Plastic. Perhaps some genes. The bacteria that act as a species-level enabler for everything we are. Some ideas, maybe, or songs, stories, pictures, the memories of us others hold, until they go, memorials like a community flower bed or a named scholarship, for a while, anyway. Less concretely: ways of being, a fitness for the world that those who flourish pass unremarked to their offspring via the epigenetics of love — the sunny inverse of patterns of trauma and abuse transmitted through the body, even unto the third generation. Predation.

And our species? Buildings and bones, maybe. Our nuclear waste and the warning signs we hope people of our deep future, or other species altogether, will decrypt. Snatches of radio-transmitted voices slipping through the vacuum of space. Perhaps some bacterial payload we’ll launch in a decade or so, trying to seed life on other planets, even in other solar systems. Or just the anomalous levels of carbon dioxide and methane in our atmosphere that will reveal, for a time, that complex forms of life were here.

Pride and despair are two sides of the same coin. Our collective denial and despair about the future we have built is preventing us from cracking on and sorting it out. We need to get over ourselves. The world we know will end, in both small and big ways. We ourselves will end. But that doesn’t matter, terribly.

Our mortality is the greatest enabler we have of positive, ongoing change, if only we can face it, if only we can understand that we don’t get to see the end of the movie, because, if what we do works, the movie won’t have to end. We’re not the protagonists. We’re just the foreshadowing. We need to hold the knowledge of our own deaths up to the light and turn it around to see each shining facet, then take the certainty that we are both finite and imperfect deep down inside of us—and put it to work.",https://cdn-images-1.medium.com/max/1200/0*avXWZmh3n3H7a8t8,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world/how-to-cope-with-the-end-of-the-world-2520ef9d3dbc?source=grid_home---------0------------------18,

Deep Learning,How to Cope With The End of The World – Medium,['Maria Farrell'],"COLUMN

How to Cope With The End of The World

There are moments of joy even in times of great despair. Maria Farrell explains how to deal with a darkening world, and how to plan for the end. It might be the end of the world as we know it, but it turns out we feel fine.",https://cdn-images-1.medium.com/max/1200/1*kvqwUuDCsbkAoSfaYXV1vQ@2x.png,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world,

Deep Learning,Chatbots were the next big thing: what happened? – The Startup – Medium,"['Matt Asay', 'Justin Lee']","Chatbots were the next big thing: what happened?

Oh, how the headlines blared:

“…the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”

Chatbots were The Next Big Thing.

Our hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.

And why wouldn’t they be? All the road signs pointed towards insane success.

Messaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!

Plus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.

At the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.

In fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:

“Will a single platform emerge to dominate the chatbot and personal assistant ecosystem?”

One year on, we have an answer to that question.

No.

Because there isn’t even an ecosystem for a platform to dominate.

Fooled by another hype cycle

Chatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.

The age-old hype cycle unfolded in familiar fashion…

Reverential TechCrunch articles were written.

Prophetic thought leaders like Chris Messina chimed in.

Silicon Valley salivated at the prospect of talking to smart automation.

Messenger began to overflow with bots.

Slack went through exponential growth and even launched a fund for bot investment.

Expectations built, built, and then….. It all kind of fizzled out.

The predicted paradim shift didn’t materialize.

And apps are, tellingly, still alive and well.

We look back at our breathless optimism and turn to each other, slightly baffled:

“is that it? THAT was the chatbot revolution we were promised?”

Digit’s Ethan Bloch sums up the general consensus:

“I’m not even sure if we can say ‘chatbots are dead,’ because I don’t even know if they were ever alive.”

According to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.

Text vs. Speech vs. GUI: a potted history

Bots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.

Users had to type commands manually into a machine to get anything done.

Then, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!

Meanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.

Another bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:

… so many different accents, people speaking too fast or too slowly, mumbling, umming and aahing.

Did you say “recognise speech” or “wreck a nice beach”?

The next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:

User: “Hello.”

Agent: “Hello, what’s your name?”

User: “Candy.”

Agent: “Hello, Candy!”

User: “Let’s set the clock.”

Agent: “What is the time?”

User: “The time is 11:00 AM.”

Agent sets the clock to 11:00 AM.

Pretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.

It was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.

Modern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.

Basically, we’re still trying to achieve the same innovations we were 30 years ago.

Here’s where I think we’re going wrong:

Thinking in terms of Bots vs. Apps

An oversized assumption has been that apps are ‘over’, and would be replaced by bots.

By pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.

You might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?

It’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.

Whether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.

Plus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.

A great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.

That’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.

Modern-day apps benefit from decades of research and experimentation. Why would we throw this away?

But, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.

Today’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.

Penny provides chatty advice and alerts alongside a traditional account dashboard and transaction list.

HubSpot Conversations unifies Facebook Messenger, onsite chat, social media, email and other messaging outlets into one shared inbox.

Layer gives developers the tools to create personalized messaging experiences on mobile web and desktop web as well as native apps.

The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.

Bots for the sake of bots

Does my product need a bot? Are existing platforms able to support its functionality? Do I have the patience to build a bot that’s capable of doing what I want it to?

Another problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.

For plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.

Building a bot for the sake of it, letting it loose and hoping for the best will never end well:

The totally necessary Maroon 5 chatbot in action

The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.

The advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.

That’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.

Problems arise when life refuses to fit into those boxes.

According to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.

When we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.

Remember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.

Inaccessibility

A competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.

In an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.

Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)

As Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.

“Consumer interest was never going to materialize until machine intelligence could get anywhere near human intelligence.

User interest depends upon AI that makes talking with a bot worthwhile for consumers.”

And conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.

Today’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.

And in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:

“Should Slack, Facebook, Google, Microsoft, Kik, and others have built their own built-in bots to lead the way?

Should they have gotten more proactive with their bot funds and incubators, hiring mentors to educate participants in the Way of the Bot, or supplying engineering and design resources? Funded Strategic Bot Initiatives at high-profile partners?

In my opinion yes, yes, and yes. When it comes to platforms, developers are the users; and we don’t rely on our users to understand why or how to use our products. We have to show them.”

GUI shouldn’t be dismissed

Once upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information

There’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.

Tapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.

We love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.

Conversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.

Sure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.

Humans like talking to other humans

Aiming for a human dimension in business interactions makes sense.

If there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.

Facebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.

A conversation encompasses so much more than just text.

Humans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.

As HubSpot team pinpointed:

Bots provide a scalable way to interact one-on-one with buyers. Yet, they fail when they don’t deliver an experience as efficient and delightful as the complex, multi-layered conversations people are accustomed to having with other humans on messaging apps.

People aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).

And even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.

And here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.

But is that how humans prefer to interact with machines?

Not necessarily.

At the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.

Where do we go from here?

In a way, those early-adopters weren’t entirely wrong.

People are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.

Not even close.

Computers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.

Computers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.

That’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.

For now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.

But that’s not the whole story.

Yes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.

As Bill Gates once said:

We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. Don’t let yourself be lulled into inaction.

The hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.

I believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.

Messaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.

Developers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.

And I can’t wait to see what happens next.",https://cdn-images-1.medium.com/max/1200/1*-_um8Nai0uer46tni1LETg.jpeg,[],https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=topic_page---8------0----------------,2018-06-05 15:55:36.912000+00:00

Deep Learning,Google’s AutoML will change how businesses use Machine Learning,['George Seif'],"Google’s AutoML will change how businesses use Machine Learning

Google’s AutoML is a new up-and-coming (alpha stage) cloud software suite of Machine Learning tools. It’s based on Google’s state-of-the-art research in image recognition called Neural Architecture Search (NAS). NAS is basically an algorithm that, given your specific dataset, searches for the most optimal neural network to perform a certain task on that dataset. AutoML is then a suite of machine learning tools that will allow one to easily train high-performance deep networks, without requiring the user to have any knowledge of deep learning or AI; all you need is labelled data! Google will use NAS to then find the best network for your specific dataset and task. They’ve already shown how their methods can achieve performance that is far better than that of hand-designed networks.

AutoML totally changes the whole machine learning game because for many applications, specialised skills and knowledge won’t be required. Many companies only need deep networks to do simpler tasks, such as image classification. At that point they don’t need to hire 5 machine learning PhDs; they just need someone who can handle moving around and organising their data.

There’s no doubt that this shift in how “AI” can be used by businesses will create change. But what kind of change are we looking at? Whom will this change benefit? And what will happen to all of the people jumping into the machine learning field? In this post, we’re going to breakdown what Google’s AutoML, and in general the shift towards Software 2.0, means for both businesses and developers in the machine learning field.

More development, less research for businesses

A lot of businesses in the AI space, especially start-ups, are doing relatively simple things in the context of deep learning. Most of their value is coming from their final put-together product. For example, most computer vision start-ups are using some kind of image classification network, which will actually be AutoML’s first tool in the suite. In fact, Google’s NASNet, which achieves the current state-of-the-art in image classification is already publicly available in TensorFlow! Businesses can now skip over this complex experimental-research part of the product pipeline and just use transfer learning for their task. Because there is less experimental-research, more business resources can be spent on product design, development, and the all important data.

Speaking of which…

It becomes more about product

Connecting from the first point, since more time is being spent on product design and development, companies will have faster product iteration. The main value of the company will become less about how great and cutting edge their research is and more about how well their product/technology is engineered. Is it well designed? Easy to use? Is their data pipeline set up in such a way that they can quickly and easily improve their models? These will be the new key questions for optimising their products and being able to iterate faster than their competition. Cutting edge research will also become less of a main driver of increasing the technology’s performance.

Now it’s more like…

Data and resources become critical

Now that research is a less significant part of the equation, how can companies stand out? How do you get ahead of the competition? Of course sales, marketing, and as we just discussed, product design are all very important. But the huge driver of the performance of these deep learning technologies is your data and resources. The more clean and diverse yet task-targeted data you have (i.e both quality and quantity), the more you can improve your models using software tools like AutoML. That means lots of resources for the acquisition and handling of data. All of this partially signifies us moving away from the nitty-gritty of writing tons of code.

It becomes more of…

Software 2.0: Deep learning becomes another tool in the toolbox for most

All you have to do to use Google’s AutoML is upload your labelled data and boom, you’re all set! For people who aren’t super deep (ha ha, pun) into the field, and just want to leverage the power of the technology, this is big. The application of deep learning becomes more accessible. There’s less coding, more using the tool suite. In fact, for most people, deep learning because just another tool in their toolbox. Andrej Karpathy wrote a great article on Software 2.0 and how we’re shifting from writing lots of code to more design and using tools, then letting AI do the rest.

But, considering all of this…

There’s still room for creative science and research

Even though we have these easy-to-use tools, the journey doesn’t just end! When cars were invented, we didn’t just stop making them better even though now they’re quite easy to use. And there’s still many improvements that can be made to improve current AI technologies. AI still isn’t very creative, nor can it reason, or handle complex tasks. It has the crutch of needing a ton of labelled data, which is both expensive and time consuming to acquire. Training still takes a long time to achieve top accuracy. The performance of deep learning models is good for some simple tasks, like classification, but does only fairly well, sometimes even poorly (depending on task complexity), on things like localisation. We don’t yet even fully understand deep networks internally.

All of these things present opportunities for science and research, and in particular for advancing the current AI technologies. On the business side of things, some companies, especially the tech giants (like Google, Microsoft, Facebook, Apple, Amazon) will need to innovate past current tools through science and research in order to compete. All of them can get lots of data and resources, design awesome products, do lots of sales and marketing etc. They could really use something more to set them apart, and that can come from cutting edge innovation.

That leaves us with a final question…

Is all of this good or bad?

Overall, I think this shift in how we create our AI technologies is a good thing. Most businesses will leverage existing machine learning tools, rather than create new ones since they don’t have a need for it. Near-cutting-edge AI becomes accessible to many people, and that means better technologies for all. AI is also quite an “open” field, with major figures like Andrew Ng creating very popular courses to teach people about this important new technology. Making things more accessible helps people transition with the fast-paced tech field.

Such a shift has happened many times before. Programming computers started with assembly level coding! We later moved on to things like C. Many people today consider C too complicated so they use C++. Much of the time, we don’t even need something as complex as C++, so we just use the super high level languages of Python or R! We use the tool that is most appropriate at hand. If you don’t need something super low-level, then you don’t have to use it (e.g C code optimisation, R&D of deep networks from scratch), and can simply use something more high-level and built-in (e.g Python, transfer learning, AI tools).

At the same time, continued efforts in the science and research of AI technologies is critical. We can definitely add tremendous value to the world by engineering new AI-based products. But there comes a point where new science is needed to move forward. Human creativity will always be valuable.

Conclusion

Thanks for reading! I hope you enjoyed this post and learned something new and useful about the current trend in AI technology! This is a partially opinionated piece, so I’d love to hear any responses you may have below!",https://cdn-images-1.medium.com/max/1200/1*g9BzirXxUauRO9rA_tSvnA.jpeg,[],https://towardsdatascience.com/googles-automl-will-change-how-businesses-use-machine-learning-c7d72257aba9?source=topic_page---8------1----------------,2018-05-14 14:27:41.145000+00:00

Deep Learning,Automated Feature Engineering in Python – Towards Data Science,['William Koehrsen'],"First, let’s take a look at our example data. We already saw some of the dataset above, and the complete collection of tables is as follows:

Deep feature synthesis stacks multiple transformation and aggregation operations (which are called feature primitives in the vocab of featuretools) to create features from data spread across many tables. Like most ideas in machine learning, it’s a complex method built on a foundation of simple concepts. By learning one building block at a time, we can form a good understanding of this powerful method.

Fortunately, featuretools is exactly the solution we are looking for. This open-source Python library will automatically create many features from a set of related tables. Featuretools is based on a method known as “ Deep Feature Synthesis ”, which sounds a lot more imposing than it actually is (the name comes from stacking multiple features not because it uses deep learning!).

These operations are not difficult by themselves, but if we have hundreds of variables spread across dozens of tables, this process is not feasible to do by hand. Ideally, we want a solution that can automatically perform transformations and aggregations across multiple tables and combine the resulting data into a single table. Although Pandas is a great resource, there’s only so much data manipulation we want to do by hand! (For more on manual feature engineering check out the excellent Python Data Science Handbook ).

This process involves grouping the loans table by the client, calculating the aggregations, and then merging the resulting data into the client data. Here’s how we would do that in Python using the language of Pandas .

On the other hand, aggregations are performed across tables, and use a one-to-many relationship to group observations and then calculate statistics. For example, if we have another table with information on the loans of clients, where each client may have multiple loans, we can calculate statistics such as the average, maximum, and minimum of loans for each client.

we can create features by finding the month of the joined column or taking the natural log of the income column. These are both transformations because they use information from only one table.

A transformation acts on a single table (thinking in terms of Python, a table is just a Pandas DataFrame ) by creating new features out of one or more of the existing columns. As an example, if we have the table of clients below

The process of constructing features is very time-consuming because each new feature usually requires several steps to build, especially when using information from more than one table. We can group the operations of feature creation into two categories: transformations and aggregations . Let’s look at a few examples to see these concepts in action.

Feature engineering means building additional features out of existing data which is often spread across multiple related tables. Feature engineering requires extracting the relevant information from the data and getting it into a single table which can then be used to train a machine learning model.

If we have a machine learning task, such as predicting whether a client will repay a future loan, we will want to combine all the information about clients into a single table. The tables are related (through the client_id and the loan_id variables) and we could use a series of transformations and aggregations to do this process by hand. However, we will shortly see that we can instead use featuretools to automate the process.

Entities and EntitySets

The first two concepts of featuretools are entities and entitysets. An entity is simply a table (or a DataFrame if you think in Pandas). An EntitySet is a collection of tables and the relationships between them. Think of an entityset as just another Python data structure, with its own methods and attributes.

We can create an empty entityset in featuretools using the following:

import featuretools as ft

# Create new entityset

es = ft.EntitySet(id = 'clients')

Now we have to add entities. Each entity must have an index, which is a column with all unique elements. That is, each value in the index must appear in the table only once. The index in the clients dataframe is the client_id because each client has only one row in this dataframe. We add an entity with an existing index to an entityset using the following syntax:

The loans dataframe also has a unique index, loan_id and the syntax to add this to the entityset is the same as for clients . However, for the payments dataframe, there is no unique index. When we add this entity to the entityset, we need to pass in the parameter make_index = True and specify the name of the index. Also, although featuretools will automatically infer the data type of each column in an entity, we can override this by passing in a dictionary of column types to the parameter variable_types .

For this dataframe, even though missed is an integer, this is not a numeric variable since it can only take on 2 discrete values, so we tell featuretools to treat is as a categorical variable. After adding the dataframes to the entityset, we inspect any of them:

The column types have been correctly inferred with the modification we specified. Next, we need to specify how the tables in the entityset are related.

Table Relationships

The best way to think of a relationship between two tables is the analogy of parent to child. This is a one-to-many relationship: each parent can have multiple children. In the realm of tables, a parent table has one row for every parent, but the child table may have multiple rows corresponding to multiple children of the same parent.

For example, in our dataset, the clients dataframe is a parent of the loans dataframe. Each client has only one row in clients but may have multiple rows in loans . Likewise, loans is the parent of payments because each loan will have multiple payments. The parents are linked to their children by a shared variable. When we perform aggregations, we group the child table by the parent variable and calculate statistics across the children of each parent.

To formalize a relationship in featuretools, we only need to specify the variable that links two tables together. The clients and the loans table are linked via the client_id variable and loans and payments are linked with the loan_id . The syntax for creating a relationship and adding it to the entityset are shown below:

The entityset now contains the three entities (tables) and the relationships that link these entities together. After adding entities and formalizing relationships, our entityset is complete and we are ready to make features.

Feature Primitives

Before we can quite get to deep feature synthesis, we need to understand feature primitives. We already know what these are, but we have just been calling them by different names! These are simply the basic operations that we use to form new features:

Aggregations: operations completed across a parent-to-child (one-to-many) relationship that group by the parent and calculate stats for the children. An example is grouping the loan table by the client_id and finding the maximum loan amount for each client.

table by the and finding the maximum loan amount for each client. Transformations: operations done on a single table to one or more columns. An example is taking the difference between two columns in one table or taking the absolute value of a column.

New features are created in featuretools using these primitives either by themselves or stacking multiple primitives. Below is a list of some of the feature primitives in featuretools (we can also define custom primitives):

Feature Primitives

These primitives can be used by themselves or combined to create features. To make features with specified primitives we use the ft.dfs function (standing for deep feature synthesis). We pass in the entityset , the target_entity , which is the table where we want to add the features, the selected trans_primitives (transformations), and agg_primitives (aggregations):

The result is a dataframe of new features for each client (because we made clients the target_entity ). For example, we have the month each client joined which is a transformation feature primitive:

We also have a number of aggregation primitives such as the average payment amounts for each client:

Even though we specified only a few feature primitives, featuretools created many new features by combining and stacking these primitives.

The complete dataframe has 793 columns of new features!

Deep Feature Synthesis

We now have all the pieces in place to understand deep feature synthesis (dfs). In fact, we already performed dfs in the previous function call! A deep feature is simply a feature made of stacking multiple primitives and dfs is the name of process that makes these features. The depth of a deep feature is the number of primitives required to make the feature.

For example, the MEAN(payments.payment_amount) column is a deep feature with a depth of 1 because it was created using a single aggregation. A feature with a depth of two is LAST(loans(MEAN(payments.payment_amount)) This is made by stacking two aggregations: LAST (most recent) on top of MEAN. This represents the average payment size of the most recent loan for each client.

We can stack features to any depth we want, but in practice, I have never gone beyond a depth of 2. After this point, the features are difficult to interpret, but I encourage anyone interested to try “going deeper”.",https://cdn-images-1.medium.com/max/1200/1*lg3OxWVYDsJFN-snBY7M5w.jpeg,[],https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219?source=topic_page---8------2----------------,2018-06-02 15:01:18.755000+00:00

Deep Learning,My Phone Wants Me to Say ‘Thank You’ – When Robots Rule The World – Medium,['Evan Selinger'],"Sincerely Thankful

Perhaps there’s something infantilizing about our phones “wanting” us to say thanks. It’s hard to draw a firm line between what you would say if only you put in the time to say it versus what you do say after predictive software fills in the blanks. Seeing suggestions is itself a suggestive situation. And so, while Google emphasizes that smart reply is intelligent enough to figure out if you’re more of a “thanks!” than a “thanks.” person, the fact remains that it’s a good bet that some variation of the word will be frequently presented to you.

If being offered a “thanks” seems familiar, it’s because the act resembles what parents do when they try to instill etiquette. Let’s imagine that Lil’ Johnny receives a gift and instinctively wants to run off and play with it. Before this happens, one of his parents admonishes, “Johnny, what do you say?” And so, robotically, Johnny responds, “Thank you.”

At the time of being coached, Lil’ Johnny doesn’t mean what he parrots back. The gesture is insincere, and Johnny offers it to avoid conflict that would further delay what he really wants to do. That’s okay, though. The hope is that, over time, Lil’ Johnny becomes Big Johnny, the type of person who can genuinely experience gratitude and doesn’t simply follow rules like an automaton. The parental admonitions made during childhood are supposed to be like a pair of moral training wheels that kids ultimately outgrow.

Software like smart reply isn’t designed to provide adults with a second round of moral education. But if we mindlessly use such tools on a regular basis so we can quickly move on to do other things—things that we actually care about—our gestures will merely take the form of gratitude while lacking the underlying substance.

True gratitude must be sincere.

To be truly grateful, you have to mean what you say — that is, you must recognize that someone did something for you that deserves to be acknowledged, and you must sincerely want to make the acknowledgment.

Graciousness is a virtue. If an adult passes off insincere gratitude as the sincere variety in situations where people reasonably expect a person’s words and beliefs to align, the person is behaving worse than Lil’ Johnny. Lil’ Johnny is trying to be compliant, not deceptive.

We also shouldn’t lose sight of the fact that people who in engage in rituals like keeping gratitude journals aim to be specific when offering their appreciation. They don’t just say “thanks” or use any of the other minimalist formulations that smart reply offers. Instead, people who are pursuing lives filled with intentionality are concrete about what they are grateful for, as well as why they’re grateful for it. They want to focus on what they have rather than despair or obsesses over what they lack.",https://cdn-images-1.medium.com/focal/1200/632/51/50/1*MpyyWHuRUnanCenqeG3sHA.jpeg,[],https://medium.com/s/when-robots-rule-the-world/my-phone-wants-me-to-say-thank-you-122cc15952a9?source=topic_page---8------3----------------,

Deep Learning,"In 2018, Numbers Lie and Fictions Paint Truth – Eve Weinberg – Medium",['Eve Weinberg'],"In 2018, Numbers Lie and Fictions Paint Truth Why storytelling is our best tool in disambiguating fact from fiction

I’d love to share a few of the lecturers who touched upon this topic and forever changed my understanding of the 2018 landscape of fact, fiction, and storytelling’s role in deciphering one from the other.

This summer, I had the great privilege of attending EyeO (June 3–8 2018). Innumerable topics that encompass the intersection of Art, Technology, and Data were covered, but one common thread has left an imprint on my brain. That is: the Sisyphean 21st century task of disambiguating fact from fiction. That’s right…

PART 1: NUMBERS ARE MALLEABLE

On the first day, we discussed climate science at length. We (a very self aware room of liberal, number-crunching, data-visualization-making, coastal-living, self-ascribed nerds) attempted to break down the problems with human psychology. We looked at the facts, stats, charts, and graphs; then investigated the human power of denial, dissonance, disincentivization, and the hurdles of behavioral change. After 6 hours of discussion, ideation, and reflection, feeling a bit helpless, we ended with questions that I kept with me throughout the next 3 days of lectures:

Why don’t people believe statistics?

Are stories more powerful than numbers?

Why is denial more powerful than behavioral change?

Why do lies travel faster than truth?

…And what should we do about this?

The next day, Amanda Cox enlightened us with her talk These Lines Are The Same. She showed us that data, even in simple bar graphs, can be misinterpreted depending on the viewer’s own bias. She bravely revealed to us that in her department The Upshot at The New York Times they struggle with how to best represent datasets objectively. They experiment in meaningful and educational ways. In one example she showed data from the US unemployment report. The article allows readers to look at the chart with ‘Democratic Goggles’ and ‘Republican Goggles.’

The numbers are the same, but they can easily be bent to the will of anyone with an agenda.

Then she humorously showed us our flaws in clinging to round numbers. She drove the point home with a series of charts, one here showing the likelihood that someone in the ER gets checked for a heart attack, according to their age. As Amanda points out, “nothing radical changes from the age of 39-and-three-quarters and 40, yet here is the data:",https://cdn-images-1.medium.com/max/1200/1*bJ58aYiSmkeNYJY73AQN3w.jpeg,[],https://medium.com/@evejweinberg/in-2018-numbers-lie-and-fictions-paint-truth-ea1f5cdc9abe?source=topic_page---8------0----------------,2018-06-08 22:01:41.763000+00:00

Deep Learning,The Art of Ethereal: Bringing Cellarius to Life – Genesis Thought – Medium,['Mally Anderson'],"The Art of Ethereal: Bringing Cellarius to Life

Whose future is it? Hers, and his, and theirs, and ours.

A sampling of the Cellarius faction portraits from our Ethereal Summit pop-up.

On May 11 and 12, our parent company ConsenSys hosted the third Ethereal Summit at the Knockdown Center in Queens, New York and invited Cellarius to participate, along with many other spokes from our Mesh. The creators of Ethereal wanted to build a different kind of crypto conference. Since this one explored the intersection of blockchain and the arts, we wanted to showcase that aspect of our project and spread the word in an unexpected way. We set up shop in “The Crypt,” a semi-outdoor concrete space with a distinctive patina that felt perfect for the Cellarius blockpunk aesthetic.

The Knockdown Center’s very blockpunk Crypt space. We displayed some not-yet-published art commissions.

We teamed with some artists from a group called Drawn Together NYC: Boris Rasin, Michael Scarola, Derrick Dent, and Rosalind Bunting. Drawn Together’s talented roster of artists creates design concepts, multimedia experiences, and fine art solutions for a wide range of projects and businesses, and they understood what we are going for right away.

The artists of Drawn Together NYC, from left to right: Boris Rasin, Rosalind Bunting, Derrick Dent, and Michael Scarola.

Boris, Michael, and Derrick created custom, in-universe faction portraits of Ethereal attendees. The CX Universe Guide imagines that nation-states and traditional economies will break down after the Cellarius AI seizes control of Earth’s energy sources and communication channels in 2084. In the absence of familiar institutions and technologies, people will begin to form factions according to their allegiance to Cellarius. We wanted to get attendees thinking about their own relationships to technology and start dreaming up characters to explore in the Cellarius universe. So we posed the question: which faction do you think you would be?

Boris drew background art for four different factions:

The 4 faction backgrounds, clockwise from top left: Bucolic, Elite, Ad-Hoc, Homotranscendus.

Bucolic: Bucolics are AI skeptics who reject technology and live on the peripheries of megacities, observing from the outside and farming small pockets of fertile soil. Though their process is completely manual and their harvests are meager, they feel a great satisfaction from working with their own hands, in stark contrast to the highly automated farming processes elsewhere.

Ad-Hoc: Ad-Hocs live off the Cellarius grid and make their own augmentations and tools with scrap pieces they scavenge and rework. Comprised of mostly poor and marginalized groups, they use ingenuity and what little tech they can access to get by.

Elite: The crypto-Elites of the future are pro-Cellarius and experiment with AI and aesthetic enhancements. Living in the highest levels of the megacities, Elites have access to bleeding-edge technology. They are known for having lifespans beyond the normal range of humans, and enjoy the neural boost that comes with AI coupling.

Homotranscendus: During the Reformation, it wasn’t just the home habitat that was transformed forever, but also humankind itself. The campaign was more than just re-imagining the economic machinery of the planet Earth, but also a re-imagining of the of the human brain and body. Through Cellarius-engineered advancements, the next evolution of humanity was born: Homotranscendus. Homotranscendi are fully integrated with AI and no longer depend on their human forms to express consciousness and gather information.

We even got a portrait of ConsenSys’s own Joe Lubin, who wore a custom Cellarius Ethereal t-shirt design during his keynote address (thanks, Joe!). Something tells us that Joe would be a Homotranscendus.

Future Homotranscendus Joe Lubin on Mars.

Reimagining how familiar scenarios from your own life play out in a future setting or speculating about how you might react to a superintelligent AI’s takeover of the world is a great place to start inventing your own ideas in the world of Cellarius. We hope some attendees will be inspired to start making art and stories based on their portraits!

Every single Ethereal portrait, as arranged by our designer, Octavian.

As we’ve mentioned in previous posts, we are also commissioning works from artists we admire to create the first round of content for the Cellarius universe. We decided to commission a mural that would take shape over the two days of the Summit and give attendees a behind-the-scenes look at the process of making a large-scale landscape painting. The design depicts what the Knockdown Center might look like a century from now, in 2118. Visitors to the Crypt got a chance to watch Rosalind transform the canvas from a faint pencil sketch into an impressive and detailed final product:

Rosalind’s “Knockdown Center in 2118” painting took shape over two days.

Rosalind & Boris outlined the sketch first, then Rosalind added color, starting with the future-NYC background.

We hope that the Cellarius platform will allow experienced artists and creators to get directly in touch with their fan bases and share some glimpses of their artistic process, just as Rosalind did with her live painting.

The Drawn Together NYC artists got to learn more about the possibilities of blockchain and decentralization for creatives in the process of chatting with the attendees. Michael noted, “There were so many passionate and interesting people from all over the world that came through. And they had as much fun as we did learning about and playing in the Cellarius world.” Rosalind agreed: “Probably my favorite thing I learnt about over the Summit was how Cellarius involves the creative talents of so many more artists in their company, and loved seeing some of their amazing artwork. Can’t wait to see more!”

We were also excited that the long-term goals of the Cellarius project resonated with the Drawn Together NYC artists. Derrick said, “This was probably the coolest on-site portrait job I’ve ever worked on. I had a great time learning about the Cellarius project and the potential for a sprawling, community-shaped open sci-fi world. It was even cooler to have our portrait work used as an onboarding tool for visitors. People immediately took to creating their own story within this world, and that says a lot about how exciting this could be for folks who are creatively inclined.” We couldn’t have said it better ourselves.

As Boris told us, “The more I spoke to the pop-up team and event attendees about the concept behind this project, the more it occurred to me that this is a game changer. Cellarius and the other projects from ConsenSys are sure to revolutionize our ecosystem in ways we can’t even begin to comprehend. It’s a challenge to explain exactly what this project is, because the underlying platform allows for limitless opportunities of invention, inspiration, and collaboration. Cellarius is whatever its contributors will it to be, and frankly, that’s a fundamentally crazy idea!”

That’s just the point: blockchain enthusiasts can become artists and use storytelling to push the conceptual limits of technology. Artists can use the platform to explore the possibilities of decentralization and blockchain for sharing and protecting their work. We can build it together. Cellarius is whatever our community of contributors wills it to be.",https://cdn-images-1.medium.com/max/1200/1*vL8856P7cdV84CYM_SkF0A.jpeg,[],https://medium.com/genesis-thought/the-art-of-ethereal-bringing-cellarius-to-life-ba4ae31811e7?source=topic_page---8------1----------------,2018-06-08 16:46:47.896000+00:00

Deep Learning,A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what…,['Rowan Trollope'],"A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what happened?” Has gotten some fun responses.

The most popular comment being one that says “not surprised, this was never going to be a big thing”…

The first thing to point out is that people are conflating the specific of a chatbot with the generic “conversational user interface” (CUI) of which a chatbot is a specific modality. The real discussion here is about the CUI.

And the last month has certainly showed us that the CUI has made dramatic strides with Google demonstrating Duplex.

So what happened to the explosion of chatbots people predicted?

Among other things, Developers figured out just how hard it is to make a really good conversational user interface. Product folks were tricked by the trio of Alexa/Siri/Google Assistant into the belief that a conversational interface is easy.

Turns out it’s really hard, requires a ton of data and is highly domain specific.

In other words, training a CUI to be really great at getting sports scores doesn’t translate at all to a chatbot that can help you with a billing problem or ordering a pizza.

Google was careful to point out that Duplex was trained for only two very specific use cases : book a salon or a restaurant appointment.

Tim Tuttle at Mindmeld figured this out and built a company to solve it, but it still required heavy lifting and tons of data specific to the domain.

My belief is that the conversational interface is inevitable.

Technology evolution is exponential not linear. Our tendency is to project the future in a linear fashion, which causes us to overestimate what’s possible in 1 year and underestimate what’s possible in 10 years.

This makes tech progress feel gradual or slow, and then sudden and surprising.

Last week Salesforce’s chief scientist, Richard Socher, spoke publicly about the future of chatbots and asserted that in 5 years we would begin to see this start to pay off.

We are early days on the conversational interface, but as with all tech progress most folks will be disappointed until one year, 5–10 years from now when they’ll be shocked and amazed and wonder how it happened so fast.",https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico,[],https://medium.com/@rowantrollope/chatbots-were-supposed-to-be-the-next-big-thing-what-happened-5a4e416308e1?source=topic_page---8------2----------------,2018-06-08 21:06:45.446000+00:00

Deep Learning,"Beethoven, Picasso, and Artificial Intelligence – Towards Data Science",['Chris Kalahiki'],"Beethoven, Picasso, and Artificial Intelligence

Introduction

When people think of the greatest artists who’ve ever lived, they probably think of names like Beethoven or Picasso. No one would ever think of a computer as a great artist. But what if one day, that was indeed the case. Could computers learn to create incredible drawings like the Mona Lisa? Perhaps one day a robot will be capable of composing the next great symphony. Some experts believe this to be the case. In fact, some of the greatest minds in artificial intelligence are diligently working to develop programs that can create drawing and music independently from humans. The use of artificial intelligence in the field of art has even been picked up by tech giants the likes of Google.

The projects that are included in this paper could have drastic implications in our everyday lives. They may also change the way we view art. They also showcase the incredible advancement that has been made in the field of artificial intelligence. Image recognition is not as far as the research goes. Nor is the ability to generate music in the styling of the great artists of our past. Although these topics will be touched upon, we will focus on several more advanced achievements such as text descriptions being turned into images and generating art and music that is totally original. Each of these projects bring something new and innovative to the table and show us exactly how the art space is a great place to further explore applications of artificial intelligence. We will be discussing problems that have been faced in these projects and how they have been overcome. The future of AI looks bright. Let’s look at what the future may hold. In doing this, we may be able to better understand the impact that artificial intelligence can have in an area that is driven by human creativity.

GAN and Its Evolved Forms

Machines must be educated. They learn from instruction. How do we lead machines away from emulating what already exists, and have them create new techniques? “No creative artist will create art today that tries to emulate the Baroque or Impressionist style, or any other traditional style, unless trying to do so ironically” [4]. This problem isn’t limited to paintings either. Music can be very structured in some respects, but is also a form of art that requires vast creativity. So how do we go about solving such a problem? The first concept we will discuss is something called GAN (Generative Adversarial Networks). GANs, although quite complex, are becoming an outdated model. If artificial intelligence in the art space is to advance, researchers and developers will have to work to find better methods to allow machines to generate art and music. Two of these such methods are presented in the form of Sketch-RNN and CAN (Creative Adversarial Networks). Each of these methods have their advantages over GANs.

First, let’s explore what exactly a GAN is. Below is a small excerpt explaining how a GAN works:

Generative Adversarial Network (GAN) has two sub networks, a generator and a discriminator. The discriminator has access to a set of images (training images). The discriminator tries to discriminate between “real” images (from the training set) and “fake” images generated by the generator. The generator tries to generate images similar to the training set without seeing the images [4].

The more images the generator creates, the closer they get to the images from the training set. The idea is that after a certain number of images are generated, the GAN will create images that are very similar to what we consider art. This is a very impressive accomplishment to say the least. But what if we take it a step further?

Many issues associated with the GAN are simply limitations on what it can do. The GAN is powerful, but can’t do quite as much as we would like. For example, the generator in the model described above will continue to create images closer and closer to the images given to the discriminator that it isn’t producing original art. Could a GAN be trained to draw alongside a user? It’s not likely. The model wouldn’t be able to turn a text-based description of an image into an actual picture either. As impressive as the GAN may be, we would all agree that it can be improved. Each of the shortcoming mentioned have actually been addressed and, to an extent, solved. Let’s look at how this is done.

Sketch-RNN is a recurrent neural network model developed by Google. The goal of Sketch-RNN is to help machines learn to create art in a manner similar to the way a human may learn. It has been used in a Google AI Experiment to be able to sketch alongside a user. While doing so, it can provide the users with suggestions and even complete the user’s sketch when they decide to take a break. Sketch-RNN is exposed to a massive number of sketches provided through a dataset of vector drawings obtained through another Google application that we will discuss later. Each of these sketches are tagged to let the program know what object is in the sketch. The data set represents the sketch as a set of pen strokes. This allows Sketch-RNN to then learn what aspects each sketch of a certain object has in common. If a user begins to draw a cat, Sketch-RNN could then show the user other common features that could be on the cat. This model could have many new creative applications. “The decoder-only model trained on various classes can assist the creative process of an artist by suggesting many possible ways of finishing a sketch” [3]. The Sketch-RNN team even believes that, given a more complex dataset, the applications could be used in an educational sense to teach users how to draw. These applications of Sketch-RNN couldn’t be nearly as easily achieved with GAN alone.

Another method used to improve upon GAN is the Creative Adversarial Network. In their paper regarding adversarial networks generating art, several researchers discuss a new way of generating art through CANs. The idea is that the CAN has two adversary networks. One, the generator, has no access to any art. It has no basis to go off of when generating images. The other network, the discriminator, is trained to classify the images generated as being art or not. When an image is generated, the discriminator gives the generator two pieces of information. The first is whether it believes the generated image comes from the same distributor as the pieces of art it was trained on, and the other being how the discriminator can fit the generated image into one of the categories of art it was taught. This technique is fantastic in that it helps the generator create images that are both emulative of past works of art in the sense that it learns what was good about those images and creative in a sense that it is taught to produce new and different artistic concepts. This is a big difference from GAN creating art that emulated the training images. Eventually, the CAN will learn how to produce only new and innovative artwork.

One final future for the vanilla GAN is StackGAN. StackGAN is a text to photo-realistic image synthesizer that uses stacked generative adversarial networks. Given a text description, the StackGAN is able to create images that are very much related to the given text. This wouldn’t be doable with a normal GAN model as it would be much too difficult to generate photo-realistic images from a text description even with a state-of-the-art training database. This is where StackGAN comes in. It breaks the problem down into 2 parts. “Low-resolution images are generated by our Stage-I GAN. On the top of our Stage-I GAN, we stack Stage-II GAN to generate realistic high-resolution images conditioned on Stage-I results and text descriptions” [7]. It is through the conditioning on Stage-I results and text descriptions that Stage-II GAN can find details that Stage-I GAN may have missed and create higher resolution images. By breaking the problem down into smaller subproblems, the StackGAN can tackle problems that aren’t possible with a regular GAN. On the next page is an image showing the difference between a regular GAN and each step of the StackGAN.

This image came from the StackGAN paper [7].

It is through advancements like these that have been made in recent years that we can continue to push the boundaries of what AI can do. We have just seen three ways to improve upon a concept that was already quite complex and innovative. Each of these advancements have a practical, everyday use. As we continue to improve on artificial intelligence techniques, we will able to do more and more in regard to, not just art and music, but a wide variety of tasks to improve our lives.

DeepBach, Magenta, and NSynth

Images aren’t the only type of art that artificial intelligence can impact though. Its effect on music is being explored as we speak. We will now explore some specific cases and their impact on both music and artificial intelligence. In doing this, we should be able to see how art can do as much for AI as AI does for it. Both fields benefit heavily from the types of projects that we are exploring here.

Could a machine ever be able to create a piece of music the likes of Johann Sebastian Bach? In a project known as DeepBach, several researchers looked to create pieces similar to Bach’s chorales. The beauty of DeepBach is that it “is able to generate coherent musical phrases and provides, for instance, varied reharmonizations of melodies without plagiarism” [6]. What this means it that DeepBach can create music with correct structure and be original. It is just in the style of Bach. It isn’t just a mashup of his works. DeepBach is creating new content. The developers of DeepBach went on to test whether their product could actually fool listeners.

As part of the experiment, over 1,250 people were asked to vote whether pieces presented to them were in fact composed by Bach. The subjects had varying degrees of musical expertise. The results showed that as the model for DeepBach’s complexity increased, the subjects had more and more trouble distinguishing the chorales of Bach from those of DeepBach. This experiment shows us that through the use of artificial intelligence and machine learning, it is quite possible to recreate original works in the likeness of the greats. But is that the limit to what artificial intelligence can do in the field of art and music?

DeepBach has achieved something that would have been unheard of in the not so distant past, but it certainly isn’t the fullest extent of what AI can do to benefit the field of music. What if we want to create new and innovative music? Maybe AI can change the way music is created all together. There must be projects that do more to push the envelope. As a matter of fact, that is exactly what the team behind Magenta look to do.

Magenta is a project being conducted by the Google Brain team and lead by Douglas Eck. Eck has been working for Google since 2010, but that isn’t where his interest in Music began. Eck helped found Brain Music and Sound, an international laboratory for brain, music, and sound research. He was also involved at the McGill Centre for Interdisciplinary Research in Music Media and Technology, and was an Associate Professor in Computer Science at the University of Montreal.

Magenta’s goal is to be “a research project to advance the state of the art in machine intelligence for music and art generation” [2]. It is an open source project that uses TensorFlow. Magenta aims to learn how to generate art and music in a way that is indeed generative. It must go past just emulating existing music. This is distinctly different that projects along the line of DeepBach which set out to emulate existing music in a way that wasn’t plagiarizing existing pieces of music. Eck and company realize that art is about capturing elements of surprise and drawing attention to certain aspects. “This leads to perhaps the biggest challenge: combining generation, attention and surprise to tell a compelling story. So much of machine-generated music and art is good in small chunks, but lacks any sort of long-term narrative arc” [2]. Such a perspective gives computer-generated music more substance, and helps it to become less of a gimmick.

One of the projects the magenta team has developed is called NSynth. The idea behind NSynth is to be able to create new sounds that have never been heard before, but beyond that, to reimagine how music synthesis can be done. Unlike ordinary synthesizers that focus on “a specific arrangement of oscillators or an algorithm for sample playback, such as FM Synthesis or Granular Synthesis” [5], NSynth generates sounds on an individual level. To do this, it uses deep neural networks. Google has even launched an experiment that allows users to really see what NSynth can do by allowing them to fuse together the sounds of existing instruments to create new hybrid sounds that have never been heard before. As an example, users can take two instruments such as a banjo and a tuba, and take parts of each of their sounds to create a totally new instrument. The experiment also allowed users to decide what percentage of each instrument would be used.

Projects like Magenta go above and beyond in showing us the full extent of what artificial intelligence can do in the way of generating music. They explore new applications of artificial intelligence that can generate new ideas independent of humans. It is the closest we have come to machine creativity. Although machines aren’t yet able to truly think and express creativity, they may soon be able to generate new and unique art and music for us to enjoy. Don’t worry though. Eck doesn’t intend to replace artists with AI. Instead he looks to provide artists with tools to create music in an entirely new way.

Deep Dream and Quick, Draw!

As we look ahead to a few more of the ways that AI has been used to accomplish new and innovative ideas in the art space, we look at projects like Quick, Draw! and Deep Dream. These projects showcase amazing progress in the space while pointing out some issues that researchers in AI will have to work out in the years to come.

Quick, Draw! is an application from the Google Creative Lab, trained to recognize quick drawings much like one would see in a game of Pictionary. The program can recognize simple objects such as cats and apples based on common aspects of the many pictures it was given before. Although the program will not get every picture right each time it is used, it continues to learn from the similarities in the picture drawn and the hundreds of pictures before it.

The science behind Quick, Draw! “uses some of the same technology that helps Google Translate recognize your handwriting. To understand handwritings or drawings, you don’t just look at what the person drew. You look at how they actually drew it” [1]. It is presented in the form of a game, with the user drawing a picture of an object chosen by the application. The program then has 20 seconds to recognize the image. In each session, the user is given a total of 6 objects. The images are then stored to the database used to train application. This happens to be the same database we saw earlier in the Sketch-RNN application. This image recognition is a very practical use of artificial intelligence in the realm of art and music. It can do a lot to benefit us in our everyday lives. But this only begins to scratch the surface of what artificial intelligence can do in this field. Although this is very impressive, we might point out that the application doesn’t truly understand what is being drawn. It is just picking up on patterns. In fact, this distinction is part of the gap between simple AI techniques and true artificial general intelligence. Machines that truly understand what the objects in images are don’t appear to be coming in the near future.

Another interesting project in the art space is Google’s Deep Dream project, which uses AI to create new and unique images. Unfortunately, the Deep Dream Generator Team wouldn’t go into too much detail about the technology itself (mostly fearing it would be too long for an email) [8]. They did, however, explain that convolutional neural networks train on the famous ImageNet dataset. Those neural networks are then used to create art-like images. Essentially, Deep Dream takes the styling of one image and uses it to modify another image. The results can be anything from a silly fusion to an artistic masterpiece. This occurs when the program identifies the unique stylings of an image provided by the user and imposes those stylings onto another image that the user provides. What can easily be observed through the use of Deep Dream is that computers aren’t yet capable of truly understanding what they are doing with respect to art. They can be fed complex algorithms to generate images, but don’t fundamentally understand what it is they are generating. For example, a computer may see a knife cutting through an onion and assume the knife and onion are one object. The lack of an ability to truly understand the contents of an image is one dilemma that researchers have yet to solve.

Perhaps as we continue to make advances in artificial intelligence we will be able to have machines that do truly understand what objects are in an image and even the emotions evoked by their music. The only way for this to be achieved is by reaching true artificial general intelligence (AGI). IN the meantime, the Deep Dream team believes that generative models will be able to create some really interesting pieces of art and digital content.

Where Do We Go From Here?

For this section, we will consider where artificial intelligence could be heading in the art space. We will take a look at how AI has impacted the space and in what ways it can continue to do so. We will also look at ways art and music could continue to impact AI in the years to come.

Although I don’t feel that we have completely mastered the ability to emulate the great artists of our past, it is just a matter of time before that problem is solved. The real task to be solved is that of creating new innovations in art and music. We need to work towards creation without emulation. It is quite clear that we are headed in that direction through projects like CAN and Magenta. Artificial general intelligence (AGI) is not the only way to complete this task. As a matter of fact, even those who dispute the possibility of AGI would have a hard time disputing the creation of unique works of art by a machine.

One path that may be taken to further improve art and music through AI is to create more advanced datasets to use in training the complex networks like Sketch-RNN and Deep Dream. AI needs to be trained to be able to perform as expected. That training has a huge impact on the results we get. Shouldn’t we want to train our machines in the most beneficial way possible. Even developing software like Sketch-RNN to use the ImageNet dataset used in Deep Dream could be huge in educating artists on techniques for drawing complex, realistic images. Complex datasets could very well be our answer to more efficient training. Until our machines can think and learn like we do, we will need to be very careful what data is used to train them.

One of the ways that art and music can help to impact AI is by providing another method of Turing Testing machines. For those who dream of creating AGI, what better way to test the machine’s ability that to create something that tests the full extent of human-like creativity? Art is the truest representation of human creativity. That is, in fact, its essence. Although art is probably not the ultimate end game for artificial intelligence, it could be one of the best ways to test the limits of what a machine can do. The day that computers can create original musical composition and create images based on descriptions given by a user could very well be the day that we stop being able to distinguish man from machine.

Conclusion

There are many benefits to using artificial intelligence in the music space. Some of them have already been seen in the projects we have discussed so far. We have seen how artificial intelligence could be used for image recognition as well as their ability to turn our words into fantastic images. We have also seen how AI can be used to synthesize new sounds that have never been heard. We know that artificial intelligence can be used to create art alongside us as well as independently from us. It can be taught to mimic music from the past and can create novel ideas. All of these accomplishments are a part of what will drive AI research into the future. Who knows? Perhaps one day we will achieve artificial general intelligence and machines will be able to understand what is really in the images it is given. Maybe our computers will be able to understand how their art makes us feel. There is a clear path showing us where to go from here. I firmly believe that it is up to us to continue this research and test the limits of what artificial intelligence can do, both in the field of art and in our everyday lives.

References",https://cdn-images-1.medium.com/max/1200/0*pIGHko-OCo1usW2c,[],https://towardsdatascience.com/beethoven-picasso-and-artificial-intelligence-caf644fc72f9?source=topic_page---8------3----------------,2018-06-08 21:34:58.310000+00:00

Deep Learning,The curious case of the vanishing & exploding gradient,['Eniola Alese'],"The curious case of the vanishing & exploding gradient

Understanding why gradients explode or vanish and methods for dealing with the problem.

Photo by SpaceX on Unsplash

In the last post, we introduced a step by step walkthrough of RNN training and how to derive the gradients of the network weights using back propagation and the chain rule. But it turns out that during this training the RNN can suffer greatly from two problems: 1. Vanishing gradients or 2. Exploding gradients.

Why Gradients Explode or Vanish

Recall the many-to-many architecture for text generation shown below and in the introduction to RNN post, lets assume the input sequence to the network is a 20 word sentence: “I grew up in France,…….. I speak French fluently.

We can see from the example above that for the RNN to predict the word “French” which comes at the end of the sequence, it would need information from the word “France”, which occurs further back at the beginning of the sentence. This kind of dependence between sequence data is called long-term dependencies because the distance between the relevant information “France” and the point where it is needed to make a prediction “French” is very wide. Unfortunately, in practice as this distance becomes wider, RNNs have a hard time learning these dependencies because it encounters either a vanishing or exploding gradient problem.

These problems arise during training of a deep network when the gradients are being propagated back in time all the way to the initial layer. The gradients coming from the deeper layers have to go through continuous matrix multiplications because of the the chain rule, and as they approach the earlier layers, if they have small values (<1), they shrink exponentially until they vanish and make it impossible for the model to learn , this is the vanishing gradient problem. While on the other hand if they have large values (>1) they get larger and eventually blow up and crash the model, this is the exploding gradient problem

Dealing with Exploding Gradients",https://cdn-images-1.medium.com/max/1200/0*UCn2LUkacEHQxgZW,[],https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb?source=topic_page---8------5----------------,2018-06-05 22:33:57.437000+00:00

Data Analysis,Media – Medium,"['Ev Williams', 'Dave Pell', 'Hossein Derakhshan', 'Dawn Ennis', 'Don Day', 'Jessie Singer', 'Tim Grierson', 'Melissa Chu']","Media Where the newsroom is the news.

Follow Following",https://cdn-images-1.medium.com/max/1200/1*wLhNmBWoSMvG0kyRGjDIqw@2x.jpeg,[],https://medium.com/topic/media,

Data Analysis,The Inspiration of Anthony Bourdain – Member Feature Stories – Medium,['Christine Byrne'],"One of my first great food memories comes from a trip my family took to Normandy when I was six years old. We hadn’t been sitting for two minutes when I announced to my parents, “I want the escargot.”

Dad: “You know that’s snails?”

Six-year-old me: “Yes! We just learned about them in French class, and I want the escargot!”

My parents went along, although I’m sure they expected I’d take a few bites out of stubbornness, then subtly push the dish of garlic and butter and earthy mollusk aside, hoping no one would call out my misplaced courage.

Actually, though, I ate every snail, then mopped up every bit of briny, herby garlic butter left behind. I still think about those snails and about how excited and proud I was to love them so much.

A decade after those snails, I sat on the living room couch with my dad and watched an episode of No Reservations, Anthony Bourdain’s first food travel show. I, like millions of others, was drawn to the irreverent reverence with which he seemed to approach every food he tried, to his eagerness to try anything, and to his ability to narrate the stories of different foods, cooks, and cultures in an unpretentious way that let them mostly speak for themselves. Until then, I had thought of food and travel writing and television as more marketing than storytelling, but watching No Reservations made it clear that, actually, food was not only a story in and of itself, but also a great way to anchor other stories in something tangible and universally understood. Bourdain wasn’t out to sell an experience or show how good something could be — every episode was about telling the story of things exactly as they are.

Bourdain wasn’t the first to talk about food this way, but he was the first to make me feel like maybe I could talk about food that way, too. Food was an important part of my life growing up, but not in a particularly extraordinary way that I felt would resonate. We lived abroad and traveled often, so I was massively privileged in that there was always something new to eat. I remember eating pâté for the first time on a pebble beach in Cornwall while watching my dad (try to) learn to windsurf. I remember tearing apart a slick piece of roti prata and dipping it into a Styrofoam container of curry sauce on a plastic picnic table in Mersing, Malaysia, before getting on a bum boat to an island where I’d go to summer camp for the first time. I remember my first drink: a Tiger beer at Newton Circus, another hawker center, after the closing night of our high school production of South Pacific. I remember, every year when we’d fly home to New Jersey, eating baked ziti and supermarket sheet cake at Fourth of July barbecues, both or which were exciting and special for me because I only ate them once a year. I remember the first time I ate lunch at a New York City deli and was awed by the enormity of both the sandwiches and the Snapple selection. None of this seemed like a story, though, because I wasn’t sure why anyone else would care.

Years later, as a rising college senior, I spent the summer working as a publishing intern in New York. Weeks in, I realized that my longtime goal of being a book editor was actually, definitely, not what I wanted. To keep the “I graduate in a year and now have no plan” anxiety at bay, I read more books that summer than I ever have. One of them was Anthony Bourdain’s Kitchen Confidential.

Bourdain’s 2000 memoir, as you may know, gets so much of its magic from the sense you get while reading that every story is true. I figured it would fall into the “I never want to go there, but that sure made me think and was fun to watch” category that some of the No Reservations episodes did, and that the stories about hypermasculine kitchen culture and the people who somehow ended up in it would make me laugh, think, and then move on to whatever book was next.

That’s not what happened. The first story the book tells is one of Bourdain as a fourth-grader on a European cruise with his family. He tries vichyssoise, a potato-based French soup, and is taken aback by the fact that it’s cold. “I’d eaten in restaurants before, sure,” he says, “but this was the first food I really noticed. It was the first food I enjoyed and, more important, remembered enjoying.” Reading it made me think of my snails, how adventurous they made me feel, and how they established food as something important and worth discovering. It’s a good, tame story that I could easily relate to, and I bet most people felt the same when reading it.

The thing is, the relatability of the book started and ended with that cold potato soup. The rest of the book — about restaurant kitchens and all the crass, stressful, macho, bonkers shit that happened inside them — took place in a world very, very different from mine. Even coming from Bourdain, whose stories had been making me feel welcome since I first watched him walk around Paris unironically wearing cowboy boots in the first episode of No Reservations, the book felt like something I was looking in on from the outside. Reading it piqued my curiosity in restaurant cooking but made it clear that it wasn’t something for me. The longer the stories sat with me, though, the more they started to feel like a sort of…dare.

I graduated soon after, six months earlier than planned. I was still put off by my intern experience in publishing and totally uninspired by every job option presented to me by career counselors and all the well-meaning adults in my life. (Although it was 2010 and the height of a recession, so calling them “options” is maybe a stretch.) Food writing had crossed my mind, but I didn’t figure it was something I could just jump into. I can’t really explain my sudden decision to go to culinary school — a mix of desperation, an interest in food, a burning need to be interesting and different, and a nagging curiosity about Kitchen Confidential, if I had to put it into words — but in 2010, I moved to New York and spent 10 months at the French Culinary Institute learning how to cook. It remains the most impulsive thing I’ve ever done—and the most significant.

The following two and a half years spent cooking in NYC restaurant kitchens taught me things that culinary school never could have—about cooking, stress, being a woman in a room of mostly men, and how to deal with constantly being under fire without falling apart. It’s hard to explain what it was like to walk into a restaurant kitchen, and I honestly don’t remember it clearly, but I do remember that everything I did was wrong, everywhere I was was in the way, and every time someone said something to me, I had to ask them to explain what they were talking about. It was the most underqualified and out of place I’d ever felt, even though I knew in theory that’s exactly what I was signing up for. (I’d read the book! I intentionally jumped out of my comfort zone!) It wasn’t the useless, undervalued feeling that comes with an entry-level office job; it was the feeling that I needed to apologize for even being there, for being the alien who disrupted a system that everyone else knew how to work in. Weeks went by before I was able to walk into that kitchen without absolute fear; months went by before I was able to actually contribute.

Was restaurant cooking the way Bourdain described? Not really. It was vaguely the same, sure: late nights, weekends, burn scars, characters, industry bars, some yelling, ticket boards that inexplicably but reliably went from empty to full in a matter of minutes every single night.

The actual experience of it was very different from what I’d read, though. Because it wasn’t his experience—it was mine. I was the one cramming four hours’ worth of food prep into two and a half every afternoon. I was the one at the stove, firing seven dishes from three different orders at the same time, in exactly the right order, totally on instinct. I was the one who stayed at the bar three hours too long on a Tuesday and somehow always managed to find my way on the L train. I was the one who felt disconnected from one world but totally plugged into another.

Which made me realize: A great storyteller is one who makes you want to experience stories for yourself. A great story is one that makes you think, “I wonder what it would be like to do that.” I’m not much of a storyteller these days, nor am I still a restaurant cook. I write recipes, and I write stories about how and why people should cook them, but I do so in a way that’s shaped by what I’ve learned: Recipes are like stories, kind of, and the best recipes are ones that people will actually cook. Getting someone to cook a recipe isn’t about presenting them with something they’re already familiar with, necessarily, but about making them think, “I wonder what it would be like to do that.”

It’s no secret that Anthony Bourdain was a great storyteller. I’ll miss following along with his unending curiosity about food and how it shapes us, and the world will miss the way he was able to share that curiosity in a way that was welcoming and inclusive. What I’m most grateful for, though, is that he showed me the inside of a world I’d never given a second thought to—restaurants—and painted a picture that, even though it was totally unrelatable to me, was interesting enough that I felt compelled to experience if for myself. Not many storytellers do their job so well that, after reading their stories, you actually feel moved to go out and live them.

“Food, for me, has always been an adventure,” Bourdain writes in the preface of Kitchen Confidential. For me, too, Chef. Thanks for teaching me that food is something worth exploring and that the exploration is something worth writing about.",https://cdn-images-1.medium.com/max/1200/1*65ru7KtyJDme4kUXz8Sl5Q.jpeg,[],https://medium.com/s/story/the-inspiration-of-anthony-bourdain-8d5679c2acb4?source=grid_home---------0------------------18,

Data Analysis,"Apple has no idea what’s next, so it’s just banging on the same old drum",['Owen Williams'],"Apple has no idea what’s next, so it’s just banging on the same old drum If you want to witness a company that’s simultaneously in its prime and losing control over its own narrative, look no further than WWDC, Apple’s second-most splashy event of the year, designed to offer a glimpse of the future. The annual developer event is a spectacle that I’ve watched live for almost a decade, but this year was different: it showcased a company that’s lost in the woods, playing the same old hits on repeat, in the same old format. Not only was it painful to watch, it demonstrated that Apple doesn’t really have a coherent plan, or understanding, of where it should take its core platform, let alone the ones it’s tried to build around it. It’s fine to have an off year, but what struck me was how… random it felt, and how little insight or forward thinking there was. Apple’s own platform advantages, company culture, and whatever else, seem to be pigeonholing its trajectory, driving it down a path that looks increasingly dated, and leaving me to wonder if the company is self-aware enough to see the shifting tide before it’s lost at sea. Big, slow, yearly

Apple struggled throughout 2017 to ship flagship features it promised at WWDC 2017, including Airplay 2 and iCloud Messages, delivering them quietly just days before this year’s event. Alongside a scandal about performance throttling, a series of major security slip-ups, and hardware that shipped without long-touted features, many have loudly asked what’s causing these issues — and why a company with so many engineers is fundamentally failing to ship. Performance improvements are arguably the biggest focus of iOS 12. They’ll be welcome for many users, along with several additional improvements: streamlined notifications, a new ‘shortcuts’ feature for custom buttons, usage reporting, group FaceTime, AR updates and a number of other minor improvements to create a major release, iOS 12. The company’s other platforms received similar treatment, including macOS. Apple finished dark mode, a feature it half-introduced all the way back in Yosemite, added basic functionality to Finder, threw in a new way to organize your desktop, and boom — there’s your major release, 10.14. None of these things are inherently bad — in fact, people have been complaining about the lack of improvements to things like FaceTime for years — but what’s interesting is Apple’s choice to bundle them together as a way to make them look truly meaningful, rather than just fixing many of these issues sooner, in a point release. I’m aware there’s a slew of tiny other fixes and features I haven’t listed here, but that’s my point: it’s a hodgepodge of things that have been neglected over the years after being debuted once and forgotten about. Here’s the rub: Apple could arguably ship notification improvements to iOS users tomorrow in a point release, iOS 11.5, but it won’t. Combining them provides the illusion of progress. Instead of servicing users and giving them features sooner, on a regular basis, Apple chooses to hold back simple functionality longer, for its bottom line. As Martin Bryant points out, Apple may have a timing problem: Yes, Apple needs to take the time to do ‘boring’ optimisation work on iOS, but why build iOS around these big, annual feature bumps and then disappoint people when the bumps aren’t very big?

Interestingly, the narrative here actually doesn’t make sense anymore, either. Every year, Apple takes the time to point out how dire the state of the competition is: Nobody’s Android phones get updates! Android people don’t get any the latest features! Your phones all suck! The reality is different: Android users, regardless of manufacturer, frequently get them sooner than iOS users do, because Google divorced the operating system and core application suite from one another. Google’s approach to unbundling Android has, for the most part, been quietly successful — in an unexpected way. Instead of shipping monolithic feature updates, Google’s applications are now updated via the Play Store, from the clock app to the calculator and even the camera (unless you’re Samsung). Apple has made a yearly ritual out of jabbing competitors for poor update histories, but conveniently omits the reality that improvements to Google Assistant, the built-in web browser, or even just the OS keyboard will reach billions of users in a matter of hours without needing to update the entire phone. Android’s support libraries mean developers can target older devices, with new features, regardless of whether or not they received the OS update. Meanwhile, if you find a bug in the iOS keyboard, or some weird security flaw in Safari’s web view, you hope it gets fixed in the next version of the operating system. Maybe next year, or the year after that. It depends how bad it is, or if Apple is actively maintaining the feature, as to when it’ll get serviced. Don’t get me wrong, Android has a terrible history of updates that is only now beginning to change, ten years after the fact. Google has made strides with Project Treble, which makes an end-run around the device maker itself, but it’s only in its infancy with new devices picking it up today. That’s not good enough either; but it’s gaining traction and getting things into people’s hands. For each platform update, Apple dangles a carrot. That’s the flagship feature to convince you it’s a Big Update™ worth having immediately. On macOS this year, that’s dark mode, and on iOS, the promise of performance improvements and, god forbid, actually decent notification management. Arguably the most interesting segment out of WWDC happens at the very end of the two-hour keynote: a peek at Project Marzipan, a long-term effort to unify the interface framework developers use to build apps for iOS and macOS, which is expected to ship to everyone in 2019.

From where I sit, this is an impressive, massive project that doesn’t do much more than play defense against Electron’s continued march on Apple’s territory, threatening to kill native application development altogether. Why build anything native at all, when you can write once, and run everywhere? Anti-Electron fans will run rabid at the idea, but as the technology has become more efficient and introduced lower-level API access, it only makes even more business sense. Marzipan is an audacious plan to defend against that by making it easier to build cross-platform apps. It’s a genuinely fascinating play with fewer apparent benefits in the short term over just building an Electron app, which addresses an additional billion users, allows developers to use familiar web technology and is truly write-once-run-everywhere. Over time, Marzipan may win favor with developers, but I’m not convinced it’ll stop web-based technologies swallowing native app development whole, particularly given that both Microsoft and Google have now bet their entire strategies on Progressive Web Applications, and how low the barrier of entry has come as a result of Electron’s success. Marzipan indicates something bigger, of course, such as an impending shift away from Intel chipsets entirely to some sort of custom Apple ARM-based silicon in — shock horror — a productivity form factor. If anything, what will win as a result will be that control, and what it could ship in a end-to-end device: true all-day battery? Always-on LTE with desktop class apps? If so, the message is this: lock in with us, develop for our platforms, and we’ll reward you. Don’t, and you’ll be shut out and stuck on the outside. Hey Siri, where’s the vision?

What’s clearly missing in all of this is a willingness to take risks, or go for the long view on what’s better than the status quo for Apple’s users. Instead of looking at how phone usage is changing and redesigning the nature of iOS, it’s another year of shoehorning new features into a decade-old shell. The new shortcuts feature promises to let users wire up workflows of their dreams, chaining together tasks behind a single button. Yes, this is a great improvement to iOS that addresses a problem without actually improving on the reason anyone needs this in the first place — it’s just glued onto the homescreen that’s responsible for causing the need for it in the first place. Apple could have offered up a way to surface the weather right there, deeply integrated with the lock screen, or calendar events at the top of your home screen along with the icons, but it didn’t. Instead, it slathered what appears to be a UX hack in the shape of a notification, and tries to guess when you want to see it. Google’s own developer conference, just down the street in Mountain View, was held in May and offered a clearer, if poorly highlighted, view of the future: AI is a core part of mobile devices going forward, so we’re beginning to add it everywhere. The Android alternative to Shortcuts, Slices and App Actions, surfaces the device’s best guess at your next action as a deeply integrated interface component, where you can actually see information before actually going further in, or taking an action. Want a button to order a Lyft? Great, here’s a button embedded within the system’s app tray, with the current estimated price of your ride, which orders it right now with a single tap. Much of this data is crunched on device, just like Apple’s audacious claims to privacy brag about as well, but instead of being a UX hack to add buttons that summon help, the information is already right there, on hand, without opening anything, even Assistant. Google and Apple both anticipate a future in which we use our phones less — time well spent is a core part of this driver — and as a result, it appears Google has spent a lot of time thinking about how AI can help get the right information to the user. The result is the exact button they need at the right time, with relevant information, sans the need to actually go away and do something. To facilitate this, Google is willing to rejig the UX of its devices, mess with the sea of icons, and has invested heavily in serendipitous computing with Google Home alongside this, so it can get you there faster regardless of if the phone is in your hand.

Google’s vision of the future of smartphones, mobile operating systems, and the way we’ll interact with devices over the long haul is a coherent, well-told story: get more out of your day, get the devices out of the way. It even has a fantastic page that showcases how its own ecosystem works better, together, than I’ve ever seen explained about Apple’s ecosystem on its own site. As for why all of this happens, I suspect it’s a difference in strategy and approach. Apple’s strategy has long been to monetize its existing cash cows as long as it can by throwing out new stuff to see what sticks and doubling down on that, rather than creating any sort of coherent narrative of what the future actually looks like, operating in secrecy until it somehow lands upon it. Incremental improvement is fine, but there’s a distinct lack of forward-looking, and a whole lot of looking over the fence at what everyone else is doing to bash it instead. Apples, oranges and comparing the two

It’s easy to compare and contrast Google and Apple because they are very different companies, but what they’re both claiming to do is the same: invent the future, whatever that actually might be. Their approaches, however, are increasingly diverging: Apple’s squeezing more out of less, shipping flashy features, and focusing on privacy, while Google and others have pushed further into understanding the user and getting out of their way. Most of this comes down to business model. Apple’s focus on features by piling them together drives more sales of iPhone, which drives reliable revenue on a yearly basis. Google’s is on advertising and relevance to the user, which doesn’t depend on a particular feature or thing to tout, it just needs you to love using its tools (and not mind advertising). Apple’s entire strategy over the last two decades has pivoted around the exploitation of a product line until something new comes along, then rinse and repeat. This is framed around improving your life and often actually does, even if that is by proxy. I’d argue that the company’s vision of the future isn’t to enrich, or drive progress, but to squeeze as much revenue as possible out of slick, well-designed and marketed ideas. The products it builds, the cycles they’re released in and the way that Apple’s entire software cycle works reflects this. An example of the manifestation of this is perhaps HomePod’s requirement to have a locally available iPhone to do anything interesting, leaving it crippled without one, and Animoji’s debut only to be locked away in Messages instead of somewhere like the camera.

Google, a latecomer in the game, has the luxury — and peril — of not depending on phone revenue, so it can risk it all and get weird, since it’s not fundamentally critical to the company’s continued trajectory. Microsoft has done the same, now finding itself the underdog, risked it all and moved to an ‘OS-as-a-service’ model in which it ships features when they’re ready instead of waiting for flashy releases. Apple, on the other hand, begins and ends with the iPhone today, the rest flows from there. It can’t just rip up the foundation on which its revenue exists, and Tim Cook hasn’t shown a flair for doing so. iOS is too valuable to go away and tear down to just reimagine it for fun, so it’s the status quo, with experiments like HomePod and AirPods on the side, where it can get weird and sometimes wonderful. That’s fine, because Apple has plenty of cash lying around, but it’s interesting how limiting the approach can become. As we hurtle toward peak smartphone, the cracks here are beginning to show because Apple don’t have the next big thing yet — that we know of, naturally — and it’s taking a long time to get here. We’re essentially watching the bottom of the metaphorical tube of toothpaste being squeezed, while others are trying to figure out if maybe the tube should work completely differently. AR is potentially the next platform, yes, and it’s clear that Apple is pushing forward on that in a big way, so it’s easy to imagine a scenario in which it makes sense to shift precious resources there instead of focusing on iOS which may wind up unimportant in a year or two. I’m not convinced that in the short term, such as the oft-claimed 2020 launch date of an Apple VR/AR headset, that we’ll be headed there in any meaningful capacity. I mean, Magic Leap, a bajillion dollar company building the future of AR showed off its hardware yesterday on Twitch, quipping that “you better not put it in your pocket or it’ll overheat.” I’m happy to be wrong, and I write this knowing I’ll probably be that guy who very publically crapped on the iPhone at launch later. Apple’s worth a very large amount of money, which is more than enough proof that it’s good at many things, including convincing people to buy a phone every year.",https://cdn-images-1.medium.com/max/1200/1*tIUbwrpHZPbdNPXB569wPQ.png,[],https://medium.com/@ow/apple-has-no-idea-whats-next-so-it-s-just-banging-on-the-same-old-drum-dcfd0179cf80?source=grid_home---------0------------------18,2018-06-07 13:54:23.876000+00:00

Data Analysis,Our Wedding Is Canceled Due to the Following Strongly-Held Beliefs,['Tim Sniffen'],"Hi, everyone. I know you weren’t expecting to see Keith and I out here so soon, but we have some bad news. We’re not getting married today.

Believe me, we were really looking forward to it, but recently — this morning, in fact — we learned our blessed event was in direct conflict with the strongly-held beliefs of many of the people providing our wedding services. And if they’re not happy, we’re not happy.

Let me bring you up to speed.

You may have noticed the empty display table by the reception tent as you filed in. That’s where our wedding cake would have been. For our baker, however, creating a cake to be employed in the marriage of two men would be the moral equivalent of using communion wine to make sangria.

We knew the risks when enlisting Give Us This Beignet, Our Daily Bread as our wedding baker. They’re the best in downtown Aurora, no question — sorry, Wild-Flour! — but their beliefs on same-sex marriage are no secret. We hoped they might get swept up in the joy of the occasion but last night their chief baker Jonah, applying the final bit of piping, had a vision of Billie Jean King physically dragging him away from the gates of Heaven. And if that’s not a sign, I don’t know what is.

I should add, it may not have helped that we requested our little cake figurines be surrounded by an added semi-circle of figurines, in likenesses of the bakery staff, giving us the thumbs-up.

But that’s all done with. They’ve made their wishes clear and we respect them.

Which brings me to the empty vases alongside the pews and the empty centerpiece bowls on the reception tables. We’ve known Joyce Gantz, owner of Rest On My Laurels, for years; I couldn’t imagine this day without her. What I couldn’t know was the war raging within Joyce, fervent Catholic, after she learned of the meat-laden Friday barbecues Keith and I throw for our softball team. Last night, Joyce looked deep within her heart to ask, can I lend my good name to this cursed union?

The dumpster full of imported delphinium behind Joyce’s shop can tell you the answer.

You see, what we’re learning is that these are not just goods and services; they’re not simply the imprints of Keith’s Capital One card and the resulting exchange of goods. Every item at a wedding is nothing less than the avatar of its vendor’s entire belief system. With this in mind, each rose petal my niece Stephanie was prepared to hurl down the aisle might as well have been embossed with JOYCE GANTZ APPLAUDS THEE, SATAN.

What faith-engorged entrepreneur should face such hell?

This is why the rows of steam-trays in the tent are empty, and your choice of beef tenderloin or grilled salmon — or the one plate of tempeh veggie kabob, bless you, Amy! — will never arrive. Because Something Borrowed, Something Cordon Bleu, exceptional wedding caterers and unapologetic druids, could not bear the thought of providing nourishment to a couple willing to rip two thriving Magnolia trees from their backyard last summer. From their email: “Your heretic’s feast will be served when the earth heals from your violence.” By our best guess that wouldn’t have been by 6 p.m.

We also won’t be dancing to Renèe and the Ring-tones. While Rènee was a woman of few beliefs when we booked her, she has since converted to the Egyptian cult of Bastet, and considers the choice to put our cat Banjo to sleep, rather than pay $15,000 for experimental feline jaw surgery, to be “unforgivable wickedness, worthy of disciples of Set.”

I’ve been handed this note: Lane, our photographer, turns out to be more of a Star Wars guy and doesn’t feel right legitimizing such an obviously Star Trek couple.

Blessings on your journey, Lane.

In closing, our apologies. We were so busy coordinating our big day that we forgot to coordinate the sacred truths of all players involved. I’m told many of our vendors will adopt an exhaustive three-week interview process before each sale to keep this from happening again.

We did have a lovely wedding favor created for each of you, which we might as well distribute. It’s a wooden plaque, engraved with the phrase Love Conquers All, hand-crafted by our friend Bryce Charles in the front row. Now, Bryce is something of a Packers fan, and Keith is all about the Bears, but in the spirit of friendly rivalry, we’ve always managed to put aside our differ — wait.

Bryce’s feelings are changing.

They’re moving from loosely-held to nonchalantly-held. They’re not done; from the set of Bryce’s jaw, her feelings have transitioned to intentionally-held, and finally, they’re — yup. They’re strongly-held. Dammit.

Sorry, folks. You’re on your own.",https://cdn-images-1.medium.com/focal/1200/632/50/45/0*fh1vaEnMNoMbHE42,[],https://medium.com/s/story/our-wedding-is-cancelled-due-to-the-following-strongly-held-beliefs-1fa71105660e?source=grid_home---------0------------------18,

Data Analysis,My So-Called (Millennial) Entitlement – Trust Issues – Medium,['Stephanie Georgopulos'],"I am at the San Francisco International Airport some barely recent morning, registering for a travel program called Clear when the automated kiosk assisting me makes a strange request: “Stand still while we scan your irises.” I’ve barely digested this first ask when another takes its place: this time, the kiosk wants my fingerprints. I find this slightly less alarming; I already use those to access my banking app, buy coins for my mobile games, and unlock the phone that hosts all this information in the first place. But my eyeballs — which I had only just learned could be used as ID, and from a machine at the airport, no less — my dude. Those are the windows to my soul! Ever heard of foreplay?

Clear is a private company that prescreens air travelers using biometric authentication. Becoming a member is like ordering the half-soup, half-sandwich version of TSA PreCheck: it works, if all you want is a taste and are willing to pay for it. With Clear, you don’t need your ID to go through security, but you still have to remove your shoes. You get to wait in a shorter line (sometimes), but you still have to take out your laptop. Basically, the Cleared still participate in the most annoying aspects of air travel and pay almost 10 times the PreCheck fee for the privilege.

If the worst has already happened, that means it’s survivable.

How we decided on this valuation of convenience—it’s $179 per year—is not the point, though. My point is that some random startup casually acquired my eye-prints, and some small voice is telling me I should care more than I do. Someone out there definitely cares about this, no doubt. I’m sure at least one other traveler was not sated when a brisk Google search revealed that Clear is based in her hometown and run by a female CEO, ergo it must be a secure and entirely trustworthy business.

But I was sated. It’s the future, right? What’s the worst one could do with my retinal scans? I already gave my social security number to Camel in exchange for a pack of promotional cigarettes one time (or 12). Somewhere in Midtown Manhattan, a market-research firm knows how many condoms I used in May of 2011 (give or take). And when I think about the fact that every hard document I’ve reproduced on a digital copy machine — at work, at the bodega, at the library — is saved on a hard drive somewhere (lots of somewheres, in fact), I feel a sense of hopelessness that, in its own demented way, translates to freedom.

That’s why I unlock my phone with my fingerprint. It’s also why I talk shit in front of Alexa, why I haven’t put tape over my laptop camera, and why I still have a Facebook account. I don’t expect the worst to happen.

Because the worst has already happened. It is happening, and it will continue to happen.

I find this to be an honest, useful framework. If the worst has already happened, that means it’s survivable. And if the worst is a given in the future, too, we know that ignoring it won’t make it go away. There’s opportunity in having nothing to lose. You just need the right attitude.

Or perhaps you need the right conditioning.

Imagine: You’re 11 years old when two teenagers bring guns to their high school and kill 13 people. They injure 21 more. Your sixth-grade humanities teacher explains the inexplicable to your class after lunch period. You have to imagine that this is a first for at least some of your classmates, crying over the national news. It won’t be the last.

When you’re 15, two planes crash into two towers. You know the towers; had toured them on school trips just like all the other famous Manhattan buildings for which you know the names, if not the functions. In fact, you’d visited the towers just one week before the planes hit. There had been a renaissance fair in one of the lobbies.

At 17, your high school economics teacher tells you that social security will run out before you retire. You’ve already been paying taxes for three years. In 2018, you learn that he was exaggerating, thank goodness — by 2034, retirees can expect to receive a whopping 79% of the full benefit they receive today. You will not be of retirement age until the 2050s.

And when you’re 21, the market crashes. You’ve had a bachelor’s degree for three months. It cost $100,000 to earn, all before interest. Your class valedictorian moves back in with her parents, and no, your internship is not hiring. Five years later, the unemployment rate for people your age is almost double the national average.

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

Neuroscience has confirmed that you were making sense of these events with an underdeveloped brain. Along with your emotional maturity and your hormones, it’ll be a work-in-progress until you’re around 25. And the same way the small hurts of being small can still seep into your present — the way your grandmother eyed you with disgust when you went for a second helping — the chipping away of every institution you were raised to believe in can have unintended consequences.

Me: Do you use Touch ID to unlock your phone?

Friend: Ya.

Me: Do you know anything about the technology behind it? Or like, how secure it is?

A beat. A blank stare.

Friend: No?

Me: Same.

My friends do not need to understand the technology behind touch ID any more than they need to understand black holes. They are not convinced that adjusting their social media privacy settings is some sort of moral duty, a symbolic middle finger to Facebook on behalf of all the little guys who understand internet economics to varying degrees, or not at all. Mostly, they were confused as to why any thinking person would have an assumption of security.

“It’s not that I don’t care about being hacked, or about my data being stolen or sold,” one friend tells me. “I assume that vulnerability because there are no physical systems or structures that have succeeded, so why would something that is essentially invisible do a better job than something tangible?”

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

I’ll go: I don’t expect to own a home. I don’t expect to retire well, or at all. I don’t expect anyone to give me anything I haven’t explicitly asked for, and even then. I don’t expect it will ever be affordable to continue my education in any formal way. If a package gets lost in the mail, I don’t expect to see it again. I don’t expect the government or the banks or the universities to do anything that benefits regular people. I don’t expect them to hold each other accountable on our behalf. I don’t expect them to expel abusers from their ranks, or to put my safety over their legacy. I don’t expect to feel safe in large crowds or alone late at night. And I don’t expect that my privacy will be respected, online or in general.

America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

As far as I can tell, security — whether financial, technological, physical, or emotional — is not a thing. You don’t get to decide whether some drunk asshole drinks his drunk ass off and gets behind the wheel. Likewise, you don’t get to decide if the drunk Congress or the drunk banker or all the drunk administrations of all the drunk institutions do what’s right for you. Sometimes they will do the right thing for somebody, but statistically speaking, that somebody is not you.

Sometimes the right thing comes served in a shit sandwich, or one guy does the right thing but it’s later counteracted by the next guy and just so we’re clear, it’s always a guy. Or sometimes, we learn that what we thought was the right thing was actually the wrong thing, in ways we didn’t anticipate, except for those of us who did anticipate it but were not asked or heard because we do not employ lobbyists and because the powers that be can’t listen to us until they sort out whether our bodies are legal or not.

Mark Zuckerberg’s Congressional hearing was probably the biggest mainstreaming of data privacy issues yet, and Facebook, with its many transgressions, made for an appropriate scapegoat. But I want to know why it’s Mark Zuckerberg’s fault that American adults of voting age lack the critical thinking skills to differentiate between fake Russian bot news and The Guardian. I want to know the plan for bringing internet literacy to those who are not digital natives. I want to know why the U.S. government is being celebrated for protecting our egos and baby-proofing the internet instead of telling us the truth: Dirty tricks are less likely to work on people with more education.

What happens when your brand of exceptionalism breeds millions of people who voted a sentient conspiracy theory into office? Where does the fault lie? After all, it’s not Facebook who’s spent decades underpaying teachers and closing schools in low-income neighborhoods. Facebook doesn’t have the jurisdiction to end standardized testing or combat the quiet continuation of white flight. Facebook’s biggest mistake? Profiting off of state-sanctioned dumbness.

We’re only supposed to be dumb enough to believe that the fight is red vs. blue and not top vs. bottom. We’re only supposed to be dumb enough to believe in Democracy the Concept™ without casting a critical eye toward its practical application. This is a dumbness cultivated by and for Washington, and Zuckerberg’s misusing of it for corporate gain almost blew the lid off the entire thing. Commence finger-wagging.

On an episode of his podcast Revisionist History, Malcolm Gladwell argues that we should treat education as a weak-link network, where strengthening the weakest links has the most positive outcome for all. This is in contrast to a strong-link network, where a couple of superstars at the top carry the weaker players on the bottom. He illustrates this dynamic using soccer and basketball. An average soccer team with one star player is less likely to win a match than an above-average team with no star players — soccer is a weak-link sport. Conversely, an NBA team with a superstar or two fares better than a team on which all the players are equally, decently good — basketball is a strong-link sport.

Much to its detriment, America acts like a strong-link country. It is the type of place where electing one mixed-race president means we solved racism. (Imagine if the lesson we took from electing one white man was that all white men who lack upward mobility just need to work harder.) We raise up a few undoubtedly smart and deserving people in each field, send them around the world like brand ambassadors for democracy, poster-adults for how advanced and distinguished and American we are. Meanwhile, most of us back home — 78%, in fact — are living paycheck to paycheck. Is that freedom ringing? We’ll call right back after we pay this phone bill.

These are complex problems. In addition to the 3000ish words here, I have written and cut an additional 4500 trying to make sense of it all. I remain overwhelmed by the number of solutions that contradict one another, the knowns and unknowns, the countless logical ends I haven’t considered. But I eventually found my demented silver lining: America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

While grim on its face, this perspective has pushed me to take inventory of myself, my own power. What can I do right now? Am I solving problems I actually care about, or were these problems unconsciously inherited from another time, problems propagated by those with a vested interest in resolving them with more money, more power, more loopholes? Should I devote my energy to righting a system that, by design, has only consistently benefited one demographic and has yet to even prove itself as a scalable model for a generation that’s tired of the same people making the same decisions on behalf of the most diverse country in the world?

Is that a problem? Because it feels more like an opportunity, to me: a chance to exercise this cache of personal agency I’ve been sitting on, agency I didn’t realize I had or needed as I waited for America to work. It feels like an opportunity to try something else.

More powerful than having nothing to lose is cultivating that which can’t be taken. Grace. Clarity. Purpose. The stuff that isn’t Amazon Prime-able. These are the indoor plants of our being; only you can feed them and grow them and expose them to the light. It’s a lot of responsibility, and the work involved is often unglamorous. Some people think they never have to learn to care for these things because they have the means to outsource what they wish: their plants are alive on paper though they don’t know the how or why of it. And besides, can’t you see they’re a little busy trying to colonize Mars?

A respectable goal, though I might suggest to anyone faced with the choice to try taking on the inner self before jumping ahead to outer space. There’s more to unearth in there than you might think, and we need more people to understand the potential of their own organic material. We need people who appreciate the slow growth of nothing into something, who drink up the sunlight and make the air a little more breathable than before.

Because that’s it, for most of us. That’s how we build power. That’s how we, a generation of janitors for the American dream, put our trust in something real: each other. We stop trying to control the world in our heads and in the headlines, and we start controlling ourselves. We sleep. We go to the doctor. We log off. We talk about our problems. We water our plants. We collect our neighbor’s mail when they’re out of town. We take a deep breath before reacting in anger, and question whether this particular battle is worth our energy. It’s not. Why were we fighting again? We volunteer. We water our plants. We focus on ourselves so we can eventually focus on others — in a real way, in a non-transactional way, in a way that slowly but authentically strengthens our fellow weak links. We don’t wait for permission. We get over ourselves; we stop demanding perfection; we start. We water our plants. And on weekends, we play soccer.",https://cdn-images-1.medium.com/max/1200/1*c5zNxCX34sYmYYO-yRxlbA.png,[],https://medium.com/s/trustissues/my-so-called-millennial-entitlement-9be84343c713?source=grid_home---------0------------------18,

Data Analysis,How to Cope with the End of the World – How to Cope With The End of The World – Medium,['Maria Farrell'],"We All Die, and That’s Okay

My favorite postapocalyptic novel is George R. Stewart’s 1951 Earth Abides. In it, scientist Isherwood Williams (nicknamed Ish) survives a plague and eventually starts a new family and community in the ruins of suburban California. His hope for the future is wholly invested in a child who is intellectually curious, like him, and who might be able to revive some of the old ways and technologies. It’s an observant and reflective novel, full of the “how stuff would probably work” thinking that makes science fiction the true literature of ideas.

Ish starts out as a scientist-savior of humanity, figuring there is just enough time to raise a generation to turn back the clock to before the disaster. But he ultimately has to make his peace with the fact that civilization as he knew it is dead, there will be no heroic rescue, no going back, and the people around him are mostly fine with that.

The 1950s may have been the last decade we could complacently believe the Ecclesiastes (1:4) maxim that “men come and go, but earth abides,” but Stewart’s basic message is correct.

The people who come after us don’t have to do better than us, or think well of us, for them to be essentially okay. And us all throwing a big “let’s blow it all up” hissy fit because we fucked up and we can’t bear to look at it is just teenage nihilism that we need to grow out of already. Coming to terms with what we have done means dumping the egotistical death drive of the mass shooter or far-right politician and gathering the maturity to look our individual and collective deaths straight in the eye and say, “Okay, we get it now. We get it. It’s not about us.”

Have you ever stood in a crowded place like a town square or an airport meet-and-greet and thought, “Every single person here is going to die”? Morbid, eh? More of us should do it.

I live in an early Victorian terraced house in the UK. It’s never been a tenement, so probably a hundred people have called it home in the almost two centuries it’s been standing. Nearly all of them are dead. The people are already born who’ll live there when I’m dead. The head of this country’s anachronistic state has already been born who I’ll never see on the throne and to whom I’ll seem as old as someone born in the 1930s seems to me.

We’re all going to die. The morning will come when those who have loved us put on dark clothes and cry and get on with the rest of their lives, seeing movies we’d have loved, depending on gadgets that now seem to us ridiculously unnecessary. Our deaths matter to us and those who love us, but they don’t fundamentally matter.

Once, while my husband was deployed to Afghanistan, I asked him on the phone if he was doing okay about someone we knew who’d recently been killed. “Oh, you know,” he said, “you know,” and quoted his regiment’s unofficial mantra:

Everything matters. Nothing matters terribly.

The soldier’s death mattered very, very much to him, and (not but) he and others were nonetheless carrying on their shared purpose. Otherwise, what had been the point of any of it?

What will outlive us, individually? Plastic. Perhaps some genes. The bacteria that act as a species-level enabler for everything we are. Some ideas, maybe, or songs, stories, pictures, the memories of us others hold, until they go, memorials like a community flower bed or a named scholarship, for a while, anyway. Less concretely: ways of being, a fitness for the world that those who flourish pass unremarked to their offspring via the epigenetics of love — the sunny inverse of patterns of trauma and abuse transmitted through the body, even unto the third generation. Predation.

And our species? Buildings and bones, maybe. Our nuclear waste and the warning signs we hope people of our deep future, or other species altogether, will decrypt. Snatches of radio-transmitted voices slipping through the vacuum of space. Perhaps some bacterial payload we’ll launch in a decade or so, trying to seed life on other planets, even in other solar systems. Or just the anomalous levels of carbon dioxide and methane in our atmosphere that will reveal, for a time, that complex forms of life were here.

Pride and despair are two sides of the same coin. Our collective denial and despair about the future we have built is preventing us from cracking on and sorting it out. We need to get over ourselves. The world we know will end, in both small and big ways. We ourselves will end. But that doesn’t matter, terribly.

Our mortality is the greatest enabler we have of positive, ongoing change, if only we can face it, if only we can understand that we don’t get to see the end of the movie, because, if what we do works, the movie won’t have to end. We’re not the protagonists. We’re just the foreshadowing. We need to hold the knowledge of our own deaths up to the light and turn it around to see each shining facet, then take the certainty that we are both finite and imperfect deep down inside of us—and put it to work.",https://cdn-images-1.medium.com/max/1200/0*avXWZmh3n3H7a8t8,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world/how-to-cope-with-the-end-of-the-world-2520ef9d3dbc?source=grid_home---------0------------------18,

Data Analysis,How to Cope With The End of The World – Medium,['Maria Farrell'],"COLUMN

How to Cope With The End of The World

There are moments of joy even in times of great despair. Maria Farrell explains how to deal with a darkening world, and how to plan for the end. It might be the end of the world as we know it, but it turns out we feel fine.",https://cdn-images-1.medium.com/max/1200/1*kvqwUuDCsbkAoSfaYXV1vQ@2x.png,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world,

Data Analysis,Chatbots were the next big thing: what happened? – The Startup – Medium,"['Matt Asay', 'Justin Lee']","Chatbots were the next big thing: what happened?

Oh, how the headlines blared:

“…the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”

Chatbots were The Next Big Thing.

Our hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.

And why wouldn’t they be? All the road signs pointed towards insane success.

Messaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!

Plus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.

At the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.

In fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:

“Will a single platform emerge to dominate the chatbot and personal assistant ecosystem?”

One year on, we have an answer to that question.

No.

Because there isn’t even an ecosystem for a platform to dominate.

Fooled by another hype cycle

Chatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.

The age-old hype cycle unfolded in familiar fashion…

Reverential TechCrunch articles were written.

Prophetic thought leaders like Chris Messina chimed in.

Silicon Valley salivated at the prospect of talking to smart automation.

Messenger began to overflow with bots.

Slack went through exponential growth and even launched a fund for bot investment.

Expectations built, built, and then….. It all kind of fizzled out.

The predicted paradim shift didn’t materialize.

And apps are, tellingly, still alive and well.

We look back at our breathless optimism and turn to each other, slightly baffled:

“is that it? THAT was the chatbot revolution we were promised?”

Digit’s Ethan Bloch sums up the general consensus:

“I’m not even sure if we can say ‘chatbots are dead,’ because I don’t even know if they were ever alive.”

According to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.

Text vs. Speech vs. GUI: a potted history

Bots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.

Users had to type commands manually into a machine to get anything done.

Then, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!

Meanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.

Another bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:

… so many different accents, people speaking too fast or too slowly, mumbling, umming and aahing.

Did you say “recognise speech” or “wreck a nice beach”?

The next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:

User: “Hello.”

Agent: “Hello, what’s your name?”

User: “Candy.”

Agent: “Hello, Candy!”

User: “Let’s set the clock.”

Agent: “What is the time?”

User: “The time is 11:00 AM.”

Agent sets the clock to 11:00 AM.

Pretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.

It was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.

Modern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.

Basically, we’re still trying to achieve the same innovations we were 30 years ago.

Here’s where I think we’re going wrong:

Thinking in terms of Bots vs. Apps

An oversized assumption has been that apps are ‘over’, and would be replaced by bots.

By pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.

You might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?

It’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.

Whether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.

Plus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.

A great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.

That’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.

Modern-day apps benefit from decades of research and experimentation. Why would we throw this away?

But, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.

Today’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.

Penny provides chatty advice and alerts alongside a traditional account dashboard and transaction list.

HubSpot Conversations unifies Facebook Messenger, onsite chat, social media, email and other messaging outlets into one shared inbox.

Layer gives developers the tools to create personalized messaging experiences on mobile web and desktop web as well as native apps.

The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.

Bots for the sake of bots

Does my product need a bot? Are existing platforms able to support its functionality? Do I have the patience to build a bot that’s capable of doing what I want it to?

Another problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.

For plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.

Building a bot for the sake of it, letting it loose and hoping for the best will never end well:

The totally necessary Maroon 5 chatbot in action

The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.

The advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.

That’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.

Problems arise when life refuses to fit into those boxes.

According to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.

When we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.

Remember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.

Inaccessibility

A competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.

In an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.

Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)

As Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.

“Consumer interest was never going to materialize until machine intelligence could get anywhere near human intelligence.

User interest depends upon AI that makes talking with a bot worthwhile for consumers.”

And conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.

Today’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.

And in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:

“Should Slack, Facebook, Google, Microsoft, Kik, and others have built their own built-in bots to lead the way?

Should they have gotten more proactive with their bot funds and incubators, hiring mentors to educate participants in the Way of the Bot, or supplying engineering and design resources? Funded Strategic Bot Initiatives at high-profile partners?

In my opinion yes, yes, and yes. When it comes to platforms, developers are the users; and we don’t rely on our users to understand why or how to use our products. We have to show them.”

GUI shouldn’t be dismissed

Once upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information

There’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.

Tapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.

We love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.

Conversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.

Sure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.

Humans like talking to other humans

Aiming for a human dimension in business interactions makes sense.

If there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.

Facebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.

A conversation encompasses so much more than just text.

Humans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.

As HubSpot team pinpointed:

Bots provide a scalable way to interact one-on-one with buyers. Yet, they fail when they don’t deliver an experience as efficient and delightful as the complex, multi-layered conversations people are accustomed to having with other humans on messaging apps.

People aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).

And even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.

And here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.

But is that how humans prefer to interact with machines?

Not necessarily.

At the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.

Where do we go from here?

In a way, those early-adopters weren’t entirely wrong.

People are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.

Not even close.

Computers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.

Computers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.

That’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.

For now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.

But that’s not the whole story.

Yes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.

As Bill Gates once said:

We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. Don’t let yourself be lulled into inaction.

The hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.

I believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.

Messaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.

Developers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.

And I can’t wait to see what happens next.",https://cdn-images-1.medium.com/max/1200/1*-_um8Nai0uer46tni1LETg.jpeg,[],https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=topic_page---8------0----------------,2018-06-05 15:55:36.912000+00:00

Data Analysis,Google’s AutoML will change how businesses use Machine Learning,['George Seif'],"Google’s AutoML will change how businesses use Machine Learning

Google’s AutoML is a new up-and-coming (alpha stage) cloud software suite of Machine Learning tools. It’s based on Google’s state-of-the-art research in image recognition called Neural Architecture Search (NAS). NAS is basically an algorithm that, given your specific dataset, searches for the most optimal neural network to perform a certain task on that dataset. AutoML is then a suite of machine learning tools that will allow one to easily train high-performance deep networks, without requiring the user to have any knowledge of deep learning or AI; all you need is labelled data! Google will use NAS to then find the best network for your specific dataset and task. They’ve already shown how their methods can achieve performance that is far better than that of hand-designed networks.

AutoML totally changes the whole machine learning game because for many applications, specialised skills and knowledge won’t be required. Many companies only need deep networks to do simpler tasks, such as image classification. At that point they don’t need to hire 5 machine learning PhDs; they just need someone who can handle moving around and organising their data.

There’s no doubt that this shift in how “AI” can be used by businesses will create change. But what kind of change are we looking at? Whom will this change benefit? And what will happen to all of the people jumping into the machine learning field? In this post, we’re going to breakdown what Google’s AutoML, and in general the shift towards Software 2.0, means for both businesses and developers in the machine learning field.

More development, less research for businesses

A lot of businesses in the AI space, especially start-ups, are doing relatively simple things in the context of deep learning. Most of their value is coming from their final put-together product. For example, most computer vision start-ups are using some kind of image classification network, which will actually be AutoML’s first tool in the suite. In fact, Google’s NASNet, which achieves the current state-of-the-art in image classification is already publicly available in TensorFlow! Businesses can now skip over this complex experimental-research part of the product pipeline and just use transfer learning for their task. Because there is less experimental-research, more business resources can be spent on product design, development, and the all important data.

Speaking of which…

It becomes more about product

Connecting from the first point, since more time is being spent on product design and development, companies will have faster product iteration. The main value of the company will become less about how great and cutting edge their research is and more about how well their product/technology is engineered. Is it well designed? Easy to use? Is their data pipeline set up in such a way that they can quickly and easily improve their models? These will be the new key questions for optimising their products and being able to iterate faster than their competition. Cutting edge research will also become less of a main driver of increasing the technology’s performance.

Now it’s more like…

Data and resources become critical

Now that research is a less significant part of the equation, how can companies stand out? How do you get ahead of the competition? Of course sales, marketing, and as we just discussed, product design are all very important. But the huge driver of the performance of these deep learning technologies is your data and resources. The more clean and diverse yet task-targeted data you have (i.e both quality and quantity), the more you can improve your models using software tools like AutoML. That means lots of resources for the acquisition and handling of data. All of this partially signifies us moving away from the nitty-gritty of writing tons of code.

It becomes more of…

Software 2.0: Deep learning becomes another tool in the toolbox for most

All you have to do to use Google’s AutoML is upload your labelled data and boom, you’re all set! For people who aren’t super deep (ha ha, pun) into the field, and just want to leverage the power of the technology, this is big. The application of deep learning becomes more accessible. There’s less coding, more using the tool suite. In fact, for most people, deep learning because just another tool in their toolbox. Andrej Karpathy wrote a great article on Software 2.0 and how we’re shifting from writing lots of code to more design and using tools, then letting AI do the rest.

But, considering all of this…

There’s still room for creative science and research

Even though we have these easy-to-use tools, the journey doesn’t just end! When cars were invented, we didn’t just stop making them better even though now they’re quite easy to use. And there’s still many improvements that can be made to improve current AI technologies. AI still isn’t very creative, nor can it reason, or handle complex tasks. It has the crutch of needing a ton of labelled data, which is both expensive and time consuming to acquire. Training still takes a long time to achieve top accuracy. The performance of deep learning models is good for some simple tasks, like classification, but does only fairly well, sometimes even poorly (depending on task complexity), on things like localisation. We don’t yet even fully understand deep networks internally.

All of these things present opportunities for science and research, and in particular for advancing the current AI technologies. On the business side of things, some companies, especially the tech giants (like Google, Microsoft, Facebook, Apple, Amazon) will need to innovate past current tools through science and research in order to compete. All of them can get lots of data and resources, design awesome products, do lots of sales and marketing etc. They could really use something more to set them apart, and that can come from cutting edge innovation.

That leaves us with a final question…

Is all of this good or bad?

Overall, I think this shift in how we create our AI technologies is a good thing. Most businesses will leverage existing machine learning tools, rather than create new ones since they don’t have a need for it. Near-cutting-edge AI becomes accessible to many people, and that means better technologies for all. AI is also quite an “open” field, with major figures like Andrew Ng creating very popular courses to teach people about this important new technology. Making things more accessible helps people transition with the fast-paced tech field.

Such a shift has happened many times before. Programming computers started with assembly level coding! We later moved on to things like C. Many people today consider C too complicated so they use C++. Much of the time, we don’t even need something as complex as C++, so we just use the super high level languages of Python or R! We use the tool that is most appropriate at hand. If you don’t need something super low-level, then you don’t have to use it (e.g C code optimisation, R&D of deep networks from scratch), and can simply use something more high-level and built-in (e.g Python, transfer learning, AI tools).

At the same time, continued efforts in the science and research of AI technologies is critical. We can definitely add tremendous value to the world by engineering new AI-based products. But there comes a point where new science is needed to move forward. Human creativity will always be valuable.

Conclusion

Thanks for reading! I hope you enjoyed this post and learned something new and useful about the current trend in AI technology! This is a partially opinionated piece, so I’d love to hear any responses you may have below!",https://cdn-images-1.medium.com/max/1200/1*g9BzirXxUauRO9rA_tSvnA.jpeg,[],https://towardsdatascience.com/googles-automl-will-change-how-businesses-use-machine-learning-c7d72257aba9?source=topic_page---8------1----------------,2018-05-14 14:27:41.145000+00:00

Data Analysis,My Phone Wants Me to Say ‘Thank You’ – When Robots Rule The World – Medium,['Evan Selinger'],"Sincerely Thankful

Perhaps there’s something infantilizing about our phones “wanting” us to say thanks. It’s hard to draw a firm line between what you would say if only you put in the time to say it versus what you do say after predictive software fills in the blanks. Seeing suggestions is itself a suggestive situation. And so, while Google emphasizes that smart reply is intelligent enough to figure out if you’re more of a “thanks!” than a “thanks.” person, the fact remains that it’s a good bet that some variation of the word will be frequently presented to you.

If being offered a “thanks” seems familiar, it’s because the act resembles what parents do when they try to instill etiquette. Let’s imagine that Lil’ Johnny receives a gift and instinctively wants to run off and play with it. Before this happens, one of his parents admonishes, “Johnny, what do you say?” And so, robotically, Johnny responds, “Thank you.”

At the time of being coached, Lil’ Johnny doesn’t mean what he parrots back. The gesture is insincere, and Johnny offers it to avoid conflict that would further delay what he really wants to do. That’s okay, though. The hope is that, over time, Lil’ Johnny becomes Big Johnny, the type of person who can genuinely experience gratitude and doesn’t simply follow rules like an automaton. The parental admonitions made during childhood are supposed to be like a pair of moral training wheels that kids ultimately outgrow.

Software like smart reply isn’t designed to provide adults with a second round of moral education. But if we mindlessly use such tools on a regular basis so we can quickly move on to do other things—things that we actually care about—our gestures will merely take the form of gratitude while lacking the underlying substance.

True gratitude must be sincere.

To be truly grateful, you have to mean what you say — that is, you must recognize that someone did something for you that deserves to be acknowledged, and you must sincerely want to make the acknowledgment.

Graciousness is a virtue. If an adult passes off insincere gratitude as the sincere variety in situations where people reasonably expect a person’s words and beliefs to align, the person is behaving worse than Lil’ Johnny. Lil’ Johnny is trying to be compliant, not deceptive.

We also shouldn’t lose sight of the fact that people who in engage in rituals like keeping gratitude journals aim to be specific when offering their appreciation. They don’t just say “thanks” or use any of the other minimalist formulations that smart reply offers. Instead, people who are pursuing lives filled with intentionality are concrete about what they are grateful for, as well as why they’re grateful for it. They want to focus on what they have rather than despair or obsesses over what they lack.",https://cdn-images-1.medium.com/focal/1200/632/51/50/1*MpyyWHuRUnanCenqeG3sHA.jpeg,[],https://medium.com/s/when-robots-rule-the-world/my-phone-wants-me-to-say-thank-you-122cc15952a9?source=topic_page---8------3----------------,

Data Analysis,"In 2018, Numbers Lie and Fictions Paint Truth – Eve Weinberg – Medium",['Eve Weinberg'],"In 2018, Numbers Lie and Fictions Paint Truth Why storytelling is our best tool in disambiguating fact from fiction

I’d love to share a few of the lecturers who touched upon this topic and forever changed my understanding of the 2018 landscape of fact, fiction, and storytelling’s role in deciphering one from the other.

This summer, I had the great privilege of attending EyeO (June 3–8 2018). Innumerable topics that encompass the intersection of Art, Technology, and Data were covered, but one common thread has left an imprint on my brain. That is: the Sisyphean 21st century task of disambiguating fact from fiction. That’s right…

PART 1: NUMBERS ARE MALLEABLE

On the first day, we discussed climate science at length. We (a very self aware room of liberal, number-crunching, data-visualization-making, coastal-living, self-ascribed nerds) attempted to break down the problems with human psychology. We looked at the facts, stats, charts, and graphs; then investigated the human power of denial, dissonance, disincentivization, and the hurdles of behavioral change. After 6 hours of discussion, ideation, and reflection, feeling a bit helpless, we ended with questions that I kept with me throughout the next 3 days of lectures:

Why don’t people believe statistics?

Are stories more powerful than numbers?

Why is denial more powerful than behavioral change?

Why do lies travel faster than truth?

…And what should we do about this?

The next day, Amanda Cox enlightened us with her talk These Lines Are The Same. She showed us that data, even in simple bar graphs, can be misinterpreted depending on the viewer’s own bias. She bravely revealed to us that in her department The Upshot at The New York Times they struggle with how to best represent datasets objectively. They experiment in meaningful and educational ways. In one example she showed data from the US unemployment report. The article allows readers to look at the chart with ‘Democratic Goggles’ and ‘Republican Goggles.’

The numbers are the same, but they can easily be bent to the will of anyone with an agenda.

Then she humorously showed us our flaws in clinging to round numbers. She drove the point home with a series of charts, one here showing the likelihood that someone in the ER gets checked for a heart attack, according to their age. As Amanda points out, “nothing radical changes from the age of 39-and-three-quarters and 40, yet here is the data:",https://cdn-images-1.medium.com/max/1200/1*bJ58aYiSmkeNYJY73AQN3w.jpeg,[],https://medium.com/@evejweinberg/in-2018-numbers-lie-and-fictions-paint-truth-ea1f5cdc9abe?source=topic_page---8------0----------------,2018-06-08 22:01:41.763000+00:00

Data Analysis,The Art of Ethereal: Bringing Cellarius to Life – Genesis Thought – Medium,['Mally Anderson'],"The Art of Ethereal: Bringing Cellarius to Life

Whose future is it? Hers, and his, and theirs, and ours.

A sampling of the Cellarius faction portraits from our Ethereal Summit pop-up.

On May 11 and 12, our parent company ConsenSys hosted the third Ethereal Summit at the Knockdown Center in Queens, New York and invited Cellarius to participate, along with many other spokes from our Mesh. The creators of Ethereal wanted to build a different kind of crypto conference. Since this one explored the intersection of blockchain and the arts, we wanted to showcase that aspect of our project and spread the word in an unexpected way. We set up shop in “The Crypt,” a semi-outdoor concrete space with a distinctive patina that felt perfect for the Cellarius blockpunk aesthetic.

The Knockdown Center’s very blockpunk Crypt space. We displayed some not-yet-published art commissions.

We teamed with some artists from a group called Drawn Together NYC: Boris Rasin, Michael Scarola, Derrick Dent, and Rosalind Bunting. Drawn Together’s talented roster of artists creates design concepts, multimedia experiences, and fine art solutions for a wide range of projects and businesses, and they understood what we are going for right away.

The artists of Drawn Together NYC, from left to right: Boris Rasin, Rosalind Bunting, Derrick Dent, and Michael Scarola.

Boris, Michael, and Derrick created custom, in-universe faction portraits of Ethereal attendees. The CX Universe Guide imagines that nation-states and traditional economies will break down after the Cellarius AI seizes control of Earth’s energy sources and communication channels in 2084. In the absence of familiar institutions and technologies, people will begin to form factions according to their allegiance to Cellarius. We wanted to get attendees thinking about their own relationships to technology and start dreaming up characters to explore in the Cellarius universe. So we posed the question: which faction do you think you would be?

Boris drew background art for four different factions:

The 4 faction backgrounds, clockwise from top left: Bucolic, Elite, Ad-Hoc, Homotranscendus.

Bucolic: Bucolics are AI skeptics who reject technology and live on the peripheries of megacities, observing from the outside and farming small pockets of fertile soil. Though their process is completely manual and their harvests are meager, they feel a great satisfaction from working with their own hands, in stark contrast to the highly automated farming processes elsewhere.

Ad-Hoc: Ad-Hocs live off the Cellarius grid and make their own augmentations and tools with scrap pieces they scavenge and rework. Comprised of mostly poor and marginalized groups, they use ingenuity and what little tech they can access to get by.

Elite: The crypto-Elites of the future are pro-Cellarius and experiment with AI and aesthetic enhancements. Living in the highest levels of the megacities, Elites have access to bleeding-edge technology. They are known for having lifespans beyond the normal range of humans, and enjoy the neural boost that comes with AI coupling.

Homotranscendus: During the Reformation, it wasn’t just the home habitat that was transformed forever, but also humankind itself. The campaign was more than just re-imagining the economic machinery of the planet Earth, but also a re-imagining of the of the human brain and body. Through Cellarius-engineered advancements, the next evolution of humanity was born: Homotranscendus. Homotranscendi are fully integrated with AI and no longer depend on their human forms to express consciousness and gather information.

We even got a portrait of ConsenSys’s own Joe Lubin, who wore a custom Cellarius Ethereal t-shirt design during his keynote address (thanks, Joe!). Something tells us that Joe would be a Homotranscendus.

Future Homotranscendus Joe Lubin on Mars.

Reimagining how familiar scenarios from your own life play out in a future setting or speculating about how you might react to a superintelligent AI’s takeover of the world is a great place to start inventing your own ideas in the world of Cellarius. We hope some attendees will be inspired to start making art and stories based on their portraits!

Every single Ethereal portrait, as arranged by our designer, Octavian.

As we’ve mentioned in previous posts, we are also commissioning works from artists we admire to create the first round of content for the Cellarius universe. We decided to commission a mural that would take shape over the two days of the Summit and give attendees a behind-the-scenes look at the process of making a large-scale landscape painting. The design depicts what the Knockdown Center might look like a century from now, in 2118. Visitors to the Crypt got a chance to watch Rosalind transform the canvas from a faint pencil sketch into an impressive and detailed final product:

Rosalind’s “Knockdown Center in 2118” painting took shape over two days.

Rosalind & Boris outlined the sketch first, then Rosalind added color, starting with the future-NYC background.

We hope that the Cellarius platform will allow experienced artists and creators to get directly in touch with their fan bases and share some glimpses of their artistic process, just as Rosalind did with her live painting.

The Drawn Together NYC artists got to learn more about the possibilities of blockchain and decentralization for creatives in the process of chatting with the attendees. Michael noted, “There were so many passionate and interesting people from all over the world that came through. And they had as much fun as we did learning about and playing in the Cellarius world.” Rosalind agreed: “Probably my favorite thing I learnt about over the Summit was how Cellarius involves the creative talents of so many more artists in their company, and loved seeing some of their amazing artwork. Can’t wait to see more!”

We were also excited that the long-term goals of the Cellarius project resonated with the Drawn Together NYC artists. Derrick said, “This was probably the coolest on-site portrait job I’ve ever worked on. I had a great time learning about the Cellarius project and the potential for a sprawling, community-shaped open sci-fi world. It was even cooler to have our portrait work used as an onboarding tool for visitors. People immediately took to creating their own story within this world, and that says a lot about how exciting this could be for folks who are creatively inclined.” We couldn’t have said it better ourselves.

As Boris told us, “The more I spoke to the pop-up team and event attendees about the concept behind this project, the more it occurred to me that this is a game changer. Cellarius and the other projects from ConsenSys are sure to revolutionize our ecosystem in ways we can’t even begin to comprehend. It’s a challenge to explain exactly what this project is, because the underlying platform allows for limitless opportunities of invention, inspiration, and collaboration. Cellarius is whatever its contributors will it to be, and frankly, that’s a fundamentally crazy idea!”

That’s just the point: blockchain enthusiasts can become artists and use storytelling to push the conceptual limits of technology. Artists can use the platform to explore the possibilities of decentralization and blockchain for sharing and protecting their work. We can build it together. Cellarius is whatever our community of contributors wills it to be.",https://cdn-images-1.medium.com/max/1200/1*vL8856P7cdV84CYM_SkF0A.jpeg,[],https://medium.com/genesis-thought/the-art-of-ethereal-bringing-cellarius-to-life-ba4ae31811e7?source=topic_page---8------1----------------,2018-06-08 16:46:47.896000+00:00

Data Analysis,A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what…,['Rowan Trollope'],"A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what happened?” Has gotten some fun responses.

The most popular comment being one that says “not surprised, this was never going to be a big thing”…

The first thing to point out is that people are conflating the specific of a chatbot with the generic “conversational user interface” (CUI) of which a chatbot is a specific modality. The real discussion here is about the CUI.

And the last month has certainly showed us that the CUI has made dramatic strides with Google demonstrating Duplex.

So what happened to the explosion of chatbots people predicted?

Among other things, Developers figured out just how hard it is to make a really good conversational user interface. Product folks were tricked by the trio of Alexa/Siri/Google Assistant into the belief that a conversational interface is easy.

Turns out it’s really hard, requires a ton of data and is highly domain specific.

In other words, training a CUI to be really great at getting sports scores doesn’t translate at all to a chatbot that can help you with a billing problem or ordering a pizza.

Google was careful to point out that Duplex was trained for only two very specific use cases : book a salon or a restaurant appointment.

Tim Tuttle at Mindmeld figured this out and built a company to solve it, but it still required heavy lifting and tons of data specific to the domain.

My belief is that the conversational interface is inevitable.

Technology evolution is exponential not linear. Our tendency is to project the future in a linear fashion, which causes us to overestimate what’s possible in 1 year and underestimate what’s possible in 10 years.

This makes tech progress feel gradual or slow, and then sudden and surprising.

Last week Salesforce’s chief scientist, Richard Socher, spoke publicly about the future of chatbots and asserted that in 5 years we would begin to see this start to pay off.

We are early days on the conversational interface, but as with all tech progress most folks will be disappointed until one year, 5–10 years from now when they’ll be shocked and amazed and wonder how it happened so fast.",https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico,[],https://medium.com/@rowantrollope/chatbots-were-supposed-to-be-the-next-big-thing-what-happened-5a4e416308e1?source=topic_page---8------2----------------,2018-06-08 21:06:45.446000+00:00

Data Analysis,"Beethoven, Picasso, and Artificial Intelligence – Towards Data Science",['Chris Kalahiki'],"Beethoven, Picasso, and Artificial Intelligence

Introduction

When people think of the greatest artists who’ve ever lived, they probably think of names like Beethoven or Picasso. No one would ever think of a computer as a great artist. But what if one day, that was indeed the case. Could computers learn to create incredible drawings like the Mona Lisa? Perhaps one day a robot will be capable of composing the next great symphony. Some experts believe this to be the case. In fact, some of the greatest minds in artificial intelligence are diligently working to develop programs that can create drawing and music independently from humans. The use of artificial intelligence in the field of art has even been picked up by tech giants the likes of Google.

The projects that are included in this paper could have drastic implications in our everyday lives. They may also change the way we view art. They also showcase the incredible advancement that has been made in the field of artificial intelligence. Image recognition is not as far as the research goes. Nor is the ability to generate music in the styling of the great artists of our past. Although these topics will be touched upon, we will focus on several more advanced achievements such as text descriptions being turned into images and generating art and music that is totally original. Each of these projects bring something new and innovative to the table and show us exactly how the art space is a great place to further explore applications of artificial intelligence. We will be discussing problems that have been faced in these projects and how they have been overcome. The future of AI looks bright. Let’s look at what the future may hold. In doing this, we may be able to better understand the impact that artificial intelligence can have in an area that is driven by human creativity.

GAN and Its Evolved Forms

Machines must be educated. They learn from instruction. How do we lead machines away from emulating what already exists, and have them create new techniques? “No creative artist will create art today that tries to emulate the Baroque or Impressionist style, or any other traditional style, unless trying to do so ironically” [4]. This problem isn’t limited to paintings either. Music can be very structured in some respects, but is also a form of art that requires vast creativity. So how do we go about solving such a problem? The first concept we will discuss is something called GAN (Generative Adversarial Networks). GANs, although quite complex, are becoming an outdated model. If artificial intelligence in the art space is to advance, researchers and developers will have to work to find better methods to allow machines to generate art and music. Two of these such methods are presented in the form of Sketch-RNN and CAN (Creative Adversarial Networks). Each of these methods have their advantages over GANs.

First, let’s explore what exactly a GAN is. Below is a small excerpt explaining how a GAN works:

Generative Adversarial Network (GAN) has two sub networks, a generator and a discriminator. The discriminator has access to a set of images (training images). The discriminator tries to discriminate between “real” images (from the training set) and “fake” images generated by the generator. The generator tries to generate images similar to the training set without seeing the images [4].

The more images the generator creates, the closer they get to the images from the training set. The idea is that after a certain number of images are generated, the GAN will create images that are very similar to what we consider art. This is a very impressive accomplishment to say the least. But what if we take it a step further?

Many issues associated with the GAN are simply limitations on what it can do. The GAN is powerful, but can’t do quite as much as we would like. For example, the generator in the model described above will continue to create images closer and closer to the images given to the discriminator that it isn’t producing original art. Could a GAN be trained to draw alongside a user? It’s not likely. The model wouldn’t be able to turn a text-based description of an image into an actual picture either. As impressive as the GAN may be, we would all agree that it can be improved. Each of the shortcoming mentioned have actually been addressed and, to an extent, solved. Let’s look at how this is done.

Sketch-RNN is a recurrent neural network model developed by Google. The goal of Sketch-RNN is to help machines learn to create art in a manner similar to the way a human may learn. It has been used in a Google AI Experiment to be able to sketch alongside a user. While doing so, it can provide the users with suggestions and even complete the user’s sketch when they decide to take a break. Sketch-RNN is exposed to a massive number of sketches provided through a dataset of vector drawings obtained through another Google application that we will discuss later. Each of these sketches are tagged to let the program know what object is in the sketch. The data set represents the sketch as a set of pen strokes. This allows Sketch-RNN to then learn what aspects each sketch of a certain object has in common. If a user begins to draw a cat, Sketch-RNN could then show the user other common features that could be on the cat. This model could have many new creative applications. “The decoder-only model trained on various classes can assist the creative process of an artist by suggesting many possible ways of finishing a sketch” [3]. The Sketch-RNN team even believes that, given a more complex dataset, the applications could be used in an educational sense to teach users how to draw. These applications of Sketch-RNN couldn’t be nearly as easily achieved with GAN alone.

Another method used to improve upon GAN is the Creative Adversarial Network. In their paper regarding adversarial networks generating art, several researchers discuss a new way of generating art through CANs. The idea is that the CAN has two adversary networks. One, the generator, has no access to any art. It has no basis to go off of when generating images. The other network, the discriminator, is trained to classify the images generated as being art or not. When an image is generated, the discriminator gives the generator two pieces of information. The first is whether it believes the generated image comes from the same distributor as the pieces of art it was trained on, and the other being how the discriminator can fit the generated image into one of the categories of art it was taught. This technique is fantastic in that it helps the generator create images that are both emulative of past works of art in the sense that it learns what was good about those images and creative in a sense that it is taught to produce new and different artistic concepts. This is a big difference from GAN creating art that emulated the training images. Eventually, the CAN will learn how to produce only new and innovative artwork.

One final future for the vanilla GAN is StackGAN. StackGAN is a text to photo-realistic image synthesizer that uses stacked generative adversarial networks. Given a text description, the StackGAN is able to create images that are very much related to the given text. This wouldn’t be doable with a normal GAN model as it would be much too difficult to generate photo-realistic images from a text description even with a state-of-the-art training database. This is where StackGAN comes in. It breaks the problem down into 2 parts. “Low-resolution images are generated by our Stage-I GAN. On the top of our Stage-I GAN, we stack Stage-II GAN to generate realistic high-resolution images conditioned on Stage-I results and text descriptions” [7]. It is through the conditioning on Stage-I results and text descriptions that Stage-II GAN can find details that Stage-I GAN may have missed and create higher resolution images. By breaking the problem down into smaller subproblems, the StackGAN can tackle problems that aren’t possible with a regular GAN. On the next page is an image showing the difference between a regular GAN and each step of the StackGAN.

This image came from the StackGAN paper [7].

It is through advancements like these that have been made in recent years that we can continue to push the boundaries of what AI can do. We have just seen three ways to improve upon a concept that was already quite complex and innovative. Each of these advancements have a practical, everyday use. As we continue to improve on artificial intelligence techniques, we will able to do more and more in regard to, not just art and music, but a wide variety of tasks to improve our lives.

DeepBach, Magenta, and NSynth

Images aren’t the only type of art that artificial intelligence can impact though. Its effect on music is being explored as we speak. We will now explore some specific cases and their impact on both music and artificial intelligence. In doing this, we should be able to see how art can do as much for AI as AI does for it. Both fields benefit heavily from the types of projects that we are exploring here.

Could a machine ever be able to create a piece of music the likes of Johann Sebastian Bach? In a project known as DeepBach, several researchers looked to create pieces similar to Bach’s chorales. The beauty of DeepBach is that it “is able to generate coherent musical phrases and provides, for instance, varied reharmonizations of melodies without plagiarism” [6]. What this means it that DeepBach can create music with correct structure and be original. It is just in the style of Bach. It isn’t just a mashup of his works. DeepBach is creating new content. The developers of DeepBach went on to test whether their product could actually fool listeners.

As part of the experiment, over 1,250 people were asked to vote whether pieces presented to them were in fact composed by Bach. The subjects had varying degrees of musical expertise. The results showed that as the model for DeepBach’s complexity increased, the subjects had more and more trouble distinguishing the chorales of Bach from those of DeepBach. This experiment shows us that through the use of artificial intelligence and machine learning, it is quite possible to recreate original works in the likeness of the greats. But is that the limit to what artificial intelligence can do in the field of art and music?

DeepBach has achieved something that would have been unheard of in the not so distant past, but it certainly isn’t the fullest extent of what AI can do to benefit the field of music. What if we want to create new and innovative music? Maybe AI can change the way music is created all together. There must be projects that do more to push the envelope. As a matter of fact, that is exactly what the team behind Magenta look to do.

Magenta is a project being conducted by the Google Brain team and lead by Douglas Eck. Eck has been working for Google since 2010, but that isn’t where his interest in Music began. Eck helped found Brain Music and Sound, an international laboratory for brain, music, and sound research. He was also involved at the McGill Centre for Interdisciplinary Research in Music Media and Technology, and was an Associate Professor in Computer Science at the University of Montreal.

Magenta’s goal is to be “a research project to advance the state of the art in machine intelligence for music and art generation” [2]. It is an open source project that uses TensorFlow. Magenta aims to learn how to generate art and music in a way that is indeed generative. It must go past just emulating existing music. This is distinctly different that projects along the line of DeepBach which set out to emulate existing music in a way that wasn’t plagiarizing existing pieces of music. Eck and company realize that art is about capturing elements of surprise and drawing attention to certain aspects. “This leads to perhaps the biggest challenge: combining generation, attention and surprise to tell a compelling story. So much of machine-generated music and art is good in small chunks, but lacks any sort of long-term narrative arc” [2]. Such a perspective gives computer-generated music more substance, and helps it to become less of a gimmick.

One of the projects the magenta team has developed is called NSynth. The idea behind NSynth is to be able to create new sounds that have never been heard before, but beyond that, to reimagine how music synthesis can be done. Unlike ordinary synthesizers that focus on “a specific arrangement of oscillators or an algorithm for sample playback, such as FM Synthesis or Granular Synthesis” [5], NSynth generates sounds on an individual level. To do this, it uses deep neural networks. Google has even launched an experiment that allows users to really see what NSynth can do by allowing them to fuse together the sounds of existing instruments to create new hybrid sounds that have never been heard before. As an example, users can take two instruments such as a banjo and a tuba, and take parts of each of their sounds to create a totally new instrument. The experiment also allowed users to decide what percentage of each instrument would be used.

Projects like Magenta go above and beyond in showing us the full extent of what artificial intelligence can do in the way of generating music. They explore new applications of artificial intelligence that can generate new ideas independent of humans. It is the closest we have come to machine creativity. Although machines aren’t yet able to truly think and express creativity, they may soon be able to generate new and unique art and music for us to enjoy. Don’t worry though. Eck doesn’t intend to replace artists with AI. Instead he looks to provide artists with tools to create music in an entirely new way.

Deep Dream and Quick, Draw!

As we look ahead to a few more of the ways that AI has been used to accomplish new and innovative ideas in the art space, we look at projects like Quick, Draw! and Deep Dream. These projects showcase amazing progress in the space while pointing out some issues that researchers in AI will have to work out in the years to come.

Quick, Draw! is an application from the Google Creative Lab, trained to recognize quick drawings much like one would see in a game of Pictionary. The program can recognize simple objects such as cats and apples based on common aspects of the many pictures it was given before. Although the program will not get every picture right each time it is used, it continues to learn from the similarities in the picture drawn and the hundreds of pictures before it.

The science behind Quick, Draw! “uses some of the same technology that helps Google Translate recognize your handwriting. To understand handwritings or drawings, you don’t just look at what the person drew. You look at how they actually drew it” [1]. It is presented in the form of a game, with the user drawing a picture of an object chosen by the application. The program then has 20 seconds to recognize the image. In each session, the user is given a total of 6 objects. The images are then stored to the database used to train application. This happens to be the same database we saw earlier in the Sketch-RNN application. This image recognition is a very practical use of artificial intelligence in the realm of art and music. It can do a lot to benefit us in our everyday lives. But this only begins to scratch the surface of what artificial intelligence can do in this field. Although this is very impressive, we might point out that the application doesn’t truly understand what is being drawn. It is just picking up on patterns. In fact, this distinction is part of the gap between simple AI techniques and true artificial general intelligence. Machines that truly understand what the objects in images are don’t appear to be coming in the near future.

Another interesting project in the art space is Google’s Deep Dream project, which uses AI to create new and unique images. Unfortunately, the Deep Dream Generator Team wouldn’t go into too much detail about the technology itself (mostly fearing it would be too long for an email) [8]. They did, however, explain that convolutional neural networks train on the famous ImageNet dataset. Those neural networks are then used to create art-like images. Essentially, Deep Dream takes the styling of one image and uses it to modify another image. The results can be anything from a silly fusion to an artistic masterpiece. This occurs when the program identifies the unique stylings of an image provided by the user and imposes those stylings onto another image that the user provides. What can easily be observed through the use of Deep Dream is that computers aren’t yet capable of truly understanding what they are doing with respect to art. They can be fed complex algorithms to generate images, but don’t fundamentally understand what it is they are generating. For example, a computer may see a knife cutting through an onion and assume the knife and onion are one object. The lack of an ability to truly understand the contents of an image is one dilemma that researchers have yet to solve.

Perhaps as we continue to make advances in artificial intelligence we will be able to have machines that do truly understand what objects are in an image and even the emotions evoked by their music. The only way for this to be achieved is by reaching true artificial general intelligence (AGI). IN the meantime, the Deep Dream team believes that generative models will be able to create some really interesting pieces of art and digital content.

Where Do We Go From Here?

For this section, we will consider where artificial intelligence could be heading in the art space. We will take a look at how AI has impacted the space and in what ways it can continue to do so. We will also look at ways art and music could continue to impact AI in the years to come.

Although I don’t feel that we have completely mastered the ability to emulate the great artists of our past, it is just a matter of time before that problem is solved. The real task to be solved is that of creating new innovations in art and music. We need to work towards creation without emulation. It is quite clear that we are headed in that direction through projects like CAN and Magenta. Artificial general intelligence (AGI) is not the only way to complete this task. As a matter of fact, even those who dispute the possibility of AGI would have a hard time disputing the creation of unique works of art by a machine.

One path that may be taken to further improve art and music through AI is to create more advanced datasets to use in training the complex networks like Sketch-RNN and Deep Dream. AI needs to be trained to be able to perform as expected. That training has a huge impact on the results we get. Shouldn’t we want to train our machines in the most beneficial way possible. Even developing software like Sketch-RNN to use the ImageNet dataset used in Deep Dream could be huge in educating artists on techniques for drawing complex, realistic images. Complex datasets could very well be our answer to more efficient training. Until our machines can think and learn like we do, we will need to be very careful what data is used to train them.

One of the ways that art and music can help to impact AI is by providing another method of Turing Testing machines. For those who dream of creating AGI, what better way to test the machine’s ability that to create something that tests the full extent of human-like creativity? Art is the truest representation of human creativity. That is, in fact, its essence. Although art is probably not the ultimate end game for artificial intelligence, it could be one of the best ways to test the limits of what a machine can do. The day that computers can create original musical composition and create images based on descriptions given by a user could very well be the day that we stop being able to distinguish man from machine.

Conclusion

There are many benefits to using artificial intelligence in the music space. Some of them have already been seen in the projects we have discussed so far. We have seen how artificial intelligence could be used for image recognition as well as their ability to turn our words into fantastic images. We have also seen how AI can be used to synthesize new sounds that have never been heard. We know that artificial intelligence can be used to create art alongside us as well as independently from us. It can be taught to mimic music from the past and can create novel ideas. All of these accomplishments are a part of what will drive AI research into the future. Who knows? Perhaps one day we will achieve artificial general intelligence and machines will be able to understand what is really in the images it is given. Maybe our computers will be able to understand how their art makes us feel. There is a clear path showing us where to go from here. I firmly believe that it is up to us to continue this research and test the limits of what artificial intelligence can do, both in the field of art and in our everyday lives.

References",https://cdn-images-1.medium.com/max/1200/0*pIGHko-OCo1usW2c,[],https://towardsdatascience.com/beethoven-picasso-and-artificial-intelligence-caf644fc72f9?source=topic_page---8------3----------------,2018-06-08 21:34:58.310000+00:00

Data Analysis,The curious case of the vanishing & exploding gradient,['Eniola Alese'],"The curious case of the vanishing & exploding gradient

Understanding why gradients explode or vanish and methods for dealing with the problem.

Photo by SpaceX on Unsplash

In the last post, we introduced a step by step walkthrough of RNN training and how to derive the gradients of the network weights using back propagation and the chain rule. But it turns out that during this training the RNN can suffer greatly from two problems: 1. Vanishing gradients or 2. Exploding gradients.

Why Gradients Explode or Vanish

Recall the many-to-many architecture for text generation shown below and in the introduction to RNN post, lets assume the input sequence to the network is a 20 word sentence: “I grew up in France,…….. I speak French fluently.

We can see from the example above that for the RNN to predict the word “French” which comes at the end of the sequence, it would need information from the word “France”, which occurs further back at the beginning of the sentence. This kind of dependence between sequence data is called long-term dependencies because the distance between the relevant information “France” and the point where it is needed to make a prediction “French” is very wide. Unfortunately, in practice as this distance becomes wider, RNNs have a hard time learning these dependencies because it encounters either a vanishing or exploding gradient problem.

These problems arise during training of a deep network when the gradients are being propagated back in time all the way to the initial layer. The gradients coming from the deeper layers have to go through continuous matrix multiplications because of the the chain rule, and as they approach the earlier layers, if they have small values (<1), they shrink exponentially until they vanish and make it impossible for the model to learn , this is the vanishing gradient problem. While on the other hand if they have large values (>1) they get larger and eventually blow up and crash the model, this is the exploding gradient problem

Dealing with Exploding Gradients",https://cdn-images-1.medium.com/max/1200/0*UCn2LUkacEHQxgZW,[],https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb?source=topic_page---8------5----------------,2018-06-05 22:33:57.437000+00:00

Data Analysis,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------,2018-06-08 22:25:33.341000+00:00

Data Analysis,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------#--responses,2018-06-08 22:25:33.341000+00:00

Data Analysis,How to build a range slider component in React from scratch using only <div> and <span>,['Rajesh Pillai'],"How to build a range slider component in React from scratch using only <div> and <span>

In this article we will build a React range slider component step by step using only <div>. We will enable it with touch support.

What can you do with a piece of about 50 <div’s>?

Build a slider control from scratch. If this sounds interesting, then follow along.

The final output will look like the below animation.

Please do note that I have developed this component as a teaching exercise for my students of ReactJS — Beyond the Basics course on Udemy, so it may have some edge cases (which I will fix as and when encountered).

You could use an HTML5 range control and customize it. But I wanted to take a different approach and build something from scratch. And the result is what you see here.

Our slider component will be composed of the below three elements:

A slider range

The actual slider controls

The current selection range

Defining the state for our component

Let us begin by defining our state. I am only showing you the important part of the code. For the full source code, please refer to the link at the end of the article.

state = {

slots: 24,

start: 0,

end: 10,

labelMode: ""mid"", // mid, long

}

The state contains the following properties.

slots: Total slots to be drawn (in this case I am using it as a time selector, so it will have 24 hour slots)

start: The start value of the selection

end: The end value of the selection

labelMode: Currently unused. But can be used to customize the scale label rendering.

The return part of the render method

Let us now take a look at the return part of the render method. The render() method will be slowly composed of small pieces of functionality.

return (

<div>

<h2>React Slider</h2>

<div className=""example-1"">

<div className=""slider-container"">

<div className=""slider-scale"">

{scale}

</div>

<div className=""slider"">

{slider}

</div>

<div className=""slider-selected-scale"">

{currentScale}

</div>

</div>

</div>

</div>

);

For those reading on mobile, the below image may be handy, as sometimes Medium breaks the code formatting.

If you take a look at the code, there are only three important pieces:

scale variable

slider variable

currentScale variable

The three variables above will be responsible for rendering the correct parts of the overall slider.

Dissecting the render () method

Let us initialize some variables. The scale , slider and currentScale JSX will be created within the for loop defined below.

render () {

let scale = [];

let slider=[];

let currentScale = [];

let minThumb = null;

let maxThumb = null

..... // rest of the code

}

Create the JSX for the ‘scale’ variable

Creating the JSX for the scale variable is quite simple. We just loop through the slots value in the state and push a <div> to the scale array with the required CSS class for styling.

The if condition ensures that we are only printing the label for i = 0, i = 12, or i = 24 (kind of mid range). Please feel free to customize this.

for (let i = 0; i <= this.state.slots;i++) {

let label = """";



if (i == 0 || i == 12 || i == 24) {

label = i;

}



scale.push(

<div

key={i}

className=""slot-scale"">

{label}

</div>

);

Here’s the code in image format:

Create the JSX for the ‘currentScale’ variable

Let us now continue with the same for loop and create the ‘currentScale’ JSX. We are still within the same for loop, so about 24 divs will be created as per the value in this.state.slots value.

The currentScale has a class of ‘slot-scale-selected’.

let currentLabel = """";



if (i === this.state.start || i === this.state.end) {

currentLabel = i;

}



currentScale.push(

<div

key={i}

className=""slot-scale-selected"">

{currentLabel}

</div>

);

The code is pretty similar to the ‘scale’ JSX that we created.

Create the JSX for the ‘slider’ variable

Let us write a function to render the ‘slider’ jsx. The slider needs two thumbs, one for min, and one for max.

Let us first initialize the thumb variable depending on the ‘i’ value. If ‘i’ is the same as this.state.start, then we set the minThumb variable. Else if the value of ‘i’ is the same as this.state.end, then we initialize the maxThumb variable.

if (i === this.state.start) {

minThumb = <this.MinSlider />

} else if (i === this.state.end) {

maxThumb = <this.MaxSlider />

} else {

minThumb = null;

maxThumb = null;

}

Create the JSX for the ‘slider’

The important code piece here is the dragover event. This is required for the HTML drop to work correctly.

let lineClass = ""line"";



if (i >= this.state.start && i < this.state.end) {

lineClass += "" line-selected"";

}

slider.push(

<div

data-slot={i}

onDragOver={this.onDragOver}

onTouchMove = {this.onDragOver}

onTouchEnd = {this.onDrop}

onDrop = {this.onDrop}

key={i}

className=""slot"">

<div data-slot={i} className={lineClass}/>

<span className=""scale-mark""></span>

{minThumb}

{maxThumb}

</div>

);

The slider variable needs two additional pieces of features to represent the min and the max thumb on the slider.

The slider JSX has additional event handlers to deal with handling the drop event/touchend event. We will take a look at the event handlers shortly.

The ‘lineClass’ styles/renders the line on the slider, and the ‘line-selected’ class styles the currently selected range.

Let us now write the MinSlider and MaxSlider function outside the render method.

The MinSlider () function to render the min thumb

Let’s take a look at the code. The important props are the events related to drag and the draggable attribute. The draggable attribute will make this element draggable.

We are also adding the touch event handler. Refer to the link at the bottom of the article to add touch support polyfill for the HTML5 API.

MinSlider=()=> {

return (

<div data-slider=""min""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-min"">

</div>

);

}

The MaxSlider () function to render the min thumb

The MaxSlider is almost the same as the MinSlider except for the data and the className.

MaxSlider=()=> {

return (

<div data-slider=""max""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-max"">

</div>

);

}

The code image is given below for reference.

Event Handling

Let us now look at the drag/touch event handlers defined within our <div> to control the movement of the slider element.

dragover:

The dragover event is required to support the drop zone when using the HTML5 drag/drop API. The only thing we need to do here is to invoke the preventDefault on the event object.

onDragOver = (e) => {

e.preventDefault();

}

dragstart:

The dragstart enables us to store which slider is being dragged. Please note that I am not using the dataTransfer object here, but simply using an instance variable to store this.

onDragStart = (e) => {

let slider = e.target.dataset.slider;

this.sliderType = slider;

}

The value of e.target.dataset.slider is either “min” or “max,” indicating which slider is being dragged.

ondrop:

The ondrop event captures where the thumb is being dropped (on which scale).

This is the important flow in the ondrop event:

Grab the source (whether min/max thumb)

Get the slot (where the drop happens)

Validations

Update the slot (in the state)

Reset the sliderType.

onDrop = (e, target) => {

let source = this.sliderType;

let slot = Number(e.target.dataset.slot);



if (isNaN(slot)) return;



if (source === ""min"") {

if (slot >= this.state.end) return;

this.setState({

start: slot

},()=>{

console.log(this.state);

})

} else if (source === ""max"") {

if (slot <= this.state.start) return;

this.setState({

end: slot

},()=>{

console.log(this.state);

})

}

this.sliderType = null;

}

The complete source code/and demo can be seen here http://jsbin.com/remodat/edit?output

Since I am using HTML5 drag and drop features to add touch, support please add this polyfill reference to your html file.

Todos

Extract the logic to a separate Component class

Test it and and add customization.

History

21-May-2018 — First release

P.S: This component is a result of a very quick coding attempt. This will be refactored.

Promotion: If you would like to support our open source curriculum Mastering Full Stack Engineering in 12 to 20 weeks then here is a special 10$ coupon for medium readers for my upcoming live ReactJS-Beyond the basicscourse on udemy (MEDIUM_500 is the coupon code, which is already tagged in the above URL)",https://cdn-images-1.medium.com/max/1200/1*iSkeoPHBQubtAL4fV4h9xQ.png,[],https://medium.freecodecamp.org/how-to-build-a-range-slider-component-in-react-from-scratch-using-only-div-and-span-d53e1a62c4a3?source=collection_home---6------1----------------,2018-06-08 21:41:33.808000+00:00

Data Analysis,The well-kept secret behind great UX: Usability Testing,['Anant Jain'],"The well-kept secret behind great UX: Usability Testing

Whether you only have a prototype or a full-fledged product, it’s a really good idea to run monthly usability tests. These make sure that whatever you’re working on is usable and the user experience is excellent.

If you’re wondering what you can do to make your usability tests more structured and organized, this guide is for you. Let’s get started!

First off, always keep the two Golden Rules of Usability Testing in mind:

Any testing is better than no testing (with no one!) A little testing earlier is better than a lot of testing later.

In this post, I will introduce you to the kind of lightweight usability testing described in Steve Krug’s books, “Don’t Make Me Think” and “Rocket Surgery Made Easy.” Steve calls this kind of testing “Do-It-Yourself Usability Testing” since it’s supposed to be cheap, easy-to-do and takes just a morning a month.

A quick intro to usability testing

The idea behind this is to:

Find a few participants

Ask them to come in and go through a list of user flows you want to test

Observe the problems they run into

Finally, make a list of issues to fix

Sounds simple enough, but very few of us actually do it. The goal of this post is to make you confident enough to run at least one usability test session this month. I ran my first usability test only a year ago, and I must say it’s actually a lot of fun!

Before we get to the test itself, here are a few things to note:

Reserve one morning a month (say the third Thursday every month) for a round of testing, debriefing, and deciding what to fix. Test with three participants each round. Recruit loosely, and grade on a curve. You don’t need to find someone who fits the exact mould of your ideal user, since most usability problems can be uncovered by testing with just about anyone. If you are part of a big company and have the budget, you can recruit via Craigslist and offer a $50 gift card for an hour of the participant’s time. If you don’t have those kind of resources, don’t worry — you can ask your friends, your existing users, or even go to a café and ask strangers for 15 minutes of their time in exchange for buying them a coffee. If you’re doing this as part of a bigger team, get as many observers as possible to observe the tests in a separate observation room. These will be the designers, engineers, project managers, executives, etc. Or, in case of side projects, it’ll be just be you later in your room!

What happens during the test?

During a usability test, you will record the participant’s voice and their computer screen, and share both these streams live with observers in another room. A typical one-hour test can be broken down into:

Welcome (4 mins): Explain how the test will work so that the participant will know what to expect. The questions (2 mins): Ask the participant a few questions about themselves. This helps put them at ease and gives you an idea of how computer-savvy they are. The Homepage tour (3 mins): Open the Home page of your site, and ask the participant to look around and tell you what they think. This will give you an idea of how easy it is to understand your home page, as well as how familiar the participant is with your domain. The tasks (35 minutes): Watch the participant perform a series of tasks you have prepared for them beforehand. If you’re building a SaaS product and you’re testing out your subscription flow, a typical task could be to find the Pricing page, compare various plans, and Subscribe to one of the plans with a provided test credit card number. Encourage the participant to think out loud as they perform the task (see the video at the end of the post for a sample test.) It’s crucial that you let them work on their own and not ask them any leading questions, or give out any clues or assistance. Probing (5 mins): Ask the participant any questions you may have about anything that happened during the test and about any issues that people in the observation room may have. Also, answer any questions that the participant may have at this point (don’t answer them during the actual tasks since you’re testing how they’ll perform with no one around.) Wrapping Up (5 mins): Thank them for their help, and give them their gift card if you promised one while recruiting them.

The debrief

During the breaks between successive tests, ask the observers to write down the top 3 usability problems that they saw. During the debriefing, focus ruthlessly on deciding to fix the most severe problems first. Here are a few other recommendations:

Keep a separate list of low-hanging fruit. These are the problems you can typically fix with one-line code changes, but have a huge impact on task completion rates. Joel Califa calls them “tiny wins”. Here’s an example:

Resist the impulse to add things — instead, try to tweak your existing design to fix the problem.

to fix the problem. Take “new feature” requests with a grain of salt. Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature.

Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature. Ignore the problems where the user goes astray for a bit but comes back on track by themselves. These are usually not worth investing much time unless you see a pattern across multiple participants.

Good design is a delicate balance, so when fixing a problem, ensure that you aren’t introducing new ones.

Remote testing and unmoderated user testing

Remote testing is very similar to an in-person usability test, except that the participant is at their home/office and you conduct the testing via screen sharing and voice call.

Unmoderated user testing is another way to test, where you specify your website, the tasks you want the users to do, and get back video recordings of people trying to accomplish those tasks. Usertesting.com is the leader in this space, but note that a single 30-minute test costs about $50.

Resources

You can download checklists, interview script, consent form, and a demo video at Steve Krug’s site here: Downloads for Rocket Surgery Made Easy.

Here’s a Usability Test demo video from Google Ventures:

I want to thank you for reading this quick guide. This was originally published as part of the UX Design course on Commonlounge, a platform that has courses with small bite-sized lessons like these on topics ranging from Project Management to Machine Learning that deliver the most value for the time you put in.

You learn by working on real-world projects and getting feedback from industry mentors. You should check it out here!",https://cdn-images-1.medium.com/max/1200/0*UWxJWKKNLXR5c1cm,[],https://medium.freecodecamp.org/the-well-kept-secret-behind-great-ux-usability-testing-b788178a64c3?source=collection_home---6------2----------------,2018-06-08 21:25:31.335000+00:00

Data Analysis,An introduction to part-of-speech tagging and the Hidden Markov Model,['Divya Godayal'],"Let’s go back into the times when we had no language to communicate. The only way we had was sign language. That’s how we usually communicate with our dog at home, right? When we tell him, “We love you, Jimmy,” he responds by wagging his tail. This doesn’t mean he knows what we are actually saying. Instead, his response is simply because he understands the language of emotions and gestures more than words.

We as humans have developed an understanding of a lot of nuances of the natural language more than any animal on this planet. That is why when we say “I LOVE you, honey” vs when we say “Lets make LOVE, honey” we mean different things. Since we understand the basic difference between the two phrases, our responses are very different. It is these very intricacies in natural language understanding that we want to teach to a machine.

What this could mean is when your future robot dog hears “I love you, Jimmy”, he would know LOVE is a Verb. He would also realize that it’s an emotion that we are expressing to which he would respond in a certain way. And maybe when you are telling your partner “Lets make LOVE”, the dog would just stay out of your business 😛.

This is just an example of how teaching a robot to communicate in a language known to us can make things easier.

The primary use case being highlighted in this example is how important it is to understand the difference in the usage of the word LOVE, in different contexts.

Part-of-Speech Tagging

From a very small age, we have been made accustomed to identifying part of speech tags. For example, reading a sentence and being able to identify what words act as nouns, pronouns, verbs, adverbs, and so on. All these are referred to as the part of speech tags.

Let’s look at the Wikipedia definition for them:

In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging or word-category disambiguation, is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context — i.e., its relationship with adjacent and related words in a phrase, sentence, or paragraph. A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.

Identifying part of speech tags is much more complicated than simply mapping words to their part of speech tags. This is because POS tagging is not something that is generic. It is quite possible for a single word to have a different part of speech tag in different sentences based on different contexts. That is why it is impossible to have a generic mapping for POS tags.

As you can see, it is not possible to manually find out different part-of-speech tags for a given corpus. New types of contexts and new words keep coming up in dictionaries in various languages, and manual POS tagging is not scalable in itself. That is why we rely on machine-based POS tagging.

Before proceeding further and looking at how part-of-speech tagging is done, we should look at why POS tagging is necessary and where it can be used.

Why Part-of-Speech tagging?

Part-of-Speech tagging in itself may not be the solution to any particular NLP problem. It is however something that is done as a pre-requisite to simplify a lot of different problems. Let us consider a few applications of POS tagging in various NLP tasks.

Text to Speech Conversion

Let us look at the following sentence:

They refuse to permit us to obtain the refuse permit.

The word refuse is being used twice in this sentence and has two different meanings here. refUSE (/rəˈfyo͞oz/)is a verb meaning “deny,” while REFuse(/ˈrefˌyo͞os/) is a noun meaning “trash” (that is, they are not homophones). Thus, we need to know which word is being used in order to pronounce the text correctly. (For this reason, text-to-speech systems usually perform POS-tagging.)

Have a look at the part-of-speech tags generated for this very sentence by the NLTK package.

>>> text = word_tokenize(""They refuse to permit us to obtain the refuse permit"")

>>> nltk.pos_tag(text)

[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'),

('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]

As we can see from the results provided by the NLTK package, POS tags for both refUSE and REFuse are different. Using these two different POS tags for our text to speech converter can come up with a different set of sounds.

Similarly, let us look at yet another classical application of POS tagging: word sense disambiguation.

Word Sense Disambiguation

Let’s talk about this kid called Peter. Since his mother is a neurological scientist, she didn’t send him to school. His life was devoid of science and math.

One day she conducted an experiment, and made him sit for a math class. Even though he didn’t have any prior subject knowledge, Peter thought he aced his first test. His mother then took an example from the test and published it as below. (Kudos to her!)

Word-sense Disambiguation example — My son Peter’s first Maths problem.

Words often occur in different senses as different parts of speech. For example:

She saw a bear.

Your efforts will bear fruit.

The word bear in the above sentences has completely different senses, but more importantly one is a noun and other is a verb. Rudimentary word sense disambiguation is possible if you can tag words with their POS tags.

Word-sense disambiguation (WSD) is identifying which sense of a word (that is, which meaning) is used in a sentence, when the word has multiple meanings.

Try to think of the multiple meanings for this sentence:

Time flies like an arrow

Here are the various interpretations of the given sentence. The meaning and hence the part-of-speech might vary for each word.

Part-of-speech tags define the meaning of a sentence based on the context

As we can clearly see, there are multiple interpretations possible for the given sentence. Different interpretations yield different kinds of part of speech tags for the words.This information, if available to us, can help us find out the exact version / interpretation of the sentence and then we can proceed from there.

The above example shows us that a single sentence can have three different POS tag sequences assigned to it that are equally likely. That means that it is very important to know what specific meaning is being conveyed by the given sentence whenever it’s appearing. This is word sense disambiguation, as we are trying to find out THE sequence.

These are just two of the numerous applications where we would require POS tagging. There are other applications as well which require POS tagging, like Question Answering, Speech Recognition, Machine Translation, and so on.

Now that we have a basic knowledge of different applications of POS tagging, let us look at how we can go about actually assigning POS tags to all the words in our corpus.

Types of POS taggers

POS-tagging algorithms fall into two distinctive groups:

Rule-Based POS Taggers

Stochastic POS Taggers

E. Brill’s tagger, one of the first and most widely used English POS-taggers, employs rule-based algorithms. Let us first look at a very brief overview of what rule-based tagging is all about.

Rule-Based Tagging

Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods.

Typical rule-based approaches use contextual information to assign tags to unknown or ambiguous words. Disambiguation is done by analyzing the linguistic features of the word, its preceding word, its following word, and other aspects.

For example, if the preceding word is an article, then the word in question must be a noun. This information is coded in the form of rules.

Example of a rule:

If an ambiguous/unknown word X is preceded by a determiner and followed by a noun, tag it as an adjective.

Defining a set of rules manually is an extremely cumbersome process and is not scalable at all. So we need some automatic way of doing this.

The Brill’s tagger is a rule-based tagger that goes through the training data and finds out the set of tagging rules that best define the data and minimize POS tagging errors. The most important point to note here about Brill’s tagger is that the rules are not hand-crafted, but are instead found out using the corpus provided. The only feature engineering required is a set of rule templates that the model can use to come up with new features.

Let’s move ahead now and look at Stochastic POS tagging.

Stochastic Part-of-Speech Tagging

The term ‘stochastic tagger’ can refer to any number of different approaches to the problem of POS tagging. Any model which somehow incorporates frequency or probability may be properly labelled stochastic.

The simplest stochastic taggers disambiguate words based solely on the probability that a word occurs with a particular tag. In other words, the tag encountered most frequently in the training set with the word is the one assigned to an ambiguous instance of that word. The problem with this approach is that while it may yield a valid tag for a given word, it can also yield inadmissible sequences of tags.

An alternative to the word frequency approach is to calculate the probability of a given sequence of tags occurring. This is sometimes referred to as the n-gram approach, referring to the fact that the best tag for a given word is determined by the probability that it occurs with the n previous tags. This approach makes much more sense than the one defined before, because it considers the tags for individual words based on context.

The next level of complexity that can be introduced into a stochastic tagger combines the previous two approaches, using both tag sequence probabilities and word frequency measurements. This is known as the Hidden Markov Model (HMM).

Before proceeding with what is a Hidden Markov Model, let us first look at what is a Markov Model. That will better help understand the meaning of the term Hidden in HMMs.

Markov Model

Say that there are only three kinds of weather conditions, namely

Rainy

Sunny

Cloudy

Now, since our young friend we introduced above, Peter, is a small kid, he loves to play outside. He loves it when the weather is sunny, because all his friends come out to play in the sunny conditions.

He hates the rainy weather for obvious reasons.

Every day, his mother observe the weather in the morning (that is when he usually goes out to play) and like always, Peter comes up to her right after getting up and asks her to tell him what the weather is going to be like. Since she is a responsible parent, she want to answer that question as accurately as possible. But the only thing she has is a set of observations taken over multiple days as to how weather has been.

How does she make a prediction of the weather for today based on what the weather has been for the past N days?

Say you have a sequence. Something like this:

Sunny, Rainy, Cloudy, Cloudy, Sunny, Sunny, Sunny, Rainy

So, the weather for any give day can be in any of the three states.

Let’s say we decide to use a Markov Chain Model to solve this problem. Now using the data that we have, we can construct the following state diagram with the labelled probabilities.",https://cdn-images-1.medium.com/max/1200/1*f6e0uf5PX17pTceYU4rbCA.jpeg,[],https://medium.freecodecamp.org/an-introduction-to-part-of-speech-tagging-and-the-hidden-markov-model-953d45338f24?source=collection_home---6------3----------------,2018-06-08 19:31:14.123000+00:00

Data Analysis,A deep dive into part-of-speech tagging using the Viterbi algorithm,['Sachin Malhotra'],"Welcome back, Caretaker!

In case you’ve forgotten the problem we were trying to tackle in the previous article, let us revise it for you.

So there’s this naughty kid Peter and he’s going to pester his new caretaker, you!

As a caretaker, one of the most important tasks for you is to tuck Peter in bed and make sure he is sound asleep. Once you’ve tucked him in, you want to make sure that he’s actually asleep and not up to some mischief.

You cannot, however, enter the room again, as that would surely wake Peter up. All you can hear are the noises that might come from the room.

Either the room is quiet or there is noise coming from the room. These are your states.

All you have as the caretaker are:

a set of observations, which is basically a sequence containing noise or quiet over time, and

or over time, and A state diagram provided by Peter’s mom — who happens to be a neurological scientist — that contains all the different sets of probabilities that you can use to solve the problem defined below.

The problem

Given the state diagram and a sequence of N observations over time, we need to tell the state of the baby at the current point in time. Mathematically, we have N observations over times t0, t1, t2 .... tN . We want to find out if Peter would be awake or asleep, or rather which state is more probable at time tN+1 .

In case any of this seems like Greek to you, go read the previous article to brush up on the Markov Chain Model, Hidden Markov Models, and Part of Speech Tagging.

The state diagram that Peter’s mom gave you before leaving.

In that previous article, we had briefly modeled the problem of Part of Speech tagging using the Hidden Markov Model.

The problem of Peter being asleep or not is just an example problem taken up for a better understanding of some of the core concepts involved in these two articles. At the core, the articles deal with solving the Part of Speech tagging problem using the Hidden Markov Models.

So, before moving on to the Viterbi Algorithm, let’s first look at a much more detailed explanation of how the tagging problem can be modeled using HMMs.

Generative Models and the Noisy Channel Model

A lot of problems in Natural Language Processing are solved using a supervised learning approach.

Supervised problems in machine learning are defined as follows. We assume training examples (x(1), y(1)) . . . (x(m) , y(m)) , where each example consists of an input x(i) paired with a label y(i) . We use X to refer to the set of possible inputs, and Y to refer to the set of possible labels. Our task is to learn a function f : X → Y that maps any input x to a label f(x).

In tagging problems, each x(i) would be a sequence of words X1 X2 X3 …. Xn(i) , and each y(i) would be a sequence of tags Y1 Y2 Y3 … Yn(i) (we use n(i)to refer to the length of the i’th training example). X would refer to the set of all sequences x1 . . . xn, and Y would be the set of all tag sequences y1 . . . yn. Our task would be to learn a function f : X → Y that maps sentences to tag sequences.

An intuitive approach to get an estimate for this problem is to use conditional probabilities. p(y | x) which is the probability of the output y given an input x. The parameters of the model would be estimated using the training samples. Finally, given an unknown input x we would like to find

f(x) = arg max(p(y | x)) ∀y ∊ Y

This here is the conditional model to solve this generic problem given the training data. Another approach that is mostly adopted in machine learning and natural language processing is to use a generative model.

Rather than directly estimating the conditional distribution p(y|x) , in generative models we instead model the joint probability p(x, y) over all the (x, y) pairs.

We can further decompose the joint probability into simpler values using Bayes’ rule:

p(y) is the prior probability of any input belonging to the label y.

is the prior probability of any input belonging to the label y. p(x | y) is the conditional probability of input x given the label y.

We can use this decomposition and the Bayes rule to determine the conditional probability.

Remember, we wanted to estimate the function

f(x) = arg max( p(y|x) ) ∀y ∊ Y

f(x) = arg max( p(y) * p(x | y) )

The reason we skipped the denominator here is because the probability p(x) remains the same no matter what the output label being considered. And so, from a computational perspective, it is treated as a normalization constant and is normally ignored.

Models that decompose a joint probability into terms p(y) and p(x|y) are often called noisy-channel models. Intuitively, when we see a test example x, we assume that it has been generated in two steps:

first, a label y has been chosen with probability p(y) second, the example x has been generated from the distribution p(x|y). The model p(x|y) can be interpreted as a “channel” which takes a label y as its input, and corrupts it to produce x as its output.

Generative Part of Speech Tagging Model

Let us assume a finite set of words V and a finite sequence of tags K. Then the set S will be the set of all sequence, tags pairs <x1, x2, x3 ... xn, y1, y2, y3, ..., yn> such that n > 0 ∀x ∊ V and ∀y ∊ K .

A generative tagging model is then the one where

2.

Given a generative tagging model, the function that we talked about earlier from input to output becomes

Thus for any given input sequence of words, the output is the highest probability tag sequence from the model. Having defined the generative model, we need to figure out three different things:

How exactly do we define the generative model probability p(<x1, x2, x3 ... xn, y1, y2, y3, ..., yn>) How do we estimate the parameters of the model, and How do we efficiently calculate

Let us look at how we can answer these three questions side by side, once for our example problem and then for the actual problem at hand: part of speech tagging.

Defining the Generative Model

Let us first look at how we can estimate the probability p(x1 .. xn, y1 .. yn) using the HMM.

We can have any N-gram HMM which considers events in the previous window of size N.

The formulas provided hereafter are corresponding to a Trigram Hidden Markov Model.

Trigram Hidden Markov Model

A trigram Hidden Markov Model can be defined using

A finite set of states.

A sequence of observations.

q(s|u, v)

Transition probability defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations.

defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations. e(x|s)

Emission probability defined as the probability of making an observation x given that the state was s.

Then, the generative model probability would be estimated as

As for the baby sleeping problem that we are considering, we will have only two possible states: that the baby is either awake or he is asleep. The caretaker can make only two observations over time. Either there is noise coming in from the room or the room is absolutely quiet. The sequence of observations and states can be represented as follows:

Observations and States over time for the baby sleeping problem

Coming on to the part of speech tagging problem, the states would be represented by the actual tags assigned to the words. The words would be our observations. The reason we say that the tags are our states is because in a Hidden Markov Model, the states are always hidden and all we have are the set of observations that are visible to us. Along similar lines, the sequence of states and observations for the part of speech tagging problem would be

Observations and States over time for the POS tagging problem

Estimating the model’s parameters

We will assume that we have access to some training data. The training data consists of a set of examples where each example is a sequence consisting of the observations, every observation being associated with a state. Given this data, how do we estimate the parameters of the model?

Estimating the model’s parameters is done by reading various counts off of the training corpus we have, and then computing maximum likelihood estimates:

Transition probability and Emission probability for a Trigram HMM

We already know that the first term represents transition probability and the second term represents the emission probability. Let us look at what the four different counts mean in the terms above.

c(u, v, s) represents the trigram count of states u, v and s. Meaning it represents the number of times the three states u, v and s occurred together in that order in the training corpus. c(u, v) following along similar lines as that of the trigram count, this is the bigram count of states u and v given the training corpus. c(s → x) is the number of times in the training set that the state s and observation x are paired with each other. And finally, c(s) is the prior probability of an observation being labelled as the state s.

Let us look at a sample training set for the toy problem first and see the calculations for transition and emission probabilities using the same.

The BLUE markings represent the transition probability, and RED is for emission probability calculations.

Note that since the example problem only has two distinct states and two distinct observations, and given that the training set is very small, the calculations shown below for the example problem are using a bigram HMM instead of a trigram HMM.

Peter’s mother was maintaining a record of observations and states. And thus she even provided you with a training corpus to help you get the transition and emission probabilities.

Transition Probability Example:

Training Corpus

Calculations for Awake appearing after Awake

Emission Probability Example:

Training corpus

Calculations for observing ‘Quiet’ when the state is ‘Awake’

That was quite simple, since the training set was very small. Let us look at a sample training set for our actual problem of part of speech tagging. Here we can consider a trigram HMM, and we will show the calculations accordingly.

We will use the following sentences as a corpus of training data (the notation word/TAG means word tagged with a specific part-of-speech tag).

The training set that we have is a tagged corpus of sentences. Every sentence consists of words tagged with their corresponding part of speech tags. eg:- eat/VB means that the word is “eat” and the part of speech tag in this sentence in this very context is “VB” i.e. Verb Phrase. Let us look at a sample calculation for transition probability and emission probability just like we saw for the baby sleeping problem.

Transition Probability

Let’s say we want to calculate the transition probability q(IN | VB, NN). For this, we see how many times we see a trigram (VB,NN,IN) in the training corpus in that specific order. We then divide it by the total number of times we see the bigram (VB,NN) in the corpus.

Emission Probability

Let’s say we want to find out the emission probability e(an | DT). For this, we see how many times the word “an” is tagged as “DT” in the corpus and divide it by the total number of times we see the tag “DT” in the corpus.

So if you look at these calculations, it shows that calculating the model’s parameters is not computationally expensive. That is, we don’t have to do multiple passes over the training data to calculate these parameters. All we need are a bunch of different counts, and a single pass over the training corpus should provide us with that.

Let’s move on and look at the final step that we need to look at given a generative model. That step is efficiently calculating

We will be looking at the famous Viterbi Algorithm for this calculation.

Finding the most probable sequence — Viterbi Algorithm

Finally, we are going to solve the problem of finding the most likely sequence of labels given a set of observations x1 … xn. That is, we are to find out

The probability here is expressed in terms of the transition and emission probabilities that we learned how to calculate in the previous section of the article. Just to remind you, the formula for the probability of a sequence of labels given a sequence of observations over “n” time steps is

Before looking at an optimized algorithm to solve this problem, let us first look at a simple brute force approach to this problem. Basically, we need to find out the most probable label sequence given a set of observations out of a finite set of possible sequences of labels. Let’s look at the total possible number of sequences for a small example for our example problem and also for a part of speech tagging problem.

Say we have the following set of observations for the example problem.

Noise Quiet Noise

We have two possible labels {Asleep and Awake}. Some of the possible sequence of labels for the observations above are:

Awake Awake Awake

Awake Awake Asleep

Awake Asleep Awake

Awake Asleep Asleep

In all we can have ²³ = 8 possible sequences. This might not seem like very many, but if we increase the number of observations over time, the number of sequences would increase exponentially. This is the case when we only had two possible labels. What if we have more? As is the case with part of speech tagging.

For example, consider the sentence

the dog barks

and assuming that the set of possible tags are {D, N, V}, let us look at some of the possible tag sequences:

D D D

D D N

D D V

D N D

D N N

D N V ... etc

Here, we would have ³³ = 27 possible tag sequences. And as you can see, the sentence was extremely short and the number of tags weren’t very many. In practice, we can have sentences that might be much larger than just three words. Then the number of unique labels at our disposal would also be too high to follow this enumeration approach and find the best possible tag sequence this way.

So the exponential growth in the number of sequences implies that for any reasonable length sentence, the brute force approach would not work out as it would take too much time to execute.

Instead of this brute force approach, we will see that we can find the highest probable tag sequence efficiently using a dynamic programming algorithm known as the Viterbi Algorithm.

Let us first define some terms that would be useful in defining the algorithm itself. We already know that the probability of a label sequence given a set of observations can be defined in terms of the transition probability and the emission probability. Mathematically, it is

Let us look at a truncated version of this which is

and let us call this the cost of a sequence of length k.

So the definition of “r” is simply considering the first k terms off of the definition of probability where k ∊ {1..n} and for any label sequence y1…yk.

Next we have the set S(k, u, v) which is basically the set of all label sequences of length k that end with the bigram (u, v) i.e.

Finally, we define the term π(k, u, v) which is basically the sequence with the maximum cost.

The main idea behind the Viterbi Algorithm is that we can calculate the values of the term π(k, u, v) efficiently in a recursive, memoized fashion. In order to define the algorithm recursively, let us look at the base cases for the recursion.

π(0, *, *) = 1

π(0, u, v) = 0

Since we are considering a trigram HMM, we would be considering all of the trigrams as a part of the execution of the Viterbi Algorithm.

Now, we can start the first trigram window from the first three words of the sentence but then the model would miss out on those trigrams where the first word or the first two words occurred independently. For that reason, we consider two special start symbols as * and so our sentence becomes

* * x1 x2 x3 ...... xn

And the first trigram we consider then would be (*, *, x1) and the second one would be (*, x1, x2).

Now that we have all our terms in place, we can finally look at the recursive definition of the algorithm which is basically the heart of the algorithm.",https://cdn-images-1.medium.com/max/1200/1*x-5ZBtUvlD78BOMuMnMAbg.png,[],https://medium.freecodecamp.org/a-deep-dive-into-part-of-speech-tagging-using-viterbi-algorithm-17c8de32e8bc?source=collection_home---6------4----------------,2018-06-08 19:05:31.518000+00:00

Data Analysis,A quick introduction to OAuth using Passport.js – freeCodeCamp,['Arun Kumar'],"A quick introduction to OAuth using Passport.js

What is OAuth?

OAuth (Open Authorization) is an authorization protocol. A third party application can use it to access user data from a site (like Google or Twitter) without revealing their password. Sites like Quora, Medium, AirBnb and many others offer authentication using OAuth.

OAuth really makes our lives simpler by eliminating the need to remember the password of every account you create on almost any site. You just have to remember your OAuth provider’s main account password.

What is Passport.js?

Passport is a middleware which implements authentication on Express-based web applications. It provides over 500+ strategies. What are these strategies? Strategies are used to authenticate requests. Each strategy has its own npm package (such as passport-twitter, passport-google-oauth20). A strategy must be configured before usage.

Why use Passport.js?

Here are six reasons stating why you should use Passport:

It is lightweight

Easily configurable

Supports persistent sessions

Offers OAuth

Provides separate modules for each strategy

Gives you the ability to implement custom strategies

Let’s build something

To get started, we need to install passport from NPM:

npm install passport

We are going to build a simple app which grants the user access to a secret route only if they log in. I’m going to be using the passport-google-oauth20 strategy in this tutorial. Feel free to use any other strategy you prefer, but make sure to check the docs to see how it is configured.

Before continuing, we need a clientID and clientSecret. To get one, head over to https://console.developers.google.com and create a new project. Then go to Enable APIs and Services and enable the Google+ API. Select the API and click on create credentials.

Fill out the form and use the same callback URL on both the form and on your file. Make sure to read the comments on the code to figure out how everything fits together.

app.js

index.ejs

As you can see, we’ve created a /secret route, and only grant access to it if the user is authenticated. To verify whether the user is authenticated, we’ve created a middleware which checks if the request has the user object in it. Finally, to log out we used the req.logout() method provided by passport to clear the session.

Here are some resources to learn more about passport

Complete Passport.js tutorial series

Conclusion

We only saw one strategy here. There are 500+ more. I highly recommend that you skim through Passport’s official documentation and find out what else they offer. Thank you for taking your time to read this. Feel free to connect with me on LinkedIn, Twitter and GitHub. I wish you good luck!

“Do what is great, written on a computer monitor.” by Martin Shreder on Unsplash

Previous article",https://cdn-images-1.medium.com/max/1200/0*gWsdm7w5PSZNR08L,[],https://medium.freecodecamp.org/a-quick-introduction-to-oauth-using-passport-js-65ea5b621a?source=collection_home---6------5----------------,2018-06-07 22:11:44.925000+00:00

Data Analysis,How to control your randomizer in R – freeCodeCamp,['Michelle Jones'],"What happens when you need a particular type of randomization?

Overview of random number generation in R

R has at least 20 random number generator functions. Each uses a specific probability distribution to create the numbers. All require you to specify the number of random numbers you want (the above image shows 200). All are available in base R — no packages required.

Common random number generator distributions are:

normal (rnorm): default mean of 0 and standard deviation of 1

binomial (rbinom): no defaults, specify the number of trials and the probability of success on each trial

uniform (runif): default minimum value of 0 and maximum value of 1

Of the three above, only the binomial random number generator creates integers.

Why create random numbers?

Problems involving random numbers are very common — there are around 50,000 questions relating to random numbers on Stack Exchange.

But why use them?

Random numbers have many practical applications. They are used in Monte Carlo simulations. They are used in cryptography. They have been used to produce CAPTCHA content. They are used in slot machines. They have also been used for more mundane tasks such as creating a random sort order for an array of ordered data.

Problems with random numbers

Common questions include “are my random numbers actually random?” and “how can I generate non-repeated random numbers?”

Note: the latter decreases randomness, because the population of possible random numbers is decreased by one each time a random number is drawn. The method is appropriate in situations such as lotteries or bingo, where each ticket or ball can only be drawn once.

This problem brings in another problem! The randomly generated, sampling without replacement numbers must be integers. No one has ticket 5.6932 or bingo ball 0.18967.

A practical example of random number problems

Let’s take the example that I have 20 female students of the same age. I have four teaching methods that I want to trial. I only want to trial one teaching method for each student. Easy math— I need five students in each group.

But how do I do this so that each student is randomly assigned?

And how do I make sure that I only have integers produced?

And how do I do all this while using randomly generated numbers without replacement? I don’t want, for example, six students in one group, and four students in another.

First, I need to create some dummy data, in R. Let’s create that list of mock female students.

FemaleStudents <- data.frame(Names=c(""Alice"", ""Betty"", ""Carol"", ""Denise"", ""Erica"", ""Frances"", ""Gina"", ""Helen"", ""Iris"", ""Julie"", ""Katherine"",

""Lisa"", ""Michelle"", ""Ngaire"", ""Olivia"", ""Penelope"", ""Rachel"", ""Sarah"", ""Trudy"", ""Uma""))

Now we have a one-dimensional dataset of our 20 students.

We know that the runif() function doesn’t create integers. Why don’t we round the random numbers so that we only get integers and use this function? We can wrap the random number in a rounding function.

Question 1: why am I using the random uniform distribution and not another one, such as the random normal distribution?

There are five types of rounding functions in R. We will use round() .

So that we get the same results, I will set a seed for the random number generation. Each time we generate random numbers, we will use the same seed. I’ve decided on 5 as the seed. If you do not set a seed, or if you set a seed other than 5, your results will be different than mine.

set.seed(5)

FemaleStudents$Group <- round(runif(20, 1, 5))

Well, that seemed to work. We have each student allocated to a group numbered between 1 and 5.

Let’s double check our allocation.

table(FemaleStudents$Group)

1 2 3 4 5

2 6 5 4 3

Darn. Only one of the five groups has the correct number of students (Group 4). Why did this happen?

We can check the numbers actually output by runif() without rounding, and letting the output print to the console. Here, the output prints because I have not assigned the function to an object (for example, to a data.frame variable).

set.seed(5)

runif(20,1,5)

[1] 1.800858 3.740874 4.667503 2.137598 1.418601 3.804230 3.111840 4.231741 4.826001 1.441812 2.093140 2.962053 2.273616 3.236691 2.050373

[16] 1.807501 2.550103 4.551479 3.219690 4.368718

As we can see, the rounding caused our problem. But if we hadn’t rounded, each student would have been assigned to a different group.

What do we do?

sample()

sample() is now one of my favourite functions in R. Let’s see how it works.

Randomly allocate to equally sized groups (counts matter)

How can we use it to randomly assign our 20 students to four equally sized groups?

What happens if we try sample() normally?

set.seed(5)

FemaleStudents$Sample <- sample(1:5, nrow(FemaleStudents), replace=TRUE)

Question 2: what output did you get when you used table(FemaleStudents$Sample) ?

We can fix this problem by creating a vector of group numbers, and then using sampling without replacement from this vector. The rep command is used to create a range of repeated values. You can use it to repeat each number in the series, as I have used here. Number 1 is repeated four times, then number 2 is repeated four times, and so forth. You can also use it to repeat a sequence of numbers, if you use this code instead: rep(1:5,4)

OurGroups <- rep(1:5, each=4)

set.seed(5)

FemaleStudents$Sample <- sample(OurGroups, nrow(FemaleStudents), replace=FALSE)

We used our vector of numbers ( OurGroups ) to allocate our students to groups. We used sampling without replacement ( replace=FALSE ) from OurGroups because we need to use each value in that vector. We need to remove each value as we use it.

And we get the result we wanted!

table(FemaleStudents$Sample)

1 2 3 4 5

4 4 4 4 4

Question 3: why did I still set a seed?

Another advantage of sample() is that it doesn’t care about type. We can repeat the allocation using a vector of strings. This can be useful if you don’t want to keep referring back to what “1” means.

OurNamedGroups <- rep(c(""Up"", ""Down"", ""Charmed"", ""Strange"", ""Top""), each=4)

set.seed(5)

FemaleStudents$Sample2 <- sample(OurNamedGroups, nrow(FemaleStudents), replace=FALSE)

table(FemaleStudents$Sample2)

Charmed Down Strange Top Up

4 4 4 4 4

Because we used the same seed, we can see that the same student allocation was performed, irrespective of whether we used numeric or character data for the assignment.

table(FemaleStudents$Sample,FemaleStudents$Sample2)



Charmed Down Strange Top Up

1 0 0 0 0 4

2 0 4 0 0 0

3 4 0 0 0 0

4 0 0 4 0 0

5 0 0 0 4 0

Randomly allocate when group size is not restricted

Sometimes we want to randomly allocate to groups, but we don’t have a vector of groups. We are still only allocating each unit (person, sheep, block of cheese) to a single group, and we use completely random allocation.

Let’s say that our school has a new, special library room. It’s been constructed to be soundproof to give students a better studying environment. The chief librarian would like to know about the experiences of students in that room. The only problem is that the room is limited in size. The chief librarian thinks that around four students is a large enough group to provide the initial feedback.

Again, we can use sample() to pick our student groups. In this case, we have “students who will test the room” and “students who won’t test the room”. I’m going to call them “Test” and “Not test”. These labels have been chosen for being 1. short and 2. easily distinguished.

Because we did sampling without replacement earlier, we didn’t specify probabilities of assignment to groups — we simply pulled out an assignment from a vector. Now we are going to use sampling with replacement. With replacement refers to the group, not to the students.

We need to sample with replacement as we only have two groups (“Test”, “Not test”) and 20 students. If we tried to sample without replacement, our code would error.

Our code is very similar:

set.seed(5)

FemaleStudents$Library <- sample(c(""Test"", ""Not test""), nrow(FemaleStudents), replace=TRUE, prob=c(4/20,16/20))

table(FemaleStudents$Library)

Not test Test

15 5

As you can see, we allocated five students to test the room, not four. This type of result is expected when dealing with small samples. However, our allocation of students is completely random. Each student had exactly the same probability of being assigned to test the room. Whether previous students were testers or not had no impact on the allocation of the next student.

Let’s walk through some of that code.

I’ve constructed a new variable in the data.frame to collect the allocation ( Library ).

Instead of dealing with numbers for group names, I’ve used the strings I mentioned earlier. Because I’ve used strings, the c() must wrap the group names ( “Test”, “Not test” ) and each group name is separated by a comma.

Replacement has been set to TRUE .

The probability of assignment to either group must be provided. This is the prob=c(4/20,16/20) part of the sample() function. Again, note how c() is used to contain the probabilities. Also of interest is that the probabilities can be expressed as fractions, rather than decimals.

Hooray for sample()

I use sample() all the time for the work I am doing. The ability to use strings, as well as to restrict numeric output to integers (and define the desired integer range), provides me with more control than trying to use one of the random number functions.

Answers

Answer 1: I used a random uniform distribution because I wanted each value to be equally probable.

Answer 2: I got this output:

1 2 3 4 5

2 7 4 2 5

Answer 3: If we don’t set a seed value, or we use a different one, the allocation of specific students will be different. For example, when the seed is 5, Alice is allocated to group 2. If the seed is 7, Alice is allocated to group 5. Replication is important when code needs to be re-run (for example, in testing).",https://cdn-images-1.medium.com/max/1200/1*aI6mpoboOmJMKqvEU593xA.png,[],https://medium.freecodecamp.org/how-to-control-your-randomizer-in-r-852ae7d8f80c?source=collection_home---6------6----------------,2018-06-07 20:10:57.677000+00:00

Data Analysis,How to style your webpage or markdown like a Medium article — or however you want,[],"View the respective pages at: https://github.com/ryandav/link-formatter/ and https://ryandav.github.io/link-formatter/

Get started with Sass at https://sass-lang.com/guide",https://cdn-images-1.medium.com/max/1200/1*L8PQs8ubyxZVIr1EC-cZ6Q.png,[],https://medium.freecodecamp.org/style-webpage-or-markdown-like-medium-article-using-html-css-sass-bootstrap-c6f9e64c0955?source=collection_home---6------7----------------,2018-06-07 19:32:27.295000+00:00

Data Analysis,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------,2018-06-07 17:57:40.375000+00:00

Data Analysis,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------,2018-06-06 21:43:33.288000+00:00

Data Analysis,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------#--responses,2018-06-06 21:43:33.288000+00:00

Data Analysis,Follow these steps to solve any Dynamic Programming interview problem,['Nikola Otasevic'],"Follow these steps to solve any Dynamic Programming interview problem

Despite having significant experience building software products, many engineers feel jittery at the thought of going through a coding interview that focuses on algorithms. I’ve interviewed hundreds of engineers at Refdash, Google, and at startups I’ve been a part of, and some of the most common questions that make engineers uneasy are the ones that involve Dynamic Programming (DP).

Many tech companies like to ask DP questions in their interviews. While we can debate whether they’re effective in evaluating someone’s ability to perform in an engineering role, DP continues to be an area that trips engineers up on their way to finding a job that they love.

Dynamic Programming — Predictable and Preparable

One of the reasons why I personally believe that DP questions might not be the best way to test engineering ability is that they’re predictable and easy to pattern match. They allow us to filter much more for preparedness as opposed to engineering ability.

These questions typically seem pretty complex on the outside, and might give you an impression that a person who solves them is very good at algorithms. Similarly, people who may not be able to get over some mind-twisting concepts of DP might seem pretty weak in their knowledge of algorithms.

The reality is different, and the biggest factor in their performance is preparedness. So let’s make sure everyone is prepared for it. Once and for all.

7 Steps to solve a Dynamic Programming problem

In the rest of this post, I will go over a recipe that you can follow to figure out if a problem is a “DP problem”, as well as to figure out a solution to such a problem. Specifically, I will go through the following steps:

How to recognize a DP problem Identify problem variables Clearly express the recurrence relation Identify the base cases Decide if you want to implement it iteratively or recursively Add memoization Determine time complexity

Sample DP Problem

For the purpose of having an example for abstractions that I am going to make, let me introduce a sample problem. In each of the sections, I will refer to the problem, but you could also read the sections independently of the problem.

Problem statement:

In this problem, we’re on a crazy jumping ball, trying to stop, while avoiding spikes along the way.

Here are the rules:

1) You’re given a flat runway with a bunch of spikes in it. The runway is represented by a boolean array which indicates if a particular (discrete) spot is clear of spikes. It is True for clear and False for not clear.

Example array representation:

2) You’re given a starting speed S. S is a non-negative integer at any given point, and it indicates how much you will move forward with the next jump.

3) Every time you land on a spot, you can adjust your speed by up to 1 unit before the next jump.

4) You want to safely stop anywhere along the runway (does not need to be at the end of the array). You stop when your speed becomes 0. However, if you land on a spike at any point, your crazy bouncing ball bursts and it’s game over.

The output of your function should be a boolean indicating whether we can safely stop anywhere along the runway.

Step 1: How to recognize a Dynamic Programming problem

First, let’s make it clear that DP is essentially just an optimization technique. DP is a method for solving problems by breaking them down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions. The next time the same subproblem occurs, instead of recomputing its solution, you simply look up the previously computed solution. This saves computation time at the expense of a (hopefully) modest expenditure in storage space.

Recognizing that a problem can be solved using DP is the first and often the most difficult step in solving it. What you want to ask yourself is whether your problem solution can be expressed as a function of solutions to similar smaller problems.

In the case of our example problem, given a point on the runway, a speed, and the runway ahead, we could determine the spots where we could potentially jump next. Furthermore, it seems that whether we can stop from the current point with the current speed depends only on whether we could stop from the point we choose to go to next.

That is a great thing, because by moving forward, we shorten the runway ahead and make our problem smaller. We should be able to repeat this process all the way until we get to a point where it is obvious whether we can stop.

Recognizing a Dynamic Programming problem is often the most difficult step in solving it. Can the problem solution be expressed as a function of solutions to similar smaller problems?

Step 2: Identify problem variables

Now we have established that there is some recursive structure between our subproblems. Next, we need to express the problem in terms of the function parameters and see which of those parameters are changing.

Typically in interviews, you will have one or two changing parameters, but technically this could be any number. A classic example of a one-changing-parameter problem is “determine an n-th Fibonacci number”. Such an example for a two-changing-parameters problem is “Compute edit distance between strings”. If you’re not familiar with these problems, don’t worry about it.

A way to determine the number of changing parameters is to list examples of several subproblems and compare the parameters. Counting the number of changing parameters is valuable to determine the number of subproblems we have to solve. It’s also important in its own right in helping us strengthen the understanding of the recurrence relation from step 1.

In our example, the two parameters that could change for every subproblem are:

Array position (P) Speed (S)

One could say that the runway ahead is changing as well, but that would be redundant considering that the entire non-changing runway and the position (P) carry that information already.

Now, with these 2 changing parameters and other static parameters, we have the complete description of our sub-problems.

Identify the changing parameters and determine the number of subproblems.

Step 3: Clearly express the recurrence relation

This is an important step that many rush through in order to get into coding. Expressing the recurrence relation as clearly as possible will strengthen your problem understanding and make everything else significantly easier.

Once you figure out that the recurrence relation exists and you specify the problems in terms of parameters, this should come as a natural step. How do problems relate to each other? In other words, let’s assume that you have computed the subproblems. How would you compute the main problem?

Here is how we think about it in our sample problem:

Because you can adjust your speed by up to 1 before jumping to the next position, there are only 3 possible speeds, and therefore 3 spots in which we could be next.

More formally, if our speed is S, position P, we could go from (S, P) to:

(S, P + S); # if we do not change the speed (S — 1, P + S — 1); # if we change the speed by -1 (S + 1, P + S + 1); # if we change the speed by +1

If we can find a way to stop in any of the subproblems above, then we can also stop from (S, P). This is because we can transition from (S, P) to any of the above three options.

This is typically a fine level of understanding of the problem (plain English explanation), but you sometimes might want to express the relation mathematically as well. Let’s call a function that we’re trying to compute canStop. Then:

canStop(S, P) = canStop(S, P + S) || canStop(S — 1, P + S — 1) || canStop(S + 1, P + S + 1)

Woohoo, it seems like we have our recurrence relation!

Recurrence relation: Assuming you have computed the subproblems, how would you compute the main problem?

Step 4: Identify the base cases

A base case is a subproblem that doesn’t depend on any other subproblem. In order to find such subproblems, you typically want to try a few examples, see how your problem simplifies into smaller subproblems, and identify at what point it cannot be simplified further.

The reason a problem cannot be simplified further is that one of the parameters would become a value that is not possible given the constraints of the problem.

In our example problem, we have two changing parameters, S and P. Let’s think about what possible values of S and P might not be legal:

P should be within the bounds of the given runway P cannot be such that runway[P] is false because that would mean that we’re standing on a spike S cannot be negative, and a S==0 indicates that we’re done

Sometimes it can be a little challenging to convert assertions that we make about parameters into programmable base cases. This is because, in addition to listing the assertions if you want to make your code look concise and not check for unnecessary conditions, you also need to think about which of these conditions are even possible.

In our example:

P < 0 || P >= length of runway seems like the right thing to do. An alternative could be to consider making P == end of runway a base case. However, it is possible that a problem splits into a subproblem which goes beyond the end of the runway, so we really need to check for inequality. This seems pretty obvious. We can simply check if runway[P] is false. Similar to #1, we could simply check for S < 0 and S == 0. However, here we can reason that it is impossible for S to be < 0 because S decreases by at most 1, so it would have to go through S == 0 case beforehand. Therefore S == 0 is a sufficient base case for the S parameter.

Step 5: Decide if you want to implement it iteratively or recursively

The way we talked about the steps so far might lead you to think that we should implement the problem recursively. However, everything that we’ve talked about so far is completely agnostic to whether you decide to implement the problem recursively or iteratively. In both approaches, you would have to determine the recurrence relation and the base cases.

To decide whether to go iteratively or recursively, you want to carefully think about the trade-offs.

Stack overflow issues are typically a deal breaker and a reason why you would not want to have recursion in a (backend) production system. However, for the purposes of the interview, as long as you mention the trade-offs, you should typically be fine with either of the implementations. You should feel comfortable implementing both.

In our particular problem, I implemented both versions. Here is python code for that:

A recursive solution: (original code snippets can be found here)

An iterative solution: (original code snippets can be found here)

Step 6: Add memoization

Memoization is a technique that is closely associated with DP. It is used for storing the results of expensive function calls and returning the cached result when the same inputs occur again.

Why are we adding memoization to our recursion? We encounter the same subproblems which, without memoization, are computed repeatedly. Those repetitions very often lead to exponential time complexities.

In recursive solutions, adding memoization should feel straightforward. Let’s see why. Remember that memoization is just a cache of the function results. There are times when you want to deviate from this definition in order to squeeze out some minor optimizations, but treating memoization as a function result cache is the most intuitive way to implement it.

This means that you should:

Store your function result into your memory before every return statement Look up the memory for the function result before you start doing any other computation

Here is the code from above with added memoization (added lines are highlighted): (original code snippets can be found here)

In order to illustrate the effectiveness of memoization and different approaches, let’s do some quick tests. I will stress test all three methods that we have seen so far. Here is the set up:

I created a runway of length 1000 with spikes in random places (I chose to have a probability of a spike being in any given spot to be 20%) initSpeed = 30 I ran all functions 10 times and measured the average time of execution

Here are the results (in seconds):

You can see that the pure recursive approach takes about 500x more time than the iterative approach and about 1300x more time than the recursive approach with memoization. Note that this discrepancy would grow rapidly with the length of the runway. I encourage you to try running it yourself.

Step 7: Determine Time complexity

There are some simple rules that can make computing time complexity of a dynamic programming problem much easier. Here are two steps that you need to do:

Count the number of states — this will depend on the number of changing parameters in your problem Think about the work done per each state. In other words, if everything else but one state has been computed, how much work do you have to do to compute that last state?

In our example problem, the number of states is |P| * |S|, where

P is the set of all positions (|P| indicates the number of elements in P)

S is the set of all speeds

The work done per each state is O(1) in this problem because, given all other states, we simply have to look at 3 subproblems to determine the resulting state.

As we noted in the code before, |S| is limited by length of the runway (|P|), so we could say that the number of states is |P|² and because work done per each state is O(1), then the total time complexity is O(|P|²).

However, it seems that |S| can be further limited, because if it were really |P|, it is very clear that stopping would not be possible because you would have to jump the length of the entire runway on the first move.

So let’s see how we can put a tighter bound on |S|. Let’s call maximum speed S. Assume that we’re starting from position 0. How quickly could we stop if we were trying to stop as soon as possible and if we ignore potential spikes?

In the first iteration, we would have to come at least to the point (S-1), by adjusting our speed at zero by -1. From there we would at a minimum go by (S-2) steps forward, and so on.

For a runway of length L, the following has to hold:

=> (S-1) + (S-2) + (S-3) + ….+ 1 < L

=> S*(S-1) / 2 < L

=> S < sqrt(2L + 1)

That is the maximum speed that we could possibly have on a runway of a length L. If we had a speed higher than that, we could not stop even theoretically, irrespective of the position of the spikes.

That means that the total time complexity depends only on the length of the runway L in the following form:

O(L * sqrt(L)) which is better than O(L²)

O(L * sqrt(L)) is the upper bound on the time complexity

Awesome, you made it through! :)

The 7 steps that we went through should give you a framework for systematically solving any dynamic programming problem. I highly recommend practicing this approach on a few more problems to perfect your approach.

Here are some next steps that you can take

Extend the sample problem by trying to find a path to a stopping point. We solved a problem that tells you whether you can stop, but what if you wanted to also know the steps to take in order to stop eventually along the runway? How would you modify the existing implementation to do that? If you want to solidify your understanding of memoization, and understand that it is just a function result cache, you should read about decorators in Python or similar concepts in other languages. Think about how they would allow you to implement memoization in general for any function that you want to memoize. Work on more DP problems by following the steps we went through. You can always find a bunch of them online (ex. LeetCode or GeeksForGeeks). As you practice, keep in mind one thing: learn ideas, don’t learn problems. The number of ideas is significantly smaller and it’s an easier space to conquer which will also serve you much better.

When you feel like you’ve conquered these ideas, check out Refdash where you are interviewed by a senior engineer and get a detailed feedback on your coding, algorithms, and system design.",https://cdn-images-1.medium.com/max/1200/0*DpsbrfUM89M_LHKY.jpg,[],https://medium.freecodecamp.org/follow-these-steps-to-solve-any-dynamic-programming-interview-problem-cc98e508cd0e?source=collection_home---6------11----------------,2018-06-06 19:32:36.335000+00:00

Data Analysis,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------,2018-06-06 17:23:02.015000+00:00

Data Analysis,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------#--responses,2018-06-06 17:23:02.015000+00:00

Data Analysis,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------,2018-06-06 16:42:46.938000+00:00

Data Analysis,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------#--responses,2018-06-06 16:42:46.938000+00:00

Data Analysis,How to process textual data using TF-IDF in Python – freeCodeCamp,[],"How to process textual data using TF-IDF in Python

Computers are good with numbers, but not that much with textual data. One of the most widely used techniques to process textual data is TF-IDF. In this article, we will learn how it works and what are its features.

From our intuition, we think that the words which appear more often should have a greater weight in textual data analysis, but that’s not always the case. Words such as “the”, “will”, and “you” — called stopwords — appear the most in a corpus of text, but are of very little significance. Instead, the words which are rare are the ones that actually help in distinguishing between the data, and carry more weight.

An introduction to TF-IDF

TF-IDF stands for “Term Frequenct — Inverse Data Frequency”. First, we will learn what this term means mathematically.

Term Frequency (tf): gives us the frequency of the word in each document in the corpus. It is the ratio of number of times the word appears in a document compared to the total number of words in that document. It increases as the number of occurrences of that word within the document increases. Each document has its own tf.

Inverse Data Frequency (idf): used to calculate the weight of rare words across all documents in the corpus. The words that occur rarely in the corpus have a high IDF score. It is given by the equation below.

Combining these two we come up with the TF-IDF score (w) for a word in a document in the corpus. It is the product of tf and idf:

Let’s take an example to get a clearer understanding.

Sentence 1 : The car is driven on the road.

Sentence 2: The truck is driven on the highway.

In this example, each sentence is a separate document.

We will now calculate the TF-IDF for the above two documents, which represent our corpus.

From the above table, we can see that TF-IDF of common words was zero, which shows they are not significant. On the other hand, the TF-IDF of “car” , “truck”, “road”, and “highway” are non-zero. These words have more significance.

Using Python to calculate TF-IDF

Lets now code TF-IDF in Python from scratch. After that, we will see how we can use sklearn to automate the process.",https://cdn-images-1.medium.com/max/1200/1*JTk6iVMiZCQCr8duiaKlHQ.png,[],https://medium.freecodecamp.org/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3?source=collection_home---6------15----------------,2018-06-06 16:07:18.115000+00:00

Data Analysis,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------,2018-06-06 01:10:32.658000+00:00

Data Analysis,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------#--responses,2018-06-06 01:10:32.658000+00:00

Data Analysis,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------,2018-06-06 00:59:12.072000+00:00

Data Analysis,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------#--responses,2018-06-06 00:59:12.072000+00:00

Data Analysis,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------,2018-06-06 00:20:56.870000+00:00

Data Analysis,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------#--responses,2018-06-06 00:20:56.870000+00:00

Data Analysis,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------,2018-06-05 20:08:25.488000+00:00

Data Analysis,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------#--responses,2018-06-05 20:08:25.488000+00:00

Data Analysis,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------,2018-06-05 16:44:13.144000+00:00

Data Analysis,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------#--responses,2018-06-05 16:44:13.144000+00:00

Data Analysis,A deeply detailed but never definitive guide to mobile development architecture,['Jose Berardo Cunha'],"A deeply detailed but never definitive guide to mobile development architecture

Native, Web, PWA, hybrid, Cross-Compiled… what is “the best” way to develop for Android and iOS platforms? What looks reasonable? And how are you supposed to choose among the options? In this article, I’ll lay it all out so you can make an informed decision.

First things first, let me provide you with a bit of context. I am an IT senior consultant, and the idea of putting together this guide was born from discussions with one of our clients about what could be the best approach for them. Yes, just for them. And we realized that we did not have a well-defined strategy, a solid and reliable foundation, to help us come up with the right answer.

And you know what? I could not find such a guide easily anywhere on the Internet, either. Although there are several articles about this topic, none of those I came across were reasonably complete. Unfortunately the majority overlook a lot of concepts or, even worse, are essentially wrong.

Now, I’d like to take a wider look. And while I’m potentially helping someone make their own decisions, I’m also asking around the community for more thoughts on the subject.

This guide has two parts:

Mobile Development Architectural Tiers (this) How to make your decision

It's also available on YouTube as a series of 10 videos and as a free course on Udemy. There, you’ll find the same written material as here, the same videos from the YouTube series, as well as quizzes to fix all the topics and a final certification.

So let’s get started.

Introduction

When it comes to mobile platforms, it's arguable that there are just two big players: Android and iOS. Other technologies like Tizen, Blackberry, or Windows Phone are either dead or have been around for a while and have no prospects of reaching any significative market share.

A quick look at this massive duopoly might make you think that developers do not have many options when creating mobile apps. This idea can't be further from the truth, though. You can quickly spot a fistful of programming languages being used out there: C/C++, Java, Kotlin, Objective-C, Swift, JavaScript, TypeScript, C#, Dart, Ruby, and I'm pretty sure I’ve missed a few more.

The same is true of mobile development frameworks. Unless you are not a developer, or have somehow been unaware of new technologies for the last 10 years, you’ve probably heard about Cordova/PhoneGap, React Native, Xamarin, Ionic, Nativescript, or Flutter, just to name a few cross-platform solutions for mobile apps.

So let’s look at all these pieces of the architecture and break things down a bit.

TL;DR

There's no clear winner. All approaches have pros and cons, and might be either the best fit or the worst fit for your next project. In this guide, I'm classifying many different solutions into various tiers according to the distance their architectures are from the native platform.

Native Apps

To start, let's go straight to the metal. Our first architectural tier is Native Apps.

Native Apps Tier — Where you develop for each specific platform (it might be even more specific when considering NDK)

This is the tier where you must be aware of the idiosyncrasies of each platform. It’s not my intention to dig into them, I just want to mention a few things in a bit of context.

You can watch this first part on Youtube.

iOS

Starting on the iOS side, just because it's simpler, there's only Apple ruling the world. Originally, developers needed to learn Objective-C, a proprietary object-oriented variation of C with some inspiration from SmallTalk (and an insanely long-named API).

In 2014, Apple announced Swift, a multi-paradigm language, which was a lot easier than its predecessor. It's still possible to deal with Objective-C legacy code, but Swift has reached high maturity levels. So, if you're planning to learn how to natively develop for iOS, Swift is definitely where you should start.

Android

On the Android side, there are a number of different manufacturers. The vast majority of them rely upon ARM processors. But generally speaking, Android apps lay on virtual machine instances (instances of ART) to help deal with potential underlying specificities (not without many amazing tricks).

That's why, originally, the language of choice was Java. It’s not only been the most popular language in the World for almost two decades (with a few position swaps with C), but it’s also notable for its Java Virtual Machine (JVM). This empowered developers to compile their code down to an intermediate bytecode that could be read and run by the JVM.

With the Android Native Development Kit (NDK), it's also possible to develop critical parts of the app directly in native code, writing in C/C++. In this case, you have to be aware of underlying platform quirks.

Kotlin is a language unveiled by JetBrains in 2011. When it first came out, despite its flexibility and conciseness, it wasn't more than yet another JVM language with more successful competitors like Scala, Clojure, or Groovy. However, after its first major release in 2016, it rapidly started to stand out from the crowd, especially after Google announced that it would be officially supported on the Android platform at Google I/O 2017.

Kotlin is becoming Google's first class language (currently Kotlin and Java — in this order — are used throughout Android's official documentation). A total Java replacement is expected even more so now that the US Federal Appeals Court has ruled on the endless lawsuit filed by Oracle accusing Google of violating Java copyrights.

Native components

Developing in this tier, you can also leverage all native APIs and, in particular, the native components. This saves your app from having to reinvent the wheel.

I've published a video demo of how to create a simple project on Xcode (iOS) and Android Studio. If you want to check it out:

Demo of iOS and Android basic projects.

Native Apps advantages

Best performance and top user engagement

Bleeding edge native features

Notably good IDEs Android Studio / Xcode

Modern high-level languages Kotlin / Swift

Very low-level approach with NDK

Native Apps disadvantages

Two codebases to maintain

Require installation (except Android Instant Apps)

Hard to analyze SEO

Very expensive to get users to download the app

Web Apps

On the other side of the spectrum, we have Web Apps. Web Apps are essentially apps run by the browser. You don't write code targeting the platform, but rather any browser running on top of it.

Web Apps Tier — clearly on top of a browser bar targeting a beast sitting in between Android and iOS.

In this tier you’ll find an insane number of contenders jumping at each other's throats. But they all use an arsenal consisting of the same weapons: HTML, CSS, and Javascript.

Web frameworks and libraries, even when leveraging CSS pre-compilers like LESS or SASS, even Javascript pre-compiled languages like TypeScript, CoffeeScript or Flow, even symbiosis like JSX or Elm, leaving alone tools like Babel used to transpile everything to Javascript with different configurable levels of conformance with ECMAScript yearly specifications (ES6 / ES7 / ES8, or if you prefer ES2015 / ES2016 / ES2017 / ES2018).

At the end of the day, they all are HTML, CSS, and JavaScript rendered and run by the browser. There's no direct access to native APIs like camera, vibration, battery status, or file system, but some of them can be achieved via Web API's:

The big issue with Web APIs is their maturity level. Many of them are not supported by some browsers. There are differences in implementations, especially across mobile browsers.

Web App advantages

Shared code between platforms and desktop browsers

Do not require previous installations, just navigate and use

Tons of frameworks and libraries to go with them

Best for SEO

Web App disadvantages

Lower performance

Hard to get a native user experience

Require an internet connection

Not available on official app stores

API not as mature and reliable as native API

Frameworks and Web components

Angular, React, and Vue are probably the most popular web frameworks as of 2018. To be precise, however, React is considered just a library due to its flexible and less opinionated nature. Angular, on the other hand, is a strongly opinionated framework. Vue lives at some point in between them.

Angular vs React vs Vue

Angular, originally called AngularJS, was presented to the world in 2010 by Google. It quickly started to shine, due to its inversion of paradigms in comparison with other libraries from that time (like jQuery, the most popular back then). Instead of directly talking to HTML elements to manipulate the UI state, with AngularJS, templates were magically updated whenever the JavaScript model was updated.

As AngularJS became more and more popular, it also grew in purpose. It turned into a complete and opinionated framework that was one of the first that took SPAs (Single Page Apps) seriously. This growth (in both aspects) was responsible for some API bloats and performance issues.

React was created by Facebook to solve their own needs on the presentation layer. It introduced many aspects that suddenly became very popular, like virtual DOM, one-way data flow (originally named Flux, especially popular through an implementation library called Redux), and a mixture of HTML and JavaScript called JSX.

Only in 2016, after long debates and unexpected big changes, Google launched version two of its popular web framework. They called it Angular, instead of AngularJS. But, as many people already called the first version “Angular” (without the ""JS"" suffix), people started calling the new version Angular 2. That turned into a naming problem, as Google also announced that it would release new major versions every 6 months.

In my opinion, that was a mammoth mistake. I've seen this before (with Struts vs Struts 2/WebWork, for example). They have a massively popular product that appears to have reached its plateau, and it has started to be more criticized than praised. If Google decides to rebuild it from the ground up, they should never, by any means, just change its major version. How will people trust that they will not repeat it every new major version release? Version two is supposed to present breaking changes, but it doesn't mean it can be totally revamped.

Angular is a spectacular web framework, and I really feel passionate about it. However, it's a completely new beast. It does not have much to do with AngularJS. Even Vue, which is another amazing framework (probably one of the most pleasant to work with, by the way) looks more similar to AngularJS from a bird's-eye view. I believe this caused a significant movement away from Angular and contributed substantially to React's popularity.

Vue is the only one of the three most popular web frameworks that is not backed by a big company. It was actually started by a former Google developer. Due to its formidable simplicity and tiny footprint, it got attention from a massive and enthusiastic community.

Although there are more complete solutions, they all work on top of the concept of web components. There's an open specification about them currently in progress in W3C, and some interesting implementations like Polymer, Stencil and X-Tag.

In the third video of the series, I don't spend too much time discussing frameworks but discuss web component libraries:

The Web Apps tier is discussed in Part 3 of the series

Mobile Apps vs Web Apps

I’m not sure if you’ve noticed, but the order of tiers I'm presenting here follows what I think is the easiest path to learn all approaches. I started from the Native Tier, the most genuinely mobile development. Then I decided to fly directly to the other extreme to present the Web Tier, which is the tier that has been available since the first smartphones.

Only now, after elaborating on a comparison between the two edges of my diagram, will I start talking about many of the cross-platform approaches to build mobile apps.

There's a long debate between Mobile Apps vs Web Apps. Everything I say about Mobile Apps is not exclusive to the Native Tier. It is also applicable to all cross-platform tiers I present later on.

The user behavior dilemma

Users spend more time on Mobile Apps (87%) than on Mobile Websites (13%)

According to a Comscore survey in 2017, a user's fidelity to a mobile app is way more relevant than it is to mobile websites. According to an aligned article on Forbes, this is usually because of convenience (for example, home screen buttons, widgets, top notifications), speed (for example, smoother interfaces, almost instant start ups), and stored settings (for example, offline content).

Mobile Websites reach more people (8.9M monthly unique visitors against 3.3M of Mobile Apps)

On the other hand, in the same Comscore data, we learn that customers can be reached more easily from mobile websites, as they are not as much tied to their few apps of preference. If you compare the most popular websites versus the most downloaded apps, it's estimated that an average of 8.9 million unique web visitors per month access the top 1000 websites. That's almost three times more than the average unique users of the top 1000 most downloaded apps.

Distribution (Web App) x Engagement (Mobile App)

That's all about distribution vs engagement. Your web app has a higher chance of being accessed, as users are more likely to try new things when navigating through their mobile browsers. But Mobile Apps have been proven to be more engaging, and catch the users attention for much longer periods.

Now that you understand the dilemma, let's have a look at Progressive Web Apps. This is an approach so tied to the Web Apps tier that I classify it as just an addendum to Web Apps. But it's a big disruptor and a serious candidate for the most prominent new and cool thing in web and mobile development.

Progressive Web Apps

Progressive Web Apps (PWAs) are a set of tools used to give Web App users the same experience they are accustomed to when they run Mobile Apps. This means that Web Apps can leverage the potentially higher levels of distribution with more decent levels of engagement.

Progressive Web Apps addendum to Web Apps tier

Google defined three main qualifications for PWAs: they must be Reliable, Fast, and Engaging.

Features called Service Workers and the App Shell are the foundation of Progressive Web Apps. They were created to promote apps’ reliability as they are now designed to work regardless of the device’s connection status. That includes offline mode, as well as poor connections. They also provide significant perceived performance boost, as apps launch using locally cached data, which eliminates delays for synchronous content downloads.

You could consider reliability an indirect vector of engagement. Users are not affected while commuting by train, for example. They can stay engaged.

The same applies to speed. According to Google:

53% of users will abandon a site if it takes longer than 3 seconds to load!

However, being exclusively reliable and fast on load doesn't necessarily guarantee high engagement. PWAs leverage mobile-related features that used to be exclusive to mobile apps, like an “Add to Home Screen” option and Push Notifications.

When it comes to to the “Add to Home Screen” feature, you might notice that Apple has had a similar feature since the very first iPhone. Some people even argue that Progressive Web Apps are Google's fancy new name for an original Apple idea.

And you really can’t completely disagree. Some ideas are actually cycling. They come, go away, and then come back with a new name and some enhancements (for instance, Service Workers), so they can finally stick around.

On the other hand, it’s hard to completely agree. Steve Jobs’ speech about Web 2.0 + AJAX and the memorable announcement of the iPhone back in WWDC 2007 are not convincing enough to call him as the father, or even the prophet, of PWAs.

To be fair, the Add to Home Screen capability on iPhone has been nothing more than a subtle, almost hidden, feature to generate desktop icons that just start up Web Apps in fullscreen mode. It has all the burden of HTTP request-response cycles and no clear path around caches.

PWAs start from the right point. They explore how previous installations of Web Apps aren’t necessary without losing the client-side bootstrap of Mobile Apps. This means that everything a user needs for their first interaction following startup might be locally cached (read: App Shell) and kept available as soon as they hit “Add to Home Screen.”

Moving onto another well-known characteristic of PWAs, let’s talk about the super engaging (or re-engaging) feature of the Mobile Apps world: Push Notifications. They are alert-style messages that appear on the top notification bar / area, as well as on lock screens. They have the power of pulling users back to your app once they receive the notification.

To reinforce the appeal of PWAs, Google has been pulling all modern Web APIs under the PWA umbrella. So expect to see things like Payment Requests, Credential Management, WebVR, Sensors, WebAssembly, and WebRTC in the context of Progressive Web Apps. But these feature are not necessarily tied to PWAs, and some were even born before the term PWA was coined.

PWA and Apple

Apple, on the other hand, announced their first solid milestones towards PWAs only in March 2018. Although there are still some limitations, the progress is appreciable. Some of the limitations might be related to the fact that Safari has fallen behind its competitors. Others could be attributed to Apple's philosophy of tight control.

Still, Apple has a more profitable App Store than Google. Apple's asserts that more criteria on app publications brings more overall reliability, and PWAs are bound to hurt the App Store's revenue. This suggests that some limitations that seem to be intentionally imposed (like 50Mb of PWA maximum cache size) will cost more to be revoked.

Unfortunately PWAs are not perfect

Web solutions and, on different levels, all cross-platform solutions struggle to attain the excellence and comprehensiveness of Native Apps. Every new feature, and every detail particular to Android or iOS makes that native feel harder and harder to access as you distance your app from the native tier.

Overall, PWAs fix some issues in the Web Apps tier. But there are other issues that can’t be fixed by a solution working on top of a browser.

What PWAs fix

More “native” experience

Faster load times

Do not require an internet connection

Force web developers to be aware of situations where there’s no connection as well as a bad connection

Incorporate features from Mobile Apps like Push Notifications, Geolocation, or Speech Recognition

What they don’t

Inherent slowness

Not available on app stores (just yet)

Still not fully supported by all browsers

Still lack mobile features like NFC, Ambient Light, Geofencing

Also lack support for peculiarities of Android or iOS like PiP, smart app banners, launch screen widgets, and 3D touch

In the video below, I do a brief overview of PWAs.

Progressive Web Apps are introduced in the Part 4 of the series

Hybrid Apps

At this level, we begin to dive into the Mobile App world. We’ll start from the most distant tier: Hybrid Apps.

The term Hybrid is also commonly applied to all cross-platform solutions. Here, however, I’m restricting it to Apps that work inside mobile components, called WebViews.

The Hybrid Apps tier. Below the browser's line but on top of WebViews

In the demos in the second video, my purpose for adding WebView as the Hello World example was to make clear that there's a native component for each platform that is able to perform like an actual browser.

Cordova/PhoneGap

Solutions like Cordova/PhoneGap close the gap (sorry for the uninspired pun) between Web and Mobile Apps. They provide tools to package developer's HTML, JavaScript, and CSS code (as well as any extra assets like images or videos) and transform them into Mobile Apps (yes, real Android or iOS apps). These apps have their WebView exclusively to interpret and run the original web code, starting with the “index.html” file in the app’s main folder (normally called “www”). They also bridge the JavaScript code to native APIs through plugins which are partially implemented in JavaScript and partially in a native language.

So, let's make things clearer. Hybrid Apps are able to access native APIs (instead of Web APIs), but they are enclosed by the WebView. A button with Cordova must be an HTML button rendered by a WebView instead of a mobile native button.

This is the magical tier that allows companies to port their Web Apps to Mobile Apps to be shipped by app stores. So any web framework is allowed here.

Ionic

Frameworks like Ionic wrap Cordova into their own solutions. With Ionic, you don't need to use Cordova’s command line interface (CLI), because all of its commands are wrapped by the Ionic CLI.

Recently, the Ionic team decided to take the reins of the entire stack of Hybrid Apps. So they launched a proposed replacement for Cordova called Capacitor. Capacitor has support for Cordova plugins, and can also be used by a non-Ionic project.

You can watch me going through a Cordova Hello World sample in the fifth video of the series:

Hybrid Apps are in Part 5 of the series.

Hybrid Apps advantages

They are essentially web apps that are shippable to official app stores

Can be used along with any JavaScript framework / library

The code is still highly shareable across platforms

Access to native features (for instance, camera, accelerometer, contact list)

Hybrid Apps disadvantages

Struggle with performance issues and memory consumption, as web views are responsible for rendering everything on screen

Have to mimic all native UI components on top of a single web view

Harder to be accepted and published on App Store

Usually take longer to have native features available for these environments

Web Native

Web Native is a relatively new and often misunderstood tier. That's where Web Apps meet native components. Although Appcelerator (Axway) Titanium has been around a long time, there are some relatively new competitors that justify making this a completely separate category of mobile apps.

Web Native Apps don't need WebView as they talk directly to other native components

As you can see above, there's no web view to render and run your application. So, how is your JavaScript executed? Is it compiled? Well, if you consider transpilation (compilation from one language to another — for example TypeScript to JavaScript), bundling, minification, mangling, and obfuscation all together as a compilation, yes JavaScript is compiled.

But the problem is, this doesn't make your JavaScript something directly understood by Android or iOS operational systems. And, in theory, there's no native component that only serves as a JavaScript engine without the bloat of the HTML layout engine.

The strategy is to ship JavaScript engines (normally V8 for Android and JavaScriptCore for iOS) along with your code. Although they have small footprints and are very fast, they are something external that must be provided by your app.

On the other hand, this approach tends to have better UI performance, as all the components are the same (or are based on the same thing for React Native, for example) as the ones used by Native Apps.

Web Native Apps advantages

Reach both platforms with one single codebase

Roughly the same performance as native apps, as they also deal with native UI components

Tweaks are necessary, but the code is still shareable with web development

Web Native Apps disadvantages

Even with one single codebase, the developer must be aware of native components

Steeper learning curve than Hybrid / Web Apps for web developers, especially when it comes to layout

React Native

In part 6 of the series, I do a quick Hello World in React Native. This shows, on Android Studio's Layout Inspector, what components were rendered in the emulator. I compare with the previous examples, ensuring that there's no WebView whatsoever.

Web Native Apps presentation with focus on React Native in Part 6 of the series.

Nativescript

Another amazing framework that I've been particularly interested in over the last two years (I have a course on Udemy about it — in Portuguese), is Nativescript. It’s similar to React Native but is not tied to the React world (there's an unofficial integration, Nativescript-Preact, though).

With Nativescript, you can develop using vanilla JavaScript, TypeScript, Angular and, more recently, Vue. Of course you can use other frameworks, but those are the ones officially supported. It’s fairly well documented too, by the way.

Nativescript has tools like Nativescript Sidekick and Nativescript Playground, as well as project structures based on templates that can be provided by the community. This should help you in project creation, giving you the ability to start, deploy, test, and run on simulators on the cloud and iPhone devices even when you are not developing using a Mac.

In the seventh part of the series, I do a Hello World using Sidekick along with another project started from the CLI and a WhatsApp clone template I created for learning purposes.

Web Native Apps with Nativescript in Part 7 of the series.

It's important to have a look at the Layout Inspector when your app is running on an Android emulator. With Nativescript, it shows the native components (again, no WebView), and direct instances of common Android classes like TextView. This is different than React Native, which has its own classes to wrap the native components.

That's probably why Nativescript claims that there’s no delay between when a new feature is available on iOS and Android and when you can use it in a Nativescript project. For example, they posted on their blog an AR project on the same day iOS 11 was officially released with the new ARKit API.

Weex

Another framework worth mentioning in this category is Weex. It's a project developed by Alibaba, and is currently incubated at Apache Sofware Foundation (ASF). It uses common HTML tags like <div> and CSS commands inside <style> tags to call native components instead. From their documentation:

Although components in Weex look like HTML tags, you are not able to use all of them. Instead, you can only use the built-in components and your custom components.

Cross Compiled

At this level, it’s time to jump off the Web bandwagon. This is the closest tier to native development, but has the advantage of using one single codebase to target Android and iOS.

Development tiers now complete with Cross Compiled Apps

RubyMotion and Xamarin

There are solutions like RubyMotion. This is a way to write mobile apps using Ruby and compile directly to the targeted platform (as it was created using any ""native"" language).

Another option is Xamarin, where you write in C#, compile to an intermediate bytecode, and deploy your app along with an instance of the Mono common language runtime. This approach has the same drawback as Web Native (where V8 and JavaScriptCore are delivered by your app), but can also rely upon JIT compilations to optimize the app at runtime.

Flutter

Last but not least, I'd like to bring up Flutter. It’s Google's newest cool initiative for mobile development. It fits in the Cross Compiled tier because you write apps using the Dart language and compile them down to the native platform.

Flutter has innovated in some aspects. Probably the most outstanding one is the fact that it provides its own set of components.

What? Own set of components?

Yes, Flutter provides a number of different components so you can completely skip the ones from the platform. It has generic components as well as Material Design components for Android, and Cupertino components for iOS.

Rather than .Net virtual machine (as Xamarin) or JavaScript engines (as Web Native frameworks), with Flutter your app will deliver the components you decide to use.

Are they native components?

Yes, they are. Your app is native, too. Everything is compiled to the native architecture. However, bear in mind they are not the pre-existing native components.

What's the point of that?

Well, in my opinion, this solution is clever and audacious. I've been waiting to talk about advantages and disadvantages, but as it's just one particular technology, let me address them now.

One of the biggest challenges for Web Native and Cross Compiled solutions (remember, above Native but below the WebView in our tiers) is how to deal with native components. For example, an important problem is how to lay them out. That's because they were not created to be used by those external resources. Also, they were not created with a counterpart in the other platform in mind. The Android NavBar doesn't work like iOS UINavBar, for example.

With Flutter, components are created with cross-platform always in mind. So let's have a look at the pros and cons of the Cross Compiled Apps tier:

Cross Compiled Apps advantages

Reach both platforms with one single language

Roughly the same performance as native apps, as they also deal with native UI components

Cross Compiled Apps disadvantages

Slightly delayed support for the latest platform updates

Code not shareable with web development

Even with one single codebase, the developer must be aware of native components

PS: With Flutter, you’ll provide your own set of widgets along with your app's code

Mobile Apps runtime architecture",https://cdn-images-1.medium.com/max/1200/1*kHze88HBCkKt8Tw4MESC9Q.png,[],https://medium.freecodecamp.org/a-deeply-detailed-but-never-definitive-guide-to-mobile-development-architecture-6b01ce3b1528?source=collection_home---6------21----------------,2018-06-05 16:34:24.241000+00:00

Data Analysis,How to deliver a React Native app to the client – freeCodeCamp,[],"How to deliver a React Native app to the client

If you have written some React Native apps, you’ve probably noticed that the process of beta-release version generation requires many repeatable steps. This happens especially for multi-platform apps.

Let’s look at sample action steps you need to perform to deliver the beta version app to the client or tester:

Download the proper branch from the repository

Android:

Insert the APK signing key into the ./android/app/ directory

directory Build the release version

Send the app, for example via e-mail

iOS:

Launch Xcode

Change the scheme to Release

Change the jsCodeLocation value to a static main.jsbundle file path

value to a static file path Archive

Upload the app to TestFlight

As you can see, the above list contains a large number of repeatable steps. Since they are repeatable, we can automate them, right?

Possible solutions

There are several solutions for automating beta release version generation and delivering the app to the client.

Visual Studio App Center

The first solution that came to our minds at Brainhub was the use of the Visual Studio App Center. A project built by Microsoft seems to be really attractive — in addition to building the app in the cloud (free 240 minutes / month of building) and distribution among testers and the client, it also provides a platform for testing apps on many real devices, giving access to reports and screenshots of every step of the process.

However, it quickly turned out that this was not the appropriate solution for our particular project. VS App Center has limited configuration abilities, and the app’s code needs to be downloaded from the Git repository hosted on GitHub, Bitbucket, or VSTS. Due to the fact that we use GitLab, we had to rule out this solution (but it could work for your project).

HockeyApp (with Fastlane)

The next option was to use HockeyApp — a tool for app distribution and collecting crash reports and users’ feedback. The service was initially created for distribution of iOS apps using the ‘ad hoc’ method (outside of App Store), but currently it works for Android also.

HockeyApp works well as a delivery platform of software testing versions, but does not give the functionality of building the app. However, we can also use Fastlane — a tool for mobile app building process automation built by fabric.io.

Preparations

Before you start building and deploying the app, you should prepare the environment. This section describes the steps you should take first.

Automatic jsCodeLocation change

React Native documentation says that you should change jsCodeLocation to the static js bundle for the iOS release version in AppDelegate.m file. But there’s no need to do that manually every time you release the app — you can use the #ifdef DEBUG macro to do it automatically. Just replace the line containing jsCodeLocation = … with the following code.

#ifdef DEBUG

// DEV

jsCodeLocation = [[RCTBundleURLProvider sharedSettings] jsBundleURLForBundleRoot:@”index” fallbackResource:nil];

#else

// PROD

jsCodeLocation = [[NSBundle mainBundle] URLForResource:@”main” withExtension:@”jsbundle”];

#endif

Ignore helper files

During the process of building the app, there will be some helper files created. There’s no need to commit them to the repository, so just add them to the following “.gitignore” file.

# Deployment

*.cer

*.jsbundle

*.jsbundle.meta

*dSYM.zip

*.keystore

*.mobileprovision

fastlane/report.xml

APK signing key

To release an Android app, you need a signing key. To learn more about this process, look here.

When you have your key generated, move it to the “android/app” directory and remember to add *.keystore to “.gitignore”.

Fastlane + HockeyApp + Testflight

You will learn how to automatically generate an app written in React Native for Android and iOS platforms, and send it to HockeyApp (Android) and Testflight (iOS).

First, let’s install Fastlane. Make sure you have the newest version of Xcode command line tools installed.

xcode-select — install

Install Fastlane.

[sudo] gem install fastlane -NV` or `brew cask install fastlane`

Init Fastlane.

fastlane init

The command above will create the “fastlane” directory in current directory with a file called “Fastfile” that contains the Fastlane configuration.

Appfile

In the “fastlane” directory, create a file called “Appfile”, which stores data that is used across all fastlane tools, for example AppleID. It is required for the iOS build and deployment to Testflight.

Add your AppleID to “Appfile”.

Fastfile

Your beta release Fastfile might look like this.

# More documentation about how to customize your build

# can be found here:

# https://docs.fastlane.tools

# fastlane_version “2.68.0”

# Fastfile actions accept additional configuration, but

# don’t worry, fastlane will prompt you for required

# info which you can add here later

platform :ios do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

get_certificates

get_provisioning_profile(

app_identifier: “org.you.yourProject”

)

# build your iOS app

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

# TestFlight

pilot()

end

end

platform :android do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

# build the release variant

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

# upload to HockeyApp

hockey(

api_token: “YOUR_TOKEN”

)

end

end

Let’s analyze our “Fastfile” step-by-step.

The code block below will be executed after typing fastlane ios beta into the console.

platform :ios do

lane :beta do

# …

end

end

For Android , type fastlane android beta .

platform :android do

lane :beta do

# …

end

end

Ensure that the current branch is master and perform git pull to sync with the remote repository.

ensure_git_branch(

branch: “master”

)

git_pull

iOS only

Let’s increment the build number (works for iOS only). The application that is being sent to Testflight has to have a higher build number than the previous version.

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

Testflight and Ad Hoc distribution require the proper certificate and provisioning profile. There are several methods of signing apps:

match

cert and sigh

Xcode’s code signing feature

manually

In this article, cert and sigh was used. For further reading about codesigning using Fastlane, visit this site.

get_certificates

get_provisioning_profile( app_identifier: “org.you.yourProject” )

Next, there is the step of building the iOS version where we pass the params such as project path, scheme , and export_method . Export_method contains one of the following values: app-store , ad-hoc , package , enterprise , development , or developer-id .

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

The last step for iOS is sending the app to Testflight.

pilot()

Android only

Now let’s look at the Android version. There are two gradle steps: cleaning, and building the release version.

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

Now you can send the generated app to HockeyApp.

hockey(

api_token: “YOUR_TOKEN”

)

If you don’t add some required parameter, for example no iTunes Connect user in Fastfile, Fastlane will ask you for that data in the console.

HockeyApp Configuration

After signing up and signing in to HockeyApp, you will see the blue “New App” button.",https://cdn-images-1.medium.com/max/1200/1*153T3TpCccNK7hs11oRNpA.png,[],https://medium.freecodecamp.org/how-to-deliver-a-react-native-app-to-the-client-e58421e7272e?source=collection_home---6------22----------------,2018-06-05 01:26:27.937000+00:00

Data Analysis,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------,2018-06-05 00:59:03.212000+00:00

Data Analysis,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------#--responses,2018-06-05 00:59:03.212000+00:00

Data Analysis,A coffee-break introduction to time complexity of algorithms,['Vicky Lai'],"A coffee-break introduction to time complexity of algorithms

Just like writing your very first for loop, understanding time complexity is an integral milestone to learning how to write efficient complex programs. Think of it as having a superpower that allows you to know exactly what type of program might be the most efficient in a particular situation — before even running a single line of code.

The fundamental concepts of complexity analysis are well worth studying. You’ll be able to better understand how the code you’re writing will interact with the program’s input, and as a result, you’ll spend a lot less wasted time writing slow and problematic code.

It won’t take long to go over all you need to know in order to start writing more efficient programs — in fact, we can do it in about fifteen minutes. You can go grab a coffee right now (or tea, if that’s your thing) and I’ll take you through it before your coffee break is over. Go ahead, I’ll wait.

All set? Let’s do it!

What is “time complexity” anyway?

The time complexity of an algorithm is an approximation of how long that algorithm will take to process some input. It describes the efficiency of the algorithm by the magnitude of its operations. This is different than the number of times an operation repeats. I’ll expand on that later. Generally, the fewer operations the algorithm has, the faster it will be.

We write about time complexity using Big O notation, which looks something like O(n). There’s rather a lot of math involved in its formal definition, but informally we can say that Big O notation gives us our algorithm’s approximate run time in the worst case, or in other words, its upper bound. It is inherently relative and comparative.

We’re describing the algorithm’s efficiency relative to the increasing size of its input data, n. If the input is a string, then n is the length of the string. If it’s a list of integers, n is the length of the list.

It’s easiest to picture what Big O notation represents with a graph:

Lines made with the very excellent Desmos graph calculator. You can play with this graph here.

Here are the main important points to remember as you read the rest of this article:

Time complexity is an approximation

An algorithm’s time complexity approximates its worst case run time

Determining time complexity

There are different classes of complexity that we can use to quickly understand an algorithm. I’ll illustrate some of these classes using nested loops and other examples.

Polynomial time complexity

A polynomial, from the Greek poly meaning “many,” and Latin nomen meaning “name,” describes an expression comprised of constant variables, and addition, multiplication, and exponentiation to a non-negative integer power. That’s a super math-y way to say that it contains variables usually denoted by letters, and symbols that look like these:

The below classes describe polynomial algorithms. Some have food examples.

Constant

A constant time algorithm doesn’t change its running time in response to the input data. No matter the size of the data it receives, the algorithm takes the same amount of time to run. We denote this as a time complexity of O(1).

Here’s one example of a constant algorithm that takes the first item in a slice.

func takeCupcake(cupcakes []int) int {

return cupcakes[0]

}

Choice of flavours are: vanilla cupcake, strawberry cupcake, mint chocolate cupcake, lemon cupcake, and “wibbly wobbly, timey wimey” cupcake.

With this contant-time algorithm, no matter how many cupcakes are on offer, you just get the first one. Oh well. Flavours are overrated anyway.

Linear

The running duration of a linear algorithm is constant. It will process the input in n number of operations. This is often the best possible (most efficient) case for time complexity where all the data must be examined.

Here’s an example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

}

Here’s another example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// double dip chip

}

}

It doesn’t matter whether the code inside the loop executes once, twice, or any number of times. Both these loops process the input by a constant factor of n, and thus can be described as linear.

Don’t double dip in a shared bowl.

Quadratic

Now here’s an example of code with time complexity of O(n2):

func pizzaDelivery(pizzas int) {

for pizza := 0; pizza <= pizzas; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

Because there are two nested loops, or nested linear operations, the algorithm process the input n2times.

Cubic

Extending on the previous example, this code with three nested loops has time complexity of O(n3):

func pizzaDelivery(boxesDelivered int) {

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

}

Seriously though, who delivers unsliced pizza??

Logarithmic

A logarithmic algorithm is one that reduces the size of the input at every step. We denote this time complexity as O(log n), where log, the logarithm function, is this shape:

One example of this is a binary search algorithm that finds the position of an element within a sorted array. Here’s how it would work, assuming we’re trying to find the element x:

If x matches the middle element m of the array, return the position of m. If x doesn’t match m, see if m is larger or smaller than x. If larger, discard all array items greater than m. If smaller, discard all array items smaller than m. Continue by repeating steps 1 and 2 on the remaining array until x is found.

I find the clearest analogy for understanding binary search is imagining the process of locating a book in a bookstore aisle. If the books are organized by author’s last name and you want to find “Terry Pratchett,” you know you need to look for the “P” section.

You can approach the shelf at any point along the aisle and look at the author’s last name there. If you’re looking at a book by Neil Gaiman, you know you can ignore all the rest of the books to your left, since no letters that come before “G” in the alphabet happen to be “P.” You would then move down the aisle to the right any amount, and repeat this process until you’ve found the Terry Pratchett section, which should be rather sizable if you’re at any decent bookstore, because wow did he write a lot of books.

Quasilinear

Often seen with sorting algorithms, the time complexity O(n log n) can describe a data structure where each operation takes O(log n) time. One example of this is quick sort, a divide-and-conquer algorithm.

Quick sort works by dividing up an unsorted array into smaller chunks that are easier to process. It sorts the sub-arrays, and thus the whole array. Think about it like trying to put a deck of cards in order. It’s faster if you split up the cards and get five friends to help you.

Non-polynomial time complexity

The below classes of algorithms are non-polynomial.

Factorial

An algorithm with time complexity O(n!) often iterates through all permutations of the input elements. One common example is a brute-force search, seen in the traveling salesman problem. It tries to find the least costly path between a number of points by enumerating all possible permutations and finding the ones with the lowest cost.

Exponential

An exponential algorithm often also iterates through all subsets of the input elements. It is denoted O(2n) and is often seen in brute-force algorithms. It is similar to factorial time except in its rate of growth, which, as you may not be surprised to hear, is exponential. The larger the data set, the more steep the curve becomes.

In cryptography, a brute-force attack may systematically check all possible elements of a password by iterating through subsets. Using an exponential algorithm to do this, it becomes incredibly resource-expensive to brute-force crack a long password versus a shorter one. This is one reason that a long password is considered more secure than a shorter one.

There are further time complexity classes less commonly seen that I won’t cover here, but you can read about these and find examples in this handy table.

Recursion time complexity

As I described in my article explaining recursion using apple pie, a recursive function calls itself under specified conditions. Its time complexity depends on how many times the function is called and the time complexity of a single function call. In other words, it’s the product of the number of times the function runs and a single execution’s time complexity.

Here’s a recursive function that eats pies until no pies are left:

func eatPies(pies int) int {

if pies == 0 {

return pies

}

return eatPies(pies - 1)

}

The time complexity of a single execution is constant. No matter how many pies are input, the program will do the same thing: check to see if the input is 0. If so, return, and if not, call itself with one fewer pie.

The initial number of pies could be any number, and we need to process all of them, so we can describe the input as n. Thus, the time complexity of this recursive function is the product O(n).

This function’s return value is zero, plus some indigestion.

Worst case time complexity

So far, we’ve talked about the time complexity of a few nested loops and some code examples. Most algorithms, however, are built from many combinations of these. How do we determine the time complexity of an algorithm containing many of these elements strung together?

Easy. We can describe the total time complexity of the algorithm by finding the largest complexity among all of its parts. This is because the slowest part of the code is the bottleneck, and time complexity is concerned with describing the worst case for the algorithm’s run time.

Say we have a program for an office party. If our program looks like this:

package main



import ""fmt""



func takeCupcake(cupcakes []int) int {

fmt.Println(""Have cupcake number"",cupcakes[0])

return cupcakes[0]

}



func eatChips(bowlOfChips int) {

fmt.Println(""Have some chips!"")

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

fmt.Println(""No more chips."")

}



func pizzaDelivery(boxesDelivered int) {

fmt.Println(""Pizza is here!"")

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

fmt.Println(""Pizza is gone."")

}



func eatPies(pies int) int {

if pies == 0 {

fmt.Println(""Someone ate all the pies!"")

return pies

}

fmt.Println(""Eating pie..."")

return eatPies(pies - 1)

}



func main() {

takeCupcake([]int{1, 2, 3})

eatChips(23)

pizzaDelivery(3)

eatPies(3)

fmt.Println(""Food gone. Back to work!"")

}

We can describe the time complexity of all the code by the complexity of its most complex part. This program is made up of functions we’ve already seen, with the following time complexity classes:

To describe the time complexity of the entire office party program, we choose the worst case. This program would have the time complexity O(n3).

Here’s the office party soundtrack, just for fun.

Have cupcake number 1

Have some chips!

No more chips.

Pizza is here!

Pizza is gone.

Eating pie...

Eating pie...

Eating pie...

Someone ate all the pies!

Food gone. Back to work!

P vs NP, NP-complete, and NP-hard

You may come across these terms in your explorations of time complexity. Informally, P (for Polynomial time), is a class of problems that is quick to solve. NP, for Nondeterministic Polynomial time, is a class of problems where the answer can be quickly verified in polynomial time. NP encompasses P, but also another class of problems called NP-complete, for which no fast solution is known. Outside of NP, but still including NP-complete, is yet another class called NP-hard, which includes problems that no one has been able to verifiably solve with polynomial algorithms.

P vs NP Euler diagram, by Behnam Esfahbod, CC BY-SA 3.0

P versus NP is an unsolved, open question in computer science.

Anyway, you don’t generally need to know about NP and NP-hard problems to begin taking advantage of understanding time complexity. They’re a whole other Pandora’s box.

Approximate the efficiency of an algorithm before you write the code

So far, we’ve identified some different time complexity classes and how we might determine which one an algorithm falls into. So how does this help us before we’ve written any code to evaluate?

By combining a little knowledge of time complexity with an awareness of the size of our input data, we can take a guess at an efficient algorithm for processing our data within a given time constraint. We can base our estimation on the fact that a modern computer can perform some hundreds of millions of operations in a second. The following table from the Competitive Programmer’s Handbook offers some estimates on required time complexity to process the respective input size in a time limit of one second.

Keep in mind that time complexity is an approximation, and not a guarantee. We can save a lot of time and effort by immediately ruling out algorithm designs that are unlikely to suit our constraints, but we must also consider that Big O notation doesn’t account for constant factors. Here’s some code to illustrate.

The following two algorithms both have O(n) time complexity.

func makeCoffee(scoops int) {

for scoop := 0; scoop <= scoops; scoop++ {

// add instant coffee

}

}

func makeStrongCoffee(scoops int) {

for scoop := 0; scoop <= 3*scoops; scoop++ {

// add instant coffee

}

}

The first function makes a cup of coffee with the number of scoops we ask for. The second function also makes a cup of coffee, but it triples the number of scoops we ask for. To see an illustrative example, let’s ask both these functions for a cup of coffee with a million scoops.

Here’s the output of the Go test:

Benchmark_makeCoffee-4 1000000000 0.29 ns/op

Benchmark_makeStrongCoffee-4 1000000000 0.86 ns/op

Our first function, makeCoffee , completed in an average 0.29 nanoseconds. Our second function, makeStrongCoffee , completed in an average of 0.86 nanoseconds. While those may both seem like pretty small numbers, consider that the stronger coffee took nearly three times longer to make. This should make sense intuitively, since we asked it to triple the scoops. Big O notation alone wouldn’t tell you this, since the constant factor of the tripled scoops isn’t accounted for.

Improve time complexity of existing code

Becoming familiar with time complexity gives us the opportunity to write code, or refactor code, to be more efficient. To illustrate, I’ll give a concrete example of one way we can refactor a bit of code to improve its time complexity.

Let’s say a bunch of people at the office want some pie. Some people want pie more than others. The amount that everyone wants some pie is represented by an int > 0:

diners := []int{2, 88, 87, 16, 42, 10, 34, 1, 43, 56}

Unfortunately, we’re bootstrapped and there are only three forks to go around. Since we’re a cooperative bunch, the three people who want pie the most will receive the forks to eat it with. Even though they’ve all agreed on this, no one seems to want to sort themselves out and line up in an orderly fashion, so we’ll have to make do with everybody jumbled about.

Without sorting the list of diners, return the three largest integers in the slice.

Here’s a function that solves this problem and has O(n2) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// loop over three forks

for i := 1; i <= 3; i++ {

// variables to keep track of the highest integer and where it is

var max, maxIndex int

// loop over the diners slice

for n := range diners {

// if this integer is higher than max, update max and maxIndex

if diners[n] > max {

max = diners[n]

maxIndex = n

}

}

// remove the highest integer from the diners slice for the next loop

diners = append(diners[:maxIndex], diners[maxIndex+1:]...)

// keep track of who gets a fork

withForks = append(withForks, max)

}

return withForks

}

This program works, and eventually returns diners [88 87 56] . Everyone gets a little impatient while it’s running though, since it takes rather a long time (about 120 nanoseconds) just to hand out three forks, and the pie’s getting cold. How could we improve it?

By thinking about our approach in a slightly different way, we can refactor this program to have O(n) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// create variables for each fork

var first, second, third int

// loop over the diners

for i := range diners {

// assign the forks

if diners[i] > first {

third = second

second = first

first = diners[i]

} else if diners[i] > second {

third = second

second = diners[i]

} else if diners[i] > third {

third = diners[i]

}

}

// list the final result of who gets a fork

withForks = append(withForks, first, second, third)

return withForks

}

Here’s how the new program works:

Initially, diner 2 (the first in the list) is assigned the first fork. The other forks remain unassigned.

Then, diner 88 is assigned the first fork instead. Diner 2 gets the second one.

Diner 87 isn’t greater than first which is currently 88 , but it is greater than 2 who has the second fork. So, the second fork goes to 87 . Diner 2 gets the third fork.

Continuing in this violent and rapid fork exchange, diner 16 is then assigned the third fork instead of 2 , and so on.

We can add a print statement in the loop to see how the fork assignments play out:

0 0 0

2 0 0

88 2 0

88 87 2

88 87 16

88 87 42

88 87 42

88 87 42

88 87 42

88 87 43

[88 87 56]

This program is much faster, and the whole epic struggle for fork domination is over in 47 nanoseconds.

As you can see, with a little change in perspective and some refactoring, we’ve made this simple bit of code faster and more efficient.

Well, it looks like our fifteen minute coffee break is up! I hope I’ve given you a comprehensive introduction to calculating time complexity. Time to get back to work, hopefully applying your new knowledge to write more effective code! Or maybe just sound smart at your next office party. :)

Sources

“If I have seen further it is by standing on the shoulders of Giants.” –Isaac Newton, 1675",https://cdn-images-1.medium.com/max/1200/1*_YsSsyFQ5sgS8F0kiZ1USA.png,[],https://medium.freecodecamp.org/a-coffee-break-introduction-to-time-complexity-of-algorithms-64df7dd8338e?source=collection_home---6------24----------------,2018-06-04 23:44:40.970000+00:00

NLP,Media – Medium,"['Ev Williams', 'Dave Pell', 'Hossein Derakhshan', 'Dawn Ennis', 'Stephan Neidenbach', 'Don Day', 'Jessie Singer', 'Tim Grierson']","Media Where the newsroom is the news.

Follow Following",https://cdn-images-1.medium.com/max/1200/1*wLhNmBWoSMvG0kyRGjDIqw@2x.jpeg,[],https://medium.com/topic/media,

NLP,The Inspiration of Anthony Bourdain – Member Feature Stories – Medium,['Christine Byrne'],"One of my first great food memories comes from a trip my family took to Normandy when I was six years old. We hadn’t been sitting for two minutes when I announced to my parents, “I want the escargot.”

Dad: “You know that’s snails?”

Six-year-old me: “Yes! We just learned about them in French class, and I want the escargot!”

My parents went along, although I’m sure they expected I’d take a few bites out of stubbornness, then subtly push the dish of garlic and butter and earthy mollusk aside, hoping no one would call out my misplaced courage.

Actually, though, I ate every snail, then mopped up every bit of briny, herby garlic butter left behind. I still think about those snails and about how excited and proud I was to love them so much.

A decade after those snails, I sat on the living room couch with my dad and watched an episode of No Reservations, Anthony Bourdain’s first food travel show. I, like millions of others, was drawn to the irreverent reverence with which he seemed to approach every food he tried, to his eagerness to try anything, and to his ability to narrate the stories of different foods, cooks, and cultures in an unpretentious way that let them mostly speak for themselves. Until then, I had thought of food and travel writing and television as more marketing than storytelling, but watching No Reservations made it clear that, actually, food was not only a story in and of itself, but also a great way to anchor other stories in something tangible and universally understood. Bourdain wasn’t out to sell an experience or show how good something could be — every episode was about telling the story of things exactly as they are.

Bourdain wasn’t the first to talk about food this way, but he was the first to make me feel like maybe I could talk about food that way, too. Food was an important part of my life growing up, but not in a particularly extraordinary way that I felt would resonate. We lived abroad and traveled often, so I was massively privileged in that there was always something new to eat. I remember eating pâté for the first time on a pebble beach in Cornwall while watching my dad (try to) learn to windsurf. I remember tearing apart a slick piece of roti prata and dipping it into a Styrofoam container of curry sauce on a plastic picnic table in Mersing, Malaysia, before getting on a bum boat to an island where I’d go to summer camp for the first time. I remember my first drink: a Tiger beer at Newton Circus, another hawker center, after the closing night of our high school production of South Pacific. I remember, every year when we’d fly home to New Jersey, eating baked ziti and supermarket sheet cake at Fourth of July barbecues, both or which were exciting and special for me because I only ate them once a year. I remember the first time I ate lunch at a New York City deli and was awed by the enormity of both the sandwiches and the Snapple selection. None of this seemed like a story, though, because I wasn’t sure why anyone else would care.

Years later, as a rising college senior, I spent the summer working as a publishing intern in New York. Weeks in, I realized that my longtime goal of being a book editor was actually, definitely, not what I wanted. To keep the “I graduate in a year and now have no plan” anxiety at bay, I read more books that summer than I ever have. One of them was Anthony Bourdain’s Kitchen Confidential.

Bourdain’s 2000 memoir, as you may know, gets so much of its magic from the sense you get while reading that every story is true. I figured it would fall into the “I never want to go there, but that sure made me think and was fun to watch” category that some of the No Reservations episodes did, and that the stories about hypermasculine kitchen culture and the people who somehow ended up in it would make me laugh, think, and then move on to whatever book was next.

That’s not what happened. The first story the book tells is one of Bourdain as a fourth-grader on a European cruise with his family. He tries vichyssoise, a potato-based French soup, and is taken aback by the fact that it’s cold. “I’d eaten in restaurants before, sure,” he says, “but this was the first food I really noticed. It was the first food I enjoyed and, more important, remembered enjoying.” Reading it made me think of my snails, how adventurous they made me feel, and how they established food as something important and worth discovering. It’s a good, tame story that I could easily relate to, and I bet most people felt the same when reading it.

The thing is, the relatability of the book started and ended with that cold potato soup. The rest of the book — about restaurant kitchens and all the crass, stressful, macho, bonkers shit that happened inside them — took place in a world very, very different from mine. Even coming from Bourdain, whose stories had been making me feel welcome since I first watched him walk around Paris unironically wearing cowboy boots in the first episode of No Reservations, the book felt like something I was looking in on from the outside. Reading it piqued my curiosity in restaurant cooking but made it clear that it wasn’t something for me. The longer the stories sat with me, though, the more they started to feel like a sort of…dare.

I graduated soon after, six months earlier than planned. I was still put off by my intern experience in publishing and totally uninspired by every job option presented to me by career counselors and all the well-meaning adults in my life. (Although it was 2010 and the height of a recession, so calling them “options” is maybe a stretch.) Food writing had crossed my mind, but I didn’t figure it was something I could just jump into. I can’t really explain my sudden decision to go to culinary school — a mix of desperation, an interest in food, a burning need to be interesting and different, and a nagging curiosity about Kitchen Confidential, if I had to put it into words — but in 2010, I moved to New York and spent 10 months at the French Culinary Institute learning how to cook. It remains the most impulsive thing I’ve ever done—and the most significant.

The following two and a half years spent cooking in NYC restaurant kitchens taught me things that culinary school never could have—about cooking, stress, being a woman in a room of mostly men, and how to deal with constantly being under fire without falling apart. It’s hard to explain what it was like to walk into a restaurant kitchen, and I honestly don’t remember it clearly, but I do remember that everything I did was wrong, everywhere I was was in the way, and every time someone said something to me, I had to ask them to explain what they were talking about. It was the most underqualified and out of place I’d ever felt, even though I knew in theory that’s exactly what I was signing up for. (I’d read the book! I intentionally jumped out of my comfort zone!) It wasn’t the useless, undervalued feeling that comes with an entry-level office job; it was the feeling that I needed to apologize for even being there, for being the alien who disrupted a system that everyone else knew how to work in. Weeks went by before I was able to walk into that kitchen without absolute fear; months went by before I was able to actually contribute.

Was restaurant cooking the way Bourdain described? Not really. It was vaguely the same, sure: late nights, weekends, burn scars, characters, industry bars, some yelling, ticket boards that inexplicably but reliably went from empty to full in a matter of minutes every single night.

The actual experience of it was very different from what I’d read, though. Because it wasn’t his experience—it was mine. I was the one cramming four hours’ worth of food prep into two and a half every afternoon. I was the one at the stove, firing seven dishes from three different orders at the same time, in exactly the right order, totally on instinct. I was the one who stayed at the bar three hours too long on a Tuesday and somehow always managed to find my way on the L train. I was the one who felt disconnected from one world but totally plugged into another.

Which made me realize: A great storyteller is one who makes you want to experience stories for yourself. A great story is one that makes you think, “I wonder what it would be like to do that.” I’m not much of a storyteller these days, nor am I still a restaurant cook. I write recipes, and I write stories about how and why people should cook them, but I do so in a way that’s shaped by what I’ve learned: Recipes are like stories, kind of, and the best recipes are ones that people will actually cook. Getting someone to cook a recipe isn’t about presenting them with something they’re already familiar with, necessarily, but about making them think, “I wonder what it would be like to do that.”

It’s no secret that Anthony Bourdain was a great storyteller. I’ll miss following along with his unending curiosity about food and how it shapes us, and the world will miss the way he was able to share that curiosity in a way that was welcoming and inclusive. What I’m most grateful for, though, is that he showed me the inside of a world I’d never given a second thought to—restaurants—and painted a picture that, even though it was totally unrelatable to me, was interesting enough that I felt compelled to experience if for myself. Not many storytellers do their job so well that, after reading their stories, you actually feel moved to go out and live them.

“Food, for me, has always been an adventure,” Bourdain writes in the preface of Kitchen Confidential. For me, too, Chef. Thanks for teaching me that food is something worth exploring and that the exploration is something worth writing about.",https://cdn-images-1.medium.com/max/1200/1*65ru7KtyJDme4kUXz8Sl5Q.jpeg,[],https://medium.com/s/story/the-inspiration-of-anthony-bourdain-8d5679c2acb4?source=grid_home---------0------------------18,

NLP,"Apple has no idea what’s next, so it’s just banging on the same old drum",['Owen Williams'],"Apple has no idea what’s next, so it’s just banging on the same old drum If you want to witness a company that’s simultaneously in its prime and losing control over its own narrative, look no further than WWDC, Apple’s second-most splashy event of the year, designed to offer a glimpse of the future. The annual developer event is a spectacle that I’ve watched live for almost a decade, but this year was different: it showcased a company that’s lost in the woods, playing the same old hits on repeat, in the same old format. Not only was it painful to watch, it demonstrated that Apple doesn’t really have a coherent plan, or understanding, of where it should take its core platform, let alone the ones it’s tried to build around it. It’s fine to have an off year, but what struck me was how… random it felt, and how little insight or forward thinking there was. Apple’s own platform advantages, company culture, and whatever else, seem to be pigeonholing its trajectory, driving it down a path that looks increasingly dated, and leaving me to wonder if the company is self-aware enough to see the shifting tide before it’s lost at sea. Big, slow, yearly

Apple struggled throughout 2017 to ship flagship features it promised at WWDC 2017, including Airplay 2 and iCloud Messages, delivering them quietly just days before this year’s event. Alongside a scandal about performance throttling, a series of major security slip-ups, and hardware that shipped without long-touted features, many have loudly asked what’s causing these issues — and why a company with so many engineers is fundamentally failing to ship. Performance improvements are arguably the biggest focus of iOS 12. They’ll be welcome for many users, along with several additional improvements: streamlined notifications, a new ‘shortcuts’ feature for custom buttons, usage reporting, group FaceTime, AR updates and a number of other minor improvements to create a major release, iOS 12. The company’s other platforms received similar treatment, including macOS. Apple finished dark mode, a feature it half-introduced all the way back in Yosemite, added basic functionality to Finder, threw in a new way to organize your desktop, and boom — there’s your major release, 10.14. None of these things are inherently bad — in fact, people have been complaining about the lack of improvements to things like FaceTime for years — but what’s interesting is Apple’s choice to bundle them together as a way to make them look truly meaningful, rather than just fixing many of these issues sooner, in a point release. I’m aware there’s a slew of tiny other fixes and features I haven’t listed here, but that’s my point: it’s a hodgepodge of things that have been neglected over the years after being debuted once and forgotten about. Here’s the rub: Apple could arguably ship notification improvements to iOS users tomorrow in a point release, iOS 11.5, but it won’t. Combining them provides the illusion of progress. Instead of servicing users and giving them features sooner, on a regular basis, Apple chooses to hold back simple functionality longer, for its bottom line. As Martin Bryant points out, Apple may have a timing problem: Yes, Apple needs to take the time to do ‘boring’ optimisation work on iOS, but why build iOS around these big, annual feature bumps and then disappoint people when the bumps aren’t very big?

Interestingly, the narrative here actually doesn’t make sense anymore, either. Every year, Apple takes the time to point out how dire the state of the competition is: Nobody’s Android phones get updates! Android people don’t get any the latest features! Your phones all suck! The reality is different: Android users, regardless of manufacturer, frequently get them sooner than iOS users do, because Google divorced the operating system and core application suite from one another. Google’s approach to unbundling Android has, for the most part, been quietly successful — in an unexpected way. Instead of shipping monolithic feature updates, Google’s applications are now updated via the Play Store, from the clock app to the calculator and even the camera (unless you’re Samsung). Apple has made a yearly ritual out of jabbing competitors for poor update histories, but conveniently omits the reality that improvements to Google Assistant, the built-in web browser, or even just the OS keyboard will reach billions of users in a matter of hours without needing to update the entire phone. Android’s support libraries mean developers can target older devices, with new features, regardless of whether or not they received the OS update. Meanwhile, if you find a bug in the iOS keyboard, or some weird security flaw in Safari’s web view, you hope it gets fixed in the next version of the operating system. Maybe next year, or the year after that. It depends how bad it is, or if Apple is actively maintaining the feature, as to when it’ll get serviced. Don’t get me wrong, Android has a terrible history of updates that is only now beginning to change, ten years after the fact. Google has made strides with Project Treble, which makes an end-run around the device maker itself, but it’s only in its infancy with new devices picking it up today. That’s not good enough either; but it’s gaining traction and getting things into people’s hands. For each platform update, Apple dangles a carrot. That’s the flagship feature to convince you it’s a Big Update™ worth having immediately. On macOS this year, that’s dark mode, and on iOS, the promise of performance improvements and, god forbid, actually decent notification management. Arguably the most interesting segment out of WWDC happens at the very end of the two-hour keynote: a peek at Project Marzipan, a long-term effort to unify the interface framework developers use to build apps for iOS and macOS, which is expected to ship to everyone in 2019.

From where I sit, this is an impressive, massive project that doesn’t do much more than play defense against Electron’s continued march on Apple’s territory, threatening to kill native application development altogether. Why build anything native at all, when you can write once, and run everywhere? Anti-Electron fans will run rabid at the idea, but as the technology has become more efficient and introduced lower-level API access, it only makes even more business sense. Marzipan is an audacious plan to defend against that by making it easier to build cross-platform apps. It’s a genuinely fascinating play with fewer apparent benefits in the short term over just building an Electron app, which addresses an additional billion users, allows developers to use familiar web technology and is truly write-once-run-everywhere. Over time, Marzipan may win favor with developers, but I’m not convinced it’ll stop web-based technologies swallowing native app development whole, particularly given that both Microsoft and Google have now bet their entire strategies on Progressive Web Applications, and how low the barrier of entry has come as a result of Electron’s success. Marzipan indicates something bigger, of course, such as an impending shift away from Intel chipsets entirely to some sort of custom Apple ARM-based silicon in — shock horror — a productivity form factor. If anything, what will win as a result will be that control, and what it could ship in a end-to-end device: true all-day battery? Always-on LTE with desktop class apps? If so, the message is this: lock in with us, develop for our platforms, and we’ll reward you. Don’t, and you’ll be shut out and stuck on the outside. Hey Siri, where’s the vision?

What’s clearly missing in all of this is a willingness to take risks, or go for the long view on what’s better than the status quo for Apple’s users. Instead of looking at how phone usage is changing and redesigning the nature of iOS, it’s another year of shoehorning new features into a decade-old shell. The new shortcuts feature promises to let users wire up workflows of their dreams, chaining together tasks behind a single button. Yes, this is a great improvement to iOS that addresses a problem without actually improving on the reason anyone needs this in the first place — it’s just glued onto the homescreen that’s responsible for causing the need for it in the first place. Apple could have offered up a way to surface the weather right there, deeply integrated with the lock screen, or calendar events at the top of your home screen along with the icons, but it didn’t. Instead, it slathered what appears to be a UX hack in the shape of a notification, and tries to guess when you want to see it. Google’s own developer conference, just down the street in Mountain View, was held in May and offered a clearer, if poorly highlighted, view of the future: AI is a core part of mobile devices going forward, so we’re beginning to add it everywhere. The Android alternative to Shortcuts, Slices and App Actions, surfaces the device’s best guess at your next action as a deeply integrated interface component, where you can actually see information before actually going further in, or taking an action. Want a button to order a Lyft? Great, here’s a button embedded within the system’s app tray, with the current estimated price of your ride, which orders it right now with a single tap. Much of this data is crunched on device, just like Apple’s audacious claims to privacy brag about as well, but instead of being a UX hack to add buttons that summon help, the information is already right there, on hand, without opening anything, even Assistant. Google and Apple both anticipate a future in which we use our phones less — time well spent is a core part of this driver — and as a result, it appears Google has spent a lot of time thinking about how AI can help get the right information to the user. The result is the exact button they need at the right time, with relevant information, sans the need to actually go away and do something. To facilitate this, Google is willing to rejig the UX of its devices, mess with the sea of icons, and has invested heavily in serendipitous computing with Google Home alongside this, so it can get you there faster regardless of if the phone is in your hand.

Google’s vision of the future of smartphones, mobile operating systems, and the way we’ll interact with devices over the long haul is a coherent, well-told story: get more out of your day, get the devices out of the way. It even has a fantastic page that showcases how its own ecosystem works better, together, than I’ve ever seen explained about Apple’s ecosystem on its own site. As for why all of this happens, I suspect it’s a difference in strategy and approach. Apple’s strategy has long been to monetize its existing cash cows as long as it can by throwing out new stuff to see what sticks and doubling down on that, rather than creating any sort of coherent narrative of what the future actually looks like, operating in secrecy until it somehow lands upon it. Incremental improvement is fine, but there’s a distinct lack of forward-looking, and a whole lot of looking over the fence at what everyone else is doing to bash it instead. Apples, oranges and comparing the two

It’s easy to compare and contrast Google and Apple because they are very different companies, but what they’re both claiming to do is the same: invent the future, whatever that actually might be. Their approaches, however, are increasingly diverging: Apple’s squeezing more out of less, shipping flashy features, and focusing on privacy, while Google and others have pushed further into understanding the user and getting out of their way. Most of this comes down to business model. Apple’s focus on features by piling them together drives more sales of iPhone, which drives reliable revenue on a yearly basis. Google’s is on advertising and relevance to the user, which doesn’t depend on a particular feature or thing to tout, it just needs you to love using its tools (and not mind advertising). Apple’s entire strategy over the last two decades has pivoted around the exploitation of a product line until something new comes along, then rinse and repeat. This is framed around improving your life and often actually does, even if that is by proxy. I’d argue that the company’s vision of the future isn’t to enrich, or drive progress, but to squeeze as much revenue as possible out of slick, well-designed and marketed ideas. The products it builds, the cycles they’re released in and the way that Apple’s entire software cycle works reflects this. An example of the manifestation of this is perhaps HomePod’s requirement to have a locally available iPhone to do anything interesting, leaving it crippled without one, and Animoji’s debut only to be locked away in Messages instead of somewhere like the camera.

Google, a latecomer in the game, has the luxury — and peril — of not depending on phone revenue, so it can risk it all and get weird, since it’s not fundamentally critical to the company’s continued trajectory. Microsoft has done the same, now finding itself the underdog, risked it all and moved to an ‘OS-as-a-service’ model in which it ships features when they’re ready instead of waiting for flashy releases. Apple, on the other hand, begins and ends with the iPhone today, the rest flows from there. It can’t just rip up the foundation on which its revenue exists, and Tim Cook hasn’t shown a flair for doing so. iOS is too valuable to go away and tear down to just reimagine it for fun, so it’s the status quo, with experiments like HomePod and AirPods on the side, where it can get weird and sometimes wonderful. That’s fine, because Apple has plenty of cash lying around, but it’s interesting how limiting the approach can become. As we hurtle toward peak smartphone, the cracks here are beginning to show because Apple don’t have the next big thing yet — that we know of, naturally — and it’s taking a long time to get here. We’re essentially watching the bottom of the metaphorical tube of toothpaste being squeezed, while others are trying to figure out if maybe the tube should work completely differently. AR is potentially the next platform, yes, and it’s clear that Apple is pushing forward on that in a big way, so it’s easy to imagine a scenario in which it makes sense to shift precious resources there instead of focusing on iOS which may wind up unimportant in a year or two. I’m not convinced that in the short term, such as the oft-claimed 2020 launch date of an Apple VR/AR headset, that we’ll be headed there in any meaningful capacity. I mean, Magic Leap, a bajillion dollar company building the future of AR showed off its hardware yesterday on Twitch, quipping that “you better not put it in your pocket or it’ll overheat.” I’m happy to be wrong, and I write this knowing I’ll probably be that guy who very publically crapped on the iPhone at launch later. Apple’s worth a very large amount of money, which is more than enough proof that it’s good at many things, including convincing people to buy a phone every year.",https://cdn-images-1.medium.com/max/1200/1*tIUbwrpHZPbdNPXB569wPQ.png,[],https://medium.com/@ow/apple-has-no-idea-whats-next-so-it-s-just-banging-on-the-same-old-drum-dcfd0179cf80?source=grid_home---------0------------------18,2018-06-07 13:54:23.876000+00:00

NLP,Our Wedding Is Canceled Due to the Following Strongly-Held Beliefs,['Tim Sniffen'],"Hi, everyone. I know you weren’t expecting to see Keith and I out here so soon, but we have some bad news. We’re not getting married today.

Believe me, we were really looking forward to it, but recently — this morning, in fact — we learned our blessed event was in direct conflict with the strongly-held beliefs of many of the people providing our wedding services. And if they’re not happy, we’re not happy.

Let me bring you up to speed.

You may have noticed the empty display table by the reception tent as you filed in. That’s where our wedding cake would have been. For our baker, however, creating a cake to be employed in the marriage of two men would be the moral equivalent of using communion wine to make sangria.

We knew the risks when enlisting Give Us This Beignet, Our Daily Bread as our wedding baker. They’re the best in downtown Aurora, no question — sorry, Wild-Flour! — but their beliefs on same-sex marriage are no secret. We hoped they might get swept up in the joy of the occasion but last night their chief baker Jonah, applying the final bit of piping, had a vision of Billie Jean King physically dragging him away from the gates of Heaven. And if that’s not a sign, I don’t know what is.

I should add, it may not have helped that we requested our little cake figurines be surrounded by an added semi-circle of figurines, in likenesses of the bakery staff, giving us the thumbs-up.

But that’s all done with. They’ve made their wishes clear and we respect them.

Which brings me to the empty vases alongside the pews and the empty centerpiece bowls on the reception tables. We’ve known Joyce Gantz, owner of Rest On My Laurels, for years; I couldn’t imagine this day without her. What I couldn’t know was the war raging within Joyce, fervent Catholic, after she learned of the meat-laden Friday barbecues Keith and I throw for our softball team. Last night, Joyce looked deep within her heart to ask, can I lend my good name to this cursed union?

The dumpster full of imported delphinium behind Joyce’s shop can tell you the answer.

You see, what we’re learning is that these are not just goods and services; they’re not simply the imprints of Keith’s Capital One card and the resulting exchange of goods. Every item at a wedding is nothing less than the avatar of its vendor’s entire belief system. With this in mind, each rose petal my niece Stephanie was prepared to hurl down the aisle might as well have been embossed with JOYCE GANTZ APPLAUDS THEE, SATAN.

What faith-engorged entrepreneur should face such hell?

This is why the rows of steam-trays in the tent are empty, and your choice of beef tenderloin or grilled salmon — or the one plate of tempeh veggie kabob, bless you, Amy! — will never arrive. Because Something Borrowed, Something Cordon Bleu, exceptional wedding caterers and unapologetic druids, could not bear the thought of providing nourishment to a couple willing to rip two thriving Magnolia trees from their backyard last summer. From their email: “Your heretic’s feast will be served when the earth heals from your violence.” By our best guess that wouldn’t have been by 6 p.m.

We also won’t be dancing to Renèe and the Ring-tones. While Rènee was a woman of few beliefs when we booked her, she has since converted to the Egyptian cult of Bastet, and considers the choice to put our cat Banjo to sleep, rather than pay $15,000 for experimental feline jaw surgery, to be “unforgivable wickedness, worthy of disciples of Set.”

I’ve been handed this note: Lane, our photographer, turns out to be more of a Star Wars guy and doesn’t feel right legitimizing such an obviously Star Trek couple.

Blessings on your journey, Lane.

In closing, our apologies. We were so busy coordinating our big day that we forgot to coordinate the sacred truths of all players involved. I’m told many of our vendors will adopt an exhaustive three-week interview process before each sale to keep this from happening again.

We did have a lovely wedding favor created for each of you, which we might as well distribute. It’s a wooden plaque, engraved with the phrase Love Conquers All, hand-crafted by our friend Bryce Charles in the front row. Now, Bryce is something of a Packers fan, and Keith is all about the Bears, but in the spirit of friendly rivalry, we’ve always managed to put aside our differ — wait.

Bryce’s feelings are changing.

They’re moving from loosely-held to nonchalantly-held. They’re not done; from the set of Bryce’s jaw, her feelings have transitioned to intentionally-held, and finally, they’re — yup. They’re strongly-held. Dammit.

Sorry, folks. You’re on your own.",https://cdn-images-1.medium.com/focal/1200/632/50/45/0*fh1vaEnMNoMbHE42,[],https://medium.com/s/story/our-wedding-is-cancelled-due-to-the-following-strongly-held-beliefs-1fa71105660e?source=grid_home---------0------------------18,

NLP,My So-Called (Millennial) Entitlement – Trust Issues – Medium,['Stephanie Georgopulos'],"I am at the San Francisco International Airport some barely recent morning, registering for a travel program called Clear when the automated kiosk assisting me makes a strange request: “Stand still while we scan your irises.” I’ve barely digested this first ask when another takes its place: this time, the kiosk wants my fingerprints. I find this slightly less alarming; I already use those to access my banking app, buy coins for my mobile games, and unlock the phone that hosts all this information in the first place. But my eyeballs — which I had only just learned could be used as ID, and from a machine at the airport, no less — my dude. Those are the windows to my soul! Ever heard of foreplay?

Clear is a private company that prescreens air travelers using biometric authentication. Becoming a member is like ordering the half-soup, half-sandwich version of TSA PreCheck: it works, if all you want is a taste and are willing to pay for it. With Clear, you don’t need your ID to go through security, but you still have to remove your shoes. You get to wait in a shorter line (sometimes), but you still have to take out your laptop. Basically, the Cleared still participate in the most annoying aspects of air travel and pay almost 10 times the PreCheck fee for the privilege.

If the worst has already happened, that means it’s survivable.

How we decided on this valuation of convenience—it’s $179 per year—is not the point, though. My point is that some random startup casually acquired my eye-prints, and some small voice is telling me I should care more than I do. Someone out there definitely cares about this, no doubt. I’m sure at least one other traveler was not sated when a brisk Google search revealed that Clear is based in her hometown and run by a female CEO, ergo it must be a secure and entirely trustworthy business.

But I was sated. It’s the future, right? What’s the worst one could do with my retinal scans? I already gave my social security number to Camel in exchange for a pack of promotional cigarettes one time (or 12). Somewhere in Midtown Manhattan, a market-research firm knows how many condoms I used in May of 2011 (give or take). And when I think about the fact that every hard document I’ve reproduced on a digital copy machine — at work, at the bodega, at the library — is saved on a hard drive somewhere (lots of somewheres, in fact), I feel a sense of hopelessness that, in its own demented way, translates to freedom.

That’s why I unlock my phone with my fingerprint. It’s also why I talk shit in front of Alexa, why I haven’t put tape over my laptop camera, and why I still have a Facebook account. I don’t expect the worst to happen.

Because the worst has already happened. It is happening, and it will continue to happen.

I find this to be an honest, useful framework. If the worst has already happened, that means it’s survivable. And if the worst is a given in the future, too, we know that ignoring it won’t make it go away. There’s opportunity in having nothing to lose. You just need the right attitude.

Or perhaps you need the right conditioning.

Imagine: You’re 11 years old when two teenagers bring guns to their high school and kill 13 people. They injure 21 more. Your sixth-grade humanities teacher explains the inexplicable to your class after lunch period. You have to imagine that this is a first for at least some of your classmates, crying over the national news. It won’t be the last.

When you’re 15, two planes crash into two towers. You know the towers; had toured them on school trips just like all the other famous Manhattan buildings for which you know the names, if not the functions. In fact, you’d visited the towers just one week before the planes hit. There had been a renaissance fair in one of the lobbies.

At 17, your high school economics teacher tells you that social security will run out before you retire. You’ve already been paying taxes for three years. In 2018, you learn that he was exaggerating, thank goodness — by 2034, retirees can expect to receive a whopping 79% of the full benefit they receive today. You will not be of retirement age until the 2050s.

And when you’re 21, the market crashes. You’ve had a bachelor’s degree for three months. It cost $100,000 to earn, all before interest. Your class valedictorian moves back in with her parents, and no, your internship is not hiring. Five years later, the unemployment rate for people your age is almost double the national average.

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

Neuroscience has confirmed that you were making sense of these events with an underdeveloped brain. Along with your emotional maturity and your hormones, it’ll be a work-in-progress until you’re around 25. And the same way the small hurts of being small can still seep into your present — the way your grandmother eyed you with disgust when you went for a second helping — the chipping away of every institution you were raised to believe in can have unintended consequences.

Me: Do you use Touch ID to unlock your phone?

Friend: Ya.

Me: Do you know anything about the technology behind it? Or like, how secure it is?

A beat. A blank stare.

Friend: No?

Me: Same.

My friends do not need to understand the technology behind touch ID any more than they need to understand black holes. They are not convinced that adjusting their social media privacy settings is some sort of moral duty, a symbolic middle finger to Facebook on behalf of all the little guys who understand internet economics to varying degrees, or not at all. Mostly, they were confused as to why any thinking person would have an assumption of security.

“It’s not that I don’t care about being hacked, or about my data being stolen or sold,” one friend tells me. “I assume that vulnerability because there are no physical systems or structures that have succeeded, so why would something that is essentially invisible do a better job than something tangible?”

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

I’ll go: I don’t expect to own a home. I don’t expect to retire well, or at all. I don’t expect anyone to give me anything I haven’t explicitly asked for, and even then. I don’t expect it will ever be affordable to continue my education in any formal way. If a package gets lost in the mail, I don’t expect to see it again. I don’t expect the government or the banks or the universities to do anything that benefits regular people. I don’t expect them to hold each other accountable on our behalf. I don’t expect them to expel abusers from their ranks, or to put my safety over their legacy. I don’t expect to feel safe in large crowds or alone late at night. And I don’t expect that my privacy will be respected, online or in general.

America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

As far as I can tell, security — whether financial, technological, physical, or emotional — is not a thing. You don’t get to decide whether some drunk asshole drinks his drunk ass off and gets behind the wheel. Likewise, you don’t get to decide if the drunk Congress or the drunk banker or all the drunk administrations of all the drunk institutions do what’s right for you. Sometimes they will do the right thing for somebody, but statistically speaking, that somebody is not you.

Sometimes the right thing comes served in a shit sandwich, or one guy does the right thing but it’s later counteracted by the next guy and just so we’re clear, it’s always a guy. Or sometimes, we learn that what we thought was the right thing was actually the wrong thing, in ways we didn’t anticipate, except for those of us who did anticipate it but were not asked or heard because we do not employ lobbyists and because the powers that be can’t listen to us until they sort out whether our bodies are legal or not.

Mark Zuckerberg’s Congressional hearing was probably the biggest mainstreaming of data privacy issues yet, and Facebook, with its many transgressions, made for an appropriate scapegoat. But I want to know why it’s Mark Zuckerberg’s fault that American adults of voting age lack the critical thinking skills to differentiate between fake Russian bot news and The Guardian. I want to know the plan for bringing internet literacy to those who are not digital natives. I want to know why the U.S. government is being celebrated for protecting our egos and baby-proofing the internet instead of telling us the truth: Dirty tricks are less likely to work on people with more education.

What happens when your brand of exceptionalism breeds millions of people who voted a sentient conspiracy theory into office? Where does the fault lie? After all, it’s not Facebook who’s spent decades underpaying teachers and closing schools in low-income neighborhoods. Facebook doesn’t have the jurisdiction to end standardized testing or combat the quiet continuation of white flight. Facebook’s biggest mistake? Profiting off of state-sanctioned dumbness.

We’re only supposed to be dumb enough to believe that the fight is red vs. blue and not top vs. bottom. We’re only supposed to be dumb enough to believe in Democracy the Concept™ without casting a critical eye toward its practical application. This is a dumbness cultivated by and for Washington, and Zuckerberg’s misusing of it for corporate gain almost blew the lid off the entire thing. Commence finger-wagging.

On an episode of his podcast Revisionist History, Malcolm Gladwell argues that we should treat education as a weak-link network, where strengthening the weakest links has the most positive outcome for all. This is in contrast to a strong-link network, where a couple of superstars at the top carry the weaker players on the bottom. He illustrates this dynamic using soccer and basketball. An average soccer team with one star player is less likely to win a match than an above-average team with no star players — soccer is a weak-link sport. Conversely, an NBA team with a superstar or two fares better than a team on which all the players are equally, decently good — basketball is a strong-link sport.

Much to its detriment, America acts like a strong-link country. It is the type of place where electing one mixed-race president means we solved racism. (Imagine if the lesson we took from electing one white man was that all white men who lack upward mobility just need to work harder.) We raise up a few undoubtedly smart and deserving people in each field, send them around the world like brand ambassadors for democracy, poster-adults for how advanced and distinguished and American we are. Meanwhile, most of us back home — 78%, in fact — are living paycheck to paycheck. Is that freedom ringing? We’ll call right back after we pay this phone bill.

These are complex problems. In addition to the 3000ish words here, I have written and cut an additional 4500 trying to make sense of it all. I remain overwhelmed by the number of solutions that contradict one another, the knowns and unknowns, the countless logical ends I haven’t considered. But I eventually found my demented silver lining: America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

While grim on its face, this perspective has pushed me to take inventory of myself, my own power. What can I do right now? Am I solving problems I actually care about, or were these problems unconsciously inherited from another time, problems propagated by those with a vested interest in resolving them with more money, more power, more loopholes? Should I devote my energy to righting a system that, by design, has only consistently benefited one demographic and has yet to even prove itself as a scalable model for a generation that’s tired of the same people making the same decisions on behalf of the most diverse country in the world?

Is that a problem? Because it feels more like an opportunity, to me: a chance to exercise this cache of personal agency I’ve been sitting on, agency I didn’t realize I had or needed as I waited for America to work. It feels like an opportunity to try something else.

More powerful than having nothing to lose is cultivating that which can’t be taken. Grace. Clarity. Purpose. The stuff that isn’t Amazon Prime-able. These are the indoor plants of our being; only you can feed them and grow them and expose them to the light. It’s a lot of responsibility, and the work involved is often unglamorous. Some people think they never have to learn to care for these things because they have the means to outsource what they wish: their plants are alive on paper though they don’t know the how or why of it. And besides, can’t you see they’re a little busy trying to colonize Mars?

A respectable goal, though I might suggest to anyone faced with the choice to try taking on the inner self before jumping ahead to outer space. There’s more to unearth in there than you might think, and we need more people to understand the potential of their own organic material. We need people who appreciate the slow growth of nothing into something, who drink up the sunlight and make the air a little more breathable than before.

Because that’s it, for most of us. That’s how we build power. That’s how we, a generation of janitors for the American dream, put our trust in something real: each other. We stop trying to control the world in our heads and in the headlines, and we start controlling ourselves. We sleep. We go to the doctor. We log off. We talk about our problems. We water our plants. We collect our neighbor’s mail when they’re out of town. We take a deep breath before reacting in anger, and question whether this particular battle is worth our energy. It’s not. Why were we fighting again? We volunteer. We water our plants. We focus on ourselves so we can eventually focus on others — in a real way, in a non-transactional way, in a way that slowly but authentically strengthens our fellow weak links. We don’t wait for permission. We get over ourselves; we stop demanding perfection; we start. We water our plants. And on weekends, we play soccer.",https://cdn-images-1.medium.com/max/1200/1*c5zNxCX34sYmYYO-yRxlbA.png,[],https://medium.com/s/trustissues/my-so-called-millennial-entitlement-9be84343c713?source=grid_home---------0------------------18,

NLP,How to Cope with the End of the World – How to Cope With The End of The World – Medium,['Maria Farrell'],"We All Die, and That’s Okay

My favorite postapocalyptic novel is George R. Stewart’s 1951 Earth Abides. In it, scientist Isherwood Williams (nicknamed Ish) survives a plague and eventually starts a new family and community in the ruins of suburban California. His hope for the future is wholly invested in a child who is intellectually curious, like him, and who might be able to revive some of the old ways and technologies. It’s an observant and reflective novel, full of the “how stuff would probably work” thinking that makes science fiction the true literature of ideas.

Ish starts out as a scientist-savior of humanity, figuring there is just enough time to raise a generation to turn back the clock to before the disaster. But he ultimately has to make his peace with the fact that civilization as he knew it is dead, there will be no heroic rescue, no going back, and the people around him are mostly fine with that.

The 1950s may have been the last decade we could complacently believe the Ecclesiastes (1:4) maxim that “men come and go, but earth abides,” but Stewart’s basic message is correct.

The people who come after us don’t have to do better than us, or think well of us, for them to be essentially okay. And us all throwing a big “let’s blow it all up” hissy fit because we fucked up and we can’t bear to look at it is just teenage nihilism that we need to grow out of already. Coming to terms with what we have done means dumping the egotistical death drive of the mass shooter or far-right politician and gathering the maturity to look our individual and collective deaths straight in the eye and say, “Okay, we get it now. We get it. It’s not about us.”

Have you ever stood in a crowded place like a town square or an airport meet-and-greet and thought, “Every single person here is going to die”? Morbid, eh? More of us should do it.

I live in an early Victorian terraced house in the UK. It’s never been a tenement, so probably a hundred people have called it home in the almost two centuries it’s been standing. Nearly all of them are dead. The people are already born who’ll live there when I’m dead. The head of this country’s anachronistic state has already been born who I’ll never see on the throne and to whom I’ll seem as old as someone born in the 1930s seems to me.

We’re all going to die. The morning will come when those who have loved us put on dark clothes and cry and get on with the rest of their lives, seeing movies we’d have loved, depending on gadgets that now seem to us ridiculously unnecessary. Our deaths matter to us and those who love us, but they don’t fundamentally matter.

Once, while my husband was deployed to Afghanistan, I asked him on the phone if he was doing okay about someone we knew who’d recently been killed. “Oh, you know,” he said, “you know,” and quoted his regiment’s unofficial mantra:

Everything matters. Nothing matters terribly.

The soldier’s death mattered very, very much to him, and (not but) he and others were nonetheless carrying on their shared purpose. Otherwise, what had been the point of any of it?

What will outlive us, individually? Plastic. Perhaps some genes. The bacteria that act as a species-level enabler for everything we are. Some ideas, maybe, or songs, stories, pictures, the memories of us others hold, until they go, memorials like a community flower bed or a named scholarship, for a while, anyway. Less concretely: ways of being, a fitness for the world that those who flourish pass unremarked to their offspring via the epigenetics of love — the sunny inverse of patterns of trauma and abuse transmitted through the body, even unto the third generation. Predation.

And our species? Buildings and bones, maybe. Our nuclear waste and the warning signs we hope people of our deep future, or other species altogether, will decrypt. Snatches of radio-transmitted voices slipping through the vacuum of space. Perhaps some bacterial payload we’ll launch in a decade or so, trying to seed life on other planets, even in other solar systems. Or just the anomalous levels of carbon dioxide and methane in our atmosphere that will reveal, for a time, that complex forms of life were here.

Pride and despair are two sides of the same coin. Our collective denial and despair about the future we have built is preventing us from cracking on and sorting it out. We need to get over ourselves. The world we know will end, in both small and big ways. We ourselves will end. But that doesn’t matter, terribly.

Our mortality is the greatest enabler we have of positive, ongoing change, if only we can face it, if only we can understand that we don’t get to see the end of the movie, because, if what we do works, the movie won’t have to end. We’re not the protagonists. We’re just the foreshadowing. We need to hold the knowledge of our own deaths up to the light and turn it around to see each shining facet, then take the certainty that we are both finite and imperfect deep down inside of us—and put it to work.",https://cdn-images-1.medium.com/max/1200/0*avXWZmh3n3H7a8t8,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world/how-to-cope-with-the-end-of-the-world-2520ef9d3dbc?source=grid_home---------0------------------18,

NLP,How to Cope With The End of The World – Medium,['Maria Farrell'],"COLUMN

How to Cope With The End of The World

There are moments of joy even in times of great despair. Maria Farrell explains how to deal with a darkening world, and how to plan for the end. It might be the end of the world as we know it, but it turns out we feel fine.",https://cdn-images-1.medium.com/max/1200/1*kvqwUuDCsbkAoSfaYXV1vQ@2x.png,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world,

NLP,Chatbots were the next big thing: what happened? – The Startup – Medium,"['Matt Asay', 'Justin Lee']","Chatbots were the next big thing: what happened?

Oh, how the headlines blared:

“…the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”

Chatbots were The Next Big Thing.

Our hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.

And why wouldn’t they be? All the road signs pointed towards insane success.

Messaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!

Plus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.

At the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.

In fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:

“Will a single platform emerge to dominate the chatbot and personal assistant ecosystem?”

One year on, we have an answer to that question.

No.

Because there isn’t even an ecosystem for a platform to dominate.

Fooled by another hype cycle

Chatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.

The age-old hype cycle unfolded in familiar fashion…

Reverential TechCrunch articles were written.

Prophetic thought leaders like Chris Messina chimed in.

Silicon Valley salivated at the prospect of talking to smart automation.

Messenger began to overflow with bots.

Slack went through exponential growth and even launched a fund for bot investment.

Expectations built, built, and then….. It all kind of fizzled out.

The predicted paradim shift didn’t materialize.

And apps are, tellingly, still alive and well.

We look back at our breathless optimism and turn to each other, slightly baffled:

“is that it? THAT was the chatbot revolution we were promised?”

Digit’s Ethan Bloch sums up the general consensus:

“I’m not even sure if we can say ‘chatbots are dead,’ because I don’t even know if they were ever alive.”

According to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.

Text vs. Speech vs. GUI: a potted history

Bots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.

Users had to type commands manually into a machine to get anything done.

Then, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!

Meanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.

Another bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:

… so many different accents, people speaking too fast or too slowly, mumbling, umming and aahing.

Did you say “recognise speech” or “wreck a nice beach”?

The next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:

User: “Hello.”

Agent: “Hello, what’s your name?”

User: “Candy.”

Agent: “Hello, Candy!”

User: “Let’s set the clock.”

Agent: “What is the time?”

User: “The time is 11:00 AM.”

Agent sets the clock to 11:00 AM.

Pretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.

It was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.

Modern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.

Basically, we’re still trying to achieve the same innovations we were 30 years ago.

Here’s where I think we’re going wrong:

Thinking in terms of Bots vs. Apps

An oversized assumption has been that apps are ‘over’, and would be replaced by bots.

By pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.

You might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?

It’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.

Whether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.

Plus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.

A great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.

That’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.

Modern-day apps benefit from decades of research and experimentation. Why would we throw this away?

But, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.

Today’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.

Penny provides chatty advice and alerts alongside a traditional account dashboard and transaction list.

HubSpot Conversations unifies Facebook Messenger, onsite chat, social media, email and other messaging outlets into one shared inbox.

Layer gives developers the tools to create personalized messaging experiences on mobile web and desktop web as well as native apps.

The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.

Bots for the sake of bots

Does my product need a bot? Are existing platforms able to support its functionality? Do I have the patience to build a bot that’s capable of doing what I want it to?

Another problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.

For plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.

Building a bot for the sake of it, letting it loose and hoping for the best will never end well:

The totally necessary Maroon 5 chatbot in action

The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.

The advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.

That’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.

Problems arise when life refuses to fit into those boxes.

According to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.

When we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.

Remember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.

Inaccessibility

A competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.

In an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.

Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)

As Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.

“Consumer interest was never going to materialize until machine intelligence could get anywhere near human intelligence.

User interest depends upon AI that makes talking with a bot worthwhile for consumers.”

And conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.

Today’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.

And in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:

“Should Slack, Facebook, Google, Microsoft, Kik, and others have built their own built-in bots to lead the way?

Should they have gotten more proactive with their bot funds and incubators, hiring mentors to educate participants in the Way of the Bot, or supplying engineering and design resources? Funded Strategic Bot Initiatives at high-profile partners?

In my opinion yes, yes, and yes. When it comes to platforms, developers are the users; and we don’t rely on our users to understand why or how to use our products. We have to show them.”

GUI shouldn’t be dismissed

Once upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information

There’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.

Tapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.

We love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.

Conversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.

Sure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.

Humans like talking to other humans

Aiming for a human dimension in business interactions makes sense.

If there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.

Facebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.

A conversation encompasses so much more than just text.

Humans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.

As HubSpot team pinpointed:

Bots provide a scalable way to interact one-on-one with buyers. Yet, they fail when they don’t deliver an experience as efficient and delightful as the complex, multi-layered conversations people are accustomed to having with other humans on messaging apps.

People aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).

And even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.

And here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.

But is that how humans prefer to interact with machines?

Not necessarily.

At the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.

Where do we go from here?

In a way, those early-adopters weren’t entirely wrong.

People are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.

Not even close.

Computers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.

Computers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.

That’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.

For now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.

But that’s not the whole story.

Yes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.

As Bill Gates once said:

We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. Don’t let yourself be lulled into inaction.

The hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.

I believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.

Messaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.

Developers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.

And I can’t wait to see what happens next.",https://cdn-images-1.medium.com/max/1200/1*-_um8Nai0uer46tni1LETg.jpeg,[],https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=topic_page---8------0----------------,2018-06-05 15:55:36.912000+00:00

NLP,Google’s AutoML will change how businesses use Machine Learning,['George Seif'],"Google’s AutoML will change how businesses use Machine Learning

Google’s AutoML is a new up-and-coming (alpha stage) cloud software suite of Machine Learning tools. It’s based on Google’s state-of-the-art research in image recognition called Neural Architecture Search (NAS). NAS is basically an algorithm that, given your specific dataset, searches for the most optimal neural network to perform a certain task on that dataset. AutoML is then a suite of machine learning tools that will allow one to easily train high-performance deep networks, without requiring the user to have any knowledge of deep learning or AI; all you need is labelled data! Google will use NAS to then find the best network for your specific dataset and task. They’ve already shown how their methods can achieve performance that is far better than that of hand-designed networks.

AutoML totally changes the whole machine learning game because for many applications, specialised skills and knowledge won’t be required. Many companies only need deep networks to do simpler tasks, such as image classification. At that point they don’t need to hire 5 machine learning PhDs; they just need someone who can handle moving around and organising their data.

There’s no doubt that this shift in how “AI” can be used by businesses will create change. But what kind of change are we looking at? Whom will this change benefit? And what will happen to all of the people jumping into the machine learning field? In this post, we’re going to breakdown what Google’s AutoML, and in general the shift towards Software 2.0, means for both businesses and developers in the machine learning field.

More development, less research for businesses

A lot of businesses in the AI space, especially start-ups, are doing relatively simple things in the context of deep learning. Most of their value is coming from their final put-together product. For example, most computer vision start-ups are using some kind of image classification network, which will actually be AutoML’s first tool in the suite. In fact, Google’s NASNet, which achieves the current state-of-the-art in image classification is already publicly available in TensorFlow! Businesses can now skip over this complex experimental-research part of the product pipeline and just use transfer learning for their task. Because there is less experimental-research, more business resources can be spent on product design, development, and the all important data.

Speaking of which…

It becomes more about product

Connecting from the first point, since more time is being spent on product design and development, companies will have faster product iteration. The main value of the company will become less about how great and cutting edge their research is and more about how well their product/technology is engineered. Is it well designed? Easy to use? Is their data pipeline set up in such a way that they can quickly and easily improve their models? These will be the new key questions for optimising their products and being able to iterate faster than their competition. Cutting edge research will also become less of a main driver of increasing the technology’s performance.

Now it’s more like…

Data and resources become critical

Now that research is a less significant part of the equation, how can companies stand out? How do you get ahead of the competition? Of course sales, marketing, and as we just discussed, product design are all very important. But the huge driver of the performance of these deep learning technologies is your data and resources. The more clean and diverse yet task-targeted data you have (i.e both quality and quantity), the more you can improve your models using software tools like AutoML. That means lots of resources for the acquisition and handling of data. All of this partially signifies us moving away from the nitty-gritty of writing tons of code.

It becomes more of…

Software 2.0: Deep learning becomes another tool in the toolbox for most

All you have to do to use Google’s AutoML is upload your labelled data and boom, you’re all set! For people who aren’t super deep (ha ha, pun) into the field, and just want to leverage the power of the technology, this is big. The application of deep learning becomes more accessible. There’s less coding, more using the tool suite. In fact, for most people, deep learning because just another tool in their toolbox. Andrej Karpathy wrote a great article on Software 2.0 and how we’re shifting from writing lots of code to more design and using tools, then letting AI do the rest.

But, considering all of this…

There’s still room for creative science and research

Even though we have these easy-to-use tools, the journey doesn’t just end! When cars were invented, we didn’t just stop making them better even though now they’re quite easy to use. And there’s still many improvements that can be made to improve current AI technologies. AI still isn’t very creative, nor can it reason, or handle complex tasks. It has the crutch of needing a ton of labelled data, which is both expensive and time consuming to acquire. Training still takes a long time to achieve top accuracy. The performance of deep learning models is good for some simple tasks, like classification, but does only fairly well, sometimes even poorly (depending on task complexity), on things like localisation. We don’t yet even fully understand deep networks internally.

All of these things present opportunities for science and research, and in particular for advancing the current AI technologies. On the business side of things, some companies, especially the tech giants (like Google, Microsoft, Facebook, Apple, Amazon) will need to innovate past current tools through science and research in order to compete. All of them can get lots of data and resources, design awesome products, do lots of sales and marketing etc. They could really use something more to set them apart, and that can come from cutting edge innovation.

That leaves us with a final question…

Is all of this good or bad?

Overall, I think this shift in how we create our AI technologies is a good thing. Most businesses will leverage existing machine learning tools, rather than create new ones since they don’t have a need for it. Near-cutting-edge AI becomes accessible to many people, and that means better technologies for all. AI is also quite an “open” field, with major figures like Andrew Ng creating very popular courses to teach people about this important new technology. Making things more accessible helps people transition with the fast-paced tech field.

Such a shift has happened many times before. Programming computers started with assembly level coding! We later moved on to things like C. Many people today consider C too complicated so they use C++. Much of the time, we don’t even need something as complex as C++, so we just use the super high level languages of Python or R! We use the tool that is most appropriate at hand. If you don’t need something super low-level, then you don’t have to use it (e.g C code optimisation, R&D of deep networks from scratch), and can simply use something more high-level and built-in (e.g Python, transfer learning, AI tools).

At the same time, continued efforts in the science and research of AI technologies is critical. We can definitely add tremendous value to the world by engineering new AI-based products. But there comes a point where new science is needed to move forward. Human creativity will always be valuable.

Conclusion

Thanks for reading! I hope you enjoyed this post and learned something new and useful about the current trend in AI technology! This is a partially opinionated piece, so I’d love to hear any responses you may have below!",https://cdn-images-1.medium.com/max/1200/1*g9BzirXxUauRO9rA_tSvnA.jpeg,[],https://towardsdatascience.com/googles-automl-will-change-how-businesses-use-machine-learning-c7d72257aba9?source=topic_page---8------1----------------,2018-05-14 14:27:41.145000+00:00

NLP,Automated Feature Engineering in Python – Towards Data Science,['William Koehrsen'],"First, let’s take a look at our example data. We already saw some of the dataset above, and the complete collection of tables is as follows:

Deep feature synthesis stacks multiple transformation and aggregation operations (which are called feature primitives in the vocab of featuretools) to create features from data spread across many tables. Like most ideas in machine learning, it’s a complex method built on a foundation of simple concepts. By learning one building block at a time, we can form a good understanding of this powerful method.

Fortunately, featuretools is exactly the solution we are looking for. This open-source Python library will automatically create many features from a set of related tables. Featuretools is based on a method known as “ Deep Feature Synthesis ”, which sounds a lot more imposing than it actually is (the name comes from stacking multiple features not because it uses deep learning!).

These operations are not difficult by themselves, but if we have hundreds of variables spread across dozens of tables, this process is not feasible to do by hand. Ideally, we want a solution that can automatically perform transformations and aggregations across multiple tables and combine the resulting data into a single table. Although Pandas is a great resource, there’s only so much data manipulation we want to do by hand! (For more on manual feature engineering check out the excellent Python Data Science Handbook ).

This process involves grouping the loans table by the client, calculating the aggregations, and then merging the resulting data into the client data. Here’s how we would do that in Python using the language of Pandas .

On the other hand, aggregations are performed across tables, and use a one-to-many relationship to group observations and then calculate statistics. For example, if we have another table with information on the loans of clients, where each client may have multiple loans, we can calculate statistics such as the average, maximum, and minimum of loans for each client.

we can create features by finding the month of the joined column or taking the natural log of the income column. These are both transformations because they use information from only one table.

A transformation acts on a single table (thinking in terms of Python, a table is just a Pandas DataFrame ) by creating new features out of one or more of the existing columns. As an example, if we have the table of clients below

The process of constructing features is very time-consuming because each new feature usually requires several steps to build, especially when using information from more than one table. We can group the operations of feature creation into two categories: transformations and aggregations . Let’s look at a few examples to see these concepts in action.

Feature engineering means building additional features out of existing data which is often spread across multiple related tables. Feature engineering requires extracting the relevant information from the data and getting it into a single table which can then be used to train a machine learning model.

If we have a machine learning task, such as predicting whether a client will repay a future loan, we will want to combine all the information about clients into a single table. The tables are related (through the client_id and the loan_id variables) and we could use a series of transformations and aggregations to do this process by hand. However, we will shortly see that we can instead use featuretools to automate the process.

Entities and EntitySets

The first two concepts of featuretools are entities and entitysets. An entity is simply a table (or a DataFrame if you think in Pandas). An EntitySet is a collection of tables and the relationships between them. Think of an entityset as just another Python data structure, with its own methods and attributes.

We can create an empty entityset in featuretools using the following:

import featuretools as ft

# Create new entityset

es = ft.EntitySet(id = 'clients')

Now we have to add entities. Each entity must have an index, which is a column with all unique elements. That is, each value in the index must appear in the table only once. The index in the clients dataframe is the client_id because each client has only one row in this dataframe. We add an entity with an existing index to an entityset using the following syntax:

The loans dataframe also has a unique index, loan_id and the syntax to add this to the entityset is the same as for clients . However, for the payments dataframe, there is no unique index. When we add this entity to the entityset, we need to pass in the parameter make_index = True and specify the name of the index. Also, although featuretools will automatically infer the data type of each column in an entity, we can override this by passing in a dictionary of column types to the parameter variable_types .

For this dataframe, even though missed is an integer, this is not a numeric variable since it can only take on 2 discrete values, so we tell featuretools to treat is as a categorical variable. After adding the dataframes to the entityset, we inspect any of them:

The column types have been correctly inferred with the modification we specified. Next, we need to specify how the tables in the entityset are related.

Table Relationships

The best way to think of a relationship between two tables is the analogy of parent to child. This is a one-to-many relationship: each parent can have multiple children. In the realm of tables, a parent table has one row for every parent, but the child table may have multiple rows corresponding to multiple children of the same parent.

For example, in our dataset, the clients dataframe is a parent of the loans dataframe. Each client has only one row in clients but may have multiple rows in loans . Likewise, loans is the parent of payments because each loan will have multiple payments. The parents are linked to their children by a shared variable. When we perform aggregations, we group the child table by the parent variable and calculate statistics across the children of each parent.

To formalize a relationship in featuretools, we only need to specify the variable that links two tables together. The clients and the loans table are linked via the client_id variable and loans and payments are linked with the loan_id . The syntax for creating a relationship and adding it to the entityset are shown below:

The entityset now contains the three entities (tables) and the relationships that link these entities together. After adding entities and formalizing relationships, our entityset is complete and we are ready to make features.

Feature Primitives

Before we can quite get to deep feature synthesis, we need to understand feature primitives. We already know what these are, but we have just been calling them by different names! These are simply the basic operations that we use to form new features:

Aggregations: operations completed across a parent-to-child (one-to-many) relationship that group by the parent and calculate stats for the children. An example is grouping the loan table by the client_id and finding the maximum loan amount for each client.

table by the and finding the maximum loan amount for each client. Transformations: operations done on a single table to one or more columns. An example is taking the difference between two columns in one table or taking the absolute value of a column.

New features are created in featuretools using these primitives either by themselves or stacking multiple primitives. Below is a list of some of the feature primitives in featuretools (we can also define custom primitives):

Feature Primitives

These primitives can be used by themselves or combined to create features. To make features with specified primitives we use the ft.dfs function (standing for deep feature synthesis). We pass in the entityset , the target_entity , which is the table where we want to add the features, the selected trans_primitives (transformations), and agg_primitives (aggregations):

The result is a dataframe of new features for each client (because we made clients the target_entity ). For example, we have the month each client joined which is a transformation feature primitive:

We also have a number of aggregation primitives such as the average payment amounts for each client:

Even though we specified only a few feature primitives, featuretools created many new features by combining and stacking these primitives.

The complete dataframe has 793 columns of new features!

Deep Feature Synthesis

We now have all the pieces in place to understand deep feature synthesis (dfs). In fact, we already performed dfs in the previous function call! A deep feature is simply a feature made of stacking multiple primitives and dfs is the name of process that makes these features. The depth of a deep feature is the number of primitives required to make the feature.

For example, the MEAN(payments.payment_amount) column is a deep feature with a depth of 1 because it was created using a single aggregation. A feature with a depth of two is LAST(loans(MEAN(payments.payment_amount)) This is made by stacking two aggregations: LAST (most recent) on top of MEAN. This represents the average payment size of the most recent loan for each client.

We can stack features to any depth we want, but in practice, I have never gone beyond a depth of 2. After this point, the features are difficult to interpret, but I encourage anyone interested to try “going deeper”.",https://cdn-images-1.medium.com/max/1200/1*lg3OxWVYDsJFN-snBY7M5w.jpeg,[],https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219?source=topic_page---8------2----------------,2018-06-02 15:01:18.755000+00:00

NLP,My Phone Wants Me to Say ‘Thank You’ – When Robots Rule The World – Medium,['Evan Selinger'],"Sincerely Thankful

Perhaps there’s something infantilizing about our phones “wanting” us to say thanks. It’s hard to draw a firm line between what you would say if only you put in the time to say it versus what you do say after predictive software fills in the blanks. Seeing suggestions is itself a suggestive situation. And so, while Google emphasizes that smart reply is intelligent enough to figure out if you’re more of a “thanks!” than a “thanks.” person, the fact remains that it’s a good bet that some variation of the word will be frequently presented to you.

If being offered a “thanks” seems familiar, it’s because the act resembles what parents do when they try to instill etiquette. Let’s imagine that Lil’ Johnny receives a gift and instinctively wants to run off and play with it. Before this happens, one of his parents admonishes, “Johnny, what do you say?” And so, robotically, Johnny responds, “Thank you.”

At the time of being coached, Lil’ Johnny doesn’t mean what he parrots back. The gesture is insincere, and Johnny offers it to avoid conflict that would further delay what he really wants to do. That’s okay, though. The hope is that, over time, Lil’ Johnny becomes Big Johnny, the type of person who can genuinely experience gratitude and doesn’t simply follow rules like an automaton. The parental admonitions made during childhood are supposed to be like a pair of moral training wheels that kids ultimately outgrow.

Software like smart reply isn’t designed to provide adults with a second round of moral education. But if we mindlessly use such tools on a regular basis so we can quickly move on to do other things—things that we actually care about—our gestures will merely take the form of gratitude while lacking the underlying substance.

True gratitude must be sincere.

To be truly grateful, you have to mean what you say — that is, you must recognize that someone did something for you that deserves to be acknowledged, and you must sincerely want to make the acknowledgment.

Graciousness is a virtue. If an adult passes off insincere gratitude as the sincere variety in situations where people reasonably expect a person’s words and beliefs to align, the person is behaving worse than Lil’ Johnny. Lil’ Johnny is trying to be compliant, not deceptive.

We also shouldn’t lose sight of the fact that people who in engage in rituals like keeping gratitude journals aim to be specific when offering their appreciation. They don’t just say “thanks” or use any of the other minimalist formulations that smart reply offers. Instead, people who are pursuing lives filled with intentionality are concrete about what they are grateful for, as well as why they’re grateful for it. They want to focus on what they have rather than despair or obsesses over what they lack.",https://cdn-images-1.medium.com/focal/1200/632/51/50/1*MpyyWHuRUnanCenqeG3sHA.jpeg,[],https://medium.com/s/when-robots-rule-the-world/my-phone-wants-me-to-say-thank-you-122cc15952a9?source=topic_page---8------3----------------,

NLP,"In 2018, Numbers Lie and Fictions Paint Truth – Eve Weinberg – Medium",['Eve Weinberg'],"In 2018, Numbers Lie and Fictions Paint Truth Why storytelling is our best tool in disambiguating fact from fiction

I’d love to share a few of the lecturers who touched upon this topic and forever changed my understanding of the 2018 landscape of fact, fiction, and storytelling’s role in deciphering one from the other.

This summer, I had the great privilege of attending EyeO (June 3–8 2018). Innumerable topics that encompass the intersection of Art, Technology, and Data were covered, but one common thread has left an imprint on my brain. That is: the Sisyphean 21st century task of disambiguating fact from fiction. That’s right…

PART 1: NUMBERS ARE MALLEABLE

On the first day, we discussed climate science at length. We (a very self aware room of liberal, number-crunching, data-visualization-making, coastal-living, self-ascribed nerds) attempted to break down the problems with human psychology. We looked at the facts, stats, charts, and graphs; then investigated the human power of denial, dissonance, disincentivization, and the hurdles of behavioral change. After 6 hours of discussion, ideation, and reflection, feeling a bit helpless, we ended with questions that I kept with me throughout the next 3 days of lectures:

Why don’t people believe statistics?

Are stories more powerful than numbers?

Why is denial more powerful than behavioral change?

Why do lies travel faster than truth?

…And what should we do about this?

The next day, Amanda Cox enlightened us with her talk These Lines Are The Same. She showed us that data, even in simple bar graphs, can be misinterpreted depending on the viewer’s own bias. She bravely revealed to us that in her department The Upshot at The New York Times they struggle with how to best represent datasets objectively. They experiment in meaningful and educational ways. In one example she showed data from the US unemployment report. The article allows readers to look at the chart with ‘Democratic Goggles’ and ‘Republican Goggles.’

The numbers are the same, but they can easily be bent to the will of anyone with an agenda.

Then she humorously showed us our flaws in clinging to round numbers. She drove the point home with a series of charts, one here showing the likelihood that someone in the ER gets checked for a heart attack, according to their age. As Amanda points out, “nothing radical changes from the age of 39-and-three-quarters and 40, yet here is the data:",https://cdn-images-1.medium.com/max/1200/1*bJ58aYiSmkeNYJY73AQN3w.jpeg,[],https://medium.com/@evejweinberg/in-2018-numbers-lie-and-fictions-paint-truth-ea1f5cdc9abe?source=topic_page---8------0----------------,2018-06-08 22:01:41.763000+00:00

NLP,The Art of Ethereal: Bringing Cellarius to Life – Genesis Thought – Medium,['Mally Anderson'],"The Art of Ethereal: Bringing Cellarius to Life

Whose future is it? Hers, and his, and theirs, and ours.

A sampling of the Cellarius faction portraits from our Ethereal Summit pop-up.

On May 11 and 12, our parent company ConsenSys hosted the third Ethereal Summit at the Knockdown Center in Queens, New York and invited Cellarius to participate, along with many other spokes from our Mesh. The creators of Ethereal wanted to build a different kind of crypto conference. Since this one explored the intersection of blockchain and the arts, we wanted to showcase that aspect of our project and spread the word in an unexpected way. We set up shop in “The Crypt,” a semi-outdoor concrete space with a distinctive patina that felt perfect for the Cellarius blockpunk aesthetic.

The Knockdown Center’s very blockpunk Crypt space. We displayed some not-yet-published art commissions.

We teamed with some artists from a group called Drawn Together NYC: Boris Rasin, Michael Scarola, Derrick Dent, and Rosalind Bunting. Drawn Together’s talented roster of artists creates design concepts, multimedia experiences, and fine art solutions for a wide range of projects and businesses, and they understood what we are going for right away.

The artists of Drawn Together NYC, from left to right: Boris Rasin, Rosalind Bunting, Derrick Dent, and Michael Scarola.

Boris, Michael, and Derrick created custom, in-universe faction portraits of Ethereal attendees. The CX Universe Guide imagines that nation-states and traditional economies will break down after the Cellarius AI seizes control of Earth’s energy sources and communication channels in 2084. In the absence of familiar institutions and technologies, people will begin to form factions according to their allegiance to Cellarius. We wanted to get attendees thinking about their own relationships to technology and start dreaming up characters to explore in the Cellarius universe. So we posed the question: which faction do you think you would be?

Boris drew background art for four different factions:

The 4 faction backgrounds, clockwise from top left: Bucolic, Elite, Ad-Hoc, Homotranscendus.

Bucolic: Bucolics are AI skeptics who reject technology and live on the peripheries of megacities, observing from the outside and farming small pockets of fertile soil. Though their process is completely manual and their harvests are meager, they feel a great satisfaction from working with their own hands, in stark contrast to the highly automated farming processes elsewhere.

Ad-Hoc: Ad-Hocs live off the Cellarius grid and make their own augmentations and tools with scrap pieces they scavenge and rework. Comprised of mostly poor and marginalized groups, they use ingenuity and what little tech they can access to get by.

Elite: The crypto-Elites of the future are pro-Cellarius and experiment with AI and aesthetic enhancements. Living in the highest levels of the megacities, Elites have access to bleeding-edge technology. They are known for having lifespans beyond the normal range of humans, and enjoy the neural boost that comes with AI coupling.

Homotranscendus: During the Reformation, it wasn’t just the home habitat that was transformed forever, but also humankind itself. The campaign was more than just re-imagining the economic machinery of the planet Earth, but also a re-imagining of the of the human brain and body. Through Cellarius-engineered advancements, the next evolution of humanity was born: Homotranscendus. Homotranscendi are fully integrated with AI and no longer depend on their human forms to express consciousness and gather information.

We even got a portrait of ConsenSys’s own Joe Lubin, who wore a custom Cellarius Ethereal t-shirt design during his keynote address (thanks, Joe!). Something tells us that Joe would be a Homotranscendus.

Future Homotranscendus Joe Lubin on Mars.

Reimagining how familiar scenarios from your own life play out in a future setting or speculating about how you might react to a superintelligent AI’s takeover of the world is a great place to start inventing your own ideas in the world of Cellarius. We hope some attendees will be inspired to start making art and stories based on their portraits!

Every single Ethereal portrait, as arranged by our designer, Octavian.

As we’ve mentioned in previous posts, we are also commissioning works from artists we admire to create the first round of content for the Cellarius universe. We decided to commission a mural that would take shape over the two days of the Summit and give attendees a behind-the-scenes look at the process of making a large-scale landscape painting. The design depicts what the Knockdown Center might look like a century from now, in 2118. Visitors to the Crypt got a chance to watch Rosalind transform the canvas from a faint pencil sketch into an impressive and detailed final product:

Rosalind’s “Knockdown Center in 2118” painting took shape over two days.

Rosalind & Boris outlined the sketch first, then Rosalind added color, starting with the future-NYC background.

We hope that the Cellarius platform will allow experienced artists and creators to get directly in touch with their fan bases and share some glimpses of their artistic process, just as Rosalind did with her live painting.

The Drawn Together NYC artists got to learn more about the possibilities of blockchain and decentralization for creatives in the process of chatting with the attendees. Michael noted, “There were so many passionate and interesting people from all over the world that came through. And they had as much fun as we did learning about and playing in the Cellarius world.” Rosalind agreed: “Probably my favorite thing I learnt about over the Summit was how Cellarius involves the creative talents of so many more artists in their company, and loved seeing some of their amazing artwork. Can’t wait to see more!”

We were also excited that the long-term goals of the Cellarius project resonated with the Drawn Together NYC artists. Derrick said, “This was probably the coolest on-site portrait job I’ve ever worked on. I had a great time learning about the Cellarius project and the potential for a sprawling, community-shaped open sci-fi world. It was even cooler to have our portrait work used as an onboarding tool for visitors. People immediately took to creating their own story within this world, and that says a lot about how exciting this could be for folks who are creatively inclined.” We couldn’t have said it better ourselves.

As Boris told us, “The more I spoke to the pop-up team and event attendees about the concept behind this project, the more it occurred to me that this is a game changer. Cellarius and the other projects from ConsenSys are sure to revolutionize our ecosystem in ways we can’t even begin to comprehend. It’s a challenge to explain exactly what this project is, because the underlying platform allows for limitless opportunities of invention, inspiration, and collaboration. Cellarius is whatever its contributors will it to be, and frankly, that’s a fundamentally crazy idea!”

That’s just the point: blockchain enthusiasts can become artists and use storytelling to push the conceptual limits of technology. Artists can use the platform to explore the possibilities of decentralization and blockchain for sharing and protecting their work. We can build it together. Cellarius is whatever our community of contributors wills it to be.",https://cdn-images-1.medium.com/max/1200/1*vL8856P7cdV84CYM_SkF0A.jpeg,[],https://medium.com/genesis-thought/the-art-of-ethereal-bringing-cellarius-to-life-ba4ae31811e7?source=topic_page---8------1----------------,2018-06-08 16:46:47.896000+00:00

NLP,A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what…,['Rowan Trollope'],"A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what happened?” Has gotten some fun responses.

The most popular comment being one that says “not surprised, this was never going to be a big thing”…

The first thing to point out is that people are conflating the specific of a chatbot with the generic “conversational user interface” (CUI) of which a chatbot is a specific modality. The real discussion here is about the CUI.

And the last month has certainly showed us that the CUI has made dramatic strides with Google demonstrating Duplex.

So what happened to the explosion of chatbots people predicted?

Among other things, Developers figured out just how hard it is to make a really good conversational user interface. Product folks were tricked by the trio of Alexa/Siri/Google Assistant into the belief that a conversational interface is easy.

Turns out it’s really hard, requires a ton of data and is highly domain specific.

In other words, training a CUI to be really great at getting sports scores doesn’t translate at all to a chatbot that can help you with a billing problem or ordering a pizza.

Google was careful to point out that Duplex was trained for only two very specific use cases : book a salon or a restaurant appointment.

Tim Tuttle at Mindmeld figured this out and built a company to solve it, but it still required heavy lifting and tons of data specific to the domain.

My belief is that the conversational interface is inevitable.

Technology evolution is exponential not linear. Our tendency is to project the future in a linear fashion, which causes us to overestimate what’s possible in 1 year and underestimate what’s possible in 10 years.

This makes tech progress feel gradual or slow, and then sudden and surprising.

Last week Salesforce’s chief scientist, Richard Socher, spoke publicly about the future of chatbots and asserted that in 5 years we would begin to see this start to pay off.

We are early days on the conversational interface, but as with all tech progress most folks will be disappointed until one year, 5–10 years from now when they’ll be shocked and amazed and wonder how it happened so fast.",https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico,[],https://medium.com/@rowantrollope/chatbots-were-supposed-to-be-the-next-big-thing-what-happened-5a4e416308e1?source=topic_page---8------2----------------,2018-06-08 21:06:45.446000+00:00

NLP,"Beethoven, Picasso, and Artificial Intelligence – Towards Data Science",['Chris Kalahiki'],"Beethoven, Picasso, and Artificial Intelligence

Introduction

When people think of the greatest artists who’ve ever lived, they probably think of names like Beethoven or Picasso. No one would ever think of a computer as a great artist. But what if one day, that was indeed the case. Could computers learn to create incredible drawings like the Mona Lisa? Perhaps one day a robot will be capable of composing the next great symphony. Some experts believe this to be the case. In fact, some of the greatest minds in artificial intelligence are diligently working to develop programs that can create drawing and music independently from humans. The use of artificial intelligence in the field of art has even been picked up by tech giants the likes of Google.

The projects that are included in this paper could have drastic implications in our everyday lives. They may also change the way we view art. They also showcase the incredible advancement that has been made in the field of artificial intelligence. Image recognition is not as far as the research goes. Nor is the ability to generate music in the styling of the great artists of our past. Although these topics will be touched upon, we will focus on several more advanced achievements such as text descriptions being turned into images and generating art and music that is totally original. Each of these projects bring something new and innovative to the table and show us exactly how the art space is a great place to further explore applications of artificial intelligence. We will be discussing problems that have been faced in these projects and how they have been overcome. The future of AI looks bright. Let’s look at what the future may hold. In doing this, we may be able to better understand the impact that artificial intelligence can have in an area that is driven by human creativity.

GAN and Its Evolved Forms

Machines must be educated. They learn from instruction. How do we lead machines away from emulating what already exists, and have them create new techniques? “No creative artist will create art today that tries to emulate the Baroque or Impressionist style, or any other traditional style, unless trying to do so ironically” [4]. This problem isn’t limited to paintings either. Music can be very structured in some respects, but is also a form of art that requires vast creativity. So how do we go about solving such a problem? The first concept we will discuss is something called GAN (Generative Adversarial Networks). GANs, although quite complex, are becoming an outdated model. If artificial intelligence in the art space is to advance, researchers and developers will have to work to find better methods to allow machines to generate art and music. Two of these such methods are presented in the form of Sketch-RNN and CAN (Creative Adversarial Networks). Each of these methods have their advantages over GANs.

First, let’s explore what exactly a GAN is. Below is a small excerpt explaining how a GAN works:

Generative Adversarial Network (GAN) has two sub networks, a generator and a discriminator. The discriminator has access to a set of images (training images). The discriminator tries to discriminate between “real” images (from the training set) and “fake” images generated by the generator. The generator tries to generate images similar to the training set without seeing the images [4].

The more images the generator creates, the closer they get to the images from the training set. The idea is that after a certain number of images are generated, the GAN will create images that are very similar to what we consider art. This is a very impressive accomplishment to say the least. But what if we take it a step further?

Many issues associated with the GAN are simply limitations on what it can do. The GAN is powerful, but can’t do quite as much as we would like. For example, the generator in the model described above will continue to create images closer and closer to the images given to the discriminator that it isn’t producing original art. Could a GAN be trained to draw alongside a user? It’s not likely. The model wouldn’t be able to turn a text-based description of an image into an actual picture either. As impressive as the GAN may be, we would all agree that it can be improved. Each of the shortcoming mentioned have actually been addressed and, to an extent, solved. Let’s look at how this is done.

Sketch-RNN is a recurrent neural network model developed by Google. The goal of Sketch-RNN is to help machines learn to create art in a manner similar to the way a human may learn. It has been used in a Google AI Experiment to be able to sketch alongside a user. While doing so, it can provide the users with suggestions and even complete the user’s sketch when they decide to take a break. Sketch-RNN is exposed to a massive number of sketches provided through a dataset of vector drawings obtained through another Google application that we will discuss later. Each of these sketches are tagged to let the program know what object is in the sketch. The data set represents the sketch as a set of pen strokes. This allows Sketch-RNN to then learn what aspects each sketch of a certain object has in common. If a user begins to draw a cat, Sketch-RNN could then show the user other common features that could be on the cat. This model could have many new creative applications. “The decoder-only model trained on various classes can assist the creative process of an artist by suggesting many possible ways of finishing a sketch” [3]. The Sketch-RNN team even believes that, given a more complex dataset, the applications could be used in an educational sense to teach users how to draw. These applications of Sketch-RNN couldn’t be nearly as easily achieved with GAN alone.

Another method used to improve upon GAN is the Creative Adversarial Network. In their paper regarding adversarial networks generating art, several researchers discuss a new way of generating art through CANs. The idea is that the CAN has two adversary networks. One, the generator, has no access to any art. It has no basis to go off of when generating images. The other network, the discriminator, is trained to classify the images generated as being art or not. When an image is generated, the discriminator gives the generator two pieces of information. The first is whether it believes the generated image comes from the same distributor as the pieces of art it was trained on, and the other being how the discriminator can fit the generated image into one of the categories of art it was taught. This technique is fantastic in that it helps the generator create images that are both emulative of past works of art in the sense that it learns what was good about those images and creative in a sense that it is taught to produce new and different artistic concepts. This is a big difference from GAN creating art that emulated the training images. Eventually, the CAN will learn how to produce only new and innovative artwork.

One final future for the vanilla GAN is StackGAN. StackGAN is a text to photo-realistic image synthesizer that uses stacked generative adversarial networks. Given a text description, the StackGAN is able to create images that are very much related to the given text. This wouldn’t be doable with a normal GAN model as it would be much too difficult to generate photo-realistic images from a text description even with a state-of-the-art training database. This is where StackGAN comes in. It breaks the problem down into 2 parts. “Low-resolution images are generated by our Stage-I GAN. On the top of our Stage-I GAN, we stack Stage-II GAN to generate realistic high-resolution images conditioned on Stage-I results and text descriptions” [7]. It is through the conditioning on Stage-I results and text descriptions that Stage-II GAN can find details that Stage-I GAN may have missed and create higher resolution images. By breaking the problem down into smaller subproblems, the StackGAN can tackle problems that aren’t possible with a regular GAN. On the next page is an image showing the difference between a regular GAN and each step of the StackGAN.

This image came from the StackGAN paper [7].

It is through advancements like these that have been made in recent years that we can continue to push the boundaries of what AI can do. We have just seen three ways to improve upon a concept that was already quite complex and innovative. Each of these advancements have a practical, everyday use. As we continue to improve on artificial intelligence techniques, we will able to do more and more in regard to, not just art and music, but a wide variety of tasks to improve our lives.

DeepBach, Magenta, and NSynth

Images aren’t the only type of art that artificial intelligence can impact though. Its effect on music is being explored as we speak. We will now explore some specific cases and their impact on both music and artificial intelligence. In doing this, we should be able to see how art can do as much for AI as AI does for it. Both fields benefit heavily from the types of projects that we are exploring here.

Could a machine ever be able to create a piece of music the likes of Johann Sebastian Bach? In a project known as DeepBach, several researchers looked to create pieces similar to Bach’s chorales. The beauty of DeepBach is that it “is able to generate coherent musical phrases and provides, for instance, varied reharmonizations of melodies without plagiarism” [6]. What this means it that DeepBach can create music with correct structure and be original. It is just in the style of Bach. It isn’t just a mashup of his works. DeepBach is creating new content. The developers of DeepBach went on to test whether their product could actually fool listeners.

As part of the experiment, over 1,250 people were asked to vote whether pieces presented to them were in fact composed by Bach. The subjects had varying degrees of musical expertise. The results showed that as the model for DeepBach’s complexity increased, the subjects had more and more trouble distinguishing the chorales of Bach from those of DeepBach. This experiment shows us that through the use of artificial intelligence and machine learning, it is quite possible to recreate original works in the likeness of the greats. But is that the limit to what artificial intelligence can do in the field of art and music?

DeepBach has achieved something that would have been unheard of in the not so distant past, but it certainly isn’t the fullest extent of what AI can do to benefit the field of music. What if we want to create new and innovative music? Maybe AI can change the way music is created all together. There must be projects that do more to push the envelope. As a matter of fact, that is exactly what the team behind Magenta look to do.

Magenta is a project being conducted by the Google Brain team and lead by Douglas Eck. Eck has been working for Google since 2010, but that isn’t where his interest in Music began. Eck helped found Brain Music and Sound, an international laboratory for brain, music, and sound research. He was also involved at the McGill Centre for Interdisciplinary Research in Music Media and Technology, and was an Associate Professor in Computer Science at the University of Montreal.

Magenta’s goal is to be “a research project to advance the state of the art in machine intelligence for music and art generation” [2]. It is an open source project that uses TensorFlow. Magenta aims to learn how to generate art and music in a way that is indeed generative. It must go past just emulating existing music. This is distinctly different that projects along the line of DeepBach which set out to emulate existing music in a way that wasn’t plagiarizing existing pieces of music. Eck and company realize that art is about capturing elements of surprise and drawing attention to certain aspects. “This leads to perhaps the biggest challenge: combining generation, attention and surprise to tell a compelling story. So much of machine-generated music and art is good in small chunks, but lacks any sort of long-term narrative arc” [2]. Such a perspective gives computer-generated music more substance, and helps it to become less of a gimmick.

One of the projects the magenta team has developed is called NSynth. The idea behind NSynth is to be able to create new sounds that have never been heard before, but beyond that, to reimagine how music synthesis can be done. Unlike ordinary synthesizers that focus on “a specific arrangement of oscillators or an algorithm for sample playback, such as FM Synthesis or Granular Synthesis” [5], NSynth generates sounds on an individual level. To do this, it uses deep neural networks. Google has even launched an experiment that allows users to really see what NSynth can do by allowing them to fuse together the sounds of existing instruments to create new hybrid sounds that have never been heard before. As an example, users can take two instruments such as a banjo and a tuba, and take parts of each of their sounds to create a totally new instrument. The experiment also allowed users to decide what percentage of each instrument would be used.

Projects like Magenta go above and beyond in showing us the full extent of what artificial intelligence can do in the way of generating music. They explore new applications of artificial intelligence that can generate new ideas independent of humans. It is the closest we have come to machine creativity. Although machines aren’t yet able to truly think and express creativity, they may soon be able to generate new and unique art and music for us to enjoy. Don’t worry though. Eck doesn’t intend to replace artists with AI. Instead he looks to provide artists with tools to create music in an entirely new way.

Deep Dream and Quick, Draw!

As we look ahead to a few more of the ways that AI has been used to accomplish new and innovative ideas in the art space, we look at projects like Quick, Draw! and Deep Dream. These projects showcase amazing progress in the space while pointing out some issues that researchers in AI will have to work out in the years to come.

Quick, Draw! is an application from the Google Creative Lab, trained to recognize quick drawings much like one would see in a game of Pictionary. The program can recognize simple objects such as cats and apples based on common aspects of the many pictures it was given before. Although the program will not get every picture right each time it is used, it continues to learn from the similarities in the picture drawn and the hundreds of pictures before it.

The science behind Quick, Draw! “uses some of the same technology that helps Google Translate recognize your handwriting. To understand handwritings or drawings, you don’t just look at what the person drew. You look at how they actually drew it” [1]. It is presented in the form of a game, with the user drawing a picture of an object chosen by the application. The program then has 20 seconds to recognize the image. In each session, the user is given a total of 6 objects. The images are then stored to the database used to train application. This happens to be the same database we saw earlier in the Sketch-RNN application. This image recognition is a very practical use of artificial intelligence in the realm of art and music. It can do a lot to benefit us in our everyday lives. But this only begins to scratch the surface of what artificial intelligence can do in this field. Although this is very impressive, we might point out that the application doesn’t truly understand what is being drawn. It is just picking up on patterns. In fact, this distinction is part of the gap between simple AI techniques and true artificial general intelligence. Machines that truly understand what the objects in images are don’t appear to be coming in the near future.

Another interesting project in the art space is Google’s Deep Dream project, which uses AI to create new and unique images. Unfortunately, the Deep Dream Generator Team wouldn’t go into too much detail about the technology itself (mostly fearing it would be too long for an email) [8]. They did, however, explain that convolutional neural networks train on the famous ImageNet dataset. Those neural networks are then used to create art-like images. Essentially, Deep Dream takes the styling of one image and uses it to modify another image. The results can be anything from a silly fusion to an artistic masterpiece. This occurs when the program identifies the unique stylings of an image provided by the user and imposes those stylings onto another image that the user provides. What can easily be observed through the use of Deep Dream is that computers aren’t yet capable of truly understanding what they are doing with respect to art. They can be fed complex algorithms to generate images, but don’t fundamentally understand what it is they are generating. For example, a computer may see a knife cutting through an onion and assume the knife and onion are one object. The lack of an ability to truly understand the contents of an image is one dilemma that researchers have yet to solve.

Perhaps as we continue to make advances in artificial intelligence we will be able to have machines that do truly understand what objects are in an image and even the emotions evoked by their music. The only way for this to be achieved is by reaching true artificial general intelligence (AGI). IN the meantime, the Deep Dream team believes that generative models will be able to create some really interesting pieces of art and digital content.

Where Do We Go From Here?

For this section, we will consider where artificial intelligence could be heading in the art space. We will take a look at how AI has impacted the space and in what ways it can continue to do so. We will also look at ways art and music could continue to impact AI in the years to come.

Although I don’t feel that we have completely mastered the ability to emulate the great artists of our past, it is just a matter of time before that problem is solved. The real task to be solved is that of creating new innovations in art and music. We need to work towards creation without emulation. It is quite clear that we are headed in that direction through projects like CAN and Magenta. Artificial general intelligence (AGI) is not the only way to complete this task. As a matter of fact, even those who dispute the possibility of AGI would have a hard time disputing the creation of unique works of art by a machine.

One path that may be taken to further improve art and music through AI is to create more advanced datasets to use in training the complex networks like Sketch-RNN and Deep Dream. AI needs to be trained to be able to perform as expected. That training has a huge impact on the results we get. Shouldn’t we want to train our machines in the most beneficial way possible. Even developing software like Sketch-RNN to use the ImageNet dataset used in Deep Dream could be huge in educating artists on techniques for drawing complex, realistic images. Complex datasets could very well be our answer to more efficient training. Until our machines can think and learn like we do, we will need to be very careful what data is used to train them.

One of the ways that art and music can help to impact AI is by providing another method of Turing Testing machines. For those who dream of creating AGI, what better way to test the machine’s ability that to create something that tests the full extent of human-like creativity? Art is the truest representation of human creativity. That is, in fact, its essence. Although art is probably not the ultimate end game for artificial intelligence, it could be one of the best ways to test the limits of what a machine can do. The day that computers can create original musical composition and create images based on descriptions given by a user could very well be the day that we stop being able to distinguish man from machine.

Conclusion

There are many benefits to using artificial intelligence in the music space. Some of them have already been seen in the projects we have discussed so far. We have seen how artificial intelligence could be used for image recognition as well as their ability to turn our words into fantastic images. We have also seen how AI can be used to synthesize new sounds that have never been heard. We know that artificial intelligence can be used to create art alongside us as well as independently from us. It can be taught to mimic music from the past and can create novel ideas. All of these accomplishments are a part of what will drive AI research into the future. Who knows? Perhaps one day we will achieve artificial general intelligence and machines will be able to understand what is really in the images it is given. Maybe our computers will be able to understand how their art makes us feel. There is a clear path showing us where to go from here. I firmly believe that it is up to us to continue this research and test the limits of what artificial intelligence can do, both in the field of art and in our everyday lives.

References",https://cdn-images-1.medium.com/max/1200/0*pIGHko-OCo1usW2c,[],https://towardsdatascience.com/beethoven-picasso-and-artificial-intelligence-caf644fc72f9?source=topic_page---8------3----------------,2018-06-08 21:34:58.310000+00:00

NLP,The curious case of the vanishing & exploding gradient,['Eniola Alese'],"The curious case of the vanishing & exploding gradient

Understanding why gradients explode or vanish and methods for dealing with the problem.

Photo by SpaceX on Unsplash

In the last post, we introduced a step by step walkthrough of RNN training and how to derive the gradients of the network weights using back propagation and the chain rule. But it turns out that during this training the RNN can suffer greatly from two problems: 1. Vanishing gradients or 2. Exploding gradients.

Why Gradients Explode or Vanish

Recall the many-to-many architecture for text generation shown below and in the introduction to RNN post, lets assume the input sequence to the network is a 20 word sentence: “I grew up in France,…….. I speak French fluently.

We can see from the example above that for the RNN to predict the word “French” which comes at the end of the sequence, it would need information from the word “France”, which occurs further back at the beginning of the sentence. This kind of dependence between sequence data is called long-term dependencies because the distance between the relevant information “France” and the point where it is needed to make a prediction “French” is very wide. Unfortunately, in practice as this distance becomes wider, RNNs have a hard time learning these dependencies because it encounters either a vanishing or exploding gradient problem.

These problems arise during training of a deep network when the gradients are being propagated back in time all the way to the initial layer. The gradients coming from the deeper layers have to go through continuous matrix multiplications because of the the chain rule, and as they approach the earlier layers, if they have small values (<1), they shrink exponentially until they vanish and make it impossible for the model to learn , this is the vanishing gradient problem. While on the other hand if they have large values (>1) they get larger and eventually blow up and crash the model, this is the exploding gradient problem

Dealing with Exploding Gradients",https://cdn-images-1.medium.com/max/1200/0*UCn2LUkacEHQxgZW,[],https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb?source=topic_page---8------5----------------,2018-06-05 22:33:57.437000+00:00

NLP,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------,2018-06-08 22:25:33.341000+00:00

NLP,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------#--responses,2018-06-08 22:25:33.341000+00:00

NLP,How to build a range slider component in React from scratch using only <div> and <span>,['Rajesh Pillai'],"How to build a range slider component in React from scratch using only <div> and <span>

In this article we will build a React range slider component step by step using only <div>. We will enable it with touch support.

What can you do with a piece of about 50 <div’s>?

Build a slider control from scratch. If this sounds interesting, then follow along.

The final output will look like the below animation.

Please do note that I have developed this component as a teaching exercise for my students of ReactJS — Beyond the Basics course on Udemy, so it may have some edge cases (which I will fix as and when encountered).

You could use an HTML5 range control and customize it. But I wanted to take a different approach and build something from scratch. And the result is what you see here.

Our slider component will be composed of the below three elements:

A slider range

The actual slider controls

The current selection range

Defining the state for our component

Let us begin by defining our state. I am only showing you the important part of the code. For the full source code, please refer to the link at the end of the article.

state = {

slots: 24,

start: 0,

end: 10,

labelMode: ""mid"", // mid, long

}

The state contains the following properties.

slots: Total slots to be drawn (in this case I am using it as a time selector, so it will have 24 hour slots)

start: The start value of the selection

end: The end value of the selection

labelMode: Currently unused. But can be used to customize the scale label rendering.

The return part of the render method

Let us now take a look at the return part of the render method. The render() method will be slowly composed of small pieces of functionality.

return (

<div>

<h2>React Slider</h2>

<div className=""example-1"">

<div className=""slider-container"">

<div className=""slider-scale"">

{scale}

</div>

<div className=""slider"">

{slider}

</div>

<div className=""slider-selected-scale"">

{currentScale}

</div>

</div>

</div>

</div>

);

For those reading on mobile, the below image may be handy, as sometimes Medium breaks the code formatting.

If you take a look at the code, there are only three important pieces:

scale variable

slider variable

currentScale variable

The three variables above will be responsible for rendering the correct parts of the overall slider.

Dissecting the render () method

Let us initialize some variables. The scale , slider and currentScale JSX will be created within the for loop defined below.

render () {

let scale = [];

let slider=[];

let currentScale = [];

let minThumb = null;

let maxThumb = null

..... // rest of the code

}

Create the JSX for the ‘scale’ variable

Creating the JSX for the scale variable is quite simple. We just loop through the slots value in the state and push a <div> to the scale array with the required CSS class for styling.

The if condition ensures that we are only printing the label for i = 0, i = 12, or i = 24 (kind of mid range). Please feel free to customize this.

for (let i = 0; i <= this.state.slots;i++) {

let label = """";



if (i == 0 || i == 12 || i == 24) {

label = i;

}



scale.push(

<div

key={i}

className=""slot-scale"">

{label}

</div>

);

Here’s the code in image format:

Create the JSX for the ‘currentScale’ variable

Let us now continue with the same for loop and create the ‘currentScale’ JSX. We are still within the same for loop, so about 24 divs will be created as per the value in this.state.slots value.

The currentScale has a class of ‘slot-scale-selected’.

let currentLabel = """";



if (i === this.state.start || i === this.state.end) {

currentLabel = i;

}



currentScale.push(

<div

key={i}

className=""slot-scale-selected"">

{currentLabel}

</div>

);

The code is pretty similar to the ‘scale’ JSX that we created.

Create the JSX for the ‘slider’ variable

Let us write a function to render the ‘slider’ jsx. The slider needs two thumbs, one for min, and one for max.

Let us first initialize the thumb variable depending on the ‘i’ value. If ‘i’ is the same as this.state.start, then we set the minThumb variable. Else if the value of ‘i’ is the same as this.state.end, then we initialize the maxThumb variable.

if (i === this.state.start) {

minThumb = <this.MinSlider />

} else if (i === this.state.end) {

maxThumb = <this.MaxSlider />

} else {

minThumb = null;

maxThumb = null;

}

Create the JSX for the ‘slider’

The important code piece here is the dragover event. This is required for the HTML drop to work correctly.

let lineClass = ""line"";



if (i >= this.state.start && i < this.state.end) {

lineClass += "" line-selected"";

}

slider.push(

<div

data-slot={i}

onDragOver={this.onDragOver}

onTouchMove = {this.onDragOver}

onTouchEnd = {this.onDrop}

onDrop = {this.onDrop}

key={i}

className=""slot"">

<div data-slot={i} className={lineClass}/>

<span className=""scale-mark""></span>

{minThumb}

{maxThumb}

</div>

);

The slider variable needs two additional pieces of features to represent the min and the max thumb on the slider.

The slider JSX has additional event handlers to deal with handling the drop event/touchend event. We will take a look at the event handlers shortly.

The ‘lineClass’ styles/renders the line on the slider, and the ‘line-selected’ class styles the currently selected range.

Let us now write the MinSlider and MaxSlider function outside the render method.

The MinSlider () function to render the min thumb

Let’s take a look at the code. The important props are the events related to drag and the draggable attribute. The draggable attribute will make this element draggable.

We are also adding the touch event handler. Refer to the link at the bottom of the article to add touch support polyfill for the HTML5 API.

MinSlider=()=> {

return (

<div data-slider=""min""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-min"">

</div>

);

}

The MaxSlider () function to render the min thumb

The MaxSlider is almost the same as the MinSlider except for the data and the className.

MaxSlider=()=> {

return (

<div data-slider=""max""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-max"">

</div>

);

}

The code image is given below for reference.

Event Handling

Let us now look at the drag/touch event handlers defined within our <div> to control the movement of the slider element.

dragover:

The dragover event is required to support the drop zone when using the HTML5 drag/drop API. The only thing we need to do here is to invoke the preventDefault on the event object.

onDragOver = (e) => {

e.preventDefault();

}

dragstart:

The dragstart enables us to store which slider is being dragged. Please note that I am not using the dataTransfer object here, but simply using an instance variable to store this.

onDragStart = (e) => {

let slider = e.target.dataset.slider;

this.sliderType = slider;

}

The value of e.target.dataset.slider is either “min” or “max,” indicating which slider is being dragged.

ondrop:

The ondrop event captures where the thumb is being dropped (on which scale).

This is the important flow in the ondrop event:

Grab the source (whether min/max thumb)

Get the slot (where the drop happens)

Validations

Update the slot (in the state)

Reset the sliderType.

onDrop = (e, target) => {

let source = this.sliderType;

let slot = Number(e.target.dataset.slot);



if (isNaN(slot)) return;



if (source === ""min"") {

if (slot >= this.state.end) return;

this.setState({

start: slot

},()=>{

console.log(this.state);

})

} else if (source === ""max"") {

if (slot <= this.state.start) return;

this.setState({

end: slot

},()=>{

console.log(this.state);

})

}

this.sliderType = null;

}

The complete source code/and demo can be seen here http://jsbin.com/remodat/edit?output

Since I am using HTML5 drag and drop features to add touch, support please add this polyfill reference to your html file.

Todos

Extract the logic to a separate Component class

Test it and and add customization.

History

21-May-2018 — First release

P.S: This component is a result of a very quick coding attempt. This will be refactored.

Promotion: If you would like to support our open source curriculum Mastering Full Stack Engineering in 12 to 20 weeks then here is a special 10$ coupon for medium readers for my upcoming live ReactJS-Beyond the basicscourse on udemy (MEDIUM_500 is the coupon code, which is already tagged in the above URL)",https://cdn-images-1.medium.com/max/1200/1*iSkeoPHBQubtAL4fV4h9xQ.png,[],https://medium.freecodecamp.org/how-to-build-a-range-slider-component-in-react-from-scratch-using-only-div-and-span-d53e1a62c4a3?source=collection_home---6------1----------------,2018-06-08 21:41:33.808000+00:00

NLP,The well-kept secret behind great UX: Usability Testing,['Anant Jain'],"The well-kept secret behind great UX: Usability Testing

Whether you only have a prototype or a full-fledged product, it’s a really good idea to run monthly usability tests. These make sure that whatever you’re working on is usable and the user experience is excellent.

If you’re wondering what you can do to make your usability tests more structured and organized, this guide is for you. Let’s get started!

First off, always keep the two Golden Rules of Usability Testing in mind:

Any testing is better than no testing (with no one!) A little testing earlier is better than a lot of testing later.

In this post, I will introduce you to the kind of lightweight usability testing described in Steve Krug’s books, “Don’t Make Me Think” and “Rocket Surgery Made Easy.” Steve calls this kind of testing “Do-It-Yourself Usability Testing” since it’s supposed to be cheap, easy-to-do and takes just a morning a month.

A quick intro to usability testing

The idea behind this is to:

Find a few participants

Ask them to come in and go through a list of user flows you want to test

Observe the problems they run into

Finally, make a list of issues to fix

Sounds simple enough, but very few of us actually do it. The goal of this post is to make you confident enough to run at least one usability test session this month. I ran my first usability test only a year ago, and I must say it’s actually a lot of fun!

Before we get to the test itself, here are a few things to note:

Reserve one morning a month (say the third Thursday every month) for a round of testing, debriefing, and deciding what to fix. Test with three participants each round. Recruit loosely, and grade on a curve. You don’t need to find someone who fits the exact mould of your ideal user, since most usability problems can be uncovered by testing with just about anyone. If you are part of a big company and have the budget, you can recruit via Craigslist and offer a $50 gift card for an hour of the participant’s time. If you don’t have those kind of resources, don’t worry — you can ask your friends, your existing users, or even go to a café and ask strangers for 15 minutes of their time in exchange for buying them a coffee. If you’re doing this as part of a bigger team, get as many observers as possible to observe the tests in a separate observation room. These will be the designers, engineers, project managers, executives, etc. Or, in case of side projects, it’ll be just be you later in your room!

What happens during the test?

During a usability test, you will record the participant’s voice and their computer screen, and share both these streams live with observers in another room. A typical one-hour test can be broken down into:

Welcome (4 mins): Explain how the test will work so that the participant will know what to expect. The questions (2 mins): Ask the participant a few questions about themselves. This helps put them at ease and gives you an idea of how computer-savvy they are. The Homepage tour (3 mins): Open the Home page of your site, and ask the participant to look around and tell you what they think. This will give you an idea of how easy it is to understand your home page, as well as how familiar the participant is with your domain. The tasks (35 minutes): Watch the participant perform a series of tasks you have prepared for them beforehand. If you’re building a SaaS product and you’re testing out your subscription flow, a typical task could be to find the Pricing page, compare various plans, and Subscribe to one of the plans with a provided test credit card number. Encourage the participant to think out loud as they perform the task (see the video at the end of the post for a sample test.) It’s crucial that you let them work on their own and not ask them any leading questions, or give out any clues or assistance. Probing (5 mins): Ask the participant any questions you may have about anything that happened during the test and about any issues that people in the observation room may have. Also, answer any questions that the participant may have at this point (don’t answer them during the actual tasks since you’re testing how they’ll perform with no one around.) Wrapping Up (5 mins): Thank them for their help, and give them their gift card if you promised one while recruiting them.

The debrief

During the breaks between successive tests, ask the observers to write down the top 3 usability problems that they saw. During the debriefing, focus ruthlessly on deciding to fix the most severe problems first. Here are a few other recommendations:

Keep a separate list of low-hanging fruit. These are the problems you can typically fix with one-line code changes, but have a huge impact on task completion rates. Joel Califa calls them “tiny wins”. Here’s an example:

Resist the impulse to add things — instead, try to tweak your existing design to fix the problem.

to fix the problem. Take “new feature” requests with a grain of salt. Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature.

Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature. Ignore the problems where the user goes astray for a bit but comes back on track by themselves. These are usually not worth investing much time unless you see a pattern across multiple participants.

Good design is a delicate balance, so when fixing a problem, ensure that you aren’t introducing new ones.

Remote testing and unmoderated user testing

Remote testing is very similar to an in-person usability test, except that the participant is at their home/office and you conduct the testing via screen sharing and voice call.

Unmoderated user testing is another way to test, where you specify your website, the tasks you want the users to do, and get back video recordings of people trying to accomplish those tasks. Usertesting.com is the leader in this space, but note that a single 30-minute test costs about $50.

Resources

You can download checklists, interview script, consent form, and a demo video at Steve Krug’s site here: Downloads for Rocket Surgery Made Easy.

Here’s a Usability Test demo video from Google Ventures:

I want to thank you for reading this quick guide. This was originally published as part of the UX Design course on Commonlounge, a platform that has courses with small bite-sized lessons like these on topics ranging from Project Management to Machine Learning that deliver the most value for the time you put in.

You learn by working on real-world projects and getting feedback from industry mentors. You should check it out here!",https://cdn-images-1.medium.com/max/1200/0*UWxJWKKNLXR5c1cm,[],https://medium.freecodecamp.org/the-well-kept-secret-behind-great-ux-usability-testing-b788178a64c3?source=collection_home---6------2----------------,2018-06-08 21:25:31.335000+00:00

NLP,An introduction to part-of-speech tagging and the Hidden Markov Model,['Divya Godayal'],"Let’s go back into the times when we had no language to communicate. The only way we had was sign language. That’s how we usually communicate with our dog at home, right? When we tell him, “We love you, Jimmy,” he responds by wagging his tail. This doesn’t mean he knows what we are actually saying. Instead, his response is simply because he understands the language of emotions and gestures more than words.

We as humans have developed an understanding of a lot of nuances of the natural language more than any animal on this planet. That is why when we say “I LOVE you, honey” vs when we say “Lets make LOVE, honey” we mean different things. Since we understand the basic difference between the two phrases, our responses are very different. It is these very intricacies in natural language understanding that we want to teach to a machine.

What this could mean is when your future robot dog hears “I love you, Jimmy”, he would know LOVE is a Verb. He would also realize that it’s an emotion that we are expressing to which he would respond in a certain way. And maybe when you are telling your partner “Lets make LOVE”, the dog would just stay out of your business 😛.

This is just an example of how teaching a robot to communicate in a language known to us can make things easier.

The primary use case being highlighted in this example is how important it is to understand the difference in the usage of the word LOVE, in different contexts.

Part-of-Speech Tagging

From a very small age, we have been made accustomed to identifying part of speech tags. For example, reading a sentence and being able to identify what words act as nouns, pronouns, verbs, adverbs, and so on. All these are referred to as the part of speech tags.

Let’s look at the Wikipedia definition for them:

In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging or word-category disambiguation, is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context — i.e., its relationship with adjacent and related words in a phrase, sentence, or paragraph. A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.

Identifying part of speech tags is much more complicated than simply mapping words to their part of speech tags. This is because POS tagging is not something that is generic. It is quite possible for a single word to have a different part of speech tag in different sentences based on different contexts. That is why it is impossible to have a generic mapping for POS tags.

As you can see, it is not possible to manually find out different part-of-speech tags for a given corpus. New types of contexts and new words keep coming up in dictionaries in various languages, and manual POS tagging is not scalable in itself. That is why we rely on machine-based POS tagging.

Before proceeding further and looking at how part-of-speech tagging is done, we should look at why POS tagging is necessary and where it can be used.

Why Part-of-Speech tagging?

Part-of-Speech tagging in itself may not be the solution to any particular NLP problem. It is however something that is done as a pre-requisite to simplify a lot of different problems. Let us consider a few applications of POS tagging in various NLP tasks.

Text to Speech Conversion

Let us look at the following sentence:

They refuse to permit us to obtain the refuse permit.

The word refuse is being used twice in this sentence and has two different meanings here. refUSE (/rəˈfyo͞oz/)is a verb meaning “deny,” while REFuse(/ˈrefˌyo͞os/) is a noun meaning “trash” (that is, they are not homophones). Thus, we need to know which word is being used in order to pronounce the text correctly. (For this reason, text-to-speech systems usually perform POS-tagging.)

Have a look at the part-of-speech tags generated for this very sentence by the NLTK package.

>>> text = word_tokenize(""They refuse to permit us to obtain the refuse permit"")

>>> nltk.pos_tag(text)

[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'),

('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]

As we can see from the results provided by the NLTK package, POS tags for both refUSE and REFuse are different. Using these two different POS tags for our text to speech converter can come up with a different set of sounds.

Similarly, let us look at yet another classical application of POS tagging: word sense disambiguation.

Word Sense Disambiguation

Let’s talk about this kid called Peter. Since his mother is a neurological scientist, she didn’t send him to school. His life was devoid of science and math.

One day she conducted an experiment, and made him sit for a math class. Even though he didn’t have any prior subject knowledge, Peter thought he aced his first test. His mother then took an example from the test and published it as below. (Kudos to her!)

Word-sense Disambiguation example — My son Peter’s first Maths problem.

Words often occur in different senses as different parts of speech. For example:

She saw a bear.

Your efforts will bear fruit.

The word bear in the above sentences has completely different senses, but more importantly one is a noun and other is a verb. Rudimentary word sense disambiguation is possible if you can tag words with their POS tags.

Word-sense disambiguation (WSD) is identifying which sense of a word (that is, which meaning) is used in a sentence, when the word has multiple meanings.

Try to think of the multiple meanings for this sentence:

Time flies like an arrow

Here are the various interpretations of the given sentence. The meaning and hence the part-of-speech might vary for each word.

Part-of-speech tags define the meaning of a sentence based on the context

As we can clearly see, there are multiple interpretations possible for the given sentence. Different interpretations yield different kinds of part of speech tags for the words.This information, if available to us, can help us find out the exact version / interpretation of the sentence and then we can proceed from there.

The above example shows us that a single sentence can have three different POS tag sequences assigned to it that are equally likely. That means that it is very important to know what specific meaning is being conveyed by the given sentence whenever it’s appearing. This is word sense disambiguation, as we are trying to find out THE sequence.

These are just two of the numerous applications where we would require POS tagging. There are other applications as well which require POS tagging, like Question Answering, Speech Recognition, Machine Translation, and so on.

Now that we have a basic knowledge of different applications of POS tagging, let us look at how we can go about actually assigning POS tags to all the words in our corpus.

Types of POS taggers

POS-tagging algorithms fall into two distinctive groups:

Rule-Based POS Taggers

Stochastic POS Taggers

E. Brill’s tagger, one of the first and most widely used English POS-taggers, employs rule-based algorithms. Let us first look at a very brief overview of what rule-based tagging is all about.

Rule-Based Tagging

Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods.

Typical rule-based approaches use contextual information to assign tags to unknown or ambiguous words. Disambiguation is done by analyzing the linguistic features of the word, its preceding word, its following word, and other aspects.

For example, if the preceding word is an article, then the word in question must be a noun. This information is coded in the form of rules.

Example of a rule:

If an ambiguous/unknown word X is preceded by a determiner and followed by a noun, tag it as an adjective.

Defining a set of rules manually is an extremely cumbersome process and is not scalable at all. So we need some automatic way of doing this.

The Brill’s tagger is a rule-based tagger that goes through the training data and finds out the set of tagging rules that best define the data and minimize POS tagging errors. The most important point to note here about Brill’s tagger is that the rules are not hand-crafted, but are instead found out using the corpus provided. The only feature engineering required is a set of rule templates that the model can use to come up with new features.

Let’s move ahead now and look at Stochastic POS tagging.

Stochastic Part-of-Speech Tagging

The term ‘stochastic tagger’ can refer to any number of different approaches to the problem of POS tagging. Any model which somehow incorporates frequency or probability may be properly labelled stochastic.

The simplest stochastic taggers disambiguate words based solely on the probability that a word occurs with a particular tag. In other words, the tag encountered most frequently in the training set with the word is the one assigned to an ambiguous instance of that word. The problem with this approach is that while it may yield a valid tag for a given word, it can also yield inadmissible sequences of tags.

An alternative to the word frequency approach is to calculate the probability of a given sequence of tags occurring. This is sometimes referred to as the n-gram approach, referring to the fact that the best tag for a given word is determined by the probability that it occurs with the n previous tags. This approach makes much more sense than the one defined before, because it considers the tags for individual words based on context.

The next level of complexity that can be introduced into a stochastic tagger combines the previous two approaches, using both tag sequence probabilities and word frequency measurements. This is known as the Hidden Markov Model (HMM).

Before proceeding with what is a Hidden Markov Model, let us first look at what is a Markov Model. That will better help understand the meaning of the term Hidden in HMMs.

Markov Model

Say that there are only three kinds of weather conditions, namely

Rainy

Sunny

Cloudy

Now, since our young friend we introduced above, Peter, is a small kid, he loves to play outside. He loves it when the weather is sunny, because all his friends come out to play in the sunny conditions.

He hates the rainy weather for obvious reasons.

Every day, his mother observe the weather in the morning (that is when he usually goes out to play) and like always, Peter comes up to her right after getting up and asks her to tell him what the weather is going to be like. Since she is a responsible parent, she want to answer that question as accurately as possible. But the only thing she has is a set of observations taken over multiple days as to how weather has been.

How does she make a prediction of the weather for today based on what the weather has been for the past N days?

Say you have a sequence. Something like this:

Sunny, Rainy, Cloudy, Cloudy, Sunny, Sunny, Sunny, Rainy

So, the weather for any give day can be in any of the three states.

Let’s say we decide to use a Markov Chain Model to solve this problem. Now using the data that we have, we can construct the following state diagram with the labelled probabilities.",https://cdn-images-1.medium.com/max/1200/1*f6e0uf5PX17pTceYU4rbCA.jpeg,[],https://medium.freecodecamp.org/an-introduction-to-part-of-speech-tagging-and-the-hidden-markov-model-953d45338f24?source=collection_home---6------3----------------,2018-06-08 19:31:14.123000+00:00

NLP,A deep dive into part-of-speech tagging using the Viterbi algorithm,['Sachin Malhotra'],"Welcome back, Caretaker!

In case you’ve forgotten the problem we were trying to tackle in the previous article, let us revise it for you.

So there’s this naughty kid Peter and he’s going to pester his new caretaker, you!

As a caretaker, one of the most important tasks for you is to tuck Peter in bed and make sure he is sound asleep. Once you’ve tucked him in, you want to make sure that he’s actually asleep and not up to some mischief.

You cannot, however, enter the room again, as that would surely wake Peter up. All you can hear are the noises that might come from the room.

Either the room is quiet or there is noise coming from the room. These are your states.

All you have as the caretaker are:

a set of observations, which is basically a sequence containing noise or quiet over time, and

or over time, and A state diagram provided by Peter’s mom — who happens to be a neurological scientist — that contains all the different sets of probabilities that you can use to solve the problem defined below.

The problem

Given the state diagram and a sequence of N observations over time, we need to tell the state of the baby at the current point in time. Mathematically, we have N observations over times t0, t1, t2 .... tN . We want to find out if Peter would be awake or asleep, or rather which state is more probable at time tN+1 .

In case any of this seems like Greek to you, go read the previous article to brush up on the Markov Chain Model, Hidden Markov Models, and Part of Speech Tagging.

The state diagram that Peter’s mom gave you before leaving.

In that previous article, we had briefly modeled the problem of Part of Speech tagging using the Hidden Markov Model.

The problem of Peter being asleep or not is just an example problem taken up for a better understanding of some of the core concepts involved in these two articles. At the core, the articles deal with solving the Part of Speech tagging problem using the Hidden Markov Models.

So, before moving on to the Viterbi Algorithm, let’s first look at a much more detailed explanation of how the tagging problem can be modeled using HMMs.

Generative Models and the Noisy Channel Model

A lot of problems in Natural Language Processing are solved using a supervised learning approach.

Supervised problems in machine learning are defined as follows. We assume training examples (x(1), y(1)) . . . (x(m) , y(m)) , where each example consists of an input x(i) paired with a label y(i) . We use X to refer to the set of possible inputs, and Y to refer to the set of possible labels. Our task is to learn a function f : X → Y that maps any input x to a label f(x).

In tagging problems, each x(i) would be a sequence of words X1 X2 X3 …. Xn(i) , and each y(i) would be a sequence of tags Y1 Y2 Y3 … Yn(i) (we use n(i)to refer to the length of the i’th training example). X would refer to the set of all sequences x1 . . . xn, and Y would be the set of all tag sequences y1 . . . yn. Our task would be to learn a function f : X → Y that maps sentences to tag sequences.

An intuitive approach to get an estimate for this problem is to use conditional probabilities. p(y | x) which is the probability of the output y given an input x. The parameters of the model would be estimated using the training samples. Finally, given an unknown input x we would like to find

f(x) = arg max(p(y | x)) ∀y ∊ Y

This here is the conditional model to solve this generic problem given the training data. Another approach that is mostly adopted in machine learning and natural language processing is to use a generative model.

Rather than directly estimating the conditional distribution p(y|x) , in generative models we instead model the joint probability p(x, y) over all the (x, y) pairs.

We can further decompose the joint probability into simpler values using Bayes’ rule:

p(y) is the prior probability of any input belonging to the label y.

is the prior probability of any input belonging to the label y. p(x | y) is the conditional probability of input x given the label y.

We can use this decomposition and the Bayes rule to determine the conditional probability.

Remember, we wanted to estimate the function

f(x) = arg max( p(y|x) ) ∀y ∊ Y

f(x) = arg max( p(y) * p(x | y) )

The reason we skipped the denominator here is because the probability p(x) remains the same no matter what the output label being considered. And so, from a computational perspective, it is treated as a normalization constant and is normally ignored.

Models that decompose a joint probability into terms p(y) and p(x|y) are often called noisy-channel models. Intuitively, when we see a test example x, we assume that it has been generated in two steps:

first, a label y has been chosen with probability p(y) second, the example x has been generated from the distribution p(x|y). The model p(x|y) can be interpreted as a “channel” which takes a label y as its input, and corrupts it to produce x as its output.

Generative Part of Speech Tagging Model

Let us assume a finite set of words V and a finite sequence of tags K. Then the set S will be the set of all sequence, tags pairs <x1, x2, x3 ... xn, y1, y2, y3, ..., yn> such that n > 0 ∀x ∊ V and ∀y ∊ K .

A generative tagging model is then the one where

2.

Given a generative tagging model, the function that we talked about earlier from input to output becomes

Thus for any given input sequence of words, the output is the highest probability tag sequence from the model. Having defined the generative model, we need to figure out three different things:

How exactly do we define the generative model probability p(<x1, x2, x3 ... xn, y1, y2, y3, ..., yn>) How do we estimate the parameters of the model, and How do we efficiently calculate

Let us look at how we can answer these three questions side by side, once for our example problem and then for the actual problem at hand: part of speech tagging.

Defining the Generative Model

Let us first look at how we can estimate the probability p(x1 .. xn, y1 .. yn) using the HMM.

We can have any N-gram HMM which considers events in the previous window of size N.

The formulas provided hereafter are corresponding to a Trigram Hidden Markov Model.

Trigram Hidden Markov Model

A trigram Hidden Markov Model can be defined using

A finite set of states.

A sequence of observations.

q(s|u, v)

Transition probability defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations.

defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations. e(x|s)

Emission probability defined as the probability of making an observation x given that the state was s.

Then, the generative model probability would be estimated as

As for the baby sleeping problem that we are considering, we will have only two possible states: that the baby is either awake or he is asleep. The caretaker can make only two observations over time. Either there is noise coming in from the room or the room is absolutely quiet. The sequence of observations and states can be represented as follows:

Observations and States over time for the baby sleeping problem

Coming on to the part of speech tagging problem, the states would be represented by the actual tags assigned to the words. The words would be our observations. The reason we say that the tags are our states is because in a Hidden Markov Model, the states are always hidden and all we have are the set of observations that are visible to us. Along similar lines, the sequence of states and observations for the part of speech tagging problem would be

Observations and States over time for the POS tagging problem

Estimating the model’s parameters

We will assume that we have access to some training data. The training data consists of a set of examples where each example is a sequence consisting of the observations, every observation being associated with a state. Given this data, how do we estimate the parameters of the model?

Estimating the model’s parameters is done by reading various counts off of the training corpus we have, and then computing maximum likelihood estimates:

Transition probability and Emission probability for a Trigram HMM

We already know that the first term represents transition probability and the second term represents the emission probability. Let us look at what the four different counts mean in the terms above.

c(u, v, s) represents the trigram count of states u, v and s. Meaning it represents the number of times the three states u, v and s occurred together in that order in the training corpus. c(u, v) following along similar lines as that of the trigram count, this is the bigram count of states u and v given the training corpus. c(s → x) is the number of times in the training set that the state s and observation x are paired with each other. And finally, c(s) is the prior probability of an observation being labelled as the state s.

Let us look at a sample training set for the toy problem first and see the calculations for transition and emission probabilities using the same.

The BLUE markings represent the transition probability, and RED is for emission probability calculations.

Note that since the example problem only has two distinct states and two distinct observations, and given that the training set is very small, the calculations shown below for the example problem are using a bigram HMM instead of a trigram HMM.

Peter’s mother was maintaining a record of observations and states. And thus she even provided you with a training corpus to help you get the transition and emission probabilities.

Transition Probability Example:

Training Corpus

Calculations for Awake appearing after Awake

Emission Probability Example:

Training corpus

Calculations for observing ‘Quiet’ when the state is ‘Awake’

That was quite simple, since the training set was very small. Let us look at a sample training set for our actual problem of part of speech tagging. Here we can consider a trigram HMM, and we will show the calculations accordingly.

We will use the following sentences as a corpus of training data (the notation word/TAG means word tagged with a specific part-of-speech tag).

The training set that we have is a tagged corpus of sentences. Every sentence consists of words tagged with their corresponding part of speech tags. eg:- eat/VB means that the word is “eat” and the part of speech tag in this sentence in this very context is “VB” i.e. Verb Phrase. Let us look at a sample calculation for transition probability and emission probability just like we saw for the baby sleeping problem.

Transition Probability

Let’s say we want to calculate the transition probability q(IN | VB, NN). For this, we see how many times we see a trigram (VB,NN,IN) in the training corpus in that specific order. We then divide it by the total number of times we see the bigram (VB,NN) in the corpus.

Emission Probability

Let’s say we want to find out the emission probability e(an | DT). For this, we see how many times the word “an” is tagged as “DT” in the corpus and divide it by the total number of times we see the tag “DT” in the corpus.

So if you look at these calculations, it shows that calculating the model’s parameters is not computationally expensive. That is, we don’t have to do multiple passes over the training data to calculate these parameters. All we need are a bunch of different counts, and a single pass over the training corpus should provide us with that.

Let’s move on and look at the final step that we need to look at given a generative model. That step is efficiently calculating

We will be looking at the famous Viterbi Algorithm for this calculation.

Finding the most probable sequence — Viterbi Algorithm

Finally, we are going to solve the problem of finding the most likely sequence of labels given a set of observations x1 … xn. That is, we are to find out

The probability here is expressed in terms of the transition and emission probabilities that we learned how to calculate in the previous section of the article. Just to remind you, the formula for the probability of a sequence of labels given a sequence of observations over “n” time steps is

Before looking at an optimized algorithm to solve this problem, let us first look at a simple brute force approach to this problem. Basically, we need to find out the most probable label sequence given a set of observations out of a finite set of possible sequences of labels. Let’s look at the total possible number of sequences for a small example for our example problem and also for a part of speech tagging problem.

Say we have the following set of observations for the example problem.

Noise Quiet Noise

We have two possible labels {Asleep and Awake}. Some of the possible sequence of labels for the observations above are:

Awake Awake Awake

Awake Awake Asleep

Awake Asleep Awake

Awake Asleep Asleep

In all we can have ²³ = 8 possible sequences. This might not seem like very many, but if we increase the number of observations over time, the number of sequences would increase exponentially. This is the case when we only had two possible labels. What if we have more? As is the case with part of speech tagging.

For example, consider the sentence

the dog barks

and assuming that the set of possible tags are {D, N, V}, let us look at some of the possible tag sequences:

D D D

D D N

D D V

D N D

D N N

D N V ... etc

Here, we would have ³³ = 27 possible tag sequences. And as you can see, the sentence was extremely short and the number of tags weren’t very many. In practice, we can have sentences that might be much larger than just three words. Then the number of unique labels at our disposal would also be too high to follow this enumeration approach and find the best possible tag sequence this way.

So the exponential growth in the number of sequences implies that for any reasonable length sentence, the brute force approach would not work out as it would take too much time to execute.

Instead of this brute force approach, we will see that we can find the highest probable tag sequence efficiently using a dynamic programming algorithm known as the Viterbi Algorithm.

Let us first define some terms that would be useful in defining the algorithm itself. We already know that the probability of a label sequence given a set of observations can be defined in terms of the transition probability and the emission probability. Mathematically, it is

Let us look at a truncated version of this which is

and let us call this the cost of a sequence of length k.

So the definition of “r” is simply considering the first k terms off of the definition of probability where k ∊ {1..n} and for any label sequence y1…yk.

Next we have the set S(k, u, v) which is basically the set of all label sequences of length k that end with the bigram (u, v) i.e.

Finally, we define the term π(k, u, v) which is basically the sequence with the maximum cost.

The main idea behind the Viterbi Algorithm is that we can calculate the values of the term π(k, u, v) efficiently in a recursive, memoized fashion. In order to define the algorithm recursively, let us look at the base cases for the recursion.

π(0, *, *) = 1

π(0, u, v) = 0

Since we are considering a trigram HMM, we would be considering all of the trigrams as a part of the execution of the Viterbi Algorithm.

Now, we can start the first trigram window from the first three words of the sentence but then the model would miss out on those trigrams where the first word or the first two words occurred independently. For that reason, we consider two special start symbols as * and so our sentence becomes

* * x1 x2 x3 ...... xn

And the first trigram we consider then would be (*, *, x1) and the second one would be (*, x1, x2).

Now that we have all our terms in place, we can finally look at the recursive definition of the algorithm which is basically the heart of the algorithm.",https://cdn-images-1.medium.com/max/1200/1*x-5ZBtUvlD78BOMuMnMAbg.png,[],https://medium.freecodecamp.org/a-deep-dive-into-part-of-speech-tagging-using-viterbi-algorithm-17c8de32e8bc?source=collection_home---6------4----------------,2018-06-08 19:05:31.518000+00:00

NLP,A quick introduction to OAuth using Passport.js – freeCodeCamp,['Arun Kumar'],"A quick introduction to OAuth using Passport.js

What is OAuth?

OAuth (Open Authorization) is an authorization protocol. A third party application can use it to access user data from a site (like Google or Twitter) without revealing their password. Sites like Quora, Medium, AirBnb and many others offer authentication using OAuth.

OAuth really makes our lives simpler by eliminating the need to remember the password of every account you create on almost any site. You just have to remember your OAuth provider’s main account password.

What is Passport.js?

Passport is a middleware which implements authentication on Express-based web applications. It provides over 500+ strategies. What are these strategies? Strategies are used to authenticate requests. Each strategy has its own npm package (such as passport-twitter, passport-google-oauth20). A strategy must be configured before usage.

Why use Passport.js?

Here are six reasons stating why you should use Passport:

It is lightweight

Easily configurable

Supports persistent sessions

Offers OAuth

Provides separate modules for each strategy

Gives you the ability to implement custom strategies

Let’s build something

To get started, we need to install passport from NPM:

npm install passport

We are going to build a simple app which grants the user access to a secret route only if they log in. I’m going to be using the passport-google-oauth20 strategy in this tutorial. Feel free to use any other strategy you prefer, but make sure to check the docs to see how it is configured.

Before continuing, we need a clientID and clientSecret. To get one, head over to https://console.developers.google.com and create a new project. Then go to Enable APIs and Services and enable the Google+ API. Select the API and click on create credentials.

Fill out the form and use the same callback URL on both the form and on your file. Make sure to read the comments on the code to figure out how everything fits together.

app.js

index.ejs

As you can see, we’ve created a /secret route, and only grant access to it if the user is authenticated. To verify whether the user is authenticated, we’ve created a middleware which checks if the request has the user object in it. Finally, to log out we used the req.logout() method provided by passport to clear the session.

Here are some resources to learn more about passport

Complete Passport.js tutorial series

Conclusion

We only saw one strategy here. There are 500+ more. I highly recommend that you skim through Passport’s official documentation and find out what else they offer. Thank you for taking your time to read this. Feel free to connect with me on LinkedIn, Twitter and GitHub. I wish you good luck!

“Do what is great, written on a computer monitor.” by Martin Shreder on Unsplash

Previous article",https://cdn-images-1.medium.com/max/1200/0*gWsdm7w5PSZNR08L,[],https://medium.freecodecamp.org/a-quick-introduction-to-oauth-using-passport-js-65ea5b621a?source=collection_home---6------5----------------,2018-06-07 22:11:44.925000+00:00

NLP,How to control your randomizer in R – freeCodeCamp,['Michelle Jones'],"What happens when you need a particular type of randomization?

Overview of random number generation in R

R has at least 20 random number generator functions. Each uses a specific probability distribution to create the numbers. All require you to specify the number of random numbers you want (the above image shows 200). All are available in base R — no packages required.

Common random number generator distributions are:

normal (rnorm): default mean of 0 and standard deviation of 1

binomial (rbinom): no defaults, specify the number of trials and the probability of success on each trial

uniform (runif): default minimum value of 0 and maximum value of 1

Of the three above, only the binomial random number generator creates integers.

Why create random numbers?

Problems involving random numbers are very common — there are around 50,000 questions relating to random numbers on Stack Exchange.

But why use them?

Random numbers have many practical applications. They are used in Monte Carlo simulations. They are used in cryptography. They have been used to produce CAPTCHA content. They are used in slot machines. They have also been used for more mundane tasks such as creating a random sort order for an array of ordered data.

Problems with random numbers

Common questions include “are my random numbers actually random?” and “how can I generate non-repeated random numbers?”

Note: the latter decreases randomness, because the population of possible random numbers is decreased by one each time a random number is drawn. The method is appropriate in situations such as lotteries or bingo, where each ticket or ball can only be drawn once.

This problem brings in another problem! The randomly generated, sampling without replacement numbers must be integers. No one has ticket 5.6932 or bingo ball 0.18967.

A practical example of random number problems

Let’s take the example that I have 20 female students of the same age. I have four teaching methods that I want to trial. I only want to trial one teaching method for each student. Easy math— I need five students in each group.

But how do I do this so that each student is randomly assigned?

And how do I make sure that I only have integers produced?

And how do I do all this while using randomly generated numbers without replacement? I don’t want, for example, six students in one group, and four students in another.

First, I need to create some dummy data, in R. Let’s create that list of mock female students.

FemaleStudents <- data.frame(Names=c(""Alice"", ""Betty"", ""Carol"", ""Denise"", ""Erica"", ""Frances"", ""Gina"", ""Helen"", ""Iris"", ""Julie"", ""Katherine"",

""Lisa"", ""Michelle"", ""Ngaire"", ""Olivia"", ""Penelope"", ""Rachel"", ""Sarah"", ""Trudy"", ""Uma""))

Now we have a one-dimensional dataset of our 20 students.

We know that the runif() function doesn’t create integers. Why don’t we round the random numbers so that we only get integers and use this function? We can wrap the random number in a rounding function.

Question 1: why am I using the random uniform distribution and not another one, such as the random normal distribution?

There are five types of rounding functions in R. We will use round() .

So that we get the same results, I will set a seed for the random number generation. Each time we generate random numbers, we will use the same seed. I’ve decided on 5 as the seed. If you do not set a seed, or if you set a seed other than 5, your results will be different than mine.

set.seed(5)

FemaleStudents$Group <- round(runif(20, 1, 5))

Well, that seemed to work. We have each student allocated to a group numbered between 1 and 5.

Let’s double check our allocation.

table(FemaleStudents$Group)

1 2 3 4 5

2 6 5 4 3

Darn. Only one of the five groups has the correct number of students (Group 4). Why did this happen?

We can check the numbers actually output by runif() without rounding, and letting the output print to the console. Here, the output prints because I have not assigned the function to an object (for example, to a data.frame variable).

set.seed(5)

runif(20,1,5)

[1] 1.800858 3.740874 4.667503 2.137598 1.418601 3.804230 3.111840 4.231741 4.826001 1.441812 2.093140 2.962053 2.273616 3.236691 2.050373

[16] 1.807501 2.550103 4.551479 3.219690 4.368718

As we can see, the rounding caused our problem. But if we hadn’t rounded, each student would have been assigned to a different group.

What do we do?

sample()

sample() is now one of my favourite functions in R. Let’s see how it works.

Randomly allocate to equally sized groups (counts matter)

How can we use it to randomly assign our 20 students to four equally sized groups?

What happens if we try sample() normally?

set.seed(5)

FemaleStudents$Sample <- sample(1:5, nrow(FemaleStudents), replace=TRUE)

Question 2: what output did you get when you used table(FemaleStudents$Sample) ?

We can fix this problem by creating a vector of group numbers, and then using sampling without replacement from this vector. The rep command is used to create a range of repeated values. You can use it to repeat each number in the series, as I have used here. Number 1 is repeated four times, then number 2 is repeated four times, and so forth. You can also use it to repeat a sequence of numbers, if you use this code instead: rep(1:5,4)

OurGroups <- rep(1:5, each=4)

set.seed(5)

FemaleStudents$Sample <- sample(OurGroups, nrow(FemaleStudents), replace=FALSE)

We used our vector of numbers ( OurGroups ) to allocate our students to groups. We used sampling without replacement ( replace=FALSE ) from OurGroups because we need to use each value in that vector. We need to remove each value as we use it.

And we get the result we wanted!

table(FemaleStudents$Sample)

1 2 3 4 5

4 4 4 4 4

Question 3: why did I still set a seed?

Another advantage of sample() is that it doesn’t care about type. We can repeat the allocation using a vector of strings. This can be useful if you don’t want to keep referring back to what “1” means.

OurNamedGroups <- rep(c(""Up"", ""Down"", ""Charmed"", ""Strange"", ""Top""), each=4)

set.seed(5)

FemaleStudents$Sample2 <- sample(OurNamedGroups, nrow(FemaleStudents), replace=FALSE)

table(FemaleStudents$Sample2)

Charmed Down Strange Top Up

4 4 4 4 4

Because we used the same seed, we can see that the same student allocation was performed, irrespective of whether we used numeric or character data for the assignment.

table(FemaleStudents$Sample,FemaleStudents$Sample2)



Charmed Down Strange Top Up

1 0 0 0 0 4

2 0 4 0 0 0

3 4 0 0 0 0

4 0 0 4 0 0

5 0 0 0 4 0

Randomly allocate when group size is not restricted

Sometimes we want to randomly allocate to groups, but we don’t have a vector of groups. We are still only allocating each unit (person, sheep, block of cheese) to a single group, and we use completely random allocation.

Let’s say that our school has a new, special library room. It’s been constructed to be soundproof to give students a better studying environment. The chief librarian would like to know about the experiences of students in that room. The only problem is that the room is limited in size. The chief librarian thinks that around four students is a large enough group to provide the initial feedback.

Again, we can use sample() to pick our student groups. In this case, we have “students who will test the room” and “students who won’t test the room”. I’m going to call them “Test” and “Not test”. These labels have been chosen for being 1. short and 2. easily distinguished.

Because we did sampling without replacement earlier, we didn’t specify probabilities of assignment to groups — we simply pulled out an assignment from a vector. Now we are going to use sampling with replacement. With replacement refers to the group, not to the students.

We need to sample with replacement as we only have two groups (“Test”, “Not test”) and 20 students. If we tried to sample without replacement, our code would error.

Our code is very similar:

set.seed(5)

FemaleStudents$Library <- sample(c(""Test"", ""Not test""), nrow(FemaleStudents), replace=TRUE, prob=c(4/20,16/20))

table(FemaleStudents$Library)

Not test Test

15 5

As you can see, we allocated five students to test the room, not four. This type of result is expected when dealing with small samples. However, our allocation of students is completely random. Each student had exactly the same probability of being assigned to test the room. Whether previous students were testers or not had no impact on the allocation of the next student.

Let’s walk through some of that code.

I’ve constructed a new variable in the data.frame to collect the allocation ( Library ).

Instead of dealing with numbers for group names, I’ve used the strings I mentioned earlier. Because I’ve used strings, the c() must wrap the group names ( “Test”, “Not test” ) and each group name is separated by a comma.

Replacement has been set to TRUE .

The probability of assignment to either group must be provided. This is the prob=c(4/20,16/20) part of the sample() function. Again, note how c() is used to contain the probabilities. Also of interest is that the probabilities can be expressed as fractions, rather than decimals.

Hooray for sample()

I use sample() all the time for the work I am doing. The ability to use strings, as well as to restrict numeric output to integers (and define the desired integer range), provides me with more control than trying to use one of the random number functions.

Answers

Answer 1: I used a random uniform distribution because I wanted each value to be equally probable.

Answer 2: I got this output:

1 2 3 4 5

2 7 4 2 5

Answer 3: If we don’t set a seed value, or we use a different one, the allocation of specific students will be different. For example, when the seed is 5, Alice is allocated to group 2. If the seed is 7, Alice is allocated to group 5. Replication is important when code needs to be re-run (for example, in testing).",https://cdn-images-1.medium.com/max/1200/1*aI6mpoboOmJMKqvEU593xA.png,[],https://medium.freecodecamp.org/how-to-control-your-randomizer-in-r-852ae7d8f80c?source=collection_home---6------6----------------,2018-06-07 20:10:57.677000+00:00

NLP,How to style your webpage or markdown like a Medium article — or however you want,[],"View the respective pages at: https://github.com/ryandav/link-formatter/ and https://ryandav.github.io/link-formatter/

Get started with Sass at https://sass-lang.com/guide",https://cdn-images-1.medium.com/max/1200/1*L8PQs8ubyxZVIr1EC-cZ6Q.png,[],https://medium.freecodecamp.org/style-webpage-or-markdown-like-medium-article-using-html-css-sass-bootstrap-c6f9e64c0955?source=collection_home---6------7----------------,2018-06-07 19:32:27.295000+00:00

NLP,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------,2018-06-07 17:57:40.375000+00:00

NLP,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------,2018-06-07 15:39:54.084000+00:00

NLP,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------#--responses,2018-06-07 15:39:54.084000+00:00

NLP,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------,2018-06-06 21:43:33.288000+00:00

NLP,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------#--responses,2018-06-06 21:43:33.288000+00:00

NLP,Follow these steps to solve any Dynamic Programming interview problem,['Nikola Otasevic'],"Follow these steps to solve any Dynamic Programming interview problem

Despite having significant experience building software products, many engineers feel jittery at the thought of going through a coding interview that focuses on algorithms. I’ve interviewed hundreds of engineers at Refdash, Google, and at startups I’ve been a part of, and some of the most common questions that make engineers uneasy are the ones that involve Dynamic Programming (DP).

Many tech companies like to ask DP questions in their interviews. While we can debate whether they’re effective in evaluating someone’s ability to perform in an engineering role, DP continues to be an area that trips engineers up on their way to finding a job that they love.

Dynamic Programming — Predictable and Preparable

One of the reasons why I personally believe that DP questions might not be the best way to test engineering ability is that they’re predictable and easy to pattern match. They allow us to filter much more for preparedness as opposed to engineering ability.

These questions typically seem pretty complex on the outside, and might give you an impression that a person who solves them is very good at algorithms. Similarly, people who may not be able to get over some mind-twisting concepts of DP might seem pretty weak in their knowledge of algorithms.

The reality is different, and the biggest factor in their performance is preparedness. So let’s make sure everyone is prepared for it. Once and for all.

7 Steps to solve a Dynamic Programming problem

In the rest of this post, I will go over a recipe that you can follow to figure out if a problem is a “DP problem”, as well as to figure out a solution to such a problem. Specifically, I will go through the following steps:

How to recognize a DP problem Identify problem variables Clearly express the recurrence relation Identify the base cases Decide if you want to implement it iteratively or recursively Add memoization Determine time complexity

Sample DP Problem

For the purpose of having an example for abstractions that I am going to make, let me introduce a sample problem. In each of the sections, I will refer to the problem, but you could also read the sections independently of the problem.

Problem statement:

In this problem, we’re on a crazy jumping ball, trying to stop, while avoiding spikes along the way.

Here are the rules:

1) You’re given a flat runway with a bunch of spikes in it. The runway is represented by a boolean array which indicates if a particular (discrete) spot is clear of spikes. It is True for clear and False for not clear.

Example array representation:

2) You’re given a starting speed S. S is a non-negative integer at any given point, and it indicates how much you will move forward with the next jump.

3) Every time you land on a spot, you can adjust your speed by up to 1 unit before the next jump.

4) You want to safely stop anywhere along the runway (does not need to be at the end of the array). You stop when your speed becomes 0. However, if you land on a spike at any point, your crazy bouncing ball bursts and it’s game over.

The output of your function should be a boolean indicating whether we can safely stop anywhere along the runway.

Step 1: How to recognize a Dynamic Programming problem

First, let’s make it clear that DP is essentially just an optimization technique. DP is a method for solving problems by breaking them down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions. The next time the same subproblem occurs, instead of recomputing its solution, you simply look up the previously computed solution. This saves computation time at the expense of a (hopefully) modest expenditure in storage space.

Recognizing that a problem can be solved using DP is the first and often the most difficult step in solving it. What you want to ask yourself is whether your problem solution can be expressed as a function of solutions to similar smaller problems.

In the case of our example problem, given a point on the runway, a speed, and the runway ahead, we could determine the spots where we could potentially jump next. Furthermore, it seems that whether we can stop from the current point with the current speed depends only on whether we could stop from the point we choose to go to next.

That is a great thing, because by moving forward, we shorten the runway ahead and make our problem smaller. We should be able to repeat this process all the way until we get to a point where it is obvious whether we can stop.

Recognizing a Dynamic Programming problem is often the most difficult step in solving it. Can the problem solution be expressed as a function of solutions to similar smaller problems?

Step 2: Identify problem variables

Now we have established that there is some recursive structure between our subproblems. Next, we need to express the problem in terms of the function parameters and see which of those parameters are changing.

Typically in interviews, you will have one or two changing parameters, but technically this could be any number. A classic example of a one-changing-parameter problem is “determine an n-th Fibonacci number”. Such an example for a two-changing-parameters problem is “Compute edit distance between strings”. If you’re not familiar with these problems, don’t worry about it.

A way to determine the number of changing parameters is to list examples of several subproblems and compare the parameters. Counting the number of changing parameters is valuable to determine the number of subproblems we have to solve. It’s also important in its own right in helping us strengthen the understanding of the recurrence relation from step 1.

In our example, the two parameters that could change for every subproblem are:

Array position (P) Speed (S)

One could say that the runway ahead is changing as well, but that would be redundant considering that the entire non-changing runway and the position (P) carry that information already.

Now, with these 2 changing parameters and other static parameters, we have the complete description of our sub-problems.

Identify the changing parameters and determine the number of subproblems.

Step 3: Clearly express the recurrence relation

This is an important step that many rush through in order to get into coding. Expressing the recurrence relation as clearly as possible will strengthen your problem understanding and make everything else significantly easier.

Once you figure out that the recurrence relation exists and you specify the problems in terms of parameters, this should come as a natural step. How do problems relate to each other? In other words, let’s assume that you have computed the subproblems. How would you compute the main problem?

Here is how we think about it in our sample problem:

Because you can adjust your speed by up to 1 before jumping to the next position, there are only 3 possible speeds, and therefore 3 spots in which we could be next.

More formally, if our speed is S, position P, we could go from (S, P) to:

(S, P + S); # if we do not change the speed (S — 1, P + S — 1); # if we change the speed by -1 (S + 1, P + S + 1); # if we change the speed by +1

If we can find a way to stop in any of the subproblems above, then we can also stop from (S, P). This is because we can transition from (S, P) to any of the above three options.

This is typically a fine level of understanding of the problem (plain English explanation), but you sometimes might want to express the relation mathematically as well. Let’s call a function that we’re trying to compute canStop. Then:

canStop(S, P) = canStop(S, P + S) || canStop(S — 1, P + S — 1) || canStop(S + 1, P + S + 1)

Woohoo, it seems like we have our recurrence relation!

Recurrence relation: Assuming you have computed the subproblems, how would you compute the main problem?

Step 4: Identify the base cases

A base case is a subproblem that doesn’t depend on any other subproblem. In order to find such subproblems, you typically want to try a few examples, see how your problem simplifies into smaller subproblems, and identify at what point it cannot be simplified further.

The reason a problem cannot be simplified further is that one of the parameters would become a value that is not possible given the constraints of the problem.

In our example problem, we have two changing parameters, S and P. Let’s think about what possible values of S and P might not be legal:

P should be within the bounds of the given runway P cannot be such that runway[P] is false because that would mean that we’re standing on a spike S cannot be negative, and a S==0 indicates that we’re done

Sometimes it can be a little challenging to convert assertions that we make about parameters into programmable base cases. This is because, in addition to listing the assertions if you want to make your code look concise and not check for unnecessary conditions, you also need to think about which of these conditions are even possible.

In our example:

P < 0 || P >= length of runway seems like the right thing to do. An alternative could be to consider making P == end of runway a base case. However, it is possible that a problem splits into a subproblem which goes beyond the end of the runway, so we really need to check for inequality. This seems pretty obvious. We can simply check if runway[P] is false. Similar to #1, we could simply check for S < 0 and S == 0. However, here we can reason that it is impossible for S to be < 0 because S decreases by at most 1, so it would have to go through S == 0 case beforehand. Therefore S == 0 is a sufficient base case for the S parameter.

Step 5: Decide if you want to implement it iteratively or recursively

The way we talked about the steps so far might lead you to think that we should implement the problem recursively. However, everything that we’ve talked about so far is completely agnostic to whether you decide to implement the problem recursively or iteratively. In both approaches, you would have to determine the recurrence relation and the base cases.

To decide whether to go iteratively or recursively, you want to carefully think about the trade-offs.

Stack overflow issues are typically a deal breaker and a reason why you would not want to have recursion in a (backend) production system. However, for the purposes of the interview, as long as you mention the trade-offs, you should typically be fine with either of the implementations. You should feel comfortable implementing both.

In our particular problem, I implemented both versions. Here is python code for that:

A recursive solution: (original code snippets can be found here)

An iterative solution: (original code snippets can be found here)

Step 6: Add memoization

Memoization is a technique that is closely associated with DP. It is used for storing the results of expensive function calls and returning the cached result when the same inputs occur again.

Why are we adding memoization to our recursion? We encounter the same subproblems which, without memoization, are computed repeatedly. Those repetitions very often lead to exponential time complexities.

In recursive solutions, adding memoization should feel straightforward. Let’s see why. Remember that memoization is just a cache of the function results. There are times when you want to deviate from this definition in order to squeeze out some minor optimizations, but treating memoization as a function result cache is the most intuitive way to implement it.

This means that you should:

Store your function result into your memory before every return statement Look up the memory for the function result before you start doing any other computation

Here is the code from above with added memoization (added lines are highlighted): (original code snippets can be found here)

In order to illustrate the effectiveness of memoization and different approaches, let’s do some quick tests. I will stress test all three methods that we have seen so far. Here is the set up:

I created a runway of length 1000 with spikes in random places (I chose to have a probability of a spike being in any given spot to be 20%) initSpeed = 30 I ran all functions 10 times and measured the average time of execution

Here are the results (in seconds):

You can see that the pure recursive approach takes about 500x more time than the iterative approach and about 1300x more time than the recursive approach with memoization. Note that this discrepancy would grow rapidly with the length of the runway. I encourage you to try running it yourself.

Step 7: Determine Time complexity

There are some simple rules that can make computing time complexity of a dynamic programming problem much easier. Here are two steps that you need to do:

Count the number of states — this will depend on the number of changing parameters in your problem Think about the work done per each state. In other words, if everything else but one state has been computed, how much work do you have to do to compute that last state?

In our example problem, the number of states is |P| * |S|, where

P is the set of all positions (|P| indicates the number of elements in P)

S is the set of all speeds

The work done per each state is O(1) in this problem because, given all other states, we simply have to look at 3 subproblems to determine the resulting state.

As we noted in the code before, |S| is limited by length of the runway (|P|), so we could say that the number of states is |P|² and because work done per each state is O(1), then the total time complexity is O(|P|²).

However, it seems that |S| can be further limited, because if it were really |P|, it is very clear that stopping would not be possible because you would have to jump the length of the entire runway on the first move.

So let’s see how we can put a tighter bound on |S|. Let’s call maximum speed S. Assume that we’re starting from position 0. How quickly could we stop if we were trying to stop as soon as possible and if we ignore potential spikes?

In the first iteration, we would have to come at least to the point (S-1), by adjusting our speed at zero by -1. From there we would at a minimum go by (S-2) steps forward, and so on.

For a runway of length L, the following has to hold:

=> (S-1) + (S-2) + (S-3) + ….+ 1 < L

=> S*(S-1) / 2 < L

=> S < sqrt(2L + 1)

That is the maximum speed that we could possibly have on a runway of a length L. If we had a speed higher than that, we could not stop even theoretically, irrespective of the position of the spikes.

That means that the total time complexity depends only on the length of the runway L in the following form:

O(L * sqrt(L)) which is better than O(L²)

O(L * sqrt(L)) is the upper bound on the time complexity

Awesome, you made it through! :)

The 7 steps that we went through should give you a framework for systematically solving any dynamic programming problem. I highly recommend practicing this approach on a few more problems to perfect your approach.

Here are some next steps that you can take

Extend the sample problem by trying to find a path to a stopping point. We solved a problem that tells you whether you can stop, but what if you wanted to also know the steps to take in order to stop eventually along the runway? How would you modify the existing implementation to do that? If you want to solidify your understanding of memoization, and understand that it is just a function result cache, you should read about decorators in Python or similar concepts in other languages. Think about how they would allow you to implement memoization in general for any function that you want to memoize. Work on more DP problems by following the steps we went through. You can always find a bunch of them online (ex. LeetCode or GeeksForGeeks). As you practice, keep in mind one thing: learn ideas, don’t learn problems. The number of ideas is significantly smaller and it’s an easier space to conquer which will also serve you much better.

When you feel like you’ve conquered these ideas, check out Refdash where you are interviewed by a senior engineer and get a detailed feedback on your coding, algorithms, and system design.",https://cdn-images-1.medium.com/max/1200/0*DpsbrfUM89M_LHKY.jpg,[],https://medium.freecodecamp.org/follow-these-steps-to-solve-any-dynamic-programming-interview-problem-cc98e508cd0e?source=collection_home---6------11----------------,2018-06-06 19:32:36.335000+00:00

NLP,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------,2018-06-06 17:23:02.015000+00:00

NLP,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------#--responses,2018-06-06 17:23:02.015000+00:00

NLP,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------,2018-06-06 16:42:46.938000+00:00

NLP,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------#--responses,2018-06-06 16:42:46.938000+00:00

NLP,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------,2018-06-06 01:10:32.658000+00:00

NLP,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------#--responses,2018-06-06 01:10:32.658000+00:00

NLP,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------,2018-06-06 00:59:12.072000+00:00

NLP,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------#--responses,2018-06-06 00:59:12.072000+00:00

NLP,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------,2018-06-06 00:20:56.870000+00:00

NLP,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------#--responses,2018-06-06 00:20:56.870000+00:00

NLP,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------,2018-06-05 20:08:25.488000+00:00

NLP,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------#--responses,2018-06-05 20:08:25.488000+00:00

NLP,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------,2018-06-05 16:44:13.144000+00:00

NLP,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------#--responses,2018-06-05 16:44:13.144000+00:00

NLP,A deeply detailed but never definitive guide to mobile development architecture,['Jose Berardo Cunha'],"A deeply detailed but never definitive guide to mobile development architecture

Native, Web, PWA, hybrid, Cross-Compiled… what is “the best” way to develop for Android and iOS platforms? What looks reasonable? And how are you supposed to choose among the options? In this article, I’ll lay it all out so you can make an informed decision.

First things first, let me provide you with a bit of context. I am an IT senior consultant, and the idea of putting together this guide was born from discussions with one of our clients about what could be the best approach for them. Yes, just for them. And we realized that we did not have a well-defined strategy, a solid and reliable foundation, to help us come up with the right answer.

And you know what? I could not find such a guide easily anywhere on the Internet, either. Although there are several articles about this topic, none of those I came across were reasonably complete. Unfortunately the majority overlook a lot of concepts or, even worse, are essentially wrong.

Now, I’d like to take a wider look. And while I’m potentially helping someone make their own decisions, I’m also asking around the community for more thoughts on the subject.

This guide has two parts:

Mobile Development Architectural Tiers (this) How to make your decision

It's also available on YouTube as a series of 10 videos and as a free course on Udemy. There, you’ll find the same written material as here, the same videos from the YouTube series, as well as quizzes to fix all the topics and a final certification.

So let’s get started.

Introduction

When it comes to mobile platforms, it's arguable that there are just two big players: Android and iOS. Other technologies like Tizen, Blackberry, or Windows Phone are either dead or have been around for a while and have no prospects of reaching any significative market share.

A quick look at this massive duopoly might make you think that developers do not have many options when creating mobile apps. This idea can't be further from the truth, though. You can quickly spot a fistful of programming languages being used out there: C/C++, Java, Kotlin, Objective-C, Swift, JavaScript, TypeScript, C#, Dart, Ruby, and I'm pretty sure I’ve missed a few more.

The same is true of mobile development frameworks. Unless you are not a developer, or have somehow been unaware of new technologies for the last 10 years, you’ve probably heard about Cordova/PhoneGap, React Native, Xamarin, Ionic, Nativescript, or Flutter, just to name a few cross-platform solutions for mobile apps.

So let’s look at all these pieces of the architecture and break things down a bit.

TL;DR

There's no clear winner. All approaches have pros and cons, and might be either the best fit or the worst fit for your next project. In this guide, I'm classifying many different solutions into various tiers according to the distance their architectures are from the native platform.

Native Apps

To start, let's go straight to the metal. Our first architectural tier is Native Apps.

Native Apps Tier — Where you develop for each specific platform (it might be even more specific when considering NDK)

This is the tier where you must be aware of the idiosyncrasies of each platform. It’s not my intention to dig into them, I just want to mention a few things in a bit of context.

You can watch this first part on Youtube.

iOS

Starting on the iOS side, just because it's simpler, there's only Apple ruling the world. Originally, developers needed to learn Objective-C, a proprietary object-oriented variation of C with some inspiration from SmallTalk (and an insanely long-named API).

In 2014, Apple announced Swift, a multi-paradigm language, which was a lot easier than its predecessor. It's still possible to deal with Objective-C legacy code, but Swift has reached high maturity levels. So, if you're planning to learn how to natively develop for iOS, Swift is definitely where you should start.

Android

On the Android side, there are a number of different manufacturers. The vast majority of them rely upon ARM processors. But generally speaking, Android apps lay on virtual machine instances (instances of ART) to help deal with potential underlying specificities (not without many amazing tricks).

That's why, originally, the language of choice was Java. It’s not only been the most popular language in the World for almost two decades (with a few position swaps with C), but it’s also notable for its Java Virtual Machine (JVM). This empowered developers to compile their code down to an intermediate bytecode that could be read and run by the JVM.

With the Android Native Development Kit (NDK), it's also possible to develop critical parts of the app directly in native code, writing in C/C++. In this case, you have to be aware of underlying platform quirks.

Kotlin is a language unveiled by JetBrains in 2011. When it first came out, despite its flexibility and conciseness, it wasn't more than yet another JVM language with more successful competitors like Scala, Clojure, or Groovy. However, after its first major release in 2016, it rapidly started to stand out from the crowd, especially after Google announced that it would be officially supported on the Android platform at Google I/O 2017.

Kotlin is becoming Google's first class language (currently Kotlin and Java — in this order — are used throughout Android's official documentation). A total Java replacement is expected even more so now that the US Federal Appeals Court has ruled on the endless lawsuit filed by Oracle accusing Google of violating Java copyrights.

Native components

Developing in this tier, you can also leverage all native APIs and, in particular, the native components. This saves your app from having to reinvent the wheel.

I've published a video demo of how to create a simple project on Xcode (iOS) and Android Studio. If you want to check it out:

Demo of iOS and Android basic projects.

Native Apps advantages

Best performance and top user engagement

Bleeding edge native features

Notably good IDEs Android Studio / Xcode

Modern high-level languages Kotlin / Swift

Very low-level approach with NDK

Native Apps disadvantages

Two codebases to maintain

Require installation (except Android Instant Apps)

Hard to analyze SEO

Very expensive to get users to download the app

Web Apps

On the other side of the spectrum, we have Web Apps. Web Apps are essentially apps run by the browser. You don't write code targeting the platform, but rather any browser running on top of it.

Web Apps Tier — clearly on top of a browser bar targeting a beast sitting in between Android and iOS.

In this tier you’ll find an insane number of contenders jumping at each other's throats. But they all use an arsenal consisting of the same weapons: HTML, CSS, and Javascript.

Web frameworks and libraries, even when leveraging CSS pre-compilers like LESS or SASS, even Javascript pre-compiled languages like TypeScript, CoffeeScript or Flow, even symbiosis like JSX or Elm, leaving alone tools like Babel used to transpile everything to Javascript with different configurable levels of conformance with ECMAScript yearly specifications (ES6 / ES7 / ES8, or if you prefer ES2015 / ES2016 / ES2017 / ES2018).

At the end of the day, they all are HTML, CSS, and JavaScript rendered and run by the browser. There's no direct access to native APIs like camera, vibration, battery status, or file system, but some of them can be achieved via Web API's:

The big issue with Web APIs is their maturity level. Many of them are not supported by some browsers. There are differences in implementations, especially across mobile browsers.

Web App advantages

Shared code between platforms and desktop browsers

Do not require previous installations, just navigate and use

Tons of frameworks and libraries to go with them

Best for SEO

Web App disadvantages

Lower performance

Hard to get a native user experience

Require an internet connection

Not available on official app stores

API not as mature and reliable as native API

Frameworks and Web components

Angular, React, and Vue are probably the most popular web frameworks as of 2018. To be precise, however, React is considered just a library due to its flexible and less opinionated nature. Angular, on the other hand, is a strongly opinionated framework. Vue lives at some point in between them.

Angular vs React vs Vue

Angular, originally called AngularJS, was presented to the world in 2010 by Google. It quickly started to shine, due to its inversion of paradigms in comparison with other libraries from that time (like jQuery, the most popular back then). Instead of directly talking to HTML elements to manipulate the UI state, with AngularJS, templates were magically updated whenever the JavaScript model was updated.

As AngularJS became more and more popular, it also grew in purpose. It turned into a complete and opinionated framework that was one of the first that took SPAs (Single Page Apps) seriously. This growth (in both aspects) was responsible for some API bloats and performance issues.

React was created by Facebook to solve their own needs on the presentation layer. It introduced many aspects that suddenly became very popular, like virtual DOM, one-way data flow (originally named Flux, especially popular through an implementation library called Redux), and a mixture of HTML and JavaScript called JSX.

Only in 2016, after long debates and unexpected big changes, Google launched version two of its popular web framework. They called it Angular, instead of AngularJS. But, as many people already called the first version “Angular” (without the ""JS"" suffix), people started calling the new version Angular 2. That turned into a naming problem, as Google also announced that it would release new major versions every 6 months.

In my opinion, that was a mammoth mistake. I've seen this before (with Struts vs Struts 2/WebWork, for example). They have a massively popular product that appears to have reached its plateau, and it has started to be more criticized than praised. If Google decides to rebuild it from the ground up, they should never, by any means, just change its major version. How will people trust that they will not repeat it every new major version release? Version two is supposed to present breaking changes, but it doesn't mean it can be totally revamped.

Angular is a spectacular web framework, and I really feel passionate about it. However, it's a completely new beast. It does not have much to do with AngularJS. Even Vue, which is another amazing framework (probably one of the most pleasant to work with, by the way) looks more similar to AngularJS from a bird's-eye view. I believe this caused a significant movement away from Angular and contributed substantially to React's popularity.

Vue is the only one of the three most popular web frameworks that is not backed by a big company. It was actually started by a former Google developer. Due to its formidable simplicity and tiny footprint, it got attention from a massive and enthusiastic community.

Although there are more complete solutions, they all work on top of the concept of web components. There's an open specification about them currently in progress in W3C, and some interesting implementations like Polymer, Stencil and X-Tag.

In the third video of the series, I don't spend too much time discussing frameworks but discuss web component libraries:

The Web Apps tier is discussed in Part 3 of the series

Mobile Apps vs Web Apps

I’m not sure if you’ve noticed, but the order of tiers I'm presenting here follows what I think is the easiest path to learn all approaches. I started from the Native Tier, the most genuinely mobile development. Then I decided to fly directly to the other extreme to present the Web Tier, which is the tier that has been available since the first smartphones.

Only now, after elaborating on a comparison between the two edges of my diagram, will I start talking about many of the cross-platform approaches to build mobile apps.

There's a long debate between Mobile Apps vs Web Apps. Everything I say about Mobile Apps is not exclusive to the Native Tier. It is also applicable to all cross-platform tiers I present later on.

The user behavior dilemma

Users spend more time on Mobile Apps (87%) than on Mobile Websites (13%)

According to a Comscore survey in 2017, a user's fidelity to a mobile app is way more relevant than it is to mobile websites. According to an aligned article on Forbes, this is usually because of convenience (for example, home screen buttons, widgets, top notifications), speed (for example, smoother interfaces, almost instant start ups), and stored settings (for example, offline content).

Mobile Websites reach more people (8.9M monthly unique visitors against 3.3M of Mobile Apps)

On the other hand, in the same Comscore data, we learn that customers can be reached more easily from mobile websites, as they are not as much tied to their few apps of preference. If you compare the most popular websites versus the most downloaded apps, it's estimated that an average of 8.9 million unique web visitors per month access the top 1000 websites. That's almost three times more than the average unique users of the top 1000 most downloaded apps.

Distribution (Web App) x Engagement (Mobile App)

That's all about distribution vs engagement. Your web app has a higher chance of being accessed, as users are more likely to try new things when navigating through their mobile browsers. But Mobile Apps have been proven to be more engaging, and catch the users attention for much longer periods.

Now that you understand the dilemma, let's have a look at Progressive Web Apps. This is an approach so tied to the Web Apps tier that I classify it as just an addendum to Web Apps. But it's a big disruptor and a serious candidate for the most prominent new and cool thing in web and mobile development.

Progressive Web Apps

Progressive Web Apps (PWAs) are a set of tools used to give Web App users the same experience they are accustomed to when they run Mobile Apps. This means that Web Apps can leverage the potentially higher levels of distribution with more decent levels of engagement.

Progressive Web Apps addendum to Web Apps tier

Google defined three main qualifications for PWAs: they must be Reliable, Fast, and Engaging.

Features called Service Workers and the App Shell are the foundation of Progressive Web Apps. They were created to promote apps’ reliability as they are now designed to work regardless of the device’s connection status. That includes offline mode, as well as poor connections. They also provide significant perceived performance boost, as apps launch using locally cached data, which eliminates delays for synchronous content downloads.

You could consider reliability an indirect vector of engagement. Users are not affected while commuting by train, for example. They can stay engaged.

The same applies to speed. According to Google:

53% of users will abandon a site if it takes longer than 3 seconds to load!

However, being exclusively reliable and fast on load doesn't necessarily guarantee high engagement. PWAs leverage mobile-related features that used to be exclusive to mobile apps, like an “Add to Home Screen” option and Push Notifications.

When it comes to to the “Add to Home Screen” feature, you might notice that Apple has had a similar feature since the very first iPhone. Some people even argue that Progressive Web Apps are Google's fancy new name for an original Apple idea.

And you really can’t completely disagree. Some ideas are actually cycling. They come, go away, and then come back with a new name and some enhancements (for instance, Service Workers), so they can finally stick around.

On the other hand, it’s hard to completely agree. Steve Jobs’ speech about Web 2.0 + AJAX and the memorable announcement of the iPhone back in WWDC 2007 are not convincing enough to call him as the father, or even the prophet, of PWAs.

To be fair, the Add to Home Screen capability on iPhone has been nothing more than a subtle, almost hidden, feature to generate desktop icons that just start up Web Apps in fullscreen mode. It has all the burden of HTTP request-response cycles and no clear path around caches.

PWAs start from the right point. They explore how previous installations of Web Apps aren’t necessary without losing the client-side bootstrap of Mobile Apps. This means that everything a user needs for their first interaction following startup might be locally cached (read: App Shell) and kept available as soon as they hit “Add to Home Screen.”

Moving onto another well-known characteristic of PWAs, let’s talk about the super engaging (or re-engaging) feature of the Mobile Apps world: Push Notifications. They are alert-style messages that appear on the top notification bar / area, as well as on lock screens. They have the power of pulling users back to your app once they receive the notification.

To reinforce the appeal of PWAs, Google has been pulling all modern Web APIs under the PWA umbrella. So expect to see things like Payment Requests, Credential Management, WebVR, Sensors, WebAssembly, and WebRTC in the context of Progressive Web Apps. But these feature are not necessarily tied to PWAs, and some were even born before the term PWA was coined.

PWA and Apple

Apple, on the other hand, announced their first solid milestones towards PWAs only in March 2018. Although there are still some limitations, the progress is appreciable. Some of the limitations might be related to the fact that Safari has fallen behind its competitors. Others could be attributed to Apple's philosophy of tight control.

Still, Apple has a more profitable App Store than Google. Apple's asserts that more criteria on app publications brings more overall reliability, and PWAs are bound to hurt the App Store's revenue. This suggests that some limitations that seem to be intentionally imposed (like 50Mb of PWA maximum cache size) will cost more to be revoked.

Unfortunately PWAs are not perfect

Web solutions and, on different levels, all cross-platform solutions struggle to attain the excellence and comprehensiveness of Native Apps. Every new feature, and every detail particular to Android or iOS makes that native feel harder and harder to access as you distance your app from the native tier.

Overall, PWAs fix some issues in the Web Apps tier. But there are other issues that can’t be fixed by a solution working on top of a browser.

What PWAs fix

More “native” experience

Faster load times

Do not require an internet connection

Force web developers to be aware of situations where there’s no connection as well as a bad connection

Incorporate features from Mobile Apps like Push Notifications, Geolocation, or Speech Recognition

What they don’t

Inherent slowness

Not available on app stores (just yet)

Still not fully supported by all browsers

Still lack mobile features like NFC, Ambient Light, Geofencing

Also lack support for peculiarities of Android or iOS like PiP, smart app banners, launch screen widgets, and 3D touch

In the video below, I do a brief overview of PWAs.

Progressive Web Apps are introduced in the Part 4 of the series

Hybrid Apps

At this level, we begin to dive into the Mobile App world. We’ll start from the most distant tier: Hybrid Apps.

The term Hybrid is also commonly applied to all cross-platform solutions. Here, however, I’m restricting it to Apps that work inside mobile components, called WebViews.

The Hybrid Apps tier. Below the browser's line but on top of WebViews

In the demos in the second video, my purpose for adding WebView as the Hello World example was to make clear that there's a native component for each platform that is able to perform like an actual browser.

Cordova/PhoneGap

Solutions like Cordova/PhoneGap close the gap (sorry for the uninspired pun) between Web and Mobile Apps. They provide tools to package developer's HTML, JavaScript, and CSS code (as well as any extra assets like images or videos) and transform them into Mobile Apps (yes, real Android or iOS apps). These apps have their WebView exclusively to interpret and run the original web code, starting with the “index.html” file in the app’s main folder (normally called “www”). They also bridge the JavaScript code to native APIs through plugins which are partially implemented in JavaScript and partially in a native language.

So, let's make things clearer. Hybrid Apps are able to access native APIs (instead of Web APIs), but they are enclosed by the WebView. A button with Cordova must be an HTML button rendered by a WebView instead of a mobile native button.

This is the magical tier that allows companies to port their Web Apps to Mobile Apps to be shipped by app stores. So any web framework is allowed here.

Ionic

Frameworks like Ionic wrap Cordova into their own solutions. With Ionic, you don't need to use Cordova’s command line interface (CLI), because all of its commands are wrapped by the Ionic CLI.

Recently, the Ionic team decided to take the reins of the entire stack of Hybrid Apps. So they launched a proposed replacement for Cordova called Capacitor. Capacitor has support for Cordova plugins, and can also be used by a non-Ionic project.

You can watch me going through a Cordova Hello World sample in the fifth video of the series:

Hybrid Apps are in Part 5 of the series.

Hybrid Apps advantages

They are essentially web apps that are shippable to official app stores

Can be used along with any JavaScript framework / library

The code is still highly shareable across platforms

Access to native features (for instance, camera, accelerometer, contact list)

Hybrid Apps disadvantages

Struggle with performance issues and memory consumption, as web views are responsible for rendering everything on screen

Have to mimic all native UI components on top of a single web view

Harder to be accepted and published on App Store

Usually take longer to have native features available for these environments

Web Native

Web Native is a relatively new and often misunderstood tier. That's where Web Apps meet native components. Although Appcelerator (Axway) Titanium has been around a long time, there are some relatively new competitors that justify making this a completely separate category of mobile apps.

Web Native Apps don't need WebView as they talk directly to other native components

As you can see above, there's no web view to render and run your application. So, how is your JavaScript executed? Is it compiled? Well, if you consider transpilation (compilation from one language to another — for example TypeScript to JavaScript), bundling, minification, mangling, and obfuscation all together as a compilation, yes JavaScript is compiled.

But the problem is, this doesn't make your JavaScript something directly understood by Android or iOS operational systems. And, in theory, there's no native component that only serves as a JavaScript engine without the bloat of the HTML layout engine.

The strategy is to ship JavaScript engines (normally V8 for Android and JavaScriptCore for iOS) along with your code. Although they have small footprints and are very fast, they are something external that must be provided by your app.

On the other hand, this approach tends to have better UI performance, as all the components are the same (or are based on the same thing for React Native, for example) as the ones used by Native Apps.

Web Native Apps advantages

Reach both platforms with one single codebase

Roughly the same performance as native apps, as they also deal with native UI components

Tweaks are necessary, but the code is still shareable with web development

Web Native Apps disadvantages

Even with one single codebase, the developer must be aware of native components

Steeper learning curve than Hybrid / Web Apps for web developers, especially when it comes to layout

React Native

In part 6 of the series, I do a quick Hello World in React Native. This shows, on Android Studio's Layout Inspector, what components were rendered in the emulator. I compare with the previous examples, ensuring that there's no WebView whatsoever.

Web Native Apps presentation with focus on React Native in Part 6 of the series.

Nativescript

Another amazing framework that I've been particularly interested in over the last two years (I have a course on Udemy about it — in Portuguese), is Nativescript. It’s similar to React Native but is not tied to the React world (there's an unofficial integration, Nativescript-Preact, though).

With Nativescript, you can develop using vanilla JavaScript, TypeScript, Angular and, more recently, Vue. Of course you can use other frameworks, but those are the ones officially supported. It’s fairly well documented too, by the way.

Nativescript has tools like Nativescript Sidekick and Nativescript Playground, as well as project structures based on templates that can be provided by the community. This should help you in project creation, giving you the ability to start, deploy, test, and run on simulators on the cloud and iPhone devices even when you are not developing using a Mac.

In the seventh part of the series, I do a Hello World using Sidekick along with another project started from the CLI and a WhatsApp clone template I created for learning purposes.

Web Native Apps with Nativescript in Part 7 of the series.

It's important to have a look at the Layout Inspector when your app is running on an Android emulator. With Nativescript, it shows the native components (again, no WebView), and direct instances of common Android classes like TextView. This is different than React Native, which has its own classes to wrap the native components.

That's probably why Nativescript claims that there’s no delay between when a new feature is available on iOS and Android and when you can use it in a Nativescript project. For example, they posted on their blog an AR project on the same day iOS 11 was officially released with the new ARKit API.

Weex

Another framework worth mentioning in this category is Weex. It's a project developed by Alibaba, and is currently incubated at Apache Sofware Foundation (ASF). It uses common HTML tags like <div> and CSS commands inside <style> tags to call native components instead. From their documentation:

Although components in Weex look like HTML tags, you are not able to use all of them. Instead, you can only use the built-in components and your custom components.

Cross Compiled

At this level, it’s time to jump off the Web bandwagon. This is the closest tier to native development, but has the advantage of using one single codebase to target Android and iOS.

Development tiers now complete with Cross Compiled Apps

RubyMotion and Xamarin

There are solutions like RubyMotion. This is a way to write mobile apps using Ruby and compile directly to the targeted platform (as it was created using any ""native"" language).

Another option is Xamarin, where you write in C#, compile to an intermediate bytecode, and deploy your app along with an instance of the Mono common language runtime. This approach has the same drawback as Web Native (where V8 and JavaScriptCore are delivered by your app), but can also rely upon JIT compilations to optimize the app at runtime.

Flutter

Last but not least, I'd like to bring up Flutter. It’s Google's newest cool initiative for mobile development. It fits in the Cross Compiled tier because you write apps using the Dart language and compile them down to the native platform.

Flutter has innovated in some aspects. Probably the most outstanding one is the fact that it provides its own set of components.

What? Own set of components?

Yes, Flutter provides a number of different components so you can completely skip the ones from the platform. It has generic components as well as Material Design components for Android, and Cupertino components for iOS.

Rather than .Net virtual machine (as Xamarin) or JavaScript engines (as Web Native frameworks), with Flutter your app will deliver the components you decide to use.

Are they native components?

Yes, they are. Your app is native, too. Everything is compiled to the native architecture. However, bear in mind they are not the pre-existing native components.

What's the point of that?

Well, in my opinion, this solution is clever and audacious. I've been waiting to talk about advantages and disadvantages, but as it's just one particular technology, let me address them now.

One of the biggest challenges for Web Native and Cross Compiled solutions (remember, above Native but below the WebView in our tiers) is how to deal with native components. For example, an important problem is how to lay them out. That's because they were not created to be used by those external resources. Also, they were not created with a counterpart in the other platform in mind. The Android NavBar doesn't work like iOS UINavBar, for example.

With Flutter, components are created with cross-platform always in mind. So let's have a look at the pros and cons of the Cross Compiled Apps tier:

Cross Compiled Apps advantages

Reach both platforms with one single language

Roughly the same performance as native apps, as they also deal with native UI components

Cross Compiled Apps disadvantages

Slightly delayed support for the latest platform updates

Code not shareable with web development

Even with one single codebase, the developer must be aware of native components

PS: With Flutter, you’ll provide your own set of widgets along with your app's code

Mobile Apps runtime architecture",https://cdn-images-1.medium.com/max/1200/1*kHze88HBCkKt8Tw4MESC9Q.png,[],https://medium.freecodecamp.org/a-deeply-detailed-but-never-definitive-guide-to-mobile-development-architecture-6b01ce3b1528?source=collection_home---6------21----------------,2018-06-05 16:34:24.241000+00:00

NLP,How to deliver a React Native app to the client – freeCodeCamp,[],"How to deliver a React Native app to the client

If you have written some React Native apps, you’ve probably noticed that the process of beta-release version generation requires many repeatable steps. This happens especially for multi-platform apps.

Let’s look at sample action steps you need to perform to deliver the beta version app to the client or tester:

Download the proper branch from the repository

Android:

Insert the APK signing key into the ./android/app/ directory

directory Build the release version

Send the app, for example via e-mail

iOS:

Launch Xcode

Change the scheme to Release

Change the jsCodeLocation value to a static main.jsbundle file path

value to a static file path Archive

Upload the app to TestFlight

As you can see, the above list contains a large number of repeatable steps. Since they are repeatable, we can automate them, right?

Possible solutions

There are several solutions for automating beta release version generation and delivering the app to the client.

Visual Studio App Center

The first solution that came to our minds at Brainhub was the use of the Visual Studio App Center. A project built by Microsoft seems to be really attractive — in addition to building the app in the cloud (free 240 minutes / month of building) and distribution among testers and the client, it also provides a platform for testing apps on many real devices, giving access to reports and screenshots of every step of the process.

However, it quickly turned out that this was not the appropriate solution for our particular project. VS App Center has limited configuration abilities, and the app’s code needs to be downloaded from the Git repository hosted on GitHub, Bitbucket, or VSTS. Due to the fact that we use GitLab, we had to rule out this solution (but it could work for your project).

HockeyApp (with Fastlane)

The next option was to use HockeyApp — a tool for app distribution and collecting crash reports and users’ feedback. The service was initially created for distribution of iOS apps using the ‘ad hoc’ method (outside of App Store), but currently it works for Android also.

HockeyApp works well as a delivery platform of software testing versions, but does not give the functionality of building the app. However, we can also use Fastlane — a tool for mobile app building process automation built by fabric.io.

Preparations

Before you start building and deploying the app, you should prepare the environment. This section describes the steps you should take first.

Automatic jsCodeLocation change

React Native documentation says that you should change jsCodeLocation to the static js bundle for the iOS release version in AppDelegate.m file. But there’s no need to do that manually every time you release the app — you can use the #ifdef DEBUG macro to do it automatically. Just replace the line containing jsCodeLocation = … with the following code.

#ifdef DEBUG

// DEV

jsCodeLocation = [[RCTBundleURLProvider sharedSettings] jsBundleURLForBundleRoot:@”index” fallbackResource:nil];

#else

// PROD

jsCodeLocation = [[NSBundle mainBundle] URLForResource:@”main” withExtension:@”jsbundle”];

#endif

Ignore helper files

During the process of building the app, there will be some helper files created. There’s no need to commit them to the repository, so just add them to the following “.gitignore” file.

# Deployment

*.cer

*.jsbundle

*.jsbundle.meta

*dSYM.zip

*.keystore

*.mobileprovision

fastlane/report.xml

APK signing key

To release an Android app, you need a signing key. To learn more about this process, look here.

When you have your key generated, move it to the “android/app” directory and remember to add *.keystore to “.gitignore”.

Fastlane + HockeyApp + Testflight

You will learn how to automatically generate an app written in React Native for Android and iOS platforms, and send it to HockeyApp (Android) and Testflight (iOS).

First, let’s install Fastlane. Make sure you have the newest version of Xcode command line tools installed.

xcode-select — install

Install Fastlane.

[sudo] gem install fastlane -NV` or `brew cask install fastlane`

Init Fastlane.

fastlane init

The command above will create the “fastlane” directory in current directory with a file called “Fastfile” that contains the Fastlane configuration.

Appfile

In the “fastlane” directory, create a file called “Appfile”, which stores data that is used across all fastlane tools, for example AppleID. It is required for the iOS build and deployment to Testflight.

Add your AppleID to “Appfile”.

Fastfile

Your beta release Fastfile might look like this.

# More documentation about how to customize your build

# can be found here:

# https://docs.fastlane.tools

# fastlane_version “2.68.0”

# Fastfile actions accept additional configuration, but

# don’t worry, fastlane will prompt you for required

# info which you can add here later

platform :ios do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

get_certificates

get_provisioning_profile(

app_identifier: “org.you.yourProject”

)

# build your iOS app

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

# TestFlight

pilot()

end

end

platform :android do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

# build the release variant

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

# upload to HockeyApp

hockey(

api_token: “YOUR_TOKEN”

)

end

end

Let’s analyze our “Fastfile” step-by-step.

The code block below will be executed after typing fastlane ios beta into the console.

platform :ios do

lane :beta do

# …

end

end

For Android , type fastlane android beta .

platform :android do

lane :beta do

# …

end

end

Ensure that the current branch is master and perform git pull to sync with the remote repository.

ensure_git_branch(

branch: “master”

)

git_pull

iOS only

Let’s increment the build number (works for iOS only). The application that is being sent to Testflight has to have a higher build number than the previous version.

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

Testflight and Ad Hoc distribution require the proper certificate and provisioning profile. There are several methods of signing apps:

match

cert and sigh

Xcode’s code signing feature

manually

In this article, cert and sigh was used. For further reading about codesigning using Fastlane, visit this site.

get_certificates

get_provisioning_profile( app_identifier: “org.you.yourProject” )

Next, there is the step of building the iOS version where we pass the params such as project path, scheme , and export_method . Export_method contains one of the following values: app-store , ad-hoc , package , enterprise , development , or developer-id .

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

The last step for iOS is sending the app to Testflight.

pilot()

Android only

Now let’s look at the Android version. There are two gradle steps: cleaning, and building the release version.

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

Now you can send the generated app to HockeyApp.

hockey(

api_token: “YOUR_TOKEN”

)

If you don’t add some required parameter, for example no iTunes Connect user in Fastfile, Fastlane will ask you for that data in the console.

HockeyApp Configuration

After signing up and signing in to HockeyApp, you will see the blue “New App” button.",https://cdn-images-1.medium.com/max/1200/1*153T3TpCccNK7hs11oRNpA.png,[],https://medium.freecodecamp.org/how-to-deliver-a-react-native-app-to-the-client-e58421e7272e?source=collection_home---6------22----------------,2018-06-05 01:26:27.937000+00:00

NLP,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------,2018-06-05 00:59:03.212000+00:00

NLP,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------#--responses,2018-06-05 00:59:03.212000+00:00

NLP,A coffee-break introduction to time complexity of algorithms,['Vicky Lai'],"A coffee-break introduction to time complexity of algorithms

Just like writing your very first for loop, understanding time complexity is an integral milestone to learning how to write efficient complex programs. Think of it as having a superpower that allows you to know exactly what type of program might be the most efficient in a particular situation — before even running a single line of code.

The fundamental concepts of complexity analysis are well worth studying. You’ll be able to better understand how the code you’re writing will interact with the program’s input, and as a result, you’ll spend a lot less wasted time writing slow and problematic code.

It won’t take long to go over all you need to know in order to start writing more efficient programs — in fact, we can do it in about fifteen minutes. You can go grab a coffee right now (or tea, if that’s your thing) and I’ll take you through it before your coffee break is over. Go ahead, I’ll wait.

All set? Let’s do it!

What is “time complexity” anyway?

The time complexity of an algorithm is an approximation of how long that algorithm will take to process some input. It describes the efficiency of the algorithm by the magnitude of its operations. This is different than the number of times an operation repeats. I’ll expand on that later. Generally, the fewer operations the algorithm has, the faster it will be.

We write about time complexity using Big O notation, which looks something like O(n). There’s rather a lot of math involved in its formal definition, but informally we can say that Big O notation gives us our algorithm’s approximate run time in the worst case, or in other words, its upper bound. It is inherently relative and comparative.

We’re describing the algorithm’s efficiency relative to the increasing size of its input data, n. If the input is a string, then n is the length of the string. If it’s a list of integers, n is the length of the list.

It’s easiest to picture what Big O notation represents with a graph:

Lines made with the very excellent Desmos graph calculator. You can play with this graph here.

Here are the main important points to remember as you read the rest of this article:

Time complexity is an approximation

An algorithm’s time complexity approximates its worst case run time

Determining time complexity

There are different classes of complexity that we can use to quickly understand an algorithm. I’ll illustrate some of these classes using nested loops and other examples.

Polynomial time complexity

A polynomial, from the Greek poly meaning “many,” and Latin nomen meaning “name,” describes an expression comprised of constant variables, and addition, multiplication, and exponentiation to a non-negative integer power. That’s a super math-y way to say that it contains variables usually denoted by letters, and symbols that look like these:

The below classes describe polynomial algorithms. Some have food examples.

Constant

A constant time algorithm doesn’t change its running time in response to the input data. No matter the size of the data it receives, the algorithm takes the same amount of time to run. We denote this as a time complexity of O(1).

Here’s one example of a constant algorithm that takes the first item in a slice.

func takeCupcake(cupcakes []int) int {

return cupcakes[0]

}

Choice of flavours are: vanilla cupcake, strawberry cupcake, mint chocolate cupcake, lemon cupcake, and “wibbly wobbly, timey wimey” cupcake.

With this contant-time algorithm, no matter how many cupcakes are on offer, you just get the first one. Oh well. Flavours are overrated anyway.

Linear

The running duration of a linear algorithm is constant. It will process the input in n number of operations. This is often the best possible (most efficient) case for time complexity where all the data must be examined.

Here’s an example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

}

Here’s another example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// double dip chip

}

}

It doesn’t matter whether the code inside the loop executes once, twice, or any number of times. Both these loops process the input by a constant factor of n, and thus can be described as linear.

Don’t double dip in a shared bowl.

Quadratic

Now here’s an example of code with time complexity of O(n2):

func pizzaDelivery(pizzas int) {

for pizza := 0; pizza <= pizzas; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

Because there are two nested loops, or nested linear operations, the algorithm process the input n2times.

Cubic

Extending on the previous example, this code with three nested loops has time complexity of O(n3):

func pizzaDelivery(boxesDelivered int) {

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

}

Seriously though, who delivers unsliced pizza??

Logarithmic

A logarithmic algorithm is one that reduces the size of the input at every step. We denote this time complexity as O(log n), where log, the logarithm function, is this shape:

One example of this is a binary search algorithm that finds the position of an element within a sorted array. Here’s how it would work, assuming we’re trying to find the element x:

If x matches the middle element m of the array, return the position of m. If x doesn’t match m, see if m is larger or smaller than x. If larger, discard all array items greater than m. If smaller, discard all array items smaller than m. Continue by repeating steps 1 and 2 on the remaining array until x is found.

I find the clearest analogy for understanding binary search is imagining the process of locating a book in a bookstore aisle. If the books are organized by author’s last name and you want to find “Terry Pratchett,” you know you need to look for the “P” section.

You can approach the shelf at any point along the aisle and look at the author’s last name there. If you’re looking at a book by Neil Gaiman, you know you can ignore all the rest of the books to your left, since no letters that come before “G” in the alphabet happen to be “P.” You would then move down the aisle to the right any amount, and repeat this process until you’ve found the Terry Pratchett section, which should be rather sizable if you’re at any decent bookstore, because wow did he write a lot of books.

Quasilinear

Often seen with sorting algorithms, the time complexity O(n log n) can describe a data structure where each operation takes O(log n) time. One example of this is quick sort, a divide-and-conquer algorithm.

Quick sort works by dividing up an unsorted array into smaller chunks that are easier to process. It sorts the sub-arrays, and thus the whole array. Think about it like trying to put a deck of cards in order. It’s faster if you split up the cards and get five friends to help you.

Non-polynomial time complexity

The below classes of algorithms are non-polynomial.

Factorial

An algorithm with time complexity O(n!) often iterates through all permutations of the input elements. One common example is a brute-force search, seen in the traveling salesman problem. It tries to find the least costly path between a number of points by enumerating all possible permutations and finding the ones with the lowest cost.

Exponential

An exponential algorithm often also iterates through all subsets of the input elements. It is denoted O(2n) and is often seen in brute-force algorithms. It is similar to factorial time except in its rate of growth, which, as you may not be surprised to hear, is exponential. The larger the data set, the more steep the curve becomes.

In cryptography, a brute-force attack may systematically check all possible elements of a password by iterating through subsets. Using an exponential algorithm to do this, it becomes incredibly resource-expensive to brute-force crack a long password versus a shorter one. This is one reason that a long password is considered more secure than a shorter one.

There are further time complexity classes less commonly seen that I won’t cover here, but you can read about these and find examples in this handy table.

Recursion time complexity

As I described in my article explaining recursion using apple pie, a recursive function calls itself under specified conditions. Its time complexity depends on how many times the function is called and the time complexity of a single function call. In other words, it’s the product of the number of times the function runs and a single execution’s time complexity.

Here’s a recursive function that eats pies until no pies are left:

func eatPies(pies int) int {

if pies == 0 {

return pies

}

return eatPies(pies - 1)

}

The time complexity of a single execution is constant. No matter how many pies are input, the program will do the same thing: check to see if the input is 0. If so, return, and if not, call itself with one fewer pie.

The initial number of pies could be any number, and we need to process all of them, so we can describe the input as n. Thus, the time complexity of this recursive function is the product O(n).

This function’s return value is zero, plus some indigestion.

Worst case time complexity

So far, we’ve talked about the time complexity of a few nested loops and some code examples. Most algorithms, however, are built from many combinations of these. How do we determine the time complexity of an algorithm containing many of these elements strung together?

Easy. We can describe the total time complexity of the algorithm by finding the largest complexity among all of its parts. This is because the slowest part of the code is the bottleneck, and time complexity is concerned with describing the worst case for the algorithm’s run time.

Say we have a program for an office party. If our program looks like this:

package main



import ""fmt""



func takeCupcake(cupcakes []int) int {

fmt.Println(""Have cupcake number"",cupcakes[0])

return cupcakes[0]

}



func eatChips(bowlOfChips int) {

fmt.Println(""Have some chips!"")

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

fmt.Println(""No more chips."")

}



func pizzaDelivery(boxesDelivered int) {

fmt.Println(""Pizza is here!"")

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

fmt.Println(""Pizza is gone."")

}



func eatPies(pies int) int {

if pies == 0 {

fmt.Println(""Someone ate all the pies!"")

return pies

}

fmt.Println(""Eating pie..."")

return eatPies(pies - 1)

}



func main() {

takeCupcake([]int{1, 2, 3})

eatChips(23)

pizzaDelivery(3)

eatPies(3)

fmt.Println(""Food gone. Back to work!"")

}

We can describe the time complexity of all the code by the complexity of its most complex part. This program is made up of functions we’ve already seen, with the following time complexity classes:

To describe the time complexity of the entire office party program, we choose the worst case. This program would have the time complexity O(n3).

Here’s the office party soundtrack, just for fun.

Have cupcake number 1

Have some chips!

No more chips.

Pizza is here!

Pizza is gone.

Eating pie...

Eating pie...

Eating pie...

Someone ate all the pies!

Food gone. Back to work!

P vs NP, NP-complete, and NP-hard

You may come across these terms in your explorations of time complexity. Informally, P (for Polynomial time), is a class of problems that is quick to solve. NP, for Nondeterministic Polynomial time, is a class of problems where the answer can be quickly verified in polynomial time. NP encompasses P, but also another class of problems called NP-complete, for which no fast solution is known. Outside of NP, but still including NP-complete, is yet another class called NP-hard, which includes problems that no one has been able to verifiably solve with polynomial algorithms.

P vs NP Euler diagram, by Behnam Esfahbod, CC BY-SA 3.0

P versus NP is an unsolved, open question in computer science.

Anyway, you don’t generally need to know about NP and NP-hard problems to begin taking advantage of understanding time complexity. They’re a whole other Pandora’s box.

Approximate the efficiency of an algorithm before you write the code

So far, we’ve identified some different time complexity classes and how we might determine which one an algorithm falls into. So how does this help us before we’ve written any code to evaluate?

By combining a little knowledge of time complexity with an awareness of the size of our input data, we can take a guess at an efficient algorithm for processing our data within a given time constraint. We can base our estimation on the fact that a modern computer can perform some hundreds of millions of operations in a second. The following table from the Competitive Programmer’s Handbook offers some estimates on required time complexity to process the respective input size in a time limit of one second.

Keep in mind that time complexity is an approximation, and not a guarantee. We can save a lot of time and effort by immediately ruling out algorithm designs that are unlikely to suit our constraints, but we must also consider that Big O notation doesn’t account for constant factors. Here’s some code to illustrate.

The following two algorithms both have O(n) time complexity.

func makeCoffee(scoops int) {

for scoop := 0; scoop <= scoops; scoop++ {

// add instant coffee

}

}

func makeStrongCoffee(scoops int) {

for scoop := 0; scoop <= 3*scoops; scoop++ {

// add instant coffee

}

}

The first function makes a cup of coffee with the number of scoops we ask for. The second function also makes a cup of coffee, but it triples the number of scoops we ask for. To see an illustrative example, let’s ask both these functions for a cup of coffee with a million scoops.

Here’s the output of the Go test:

Benchmark_makeCoffee-4 1000000000 0.29 ns/op

Benchmark_makeStrongCoffee-4 1000000000 0.86 ns/op

Our first function, makeCoffee , completed in an average 0.29 nanoseconds. Our second function, makeStrongCoffee , completed in an average of 0.86 nanoseconds. While those may both seem like pretty small numbers, consider that the stronger coffee took nearly three times longer to make. This should make sense intuitively, since we asked it to triple the scoops. Big O notation alone wouldn’t tell you this, since the constant factor of the tripled scoops isn’t accounted for.

Improve time complexity of existing code

Becoming familiar with time complexity gives us the opportunity to write code, or refactor code, to be more efficient. To illustrate, I’ll give a concrete example of one way we can refactor a bit of code to improve its time complexity.

Let’s say a bunch of people at the office want some pie. Some people want pie more than others. The amount that everyone wants some pie is represented by an int > 0:

diners := []int{2, 88, 87, 16, 42, 10, 34, 1, 43, 56}

Unfortunately, we’re bootstrapped and there are only three forks to go around. Since we’re a cooperative bunch, the three people who want pie the most will receive the forks to eat it with. Even though they’ve all agreed on this, no one seems to want to sort themselves out and line up in an orderly fashion, so we’ll have to make do with everybody jumbled about.

Without sorting the list of diners, return the three largest integers in the slice.

Here’s a function that solves this problem and has O(n2) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// loop over three forks

for i := 1; i <= 3; i++ {

// variables to keep track of the highest integer and where it is

var max, maxIndex int

// loop over the diners slice

for n := range diners {

// if this integer is higher than max, update max and maxIndex

if diners[n] > max {

max = diners[n]

maxIndex = n

}

}

// remove the highest integer from the diners slice for the next loop

diners = append(diners[:maxIndex], diners[maxIndex+1:]...)

// keep track of who gets a fork

withForks = append(withForks, max)

}

return withForks

}

This program works, and eventually returns diners [88 87 56] . Everyone gets a little impatient while it’s running though, since it takes rather a long time (about 120 nanoseconds) just to hand out three forks, and the pie’s getting cold. How could we improve it?

By thinking about our approach in a slightly different way, we can refactor this program to have O(n) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// create variables for each fork

var first, second, third int

// loop over the diners

for i := range diners {

// assign the forks

if diners[i] > first {

third = second

second = first

first = diners[i]

} else if diners[i] > second {

third = second

second = diners[i]

} else if diners[i] > third {

third = diners[i]

}

}

// list the final result of who gets a fork

withForks = append(withForks, first, second, third)

return withForks

}

Here’s how the new program works:

Initially, diner 2 (the first in the list) is assigned the first fork. The other forks remain unassigned.

Then, diner 88 is assigned the first fork instead. Diner 2 gets the second one.

Diner 87 isn’t greater than first which is currently 88 , but it is greater than 2 who has the second fork. So, the second fork goes to 87 . Diner 2 gets the third fork.

Continuing in this violent and rapid fork exchange, diner 16 is then assigned the third fork instead of 2 , and so on.

We can add a print statement in the loop to see how the fork assignments play out:

0 0 0

2 0 0

88 2 0

88 87 2

88 87 16

88 87 42

88 87 42

88 87 42

88 87 42

88 87 43

[88 87 56]

This program is much faster, and the whole epic struggle for fork domination is over in 47 nanoseconds.

As you can see, with a little change in perspective and some refactoring, we’ve made this simple bit of code faster and more efficient.

Well, it looks like our fifteen minute coffee break is up! I hope I’ve given you a comprehensive introduction to calculating time complexity. Time to get back to work, hopefully applying your new knowledge to write more effective code! Or maybe just sound smart at your next office party. :)

Sources

“If I have seen further it is by standing on the shoulders of Giants.” –Isaac Newton, 1675",https://cdn-images-1.medium.com/max/1200/1*_YsSsyFQ5sgS8F0kiZ1USA.png,[],https://medium.freecodecamp.org/a-coffee-break-introduction-to-time-complexity-of-algorithms-64df7dd8338e?source=collection_home---6------24----------------,2018-06-04 23:44:40.970000+00:00

Neural Networks,Media – Medium,"['Dawn Ennis', 'Don Day', 'Jessie Singer', 'Tim Grierson', 'Melissa Chu']","Media Where the newsroom is the news.

Follow Following",https://cdn-images-1.medium.com/max/1200/1*wLhNmBWoSMvG0kyRGjDIqw@2x.jpeg,[],https://medium.com/topic/media,

Neural Networks,The Inspiration of Anthony Bourdain – Member Feature Stories – Medium,['Christine Byrne'],"One of my first great food memories comes from a trip my family took to Normandy when I was six years old. We hadn’t been sitting for two minutes when I announced to my parents, “I want the escargot.”

Dad: “You know that’s snails?”

Six-year-old me: “Yes! We just learned about them in French class, and I want the escargot!”

My parents went along, although I’m sure they expected I’d take a few bites out of stubbornness, then subtly push the dish of garlic and butter and earthy mollusk aside, hoping no one would call out my misplaced courage.

Actually, though, I ate every snail, then mopped up every bit of briny, herby garlic butter left behind. I still think about those snails and about how excited and proud I was to love them so much.

A decade after those snails, I sat on the living room couch with my dad and watched an episode of No Reservations, Anthony Bourdain’s first food travel show. I, like millions of others, was drawn to the irreverent reverence with which he seemed to approach every food he tried, to his eagerness to try anything, and to his ability to narrate the stories of different foods, cooks, and cultures in an unpretentious way that let them mostly speak for themselves. Until then, I had thought of food and travel writing and television as more marketing than storytelling, but watching No Reservations made it clear that, actually, food was not only a story in and of itself, but also a great way to anchor other stories in something tangible and universally understood. Bourdain wasn’t out to sell an experience or show how good something could be — every episode was about telling the story of things exactly as they are.

Bourdain wasn’t the first to talk about food this way, but he was the first to make me feel like maybe I could talk about food that way, too. Food was an important part of my life growing up, but not in a particularly extraordinary way that I felt would resonate. We lived abroad and traveled often, so I was massively privileged in that there was always something new to eat. I remember eating pâté for the first time on a pebble beach in Cornwall while watching my dad (try to) learn to windsurf. I remember tearing apart a slick piece of roti prata and dipping it into a Styrofoam container of curry sauce on a plastic picnic table in Mersing, Malaysia, before getting on a bum boat to an island where I’d go to summer camp for the first time. I remember my first drink: a Tiger beer at Newton Circus, another hawker center, after the closing night of our high school production of South Pacific. I remember, every year when we’d fly home to New Jersey, eating baked ziti and supermarket sheet cake at Fourth of July barbecues, both or which were exciting and special for me because I only ate them once a year. I remember the first time I ate lunch at a New York City deli and was awed by the enormity of both the sandwiches and the Snapple selection. None of this seemed like a story, though, because I wasn’t sure why anyone else would care.

Years later, as a rising college senior, I spent the summer working as a publishing intern in New York. Weeks in, I realized that my longtime goal of being a book editor was actually, definitely, not what I wanted. To keep the “I graduate in a year and now have no plan” anxiety at bay, I read more books that summer than I ever have. One of them was Anthony Bourdain’s Kitchen Confidential.

Bourdain’s 2000 memoir, as you may know, gets so much of its magic from the sense you get while reading that every story is true. I figured it would fall into the “I never want to go there, but that sure made me think and was fun to watch” category that some of the No Reservations episodes did, and that the stories about hypermasculine kitchen culture and the people who somehow ended up in it would make me laugh, think, and then move on to whatever book was next.

That’s not what happened. The first story the book tells is one of Bourdain as a fourth-grader on a European cruise with his family. He tries vichyssoise, a potato-based French soup, and is taken aback by the fact that it’s cold. “I’d eaten in restaurants before, sure,” he says, “but this was the first food I really noticed. It was the first food I enjoyed and, more important, remembered enjoying.” Reading it made me think of my snails, how adventurous they made me feel, and how they established food as something important and worth discovering. It’s a good, tame story that I could easily relate to, and I bet most people felt the same when reading it.

The thing is, the relatability of the book started and ended with that cold potato soup. The rest of the book — about restaurant kitchens and all the crass, stressful, macho, bonkers shit that happened inside them — took place in a world very, very different from mine. Even coming from Bourdain, whose stories had been making me feel welcome since I first watched him walk around Paris unironically wearing cowboy boots in the first episode of No Reservations, the book felt like something I was looking in on from the outside. Reading it piqued my curiosity in restaurant cooking but made it clear that it wasn’t something for me. The longer the stories sat with me, though, the more they started to feel like a sort of…dare.

I graduated soon after, six months earlier than planned. I was still put off by my intern experience in publishing and totally uninspired by every job option presented to me by career counselors and all the well-meaning adults in my life. (Although it was 2010 and the height of a recession, so calling them “options” is maybe a stretch.) Food writing had crossed my mind, but I didn’t figure it was something I could just jump into. I can’t really explain my sudden decision to go to culinary school — a mix of desperation, an interest in food, a burning need to be interesting and different, and a nagging curiosity about Kitchen Confidential, if I had to put it into words — but in 2010, I moved to New York and spent 10 months at the French Culinary Institute learning how to cook. It remains the most impulsive thing I’ve ever done—and the most significant.

The following two and a half years spent cooking in NYC restaurant kitchens taught me things that culinary school never could have—about cooking, stress, being a woman in a room of mostly men, and how to deal with constantly being under fire without falling apart. It’s hard to explain what it was like to walk into a restaurant kitchen, and I honestly don’t remember it clearly, but I do remember that everything I did was wrong, everywhere I was was in the way, and every time someone said something to me, I had to ask them to explain what they were talking about. It was the most underqualified and out of place I’d ever felt, even though I knew in theory that’s exactly what I was signing up for. (I’d read the book! I intentionally jumped out of my comfort zone!) It wasn’t the useless, undervalued feeling that comes with an entry-level office job; it was the feeling that I needed to apologize for even being there, for being the alien who disrupted a system that everyone else knew how to work in. Weeks went by before I was able to walk into that kitchen without absolute fear; months went by before I was able to actually contribute.

Was restaurant cooking the way Bourdain described? Not really. It was vaguely the same, sure: late nights, weekends, burn scars, characters, industry bars, some yelling, ticket boards that inexplicably but reliably went from empty to full in a matter of minutes every single night.

The actual experience of it was very different from what I’d read, though. Because it wasn’t his experience—it was mine. I was the one cramming four hours’ worth of food prep into two and a half every afternoon. I was the one at the stove, firing seven dishes from three different orders at the same time, in exactly the right order, totally on instinct. I was the one who stayed at the bar three hours too long on a Tuesday and somehow always managed to find my way on the L train. I was the one who felt disconnected from one world but totally plugged into another.

Which made me realize: A great storyteller is one who makes you want to experience stories for yourself. A great story is one that makes you think, “I wonder what it would be like to do that.” I’m not much of a storyteller these days, nor am I still a restaurant cook. I write recipes, and I write stories about how and why people should cook them, but I do so in a way that’s shaped by what I’ve learned: Recipes are like stories, kind of, and the best recipes are ones that people will actually cook. Getting someone to cook a recipe isn’t about presenting them with something they’re already familiar with, necessarily, but about making them think, “I wonder what it would be like to do that.”

It’s no secret that Anthony Bourdain was a great storyteller. I’ll miss following along with his unending curiosity about food and how it shapes us, and the world will miss the way he was able to share that curiosity in a way that was welcoming and inclusive. What I’m most grateful for, though, is that he showed me the inside of a world I’d never given a second thought to—restaurants—and painted a picture that, even though it was totally unrelatable to me, was interesting enough that I felt compelled to experience if for myself. Not many storytellers do their job so well that, after reading their stories, you actually feel moved to go out and live them.

“Food, for me, has always been an adventure,” Bourdain writes in the preface of Kitchen Confidential. For me, too, Chef. Thanks for teaching me that food is something worth exploring and that the exploration is something worth writing about.",https://cdn-images-1.medium.com/max/1200/1*65ru7KtyJDme4kUXz8Sl5Q.jpeg,[],https://medium.com/s/story/the-inspiration-of-anthony-bourdain-8d5679c2acb4?source=grid_home---------0------------------18,

Neural Networks,"Apple has no idea what’s next, so it’s just banging on the same old drum",['Owen Williams'],"Apple has no idea what’s next, so it’s just banging on the same old drum If you want to witness a company that’s simultaneously in its prime and losing control over its own narrative, look no further than WWDC, Apple’s second-most splashy event of the year, designed to offer a glimpse of the future. The annual developer event is a spectacle that I’ve watched live for almost a decade, but this year was different: it showcased a company that’s lost in the woods, playing the same old hits on repeat, in the same old format. Not only was it painful to watch, it demonstrated that Apple doesn’t really have a coherent plan, or understanding, of where it should take its core platform, let alone the ones it’s tried to build around it. It’s fine to have an off year, but what struck me was how… random it felt, and how little insight or forward thinking there was. Apple’s own platform advantages, company culture, and whatever else, seem to be pigeonholing its trajectory, driving it down a path that looks increasingly dated, and leaving me to wonder if the company is self-aware enough to see the shifting tide before it’s lost at sea. Big, slow, yearly

Apple struggled throughout 2017 to ship flagship features it promised at WWDC 2017, including Airplay 2 and iCloud Messages, delivering them quietly just days before this year’s event. Alongside a scandal about performance throttling, a series of major security slip-ups, and hardware that shipped without long-touted features, many have loudly asked what’s causing these issues — and why a company with so many engineers is fundamentally failing to ship. Performance improvements are arguably the biggest focus of iOS 12. They’ll be welcome for many users, along with several additional improvements: streamlined notifications, a new ‘shortcuts’ feature for custom buttons, usage reporting, group FaceTime, AR updates and a number of other minor improvements to create a major release, iOS 12. The company’s other platforms received similar treatment, including macOS. Apple finished dark mode, a feature it half-introduced all the way back in Yosemite, added basic functionality to Finder, threw in a new way to organize your desktop, and boom — there’s your major release, 10.14. None of these things are inherently bad — in fact, people have been complaining about the lack of improvements to things like FaceTime for years — but what’s interesting is Apple’s choice to bundle them together as a way to make them look truly meaningful, rather than just fixing many of these issues sooner, in a point release. I’m aware there’s a slew of tiny other fixes and features I haven’t listed here, but that’s my point: it’s a hodgepodge of things that have been neglected over the years after being debuted once and forgotten about. Here’s the rub: Apple could arguably ship notification improvements to iOS users tomorrow in a point release, iOS 11.5, but it won’t. Combining them provides the illusion of progress. Instead of servicing users and giving them features sooner, on a regular basis, Apple chooses to hold back simple functionality longer, for its bottom line. As Martin Bryant points out, Apple may have a timing problem: Yes, Apple needs to take the time to do ‘boring’ optimisation work on iOS, but why build iOS around these big, annual feature bumps and then disappoint people when the bumps aren’t very big?

Interestingly, the narrative here actually doesn’t make sense anymore, either. Every year, Apple takes the time to point out how dire the state of the competition is: Nobody’s Android phones get updates! Android people don’t get any the latest features! Your phones all suck! The reality is different: Android users, regardless of manufacturer, frequently get them sooner than iOS users do, because Google divorced the operating system and core application suite from one another. Google’s approach to unbundling Android has, for the most part, been quietly successful — in an unexpected way. Instead of shipping monolithic feature updates, Google’s applications are now updated via the Play Store, from the clock app to the calculator and even the camera (unless you’re Samsung). Apple has made a yearly ritual out of jabbing competitors for poor update histories, but conveniently omits the reality that improvements to Google Assistant, the built-in web browser, or even just the OS keyboard will reach billions of users in a matter of hours without needing to update the entire phone. Android’s support libraries mean developers can target older devices, with new features, regardless of whether or not they received the OS update. Meanwhile, if you find a bug in the iOS keyboard, or some weird security flaw in Safari’s web view, you hope it gets fixed in the next version of the operating system. Maybe next year, or the year after that. It depends how bad it is, or if Apple is actively maintaining the feature, as to when it’ll get serviced. Don’t get me wrong, Android has a terrible history of updates that is only now beginning to change, ten years after the fact. Google has made strides with Project Treble, which makes an end-run around the device maker itself, but it’s only in its infancy with new devices picking it up today. That’s not good enough either; but it’s gaining traction and getting things into people’s hands. For each platform update, Apple dangles a carrot. That’s the flagship feature to convince you it’s a Big Update™ worth having immediately. On macOS this year, that’s dark mode, and on iOS, the promise of performance improvements and, god forbid, actually decent notification management. Arguably the most interesting segment out of WWDC happens at the very end of the two-hour keynote: a peek at Project Marzipan, a long-term effort to unify the interface framework developers use to build apps for iOS and macOS, which is expected to ship to everyone in 2019.

From where I sit, this is an impressive, massive project that doesn’t do much more than play defense against Electron’s continued march on Apple’s territory, threatening to kill native application development altogether. Why build anything native at all, when you can write once, and run everywhere? Anti-Electron fans will run rabid at the idea, but as the technology has become more efficient and introduced lower-level API access, it only makes even more business sense. Marzipan is an audacious plan to defend against that by making it easier to build cross-platform apps. It’s a genuinely fascinating play with fewer apparent benefits in the short term over just building an Electron app, which addresses an additional billion users, allows developers to use familiar web technology and is truly write-once-run-everywhere. Over time, Marzipan may win favor with developers, but I’m not convinced it’ll stop web-based technologies swallowing native app development whole, particularly given that both Microsoft and Google have now bet their entire strategies on Progressive Web Applications, and how low the barrier of entry has come as a result of Electron’s success. Marzipan indicates something bigger, of course, such as an impending shift away from Intel chipsets entirely to some sort of custom Apple ARM-based silicon in — shock horror — a productivity form factor. If anything, what will win as a result will be that control, and what it could ship in a end-to-end device: true all-day battery? Always-on LTE with desktop class apps? If so, the message is this: lock in with us, develop for our platforms, and we’ll reward you. Don’t, and you’ll be shut out and stuck on the outside. Hey Siri, where’s the vision?

What’s clearly missing in all of this is a willingness to take risks, or go for the long view on what’s better than the status quo for Apple’s users. Instead of looking at how phone usage is changing and redesigning the nature of iOS, it’s another year of shoehorning new features into a decade-old shell. The new shortcuts feature promises to let users wire up workflows of their dreams, chaining together tasks behind a single button. Yes, this is a great improvement to iOS that addresses a problem without actually improving on the reason anyone needs this in the first place — it’s just glued onto the homescreen that’s responsible for causing the need for it in the first place. Apple could have offered up a way to surface the weather right there, deeply integrated with the lock screen, or calendar events at the top of your home screen along with the icons, but it didn’t. Instead, it slathered what appears to be a UX hack in the shape of a notification, and tries to guess when you want to see it. Google’s own developer conference, just down the street in Mountain View, was held in May and offered a clearer, if poorly highlighted, view of the future: AI is a core part of mobile devices going forward, so we’re beginning to add it everywhere. The Android alternative to Shortcuts, Slices and App Actions, surfaces the device’s best guess at your next action as a deeply integrated interface component, where you can actually see information before actually going further in, or taking an action. Want a button to order a Lyft? Great, here’s a button embedded within the system’s app tray, with the current estimated price of your ride, which orders it right now with a single tap. Much of this data is crunched on device, just like Apple’s audacious claims to privacy brag about as well, but instead of being a UX hack to add buttons that summon help, the information is already right there, on hand, without opening anything, even Assistant. Google and Apple both anticipate a future in which we use our phones less — time well spent is a core part of this driver — and as a result, it appears Google has spent a lot of time thinking about how AI can help get the right information to the user. The result is the exact button they need at the right time, with relevant information, sans the need to actually go away and do something. To facilitate this, Google is willing to rejig the UX of its devices, mess with the sea of icons, and has invested heavily in serendipitous computing with Google Home alongside this, so it can get you there faster regardless of if the phone is in your hand.

Google’s vision of the future of smartphones, mobile operating systems, and the way we’ll interact with devices over the long haul is a coherent, well-told story: get more out of your day, get the devices out of the way. It even has a fantastic page that showcases how its own ecosystem works better, together, than I’ve ever seen explained about Apple’s ecosystem on its own site. As for why all of this happens, I suspect it’s a difference in strategy and approach. Apple’s strategy has long been to monetize its existing cash cows as long as it can by throwing out new stuff to see what sticks and doubling down on that, rather than creating any sort of coherent narrative of what the future actually looks like, operating in secrecy until it somehow lands upon it. Incremental improvement is fine, but there’s a distinct lack of forward-looking, and a whole lot of looking over the fence at what everyone else is doing to bash it instead. Apples, oranges and comparing the two

It’s easy to compare and contrast Google and Apple because they are very different companies, but what they’re both claiming to do is the same: invent the future, whatever that actually might be. Their approaches, however, are increasingly diverging: Apple’s squeezing more out of less, shipping flashy features, and focusing on privacy, while Google and others have pushed further into understanding the user and getting out of their way. Most of this comes down to business model. Apple’s focus on features by piling them together drives more sales of iPhone, which drives reliable revenue on a yearly basis. Google’s is on advertising and relevance to the user, which doesn’t depend on a particular feature or thing to tout, it just needs you to love using its tools (and not mind advertising). Apple’s entire strategy over the last two decades has pivoted around the exploitation of a product line until something new comes along, then rinse and repeat. This is framed around improving your life and often actually does, even if that is by proxy. I’d argue that the company’s vision of the future isn’t to enrich, or drive progress, but to squeeze as much revenue as possible out of slick, well-designed and marketed ideas. The products it builds, the cycles they’re released in and the way that Apple’s entire software cycle works reflects this. An example of the manifestation of this is perhaps HomePod’s requirement to have a locally available iPhone to do anything interesting, leaving it crippled without one, and Animoji’s debut only to be locked away in Messages instead of somewhere like the camera.

Google, a latecomer in the game, has the luxury — and peril — of not depending on phone revenue, so it can risk it all and get weird, since it’s not fundamentally critical to the company’s continued trajectory. Microsoft has done the same, now finding itself the underdog, risked it all and moved to an ‘OS-as-a-service’ model in which it ships features when they’re ready instead of waiting for flashy releases. Apple, on the other hand, begins and ends with the iPhone today, the rest flows from there. It can’t just rip up the foundation on which its revenue exists, and Tim Cook hasn’t shown a flair for doing so. iOS is too valuable to go away and tear down to just reimagine it for fun, so it’s the status quo, with experiments like HomePod and AirPods on the side, where it can get weird and sometimes wonderful. That’s fine, because Apple has plenty of cash lying around, but it’s interesting how limiting the approach can become. As we hurtle toward peak smartphone, the cracks here are beginning to show because Apple don’t have the next big thing yet — that we know of, naturally — and it’s taking a long time to get here. We’re essentially watching the bottom of the metaphorical tube of toothpaste being squeezed, while others are trying to figure out if maybe the tube should work completely differently. AR is potentially the next platform, yes, and it’s clear that Apple is pushing forward on that in a big way, so it’s easy to imagine a scenario in which it makes sense to shift precious resources there instead of focusing on iOS which may wind up unimportant in a year or two. I’m not convinced that in the short term, such as the oft-claimed 2020 launch date of an Apple VR/AR headset, that we’ll be headed there in any meaningful capacity. I mean, Magic Leap, a bajillion dollar company building the future of AR showed off its hardware yesterday on Twitch, quipping that “you better not put it in your pocket or it’ll overheat.” I’m happy to be wrong, and I write this knowing I’ll probably be that guy who very publically crapped on the iPhone at launch later. Apple’s worth a very large amount of money, which is more than enough proof that it’s good at many things, including convincing people to buy a phone every year.",https://cdn-images-1.medium.com/max/1200/1*tIUbwrpHZPbdNPXB569wPQ.png,[],https://medium.com/@ow/apple-has-no-idea-whats-next-so-it-s-just-banging-on-the-same-old-drum-dcfd0179cf80?source=grid_home---------0------------------18,2018-06-07 13:54:23.876000+00:00

Neural Networks,Our Wedding Is Canceled Due to the Following Strongly-Held Beliefs,['Tim Sniffen'],"Hi, everyone. I know you weren’t expecting to see Keith and I out here so soon, but we have some bad news. We’re not getting married today.

Believe me, we were really looking forward to it, but recently — this morning, in fact — we learned our blessed event was in direct conflict with the strongly-held beliefs of many of the people providing our wedding services. And if they’re not happy, we’re not happy.

Let me bring you up to speed.

You may have noticed the empty display table by the reception tent as you filed in. That’s where our wedding cake would have been. For our baker, however, creating a cake to be employed in the marriage of two men would be the moral equivalent of using communion wine to make sangria.

We knew the risks when enlisting Give Us This Beignet, Our Daily Bread as our wedding baker. They’re the best in downtown Aurora, no question — sorry, Wild-Flour! — but their beliefs on same-sex marriage are no secret. We hoped they might get swept up in the joy of the occasion but last night their chief baker Jonah, applying the final bit of piping, had a vision of Billie Jean King physically dragging him away from the gates of Heaven. And if that’s not a sign, I don’t know what is.

I should add, it may not have helped that we requested our little cake figurines be surrounded by an added semi-circle of figurines, in likenesses of the bakery staff, giving us the thumbs-up.

But that’s all done with. They’ve made their wishes clear and we respect them.

Which brings me to the empty vases alongside the pews and the empty centerpiece bowls on the reception tables. We’ve known Joyce Gantz, owner of Rest On My Laurels, for years; I couldn’t imagine this day without her. What I couldn’t know was the war raging within Joyce, fervent Catholic, after she learned of the meat-laden Friday barbecues Keith and I throw for our softball team. Last night, Joyce looked deep within her heart to ask, can I lend my good name to this cursed union?

The dumpster full of imported delphinium behind Joyce’s shop can tell you the answer.

You see, what we’re learning is that these are not just goods and services; they’re not simply the imprints of Keith’s Capital One card and the resulting exchange of goods. Every item at a wedding is nothing less than the avatar of its vendor’s entire belief system. With this in mind, each rose petal my niece Stephanie was prepared to hurl down the aisle might as well have been embossed with JOYCE GANTZ APPLAUDS THEE, SATAN.

What faith-engorged entrepreneur should face such hell?

This is why the rows of steam-trays in the tent are empty, and your choice of beef tenderloin or grilled salmon — or the one plate of tempeh veggie kabob, bless you, Amy! — will never arrive. Because Something Borrowed, Something Cordon Bleu, exceptional wedding caterers and unapologetic druids, could not bear the thought of providing nourishment to a couple willing to rip two thriving Magnolia trees from their backyard last summer. From their email: “Your heretic’s feast will be served when the earth heals from your violence.” By our best guess that wouldn’t have been by 6 p.m.

We also won’t be dancing to Renèe and the Ring-tones. While Rènee was a woman of few beliefs when we booked her, she has since converted to the Egyptian cult of Bastet, and considers the choice to put our cat Banjo to sleep, rather than pay $15,000 for experimental feline jaw surgery, to be “unforgivable wickedness, worthy of disciples of Set.”

I’ve been handed this note: Lane, our photographer, turns out to be more of a Star Wars guy and doesn’t feel right legitimizing such an obviously Star Trek couple.

Blessings on your journey, Lane.

In closing, our apologies. We were so busy coordinating our big day that we forgot to coordinate the sacred truths of all players involved. I’m told many of our vendors will adopt an exhaustive three-week interview process before each sale to keep this from happening again.

We did have a lovely wedding favor created for each of you, which we might as well distribute. It’s a wooden plaque, engraved with the phrase Love Conquers All, hand-crafted by our friend Bryce Charles in the front row. Now, Bryce is something of a Packers fan, and Keith is all about the Bears, but in the spirit of friendly rivalry, we’ve always managed to put aside our differ — wait.

Bryce’s feelings are changing.

They’re moving from loosely-held to nonchalantly-held. They’re not done; from the set of Bryce’s jaw, her feelings have transitioned to intentionally-held, and finally, they’re — yup. They’re strongly-held. Dammit.

Sorry, folks. You’re on your own.",https://cdn-images-1.medium.com/focal/1200/632/50/45/0*fh1vaEnMNoMbHE42,[],https://medium.com/s/story/our-wedding-is-cancelled-due-to-the-following-strongly-held-beliefs-1fa71105660e?source=grid_home---------0------------------18,

Neural Networks,My So-Called (Millennial) Entitlement – Trust Issues – Medium,['Stephanie Georgopulos'],"I am at the San Francisco International Airport some barely recent morning, registering for a travel program called Clear when the automated kiosk assisting me makes a strange request: “Stand still while we scan your irises.” I’ve barely digested this first ask when another takes its place: this time, the kiosk wants my fingerprints. I find this slightly less alarming; I already use those to access my banking app, buy coins for my mobile games, and unlock the phone that hosts all this information in the first place. But my eyeballs — which I had only just learned could be used as ID, and from a machine at the airport, no less — my dude. Those are the windows to my soul! Ever heard of foreplay?

Clear is a private company that prescreens air travelers using biometric authentication. Becoming a member is like ordering the half-soup, half-sandwich version of TSA PreCheck: it works, if all you want is a taste and are willing to pay for it. With Clear, you don’t need your ID to go through security, but you still have to remove your shoes. You get to wait in a shorter line (sometimes), but you still have to take out your laptop. Basically, the Cleared still participate in the most annoying aspects of air travel and pay almost 10 times the PreCheck fee for the privilege.

If the worst has already happened, that means it’s survivable.

How we decided on this valuation of convenience—it’s $179 per year—is not the point, though. My point is that some random startup casually acquired my eye-prints, and some small voice is telling me I should care more than I do. Someone out there definitely cares about this, no doubt. I’m sure at least one other traveler was not sated when a brisk Google search revealed that Clear is based in her hometown and run by a female CEO, ergo it must be a secure and entirely trustworthy business.

But I was sated. It’s the future, right? What’s the worst one could do with my retinal scans? I already gave my social security number to Camel in exchange for a pack of promotional cigarettes one time (or 12). Somewhere in Midtown Manhattan, a market-research firm knows how many condoms I used in May of 2011 (give or take). And when I think about the fact that every hard document I’ve reproduced on a digital copy machine — at work, at the bodega, at the library — is saved on a hard drive somewhere (lots of somewheres, in fact), I feel a sense of hopelessness that, in its own demented way, translates to freedom.

That’s why I unlock my phone with my fingerprint. It’s also why I talk shit in front of Alexa, why I haven’t put tape over my laptop camera, and why I still have a Facebook account. I don’t expect the worst to happen.

Because the worst has already happened. It is happening, and it will continue to happen.

I find this to be an honest, useful framework. If the worst has already happened, that means it’s survivable. And if the worst is a given in the future, too, we know that ignoring it won’t make it go away. There’s opportunity in having nothing to lose. You just need the right attitude.

Or perhaps you need the right conditioning.

Imagine: You’re 11 years old when two teenagers bring guns to their high school and kill 13 people. They injure 21 more. Your sixth-grade humanities teacher explains the inexplicable to your class after lunch period. You have to imagine that this is a first for at least some of your classmates, crying over the national news. It won’t be the last.

When you’re 15, two planes crash into two towers. You know the towers; had toured them on school trips just like all the other famous Manhattan buildings for which you know the names, if not the functions. In fact, you’d visited the towers just one week before the planes hit. There had been a renaissance fair in one of the lobbies.

At 17, your high school economics teacher tells you that social security will run out before you retire. You’ve already been paying taxes for three years. In 2018, you learn that he was exaggerating, thank goodness — by 2034, retirees can expect to receive a whopping 79% of the full benefit they receive today. You will not be of retirement age until the 2050s.

And when you’re 21, the market crashes. You’ve had a bachelor’s degree for three months. It cost $100,000 to earn, all before interest. Your class valedictorian moves back in with her parents, and no, your internship is not hiring. Five years later, the unemployment rate for people your age is almost double the national average.

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

Neuroscience has confirmed that you were making sense of these events with an underdeveloped brain. Along with your emotional maturity and your hormones, it’ll be a work-in-progress until you’re around 25. And the same way the small hurts of being small can still seep into your present — the way your grandmother eyed you with disgust when you went for a second helping — the chipping away of every institution you were raised to believe in can have unintended consequences.

Me: Do you use Touch ID to unlock your phone?

Friend: Ya.

Me: Do you know anything about the technology behind it? Or like, how secure it is?

A beat. A blank stare.

Friend: No?

Me: Same.

My friends do not need to understand the technology behind touch ID any more than they need to understand black holes. They are not convinced that adjusting their social media privacy settings is some sort of moral duty, a symbolic middle finger to Facebook on behalf of all the little guys who understand internet economics to varying degrees, or not at all. Mostly, they were confused as to why any thinking person would have an assumption of security.

“It’s not that I don’t care about being hacked, or about my data being stolen or sold,” one friend tells me. “I assume that vulnerability because there are no physical systems or structures that have succeeded, so why would something that is essentially invisible do a better job than something tangible?”

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

I’ll go: I don’t expect to own a home. I don’t expect to retire well, or at all. I don’t expect anyone to give me anything I haven’t explicitly asked for, and even then. I don’t expect it will ever be affordable to continue my education in any formal way. If a package gets lost in the mail, I don’t expect to see it again. I don’t expect the government or the banks or the universities to do anything that benefits regular people. I don’t expect them to hold each other accountable on our behalf. I don’t expect them to expel abusers from their ranks, or to put my safety over their legacy. I don’t expect to feel safe in large crowds or alone late at night. And I don’t expect that my privacy will be respected, online or in general.

America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

As far as I can tell, security — whether financial, technological, physical, or emotional — is not a thing. You don’t get to decide whether some drunk asshole drinks his drunk ass off and gets behind the wheel. Likewise, you don’t get to decide if the drunk Congress or the drunk banker or all the drunk administrations of all the drunk institutions do what’s right for you. Sometimes they will do the right thing for somebody, but statistically speaking, that somebody is not you.

Sometimes the right thing comes served in a shit sandwich, or one guy does the right thing but it’s later counteracted by the next guy and just so we’re clear, it’s always a guy. Or sometimes, we learn that what we thought was the right thing was actually the wrong thing, in ways we didn’t anticipate, except for those of us who did anticipate it but were not asked or heard because we do not employ lobbyists and because the powers that be can’t listen to us until they sort out whether our bodies are legal or not.

Mark Zuckerberg’s Congressional hearing was probably the biggest mainstreaming of data privacy issues yet, and Facebook, with its many transgressions, made for an appropriate scapegoat. But I want to know why it’s Mark Zuckerberg’s fault that American adults of voting age lack the critical thinking skills to differentiate between fake Russian bot news and The Guardian. I want to know the plan for bringing internet literacy to those who are not digital natives. I want to know why the U.S. government is being celebrated for protecting our egos and baby-proofing the internet instead of telling us the truth: Dirty tricks are less likely to work on people with more education.

What happens when your brand of exceptionalism breeds millions of people who voted a sentient conspiracy theory into office? Where does the fault lie? After all, it’s not Facebook who’s spent decades underpaying teachers and closing schools in low-income neighborhoods. Facebook doesn’t have the jurisdiction to end standardized testing or combat the quiet continuation of white flight. Facebook’s biggest mistake? Profiting off of state-sanctioned dumbness.

We’re only supposed to be dumb enough to believe that the fight is red vs. blue and not top vs. bottom. We’re only supposed to be dumb enough to believe in Democracy the Concept™ without casting a critical eye toward its practical application. This is a dumbness cultivated by and for Washington, and Zuckerberg’s misusing of it for corporate gain almost blew the lid off the entire thing. Commence finger-wagging.

On an episode of his podcast Revisionist History, Malcolm Gladwell argues that we should treat education as a weak-link network, where strengthening the weakest links has the most positive outcome for all. This is in contrast to a strong-link network, where a couple of superstars at the top carry the weaker players on the bottom. He illustrates this dynamic using soccer and basketball. An average soccer team with one star player is less likely to win a match than an above-average team with no star players — soccer is a weak-link sport. Conversely, an NBA team with a superstar or two fares better than a team on which all the players are equally, decently good — basketball is a strong-link sport.

Much to its detriment, America acts like a strong-link country. It is the type of place where electing one mixed-race president means we solved racism. (Imagine if the lesson we took from electing one white man was that all white men who lack upward mobility just need to work harder.) We raise up a few undoubtedly smart and deserving people in each field, send them around the world like brand ambassadors for democracy, poster-adults for how advanced and distinguished and American we are. Meanwhile, most of us back home — 78%, in fact — are living paycheck to paycheck. Is that freedom ringing? We’ll call right back after we pay this phone bill.

These are complex problems. In addition to the 3000ish words here, I have written and cut an additional 4500 trying to make sense of it all. I remain overwhelmed by the number of solutions that contradict one another, the knowns and unknowns, the countless logical ends I haven’t considered. But I eventually found my demented silver lining: America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

While grim on its face, this perspective has pushed me to take inventory of myself, my own power. What can I do right now? Am I solving problems I actually care about, or were these problems unconsciously inherited from another time, problems propagated by those with a vested interest in resolving them with more money, more power, more loopholes? Should I devote my energy to righting a system that, by design, has only consistently benefited one demographic and has yet to even prove itself as a scalable model for a generation that’s tired of the same people making the same decisions on behalf of the most diverse country in the world?

Is that a problem? Because it feels more like an opportunity, to me: a chance to exercise this cache of personal agency I’ve been sitting on, agency I didn’t realize I had or needed as I waited for America to work. It feels like an opportunity to try something else.

More powerful than having nothing to lose is cultivating that which can’t be taken. Grace. Clarity. Purpose. The stuff that isn’t Amazon Prime-able. These are the indoor plants of our being; only you can feed them and grow them and expose them to the light. It’s a lot of responsibility, and the work involved is often unglamorous. Some people think they never have to learn to care for these things because they have the means to outsource what they wish: their plants are alive on paper though they don’t know the how or why of it. And besides, can’t you see they’re a little busy trying to colonize Mars?

A respectable goal, though I might suggest to anyone faced with the choice to try taking on the inner self before jumping ahead to outer space. There’s more to unearth in there than you might think, and we need more people to understand the potential of their own organic material. We need people who appreciate the slow growth of nothing into something, who drink up the sunlight and make the air a little more breathable than before.

Because that’s it, for most of us. That’s how we build power. That’s how we, a generation of janitors for the American dream, put our trust in something real: each other. We stop trying to control the world in our heads and in the headlines, and we start controlling ourselves. We sleep. We go to the doctor. We log off. We talk about our problems. We water our plants. We collect our neighbor’s mail when they’re out of town. We take a deep breath before reacting in anger, and question whether this particular battle is worth our energy. It’s not. Why were we fighting again? We volunteer. We water our plants. We focus on ourselves so we can eventually focus on others — in a real way, in a non-transactional way, in a way that slowly but authentically strengthens our fellow weak links. We don’t wait for permission. We get over ourselves; we stop demanding perfection; we start. We water our plants. And on weekends, we play soccer.",https://cdn-images-1.medium.com/max/1200/1*c5zNxCX34sYmYYO-yRxlbA.png,[],https://medium.com/s/trustissues/my-so-called-millennial-entitlement-9be84343c713?source=grid_home---------0------------------18,

Neural Networks,How to Cope with the End of the World – How to Cope With The End of The World – Medium,['Maria Farrell'],"We All Die, and That’s Okay

My favorite postapocalyptic novel is George R. Stewart’s 1951 Earth Abides. In it, scientist Isherwood Williams (nicknamed Ish) survives a plague and eventually starts a new family and community in the ruins of suburban California. His hope for the future is wholly invested in a child who is intellectually curious, like him, and who might be able to revive some of the old ways and technologies. It’s an observant and reflective novel, full of the “how stuff would probably work” thinking that makes science fiction the true literature of ideas.

Ish starts out as a scientist-savior of humanity, figuring there is just enough time to raise a generation to turn back the clock to before the disaster. But he ultimately has to make his peace with the fact that civilization as he knew it is dead, there will be no heroic rescue, no going back, and the people around him are mostly fine with that.

The 1950s may have been the last decade we could complacently believe the Ecclesiastes (1:4) maxim that “men come and go, but earth abides,” but Stewart’s basic message is correct.

The people who come after us don’t have to do better than us, or think well of us, for them to be essentially okay. And us all throwing a big “let’s blow it all up” hissy fit because we fucked up and we can’t bear to look at it is just teenage nihilism that we need to grow out of already. Coming to terms with what we have done means dumping the egotistical death drive of the mass shooter or far-right politician and gathering the maturity to look our individual and collective deaths straight in the eye and say, “Okay, we get it now. We get it. It’s not about us.”

Have you ever stood in a crowded place like a town square or an airport meet-and-greet and thought, “Every single person here is going to die”? Morbid, eh? More of us should do it.

I live in an early Victorian terraced house in the UK. It’s never been a tenement, so probably a hundred people have called it home in the almost two centuries it’s been standing. Nearly all of them are dead. The people are already born who’ll live there when I’m dead. The head of this country’s anachronistic state has already been born who I’ll never see on the throne and to whom I’ll seem as old as someone born in the 1930s seems to me.

We’re all going to die. The morning will come when those who have loved us put on dark clothes and cry and get on with the rest of their lives, seeing movies we’d have loved, depending on gadgets that now seem to us ridiculously unnecessary. Our deaths matter to us and those who love us, but they don’t fundamentally matter.

Once, while my husband was deployed to Afghanistan, I asked him on the phone if he was doing okay about someone we knew who’d recently been killed. “Oh, you know,” he said, “you know,” and quoted his regiment’s unofficial mantra:

Everything matters. Nothing matters terribly.

The soldier’s death mattered very, very much to him, and (not but) he and others were nonetheless carrying on their shared purpose. Otherwise, what had been the point of any of it?

What will outlive us, individually? Plastic. Perhaps some genes. The bacteria that act as a species-level enabler for everything we are. Some ideas, maybe, or songs, stories, pictures, the memories of us others hold, until they go, memorials like a community flower bed or a named scholarship, for a while, anyway. Less concretely: ways of being, a fitness for the world that those who flourish pass unremarked to their offspring via the epigenetics of love — the sunny inverse of patterns of trauma and abuse transmitted through the body, even unto the third generation. Predation.

And our species? Buildings and bones, maybe. Our nuclear waste and the warning signs we hope people of our deep future, or other species altogether, will decrypt. Snatches of radio-transmitted voices slipping through the vacuum of space. Perhaps some bacterial payload we’ll launch in a decade or so, trying to seed life on other planets, even in other solar systems. Or just the anomalous levels of carbon dioxide and methane in our atmosphere that will reveal, for a time, that complex forms of life were here.

Pride and despair are two sides of the same coin. Our collective denial and despair about the future we have built is preventing us from cracking on and sorting it out. We need to get over ourselves. The world we know will end, in both small and big ways. We ourselves will end. But that doesn’t matter, terribly.

Our mortality is the greatest enabler we have of positive, ongoing change, if only we can face it, if only we can understand that we don’t get to see the end of the movie, because, if what we do works, the movie won’t have to end. We’re not the protagonists. We’re just the foreshadowing. We need to hold the knowledge of our own deaths up to the light and turn it around to see each shining facet, then take the certainty that we are both finite and imperfect deep down inside of us—and put it to work.",https://cdn-images-1.medium.com/max/1200/0*avXWZmh3n3H7a8t8,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world/how-to-cope-with-the-end-of-the-world-2520ef9d3dbc?source=grid_home---------0------------------18,

Neural Networks,How to Cope With The End of The World – Medium,['Maria Farrell'],"COLUMN

How to Cope With The End of The World

There are moments of joy even in times of great despair. Maria Farrell explains how to deal with a darkening world, and how to plan for the end. It might be the end of the world as we know it, but it turns out we feel fine.",https://cdn-images-1.medium.com/max/1200/1*kvqwUuDCsbkAoSfaYXV1vQ@2x.png,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world,

Neural Networks,Chatbots were the next big thing: what happened? – The Startup – Medium,"['Matt Asay', 'Justin Lee']","Chatbots were the next big thing: what happened?

Oh, how the headlines blared:

“…the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”

Chatbots were The Next Big Thing.

Our hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.

And why wouldn’t they be? All the road signs pointed towards insane success.

Messaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!

Plus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.

At the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.

In fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:

“Will a single platform emerge to dominate the chatbot and personal assistant ecosystem?”

One year on, we have an answer to that question.

No.

Because there isn’t even an ecosystem for a platform to dominate.

Fooled by another hype cycle

Chatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.

The age-old hype cycle unfolded in familiar fashion…

Reverential TechCrunch articles were written.

Prophetic thought leaders like Chris Messina chimed in.

Silicon Valley salivated at the prospect of talking to smart automation.

Messenger began to overflow with bots.

Slack went through exponential growth and even launched a fund for bot investment.

Expectations built, built, and then….. It all kind of fizzled out.

The predicted paradim shift didn’t materialize.

And apps are, tellingly, still alive and well.

We look back at our breathless optimism and turn to each other, slightly baffled:

“is that it? THAT was the chatbot revolution we were promised?”

Digit’s Ethan Bloch sums up the general consensus:

“I’m not even sure if we can say ‘chatbots are dead,’ because I don’t even know if they were ever alive.”

According to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.

Text vs. Speech vs. GUI: a potted history

Bots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.

Users had to type commands manually into a machine to get anything done.

Then, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!

Meanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.

Another bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:

… so many different accents, people speaking too fast or too slowly, mumbling, umming and aahing.

Did you say “recognise speech” or “wreck a nice beach”?

The next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:

User: “Hello.”

Agent: “Hello, what’s your name?”

User: “Candy.”

Agent: “Hello, Candy!”

User: “Let’s set the clock.”

Agent: “What is the time?”

User: “The time is 11:00 AM.”

Agent sets the clock to 11:00 AM.

Pretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.

It was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.

Modern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.

Basically, we’re still trying to achieve the same innovations we were 30 years ago.

Here’s where I think we’re going wrong:

Thinking in terms of Bots vs. Apps

An oversized assumption has been that apps are ‘over’, and would be replaced by bots.

By pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.

You might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?

It’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.

Whether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.

Plus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.

A great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.

That’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.

Modern-day apps benefit from decades of research and experimentation. Why would we throw this away?

But, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.

Today’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.

Penny provides chatty advice and alerts alongside a traditional account dashboard and transaction list.

HubSpot Conversations unifies Facebook Messenger, onsite chat, social media, email and other messaging outlets into one shared inbox.

Layer gives developers the tools to create personalized messaging experiences on mobile web and desktop web as well as native apps.

The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.

Bots for the sake of bots

Does my product need a bot? Are existing platforms able to support its functionality? Do I have the patience to build a bot that’s capable of doing what I want it to?

Another problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.

For plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.

Building a bot for the sake of it, letting it loose and hoping for the best will never end well:

The totally necessary Maroon 5 chatbot in action

The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.

The advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.

That’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.

Problems arise when life refuses to fit into those boxes.

According to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.

When we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.

Remember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.

Inaccessibility

A competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.

In an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.

Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)

As Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.

“Consumer interest was never going to materialize until machine intelligence could get anywhere near human intelligence.

User interest depends upon AI that makes talking with a bot worthwhile for consumers.”

And conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.

Today’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.

And in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:

“Should Slack, Facebook, Google, Microsoft, Kik, and others have built their own built-in bots to lead the way?

Should they have gotten more proactive with their bot funds and incubators, hiring mentors to educate participants in the Way of the Bot, or supplying engineering and design resources? Funded Strategic Bot Initiatives at high-profile partners?

In my opinion yes, yes, and yes. When it comes to platforms, developers are the users; and we don’t rely on our users to understand why or how to use our products. We have to show them.”

GUI shouldn’t be dismissed

Once upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information

There’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.

Tapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.

We love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.

Conversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.

Sure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.

Humans like talking to other humans

Aiming for a human dimension in business interactions makes sense.

If there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.

Facebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.

A conversation encompasses so much more than just text.

Humans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.

As HubSpot team pinpointed:

Bots provide a scalable way to interact one-on-one with buyers. Yet, they fail when they don’t deliver an experience as efficient and delightful as the complex, multi-layered conversations people are accustomed to having with other humans on messaging apps.

People aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).

And even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.

And here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.

But is that how humans prefer to interact with machines?

Not necessarily.

At the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.

Where do we go from here?

In a way, those early-adopters weren’t entirely wrong.

People are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.

Not even close.

Computers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.

Computers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.

That’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.

For now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.

But that’s not the whole story.

Yes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.

As Bill Gates once said:

We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. Don’t let yourself be lulled into inaction.

The hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.

I believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.

Messaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.

Developers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.

And I can’t wait to see what happens next.",https://cdn-images-1.medium.com/max/1200/1*-_um8Nai0uer46tni1LETg.jpeg,[],https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=topic_page---8------0----------------,2018-06-05 15:55:36.912000+00:00

Neural Networks,Automated Feature Engineering in Python – Towards Data Science,['William Koehrsen'],"First, let’s take a look at our example data. We already saw some of the dataset above, and the complete collection of tables is as follows:

Deep feature synthesis stacks multiple transformation and aggregation operations (which are called feature primitives in the vocab of featuretools) to create features from data spread across many tables. Like most ideas in machine learning, it’s a complex method built on a foundation of simple concepts. By learning one building block at a time, we can form a good understanding of this powerful method.

Fortunately, featuretools is exactly the solution we are looking for. This open-source Python library will automatically create many features from a set of related tables. Featuretools is based on a method known as “ Deep Feature Synthesis ”, which sounds a lot more imposing than it actually is (the name comes from stacking multiple features not because it uses deep learning!).

These operations are not difficult by themselves, but if we have hundreds of variables spread across dozens of tables, this process is not feasible to do by hand. Ideally, we want a solution that can automatically perform transformations and aggregations across multiple tables and combine the resulting data into a single table. Although Pandas is a great resource, there’s only so much data manipulation we want to do by hand! (For more on manual feature engineering check out the excellent Python Data Science Handbook ).

This process involves grouping the loans table by the client, calculating the aggregations, and then merging the resulting data into the client data. Here’s how we would do that in Python using the language of Pandas .

On the other hand, aggregations are performed across tables, and use a one-to-many relationship to group observations and then calculate statistics. For example, if we have another table with information on the loans of clients, where each client may have multiple loans, we can calculate statistics such as the average, maximum, and minimum of loans for each client.

we can create features by finding the month of the joined column or taking the natural log of the income column. These are both transformations because they use information from only one table.

A transformation acts on a single table (thinking in terms of Python, a table is just a Pandas DataFrame ) by creating new features out of one or more of the existing columns. As an example, if we have the table of clients below

The process of constructing features is very time-consuming because each new feature usually requires several steps to build, especially when using information from more than one table. We can group the operations of feature creation into two categories: transformations and aggregations . Let’s look at a few examples to see these concepts in action.

Feature engineering means building additional features out of existing data which is often spread across multiple related tables. Feature engineering requires extracting the relevant information from the data and getting it into a single table which can then be used to train a machine learning model.

If we have a machine learning task, such as predicting whether a client will repay a future loan, we will want to combine all the information about clients into a single table. The tables are related (through the client_id and the loan_id variables) and we could use a series of transformations and aggregations to do this process by hand. However, we will shortly see that we can instead use featuretools to automate the process.

Entities and EntitySets

The first two concepts of featuretools are entities and entitysets. An entity is simply a table (or a DataFrame if you think in Pandas). An EntitySet is a collection of tables and the relationships between them. Think of an entityset as just another Python data structure, with its own methods and attributes.

We can create an empty entityset in featuretools using the following:

import featuretools as ft

# Create new entityset

es = ft.EntitySet(id = 'clients')

Now we have to add entities. Each entity must have an index, which is a column with all unique elements. That is, each value in the index must appear in the table only once. The index in the clients dataframe is the client_id because each client has only one row in this dataframe. We add an entity with an existing index to an entityset using the following syntax:

The loans dataframe also has a unique index, loan_id and the syntax to add this to the entityset is the same as for clients . However, for the payments dataframe, there is no unique index. When we add this entity to the entityset, we need to pass in the parameter make_index = True and specify the name of the index. Also, although featuretools will automatically infer the data type of each column in an entity, we can override this by passing in a dictionary of column types to the parameter variable_types .

For this dataframe, even though missed is an integer, this is not a numeric variable since it can only take on 2 discrete values, so we tell featuretools to treat is as a categorical variable. After adding the dataframes to the entityset, we inspect any of them:

The column types have been correctly inferred with the modification we specified. Next, we need to specify how the tables in the entityset are related.

Table Relationships

The best way to think of a relationship between two tables is the analogy of parent to child. This is a one-to-many relationship: each parent can have multiple children. In the realm of tables, a parent table has one row for every parent, but the child table may have multiple rows corresponding to multiple children of the same parent.

For example, in our dataset, the clients dataframe is a parent of the loans dataframe. Each client has only one row in clients but may have multiple rows in loans . Likewise, loans is the parent of payments because each loan will have multiple payments. The parents are linked to their children by a shared variable. When we perform aggregations, we group the child table by the parent variable and calculate statistics across the children of each parent.

To formalize a relationship in featuretools, we only need to specify the variable that links two tables together. The clients and the loans table are linked via the client_id variable and loans and payments are linked with the loan_id . The syntax for creating a relationship and adding it to the entityset are shown below:

The entityset now contains the three entities (tables) and the relationships that link these entities together. After adding entities and formalizing relationships, our entityset is complete and we are ready to make features.

Feature Primitives

Before we can quite get to deep feature synthesis, we need to understand feature primitives. We already know what these are, but we have just been calling them by different names! These are simply the basic operations that we use to form new features:

Aggregations: operations completed across a parent-to-child (one-to-many) relationship that group by the parent and calculate stats for the children. An example is grouping the loan table by the client_id and finding the maximum loan amount for each client.

table by the and finding the maximum loan amount for each client. Transformations: operations done on a single table to one or more columns. An example is taking the difference between two columns in one table or taking the absolute value of a column.

New features are created in featuretools using these primitives either by themselves or stacking multiple primitives. Below is a list of some of the feature primitives in featuretools (we can also define custom primitives):

Feature Primitives

These primitives can be used by themselves or combined to create features. To make features with specified primitives we use the ft.dfs function (standing for deep feature synthesis). We pass in the entityset , the target_entity , which is the table where we want to add the features, the selected trans_primitives (transformations), and agg_primitives (aggregations):

The result is a dataframe of new features for each client (because we made clients the target_entity ). For example, we have the month each client joined which is a transformation feature primitive:

We also have a number of aggregation primitives such as the average payment amounts for each client:

Even though we specified only a few feature primitives, featuretools created many new features by combining and stacking these primitives.

The complete dataframe has 793 columns of new features!

Deep Feature Synthesis

We now have all the pieces in place to understand deep feature synthesis (dfs). In fact, we already performed dfs in the previous function call! A deep feature is simply a feature made of stacking multiple primitives and dfs is the name of process that makes these features. The depth of a deep feature is the number of primitives required to make the feature.

For example, the MEAN(payments.payment_amount) column is a deep feature with a depth of 1 because it was created using a single aggregation. A feature with a depth of two is LAST(loans(MEAN(payments.payment_amount)) This is made by stacking two aggregations: LAST (most recent) on top of MEAN. This represents the average payment size of the most recent loan for each client.

We can stack features to any depth we want, but in practice, I have never gone beyond a depth of 2. After this point, the features are difficult to interpret, but I encourage anyone interested to try “going deeper”.",https://cdn-images-1.medium.com/max/1200/1*lg3OxWVYDsJFN-snBY7M5w.jpeg,[],https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219?source=topic_page---8------2----------------,2018-06-02 15:01:18.755000+00:00

Neural Networks,My Phone Wants Me to Say ‘Thank You’ – When Robots Rule The World – Medium,['Evan Selinger'],"Sincerely Thankful

Perhaps there’s something infantilizing about our phones “wanting” us to say thanks. It’s hard to draw a firm line between what you would say if only you put in the time to say it versus what you do say after predictive software fills in the blanks. Seeing suggestions is itself a suggestive situation. And so, while Google emphasizes that smart reply is intelligent enough to figure out if you’re more of a “thanks!” than a “thanks.” person, the fact remains that it’s a good bet that some variation of the word will be frequently presented to you.

If being offered a “thanks” seems familiar, it’s because the act resembles what parents do when they try to instill etiquette. Let’s imagine that Lil’ Johnny receives a gift and instinctively wants to run off and play with it. Before this happens, one of his parents admonishes, “Johnny, what do you say?” And so, robotically, Johnny responds, “Thank you.”

At the time of being coached, Lil’ Johnny doesn’t mean what he parrots back. The gesture is insincere, and Johnny offers it to avoid conflict that would further delay what he really wants to do. That’s okay, though. The hope is that, over time, Lil’ Johnny becomes Big Johnny, the type of person who can genuinely experience gratitude and doesn’t simply follow rules like an automaton. The parental admonitions made during childhood are supposed to be like a pair of moral training wheels that kids ultimately outgrow.

Software like smart reply isn’t designed to provide adults with a second round of moral education. But if we mindlessly use such tools on a regular basis so we can quickly move on to do other things—things that we actually care about—our gestures will merely take the form of gratitude while lacking the underlying substance.

True gratitude must be sincere.

To be truly grateful, you have to mean what you say — that is, you must recognize that someone did something for you that deserves to be acknowledged, and you must sincerely want to make the acknowledgment.

Graciousness is a virtue. If an adult passes off insincere gratitude as the sincere variety in situations where people reasonably expect a person’s words and beliefs to align, the person is behaving worse than Lil’ Johnny. Lil’ Johnny is trying to be compliant, not deceptive.

We also shouldn’t lose sight of the fact that people who in engage in rituals like keeping gratitude journals aim to be specific when offering their appreciation. They don’t just say “thanks” or use any of the other minimalist formulations that smart reply offers. Instead, people who are pursuing lives filled with intentionality are concrete about what they are grateful for, as well as why they’re grateful for it. They want to focus on what they have rather than despair or obsesses over what they lack.",https://cdn-images-1.medium.com/focal/1200/632/51/50/1*MpyyWHuRUnanCenqeG3sHA.jpeg,[],https://medium.com/s/when-robots-rule-the-world/my-phone-wants-me-to-say-thank-you-122cc15952a9?source=topic_page---8------3----------------,

Neural Networks,"In 2018, Numbers Lie and Fictions Paint Truth – Eve Weinberg – Medium",['Eve Weinberg'],"In 2018, Numbers Lie and Fictions Paint Truth Why storytelling is our best tool in disambiguating fact from fiction

I’d love to share a few of the lecturers who touched upon this topic and forever changed my understanding of the 2018 landscape of fact, fiction, and storytelling’s role in deciphering one from the other.

This summer, I had the great privilege of attending EyeO (June 3–8 2018). Innumerable topics that encompass the intersection of Art, Technology, and Data were covered, but one common thread has left an imprint on my brain. That is: the Sisyphean 21st century task of disambiguating fact from fiction. That’s right…

PART 1: NUMBERS ARE MALLEABLE

On the first day, we discussed climate science at length. We (a very self aware room of liberal, number-crunching, data-visualization-making, coastal-living, self-ascribed nerds) attempted to break down the problems with human psychology. We looked at the facts, stats, charts, and graphs; then investigated the human power of denial, dissonance, disincentivization, and the hurdles of behavioral change. After 6 hours of discussion, ideation, and reflection, feeling a bit helpless, we ended with questions that I kept with me throughout the next 3 days of lectures:

Why don’t people believe statistics?

Are stories more powerful than numbers?

Why is denial more powerful than behavioral change?

Why do lies travel faster than truth?

…And what should we do about this?

The next day, Amanda Cox enlightened us with her talk These Lines Are The Same. She showed us that data, even in simple bar graphs, can be misinterpreted depending on the viewer’s own bias. She bravely revealed to us that in her department The Upshot at The New York Times they struggle with how to best represent datasets objectively. They experiment in meaningful and educational ways. In one example she showed data from the US unemployment report. The article allows readers to look at the chart with ‘Democratic Goggles’ and ‘Republican Goggles.’

The numbers are the same, but they can easily be bent to the will of anyone with an agenda.

Then she humorously showed us our flaws in clinging to round numbers. She drove the point home with a series of charts, one here showing the likelihood that someone in the ER gets checked for a heart attack, according to their age. As Amanda points out, “nothing radical changes from the age of 39-and-three-quarters and 40, yet here is the data:",https://cdn-images-1.medium.com/max/1200/1*bJ58aYiSmkeNYJY73AQN3w.jpeg,[],https://medium.com/@evejweinberg/in-2018-numbers-lie-and-fictions-paint-truth-ea1f5cdc9abe?source=topic_page---8------0----------------,2018-06-08 22:01:41.763000+00:00

Neural Networks,The Art of Ethereal: Bringing Cellarius to Life – Genesis Thought – Medium,['Mally Anderson'],"The Art of Ethereal: Bringing Cellarius to Life

Whose future is it? Hers, and his, and theirs, and ours.

A sampling of the Cellarius faction portraits from our Ethereal Summit pop-up.

On May 11 and 12, our parent company ConsenSys hosted the third Ethereal Summit at the Knockdown Center in Queens, New York and invited Cellarius to participate, along with many other spokes from our Mesh. The creators of Ethereal wanted to build a different kind of crypto conference. Since this one explored the intersection of blockchain and the arts, we wanted to showcase that aspect of our project and spread the word in an unexpected way. We set up shop in “The Crypt,” a semi-outdoor concrete space with a distinctive patina that felt perfect for the Cellarius blockpunk aesthetic.

The Knockdown Center’s very blockpunk Crypt space. We displayed some not-yet-published art commissions.

We teamed with some artists from a group called Drawn Together NYC: Boris Rasin, Michael Scarola, Derrick Dent, and Rosalind Bunting. Drawn Together’s talented roster of artists creates design concepts, multimedia experiences, and fine art solutions for a wide range of projects and businesses, and they understood what we are going for right away.

The artists of Drawn Together NYC, from left to right: Boris Rasin, Rosalind Bunting, Derrick Dent, and Michael Scarola.

Boris, Michael, and Derrick created custom, in-universe faction portraits of Ethereal attendees. The CX Universe Guide imagines that nation-states and traditional economies will break down after the Cellarius AI seizes control of Earth’s energy sources and communication channels in 2084. In the absence of familiar institutions and technologies, people will begin to form factions according to their allegiance to Cellarius. We wanted to get attendees thinking about their own relationships to technology and start dreaming up characters to explore in the Cellarius universe. So we posed the question: which faction do you think you would be?

Boris drew background art for four different factions:

The 4 faction backgrounds, clockwise from top left: Bucolic, Elite, Ad-Hoc, Homotranscendus.

Bucolic: Bucolics are AI skeptics who reject technology and live on the peripheries of megacities, observing from the outside and farming small pockets of fertile soil. Though their process is completely manual and their harvests are meager, they feel a great satisfaction from working with their own hands, in stark contrast to the highly automated farming processes elsewhere.

Ad-Hoc: Ad-Hocs live off the Cellarius grid and make their own augmentations and tools with scrap pieces they scavenge and rework. Comprised of mostly poor and marginalized groups, they use ingenuity and what little tech they can access to get by.

Elite: The crypto-Elites of the future are pro-Cellarius and experiment with AI and aesthetic enhancements. Living in the highest levels of the megacities, Elites have access to bleeding-edge technology. They are known for having lifespans beyond the normal range of humans, and enjoy the neural boost that comes with AI coupling.

Homotranscendus: During the Reformation, it wasn’t just the home habitat that was transformed forever, but also humankind itself. The campaign was more than just re-imagining the economic machinery of the planet Earth, but also a re-imagining of the of the human brain and body. Through Cellarius-engineered advancements, the next evolution of humanity was born: Homotranscendus. Homotranscendi are fully integrated with AI and no longer depend on their human forms to express consciousness and gather information.

We even got a portrait of ConsenSys’s own Joe Lubin, who wore a custom Cellarius Ethereal t-shirt design during his keynote address (thanks, Joe!). Something tells us that Joe would be a Homotranscendus.

Future Homotranscendus Joe Lubin on Mars.

Reimagining how familiar scenarios from your own life play out in a future setting or speculating about how you might react to a superintelligent AI’s takeover of the world is a great place to start inventing your own ideas in the world of Cellarius. We hope some attendees will be inspired to start making art and stories based on their portraits!

Every single Ethereal portrait, as arranged by our designer, Octavian.

As we’ve mentioned in previous posts, we are also commissioning works from artists we admire to create the first round of content for the Cellarius universe. We decided to commission a mural that would take shape over the two days of the Summit and give attendees a behind-the-scenes look at the process of making a large-scale landscape painting. The design depicts what the Knockdown Center might look like a century from now, in 2118. Visitors to the Crypt got a chance to watch Rosalind transform the canvas from a faint pencil sketch into an impressive and detailed final product:

Rosalind’s “Knockdown Center in 2118” painting took shape over two days.

Rosalind & Boris outlined the sketch first, then Rosalind added color, starting with the future-NYC background.

We hope that the Cellarius platform will allow experienced artists and creators to get directly in touch with their fan bases and share some glimpses of their artistic process, just as Rosalind did with her live painting.

The Drawn Together NYC artists got to learn more about the possibilities of blockchain and decentralization for creatives in the process of chatting with the attendees. Michael noted, “There were so many passionate and interesting people from all over the world that came through. And they had as much fun as we did learning about and playing in the Cellarius world.” Rosalind agreed: “Probably my favorite thing I learnt about over the Summit was how Cellarius involves the creative talents of so many more artists in their company, and loved seeing some of their amazing artwork. Can’t wait to see more!”

We were also excited that the long-term goals of the Cellarius project resonated with the Drawn Together NYC artists. Derrick said, “This was probably the coolest on-site portrait job I’ve ever worked on. I had a great time learning about the Cellarius project and the potential for a sprawling, community-shaped open sci-fi world. It was even cooler to have our portrait work used as an onboarding tool for visitors. People immediately took to creating their own story within this world, and that says a lot about how exciting this could be for folks who are creatively inclined.” We couldn’t have said it better ourselves.

As Boris told us, “The more I spoke to the pop-up team and event attendees about the concept behind this project, the more it occurred to me that this is a game changer. Cellarius and the other projects from ConsenSys are sure to revolutionize our ecosystem in ways we can’t even begin to comprehend. It’s a challenge to explain exactly what this project is, because the underlying platform allows for limitless opportunities of invention, inspiration, and collaboration. Cellarius is whatever its contributors will it to be, and frankly, that’s a fundamentally crazy idea!”

That’s just the point: blockchain enthusiasts can become artists and use storytelling to push the conceptual limits of technology. Artists can use the platform to explore the possibilities of decentralization and blockchain for sharing and protecting their work. We can build it together. Cellarius is whatever our community of contributors wills it to be.",https://cdn-images-1.medium.com/max/1200/1*vL8856P7cdV84CYM_SkF0A.jpeg,[],https://medium.com/genesis-thought/the-art-of-ethereal-bringing-cellarius-to-life-ba4ae31811e7?source=topic_page---8------1----------------,2018-06-08 16:46:47.896000+00:00

Neural Networks,A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what…,['Rowan Trollope'],"A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what happened?” Has gotten some fun responses.

The most popular comment being one that says “not surprised, this was never going to be a big thing”…

The first thing to point out is that people are conflating the specific of a chatbot with the generic “conversational user interface” (CUI) of which a chatbot is a specific modality. The real discussion here is about the CUI.

And the last month has certainly showed us that the CUI has made dramatic strides with Google demonstrating Duplex.

So what happened to the explosion of chatbots people predicted?

Among other things, Developers figured out just how hard it is to make a really good conversational user interface. Product folks were tricked by the trio of Alexa/Siri/Google Assistant into the belief that a conversational interface is easy.

Turns out it’s really hard, requires a ton of data and is highly domain specific.

In other words, training a CUI to be really great at getting sports scores doesn’t translate at all to a chatbot that can help you with a billing problem or ordering a pizza.

Google was careful to point out that Duplex was trained for only two very specific use cases : book a salon or a restaurant appointment.

Tim Tuttle at Mindmeld figured this out and built a company to solve it, but it still required heavy lifting and tons of data specific to the domain.

My belief is that the conversational interface is inevitable.

Technology evolution is exponential not linear. Our tendency is to project the future in a linear fashion, which causes us to overestimate what’s possible in 1 year and underestimate what’s possible in 10 years.

This makes tech progress feel gradual or slow, and then sudden and surprising.

Last week Salesforce’s chief scientist, Richard Socher, spoke publicly about the future of chatbots and asserted that in 5 years we would begin to see this start to pay off.

We are early days on the conversational interface, but as with all tech progress most folks will be disappointed until one year, 5–10 years from now when they’ll be shocked and amazed and wonder how it happened so fast.",https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico,[],https://medium.com/@rowantrollope/chatbots-were-supposed-to-be-the-next-big-thing-what-happened-5a4e416308e1?source=topic_page---8------2----------------,2018-06-08 21:06:45.446000+00:00

Neural Networks,"Beethoven, Picasso, and Artificial Intelligence – Towards Data Science",['Chris Kalahiki'],"Beethoven, Picasso, and Artificial Intelligence

Introduction

When people think of the greatest artists who’ve ever lived, they probably think of names like Beethoven or Picasso. No one would ever think of a computer as a great artist. But what if one day, that was indeed the case. Could computers learn to create incredible drawings like the Mona Lisa? Perhaps one day a robot will be capable of composing the next great symphony. Some experts believe this to be the case. In fact, some of the greatest minds in artificial intelligence are diligently working to develop programs that can create drawing and music independently from humans. The use of artificial intelligence in the field of art has even been picked up by tech giants the likes of Google.

The projects that are included in this paper could have drastic implications in our everyday lives. They may also change the way we view art. They also showcase the incredible advancement that has been made in the field of artificial intelligence. Image recognition is not as far as the research goes. Nor is the ability to generate music in the styling of the great artists of our past. Although these topics will be touched upon, we will focus on several more advanced achievements such as text descriptions being turned into images and generating art and music that is totally original. Each of these projects bring something new and innovative to the table and show us exactly how the art space is a great place to further explore applications of artificial intelligence. We will be discussing problems that have been faced in these projects and how they have been overcome. The future of AI looks bright. Let’s look at what the future may hold. In doing this, we may be able to better understand the impact that artificial intelligence can have in an area that is driven by human creativity.

GAN and Its Evolved Forms

Machines must be educated. They learn from instruction. How do we lead machines away from emulating what already exists, and have them create new techniques? “No creative artist will create art today that tries to emulate the Baroque or Impressionist style, or any other traditional style, unless trying to do so ironically” [4]. This problem isn’t limited to paintings either. Music can be very structured in some respects, but is also a form of art that requires vast creativity. So how do we go about solving such a problem? The first concept we will discuss is something called GAN (Generative Adversarial Networks). GANs, although quite complex, are becoming an outdated model. If artificial intelligence in the art space is to advance, researchers and developers will have to work to find better methods to allow machines to generate art and music. Two of these such methods are presented in the form of Sketch-RNN and CAN (Creative Adversarial Networks). Each of these methods have their advantages over GANs.

First, let’s explore what exactly a GAN is. Below is a small excerpt explaining how a GAN works:

Generative Adversarial Network (GAN) has two sub networks, a generator and a discriminator. The discriminator has access to a set of images (training images). The discriminator tries to discriminate between “real” images (from the training set) and “fake” images generated by the generator. The generator tries to generate images similar to the training set without seeing the images [4].

The more images the generator creates, the closer they get to the images from the training set. The idea is that after a certain number of images are generated, the GAN will create images that are very similar to what we consider art. This is a very impressive accomplishment to say the least. But what if we take it a step further?

Many issues associated with the GAN are simply limitations on what it can do. The GAN is powerful, but can’t do quite as much as we would like. For example, the generator in the model described above will continue to create images closer and closer to the images given to the discriminator that it isn’t producing original art. Could a GAN be trained to draw alongside a user? It’s not likely. The model wouldn’t be able to turn a text-based description of an image into an actual picture either. As impressive as the GAN may be, we would all agree that it can be improved. Each of the shortcoming mentioned have actually been addressed and, to an extent, solved. Let’s look at how this is done.

Sketch-RNN is a recurrent neural network model developed by Google. The goal of Sketch-RNN is to help machines learn to create art in a manner similar to the way a human may learn. It has been used in a Google AI Experiment to be able to sketch alongside a user. While doing so, it can provide the users with suggestions and even complete the user’s sketch when they decide to take a break. Sketch-RNN is exposed to a massive number of sketches provided through a dataset of vector drawings obtained through another Google application that we will discuss later. Each of these sketches are tagged to let the program know what object is in the sketch. The data set represents the sketch as a set of pen strokes. This allows Sketch-RNN to then learn what aspects each sketch of a certain object has in common. If a user begins to draw a cat, Sketch-RNN could then show the user other common features that could be on the cat. This model could have many new creative applications. “The decoder-only model trained on various classes can assist the creative process of an artist by suggesting many possible ways of finishing a sketch” [3]. The Sketch-RNN team even believes that, given a more complex dataset, the applications could be used in an educational sense to teach users how to draw. These applications of Sketch-RNN couldn’t be nearly as easily achieved with GAN alone.

Another method used to improve upon GAN is the Creative Adversarial Network. In their paper regarding adversarial networks generating art, several researchers discuss a new way of generating art through CANs. The idea is that the CAN has two adversary networks. One, the generator, has no access to any art. It has no basis to go off of when generating images. The other network, the discriminator, is trained to classify the images generated as being art or not. When an image is generated, the discriminator gives the generator two pieces of information. The first is whether it believes the generated image comes from the same distributor as the pieces of art it was trained on, and the other being how the discriminator can fit the generated image into one of the categories of art it was taught. This technique is fantastic in that it helps the generator create images that are both emulative of past works of art in the sense that it learns what was good about those images and creative in a sense that it is taught to produce new and different artistic concepts. This is a big difference from GAN creating art that emulated the training images. Eventually, the CAN will learn how to produce only new and innovative artwork.

One final future for the vanilla GAN is StackGAN. StackGAN is a text to photo-realistic image synthesizer that uses stacked generative adversarial networks. Given a text description, the StackGAN is able to create images that are very much related to the given text. This wouldn’t be doable with a normal GAN model as it would be much too difficult to generate photo-realistic images from a text description even with a state-of-the-art training database. This is where StackGAN comes in. It breaks the problem down into 2 parts. “Low-resolution images are generated by our Stage-I GAN. On the top of our Stage-I GAN, we stack Stage-II GAN to generate realistic high-resolution images conditioned on Stage-I results and text descriptions” [7]. It is through the conditioning on Stage-I results and text descriptions that Stage-II GAN can find details that Stage-I GAN may have missed and create higher resolution images. By breaking the problem down into smaller subproblems, the StackGAN can tackle problems that aren’t possible with a regular GAN. On the next page is an image showing the difference between a regular GAN and each step of the StackGAN.

This image came from the StackGAN paper [7].

It is through advancements like these that have been made in recent years that we can continue to push the boundaries of what AI can do. We have just seen three ways to improve upon a concept that was already quite complex and innovative. Each of these advancements have a practical, everyday use. As we continue to improve on artificial intelligence techniques, we will able to do more and more in regard to, not just art and music, but a wide variety of tasks to improve our lives.

DeepBach, Magenta, and NSynth

Images aren’t the only type of art that artificial intelligence can impact though. Its effect on music is being explored as we speak. We will now explore some specific cases and their impact on both music and artificial intelligence. In doing this, we should be able to see how art can do as much for AI as AI does for it. Both fields benefit heavily from the types of projects that we are exploring here.

Could a machine ever be able to create a piece of music the likes of Johann Sebastian Bach? In a project known as DeepBach, several researchers looked to create pieces similar to Bach’s chorales. The beauty of DeepBach is that it “is able to generate coherent musical phrases and provides, for instance, varied reharmonizations of melodies without plagiarism” [6]. What this means it that DeepBach can create music with correct structure and be original. It is just in the style of Bach. It isn’t just a mashup of his works. DeepBach is creating new content. The developers of DeepBach went on to test whether their product could actually fool listeners.

As part of the experiment, over 1,250 people were asked to vote whether pieces presented to them were in fact composed by Bach. The subjects had varying degrees of musical expertise. The results showed that as the model for DeepBach’s complexity increased, the subjects had more and more trouble distinguishing the chorales of Bach from those of DeepBach. This experiment shows us that through the use of artificial intelligence and machine learning, it is quite possible to recreate original works in the likeness of the greats. But is that the limit to what artificial intelligence can do in the field of art and music?

DeepBach has achieved something that would have been unheard of in the not so distant past, but it certainly isn’t the fullest extent of what AI can do to benefit the field of music. What if we want to create new and innovative music? Maybe AI can change the way music is created all together. There must be projects that do more to push the envelope. As a matter of fact, that is exactly what the team behind Magenta look to do.

Magenta is a project being conducted by the Google Brain team and lead by Douglas Eck. Eck has been working for Google since 2010, but that isn’t where his interest in Music began. Eck helped found Brain Music and Sound, an international laboratory for brain, music, and sound research. He was also involved at the McGill Centre for Interdisciplinary Research in Music Media and Technology, and was an Associate Professor in Computer Science at the University of Montreal.

Magenta’s goal is to be “a research project to advance the state of the art in machine intelligence for music and art generation” [2]. It is an open source project that uses TensorFlow. Magenta aims to learn how to generate art and music in a way that is indeed generative. It must go past just emulating existing music. This is distinctly different that projects along the line of DeepBach which set out to emulate existing music in a way that wasn’t plagiarizing existing pieces of music. Eck and company realize that art is about capturing elements of surprise and drawing attention to certain aspects. “This leads to perhaps the biggest challenge: combining generation, attention and surprise to tell a compelling story. So much of machine-generated music and art is good in small chunks, but lacks any sort of long-term narrative arc” [2]. Such a perspective gives computer-generated music more substance, and helps it to become less of a gimmick.

One of the projects the magenta team has developed is called NSynth. The idea behind NSynth is to be able to create new sounds that have never been heard before, but beyond that, to reimagine how music synthesis can be done. Unlike ordinary synthesizers that focus on “a specific arrangement of oscillators or an algorithm for sample playback, such as FM Synthesis or Granular Synthesis” [5], NSynth generates sounds on an individual level. To do this, it uses deep neural networks. Google has even launched an experiment that allows users to really see what NSynth can do by allowing them to fuse together the sounds of existing instruments to create new hybrid sounds that have never been heard before. As an example, users can take two instruments such as a banjo and a tuba, and take parts of each of their sounds to create a totally new instrument. The experiment also allowed users to decide what percentage of each instrument would be used.

Projects like Magenta go above and beyond in showing us the full extent of what artificial intelligence can do in the way of generating music. They explore new applications of artificial intelligence that can generate new ideas independent of humans. It is the closest we have come to machine creativity. Although machines aren’t yet able to truly think and express creativity, they may soon be able to generate new and unique art and music for us to enjoy. Don’t worry though. Eck doesn’t intend to replace artists with AI. Instead he looks to provide artists with tools to create music in an entirely new way.

Deep Dream and Quick, Draw!

As we look ahead to a few more of the ways that AI has been used to accomplish new and innovative ideas in the art space, we look at projects like Quick, Draw! and Deep Dream. These projects showcase amazing progress in the space while pointing out some issues that researchers in AI will have to work out in the years to come.

Quick, Draw! is an application from the Google Creative Lab, trained to recognize quick drawings much like one would see in a game of Pictionary. The program can recognize simple objects such as cats and apples based on common aspects of the many pictures it was given before. Although the program will not get every picture right each time it is used, it continues to learn from the similarities in the picture drawn and the hundreds of pictures before it.

The science behind Quick, Draw! “uses some of the same technology that helps Google Translate recognize your handwriting. To understand handwritings or drawings, you don’t just look at what the person drew. You look at how they actually drew it” [1]. It is presented in the form of a game, with the user drawing a picture of an object chosen by the application. The program then has 20 seconds to recognize the image. In each session, the user is given a total of 6 objects. The images are then stored to the database used to train application. This happens to be the same database we saw earlier in the Sketch-RNN application. This image recognition is a very practical use of artificial intelligence in the realm of art and music. It can do a lot to benefit us in our everyday lives. But this only begins to scratch the surface of what artificial intelligence can do in this field. Although this is very impressive, we might point out that the application doesn’t truly understand what is being drawn. It is just picking up on patterns. In fact, this distinction is part of the gap between simple AI techniques and true artificial general intelligence. Machines that truly understand what the objects in images are don’t appear to be coming in the near future.

Another interesting project in the art space is Google’s Deep Dream project, which uses AI to create new and unique images. Unfortunately, the Deep Dream Generator Team wouldn’t go into too much detail about the technology itself (mostly fearing it would be too long for an email) [8]. They did, however, explain that convolutional neural networks train on the famous ImageNet dataset. Those neural networks are then used to create art-like images. Essentially, Deep Dream takes the styling of one image and uses it to modify another image. The results can be anything from a silly fusion to an artistic masterpiece. This occurs when the program identifies the unique stylings of an image provided by the user and imposes those stylings onto another image that the user provides. What can easily be observed through the use of Deep Dream is that computers aren’t yet capable of truly understanding what they are doing with respect to art. They can be fed complex algorithms to generate images, but don’t fundamentally understand what it is they are generating. For example, a computer may see a knife cutting through an onion and assume the knife and onion are one object. The lack of an ability to truly understand the contents of an image is one dilemma that researchers have yet to solve.

Perhaps as we continue to make advances in artificial intelligence we will be able to have machines that do truly understand what objects are in an image and even the emotions evoked by their music. The only way for this to be achieved is by reaching true artificial general intelligence (AGI). IN the meantime, the Deep Dream team believes that generative models will be able to create some really interesting pieces of art and digital content.

Where Do We Go From Here?

For this section, we will consider where artificial intelligence could be heading in the art space. We will take a look at how AI has impacted the space and in what ways it can continue to do so. We will also look at ways art and music could continue to impact AI in the years to come.

Although I don’t feel that we have completely mastered the ability to emulate the great artists of our past, it is just a matter of time before that problem is solved. The real task to be solved is that of creating new innovations in art and music. We need to work towards creation without emulation. It is quite clear that we are headed in that direction through projects like CAN and Magenta. Artificial general intelligence (AGI) is not the only way to complete this task. As a matter of fact, even those who dispute the possibility of AGI would have a hard time disputing the creation of unique works of art by a machine.

One path that may be taken to further improve art and music through AI is to create more advanced datasets to use in training the complex networks like Sketch-RNN and Deep Dream. AI needs to be trained to be able to perform as expected. That training has a huge impact on the results we get. Shouldn’t we want to train our machines in the most beneficial way possible. Even developing software like Sketch-RNN to use the ImageNet dataset used in Deep Dream could be huge in educating artists on techniques for drawing complex, realistic images. Complex datasets could very well be our answer to more efficient training. Until our machines can think and learn like we do, we will need to be very careful what data is used to train them.

One of the ways that art and music can help to impact AI is by providing another method of Turing Testing machines. For those who dream of creating AGI, what better way to test the machine’s ability that to create something that tests the full extent of human-like creativity? Art is the truest representation of human creativity. That is, in fact, its essence. Although art is probably not the ultimate end game for artificial intelligence, it could be one of the best ways to test the limits of what a machine can do. The day that computers can create original musical composition and create images based on descriptions given by a user could very well be the day that we stop being able to distinguish man from machine.

Conclusion

There are many benefits to using artificial intelligence in the music space. Some of them have already been seen in the projects we have discussed so far. We have seen how artificial intelligence could be used for image recognition as well as their ability to turn our words into fantastic images. We have also seen how AI can be used to synthesize new sounds that have never been heard. We know that artificial intelligence can be used to create art alongside us as well as independently from us. It can be taught to mimic music from the past and can create novel ideas. All of these accomplishments are a part of what will drive AI research into the future. Who knows? Perhaps one day we will achieve artificial general intelligence and machines will be able to understand what is really in the images it is given. Maybe our computers will be able to understand how their art makes us feel. There is a clear path showing us where to go from here. I firmly believe that it is up to us to continue this research and test the limits of what artificial intelligence can do, both in the field of art and in our everyday lives.

References",https://cdn-images-1.medium.com/max/1200/0*pIGHko-OCo1usW2c,[],https://towardsdatascience.com/beethoven-picasso-and-artificial-intelligence-caf644fc72f9?source=topic_page---8------3----------------,2018-06-08 21:34:58.310000+00:00

Neural Networks,The curious case of the vanishing & exploding gradient,['Eniola Alese'],"The curious case of the vanishing & exploding gradient

Understanding why gradients explode or vanish and methods for dealing with the problem.

Photo by SpaceX on Unsplash

In the last post, we introduced a step by step walkthrough of RNN training and how to derive the gradients of the network weights using back propagation and the chain rule. But it turns out that during this training the RNN can suffer greatly from two problems: 1. Vanishing gradients or 2. Exploding gradients.

Why Gradients Explode or Vanish

Recall the many-to-many architecture for text generation shown below and in the introduction to RNN post, lets assume the input sequence to the network is a 20 word sentence: “I grew up in France,…….. I speak French fluently.

We can see from the example above that for the RNN to predict the word “French” which comes at the end of the sequence, it would need information from the word “France”, which occurs further back at the beginning of the sentence. This kind of dependence between sequence data is called long-term dependencies because the distance between the relevant information “France” and the point where it is needed to make a prediction “French” is very wide. Unfortunately, in practice as this distance becomes wider, RNNs have a hard time learning these dependencies because it encounters either a vanishing or exploding gradient problem.

These problems arise during training of a deep network when the gradients are being propagated back in time all the way to the initial layer. The gradients coming from the deeper layers have to go through continuous matrix multiplications because of the the chain rule, and as they approach the earlier layers, if they have small values (<1), they shrink exponentially until they vanish and make it impossible for the model to learn , this is the vanishing gradient problem. While on the other hand if they have large values (>1) they get larger and eventually blow up and crash the model, this is the exploding gradient problem

Dealing with Exploding Gradients",https://cdn-images-1.medium.com/max/1200/0*UCn2LUkacEHQxgZW,[],https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb?source=topic_page---8------5----------------,2018-06-05 22:33:57.437000+00:00

Neural Networks,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------,2018-06-08 22:25:33.341000+00:00

Neural Networks,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------#--responses,2018-06-08 22:25:33.341000+00:00

Neural Networks,How to build a range slider component in React from scratch using only <div> and <span>,['Rajesh Pillai'],"How to build a range slider component in React from scratch using only <div> and <span>

In this article we will build a React range slider component step by step using only <div>. We will enable it with touch support.

What can you do with a piece of about 50 <div’s>?

Build a slider control from scratch. If this sounds interesting, then follow along.

The final output will look like the below animation.

Please do note that I have developed this component as a teaching exercise for my students of ReactJS — Beyond the Basics course on Udemy, so it may have some edge cases (which I will fix as and when encountered).

You could use an HTML5 range control and customize it. But I wanted to take a different approach and build something from scratch. And the result is what you see here.

Our slider component will be composed of the below three elements:

A slider range

The actual slider controls

The current selection range

Defining the state for our component

Let us begin by defining our state. I am only showing you the important part of the code. For the full source code, please refer to the link at the end of the article.

state = {

slots: 24,

start: 0,

end: 10,

labelMode: ""mid"", // mid, long

}

The state contains the following properties.

slots: Total slots to be drawn (in this case I am using it as a time selector, so it will have 24 hour slots)

start: The start value of the selection

end: The end value of the selection

labelMode: Currently unused. But can be used to customize the scale label rendering.

The return part of the render method

Let us now take a look at the return part of the render method. The render() method will be slowly composed of small pieces of functionality.

return (

<div>

<h2>React Slider</h2>

<div className=""example-1"">

<div className=""slider-container"">

<div className=""slider-scale"">

{scale}

</div>

<div className=""slider"">

{slider}

</div>

<div className=""slider-selected-scale"">

{currentScale}

</div>

</div>

</div>

</div>

);

For those reading on mobile, the below image may be handy, as sometimes Medium breaks the code formatting.

If you take a look at the code, there are only three important pieces:

scale variable

slider variable

currentScale variable

The three variables above will be responsible for rendering the correct parts of the overall slider.

Dissecting the render () method

Let us initialize some variables. The scale , slider and currentScale JSX will be created within the for loop defined below.

render () {

let scale = [];

let slider=[];

let currentScale = [];

let minThumb = null;

let maxThumb = null

..... // rest of the code

}

Create the JSX for the ‘scale’ variable

Creating the JSX for the scale variable is quite simple. We just loop through the slots value in the state and push a <div> to the scale array with the required CSS class for styling.

The if condition ensures that we are only printing the label for i = 0, i = 12, or i = 24 (kind of mid range). Please feel free to customize this.

for (let i = 0; i <= this.state.slots;i++) {

let label = """";



if (i == 0 || i == 12 || i == 24) {

label = i;

}



scale.push(

<div

key={i}

className=""slot-scale"">

{label}

</div>

);

Here’s the code in image format:

Create the JSX for the ‘currentScale’ variable

Let us now continue with the same for loop and create the ‘currentScale’ JSX. We are still within the same for loop, so about 24 divs will be created as per the value in this.state.slots value.

The currentScale has a class of ‘slot-scale-selected’.

let currentLabel = """";



if (i === this.state.start || i === this.state.end) {

currentLabel = i;

}



currentScale.push(

<div

key={i}

className=""slot-scale-selected"">

{currentLabel}

</div>

);

The code is pretty similar to the ‘scale’ JSX that we created.

Create the JSX for the ‘slider’ variable

Let us write a function to render the ‘slider’ jsx. The slider needs two thumbs, one for min, and one for max.

Let us first initialize the thumb variable depending on the ‘i’ value. If ‘i’ is the same as this.state.start, then we set the minThumb variable. Else if the value of ‘i’ is the same as this.state.end, then we initialize the maxThumb variable.

if (i === this.state.start) {

minThumb = <this.MinSlider />

} else if (i === this.state.end) {

maxThumb = <this.MaxSlider />

} else {

minThumb = null;

maxThumb = null;

}

Create the JSX for the ‘slider’

The important code piece here is the dragover event. This is required for the HTML drop to work correctly.

let lineClass = ""line"";



if (i >= this.state.start && i < this.state.end) {

lineClass += "" line-selected"";

}

slider.push(

<div

data-slot={i}

onDragOver={this.onDragOver}

onTouchMove = {this.onDragOver}

onTouchEnd = {this.onDrop}

onDrop = {this.onDrop}

key={i}

className=""slot"">

<div data-slot={i} className={lineClass}/>

<span className=""scale-mark""></span>

{minThumb}

{maxThumb}

</div>

);

The slider variable needs two additional pieces of features to represent the min and the max thumb on the slider.

The slider JSX has additional event handlers to deal with handling the drop event/touchend event. We will take a look at the event handlers shortly.

The ‘lineClass’ styles/renders the line on the slider, and the ‘line-selected’ class styles the currently selected range.

Let us now write the MinSlider and MaxSlider function outside the render method.

The MinSlider () function to render the min thumb

Let’s take a look at the code. The important props are the events related to drag and the draggable attribute. The draggable attribute will make this element draggable.

We are also adding the touch event handler. Refer to the link at the bottom of the article to add touch support polyfill for the HTML5 API.

MinSlider=()=> {

return (

<div data-slider=""min""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-min"">

</div>

);

}

The MaxSlider () function to render the min thumb

The MaxSlider is almost the same as the MinSlider except for the data and the className.

MaxSlider=()=> {

return (

<div data-slider=""max""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-max"">

</div>

);

}

The code image is given below for reference.

Event Handling

Let us now look at the drag/touch event handlers defined within our <div> to control the movement of the slider element.

dragover:

The dragover event is required to support the drop zone when using the HTML5 drag/drop API. The only thing we need to do here is to invoke the preventDefault on the event object.

onDragOver = (e) => {

e.preventDefault();

}

dragstart:

The dragstart enables us to store which slider is being dragged. Please note that I am not using the dataTransfer object here, but simply using an instance variable to store this.

onDragStart = (e) => {

let slider = e.target.dataset.slider;

this.sliderType = slider;

}

The value of e.target.dataset.slider is either “min” or “max,” indicating which slider is being dragged.

ondrop:

The ondrop event captures where the thumb is being dropped (on which scale).

This is the important flow in the ondrop event:

Grab the source (whether min/max thumb)

Get the slot (where the drop happens)

Validations

Update the slot (in the state)

Reset the sliderType.

onDrop = (e, target) => {

let source = this.sliderType;

let slot = Number(e.target.dataset.slot);



if (isNaN(slot)) return;



if (source === ""min"") {

if (slot >= this.state.end) return;

this.setState({

start: slot

},()=>{

console.log(this.state);

})

} else if (source === ""max"") {

if (slot <= this.state.start) return;

this.setState({

end: slot

},()=>{

console.log(this.state);

})

}

this.sliderType = null;

}

The complete source code/and demo can be seen here http://jsbin.com/remodat/edit?output

Since I am using HTML5 drag and drop features to add touch, support please add this polyfill reference to your html file.

Todos

Extract the logic to a separate Component class

Test it and and add customization.

History

21-May-2018 — First release

P.S: This component is a result of a very quick coding attempt. This will be refactored.

Promotion: If you would like to support our open source curriculum Mastering Full Stack Engineering in 12 to 20 weeks then here is a special 10$ coupon for medium readers for my upcoming live ReactJS-Beyond the basicscourse on udemy (MEDIUM_500 is the coupon code, which is already tagged in the above URL)",https://cdn-images-1.medium.com/max/1200/1*iSkeoPHBQubtAL4fV4h9xQ.png,[],https://medium.freecodecamp.org/how-to-build-a-range-slider-component-in-react-from-scratch-using-only-div-and-span-d53e1a62c4a3?source=collection_home---6------1----------------,2018-06-08 21:41:33.808000+00:00

Neural Networks,The well-kept secret behind great UX: Usability Testing,['Anant Jain'],"The well-kept secret behind great UX: Usability Testing

Whether you only have a prototype or a full-fledged product, it’s a really good idea to run monthly usability tests. These make sure that whatever you’re working on is usable and the user experience is excellent.

If you’re wondering what you can do to make your usability tests more structured and organized, this guide is for you. Let’s get started!

First off, always keep the two Golden Rules of Usability Testing in mind:

Any testing is better than no testing (with no one!) A little testing earlier is better than a lot of testing later.

In this post, I will introduce you to the kind of lightweight usability testing described in Steve Krug’s books, “Don’t Make Me Think” and “Rocket Surgery Made Easy.” Steve calls this kind of testing “Do-It-Yourself Usability Testing” since it’s supposed to be cheap, easy-to-do and takes just a morning a month.

A quick intro to usability testing

The idea behind this is to:

Find a few participants

Ask them to come in and go through a list of user flows you want to test

Observe the problems they run into

Finally, make a list of issues to fix

Sounds simple enough, but very few of us actually do it. The goal of this post is to make you confident enough to run at least one usability test session this month. I ran my first usability test only a year ago, and I must say it’s actually a lot of fun!

Before we get to the test itself, here are a few things to note:

Reserve one morning a month (say the third Thursday every month) for a round of testing, debriefing, and deciding what to fix. Test with three participants each round. Recruit loosely, and grade on a curve. You don’t need to find someone who fits the exact mould of your ideal user, since most usability problems can be uncovered by testing with just about anyone. If you are part of a big company and have the budget, you can recruit via Craigslist and offer a $50 gift card for an hour of the participant’s time. If you don’t have those kind of resources, don’t worry — you can ask your friends, your existing users, or even go to a café and ask strangers for 15 minutes of their time in exchange for buying them a coffee. If you’re doing this as part of a bigger team, get as many observers as possible to observe the tests in a separate observation room. These will be the designers, engineers, project managers, executives, etc. Or, in case of side projects, it’ll be just be you later in your room!

What happens during the test?

During a usability test, you will record the participant’s voice and their computer screen, and share both these streams live with observers in another room. A typical one-hour test can be broken down into:

Welcome (4 mins): Explain how the test will work so that the participant will know what to expect. The questions (2 mins): Ask the participant a few questions about themselves. This helps put them at ease and gives you an idea of how computer-savvy they are. The Homepage tour (3 mins): Open the Home page of your site, and ask the participant to look around and tell you what they think. This will give you an idea of how easy it is to understand your home page, as well as how familiar the participant is with your domain. The tasks (35 minutes): Watch the participant perform a series of tasks you have prepared for them beforehand. If you’re building a SaaS product and you’re testing out your subscription flow, a typical task could be to find the Pricing page, compare various plans, and Subscribe to one of the plans with a provided test credit card number. Encourage the participant to think out loud as they perform the task (see the video at the end of the post for a sample test.) It’s crucial that you let them work on their own and not ask them any leading questions, or give out any clues or assistance. Probing (5 mins): Ask the participant any questions you may have about anything that happened during the test and about any issues that people in the observation room may have. Also, answer any questions that the participant may have at this point (don’t answer them during the actual tasks since you’re testing how they’ll perform with no one around.) Wrapping Up (5 mins): Thank them for their help, and give them their gift card if you promised one while recruiting them.

The debrief

During the breaks between successive tests, ask the observers to write down the top 3 usability problems that they saw. During the debriefing, focus ruthlessly on deciding to fix the most severe problems first. Here are a few other recommendations:

Keep a separate list of low-hanging fruit. These are the problems you can typically fix with one-line code changes, but have a huge impact on task completion rates. Joel Califa calls them “tiny wins”. Here’s an example:

Resist the impulse to add things — instead, try to tweak your existing design to fix the problem.

to fix the problem. Take “new feature” requests with a grain of salt. Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature.

Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature. Ignore the problems where the user goes astray for a bit but comes back on track by themselves. These are usually not worth investing much time unless you see a pattern across multiple participants.

Good design is a delicate balance, so when fixing a problem, ensure that you aren’t introducing new ones.

Remote testing and unmoderated user testing

Remote testing is very similar to an in-person usability test, except that the participant is at their home/office and you conduct the testing via screen sharing and voice call.

Unmoderated user testing is another way to test, where you specify your website, the tasks you want the users to do, and get back video recordings of people trying to accomplish those tasks. Usertesting.com is the leader in this space, but note that a single 30-minute test costs about $50.

Resources

You can download checklists, interview script, consent form, and a demo video at Steve Krug’s site here: Downloads for Rocket Surgery Made Easy.

Here’s a Usability Test demo video from Google Ventures:

I want to thank you for reading this quick guide. This was originally published as part of the UX Design course on Commonlounge, a platform that has courses with small bite-sized lessons like these on topics ranging from Project Management to Machine Learning that deliver the most value for the time you put in.

You learn by working on real-world projects and getting feedback from industry mentors. You should check it out here!",https://cdn-images-1.medium.com/max/1200/0*UWxJWKKNLXR5c1cm,[],https://medium.freecodecamp.org/the-well-kept-secret-behind-great-ux-usability-testing-b788178a64c3?source=collection_home---6------2----------------,2018-06-08 21:25:31.335000+00:00

Neural Networks,An introduction to part-of-speech tagging and the Hidden Markov Model,['Divya Godayal'],"Let’s go back into the times when we had no language to communicate. The only way we had was sign language. That’s how we usually communicate with our dog at home, right? When we tell him, “We love you, Jimmy,” he responds by wagging his tail. This doesn’t mean he knows what we are actually saying. Instead, his response is simply because he understands the language of emotions and gestures more than words.

We as humans have developed an understanding of a lot of nuances of the natural language more than any animal on this planet. That is why when we say “I LOVE you, honey” vs when we say “Lets make LOVE, honey” we mean different things. Since we understand the basic difference between the two phrases, our responses are very different. It is these very intricacies in natural language understanding that we want to teach to a machine.

What this could mean is when your future robot dog hears “I love you, Jimmy”, he would know LOVE is a Verb. He would also realize that it’s an emotion that we are expressing to which he would respond in a certain way. And maybe when you are telling your partner “Lets make LOVE”, the dog would just stay out of your business 😛.

This is just an example of how teaching a robot to communicate in a language known to us can make things easier.

The primary use case being highlighted in this example is how important it is to understand the difference in the usage of the word LOVE, in different contexts.

Part-of-Speech Tagging

From a very small age, we have been made accustomed to identifying part of speech tags. For example, reading a sentence and being able to identify what words act as nouns, pronouns, verbs, adverbs, and so on. All these are referred to as the part of speech tags.

Let’s look at the Wikipedia definition for them:

In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging or word-category disambiguation, is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context — i.e., its relationship with adjacent and related words in a phrase, sentence, or paragraph. A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.

Identifying part of speech tags is much more complicated than simply mapping words to their part of speech tags. This is because POS tagging is not something that is generic. It is quite possible for a single word to have a different part of speech tag in different sentences based on different contexts. That is why it is impossible to have a generic mapping for POS tags.

As you can see, it is not possible to manually find out different part-of-speech tags for a given corpus. New types of contexts and new words keep coming up in dictionaries in various languages, and manual POS tagging is not scalable in itself. That is why we rely on machine-based POS tagging.

Before proceeding further and looking at how part-of-speech tagging is done, we should look at why POS tagging is necessary and where it can be used.

Why Part-of-Speech tagging?

Part-of-Speech tagging in itself may not be the solution to any particular NLP problem. It is however something that is done as a pre-requisite to simplify a lot of different problems. Let us consider a few applications of POS tagging in various NLP tasks.

Text to Speech Conversion

Let us look at the following sentence:

They refuse to permit us to obtain the refuse permit.

The word refuse is being used twice in this sentence and has two different meanings here. refUSE (/rəˈfyo͞oz/)is a verb meaning “deny,” while REFuse(/ˈrefˌyo͞os/) is a noun meaning “trash” (that is, they are not homophones). Thus, we need to know which word is being used in order to pronounce the text correctly. (For this reason, text-to-speech systems usually perform POS-tagging.)

Have a look at the part-of-speech tags generated for this very sentence by the NLTK package.

>>> text = word_tokenize(""They refuse to permit us to obtain the refuse permit"")

>>> nltk.pos_tag(text)

[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'),

('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]

As we can see from the results provided by the NLTK package, POS tags for both refUSE and REFuse are different. Using these two different POS tags for our text to speech converter can come up with a different set of sounds.

Similarly, let us look at yet another classical application of POS tagging: word sense disambiguation.

Word Sense Disambiguation

Let’s talk about this kid called Peter. Since his mother is a neurological scientist, she didn’t send him to school. His life was devoid of science and math.

One day she conducted an experiment, and made him sit for a math class. Even though he didn’t have any prior subject knowledge, Peter thought he aced his first test. His mother then took an example from the test and published it as below. (Kudos to her!)

Word-sense Disambiguation example — My son Peter’s first Maths problem.

Words often occur in different senses as different parts of speech. For example:

She saw a bear.

Your efforts will bear fruit.

The word bear in the above sentences has completely different senses, but more importantly one is a noun and other is a verb. Rudimentary word sense disambiguation is possible if you can tag words with their POS tags.

Word-sense disambiguation (WSD) is identifying which sense of a word (that is, which meaning) is used in a sentence, when the word has multiple meanings.

Try to think of the multiple meanings for this sentence:

Time flies like an arrow

Here are the various interpretations of the given sentence. The meaning and hence the part-of-speech might vary for each word.

Part-of-speech tags define the meaning of a sentence based on the context

As we can clearly see, there are multiple interpretations possible for the given sentence. Different interpretations yield different kinds of part of speech tags for the words.This information, if available to us, can help us find out the exact version / interpretation of the sentence and then we can proceed from there.

The above example shows us that a single sentence can have three different POS tag sequences assigned to it that are equally likely. That means that it is very important to know what specific meaning is being conveyed by the given sentence whenever it’s appearing. This is word sense disambiguation, as we are trying to find out THE sequence.

These are just two of the numerous applications where we would require POS tagging. There are other applications as well which require POS tagging, like Question Answering, Speech Recognition, Machine Translation, and so on.

Now that we have a basic knowledge of different applications of POS tagging, let us look at how we can go about actually assigning POS tags to all the words in our corpus.

Types of POS taggers

POS-tagging algorithms fall into two distinctive groups:

Rule-Based POS Taggers

Stochastic POS Taggers

E. Brill’s tagger, one of the first and most widely used English POS-taggers, employs rule-based algorithms. Let us first look at a very brief overview of what rule-based tagging is all about.

Rule-Based Tagging

Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods.

Typical rule-based approaches use contextual information to assign tags to unknown or ambiguous words. Disambiguation is done by analyzing the linguistic features of the word, its preceding word, its following word, and other aspects.

For example, if the preceding word is an article, then the word in question must be a noun. This information is coded in the form of rules.

Example of a rule:

If an ambiguous/unknown word X is preceded by a determiner and followed by a noun, tag it as an adjective.

Defining a set of rules manually is an extremely cumbersome process and is not scalable at all. So we need some automatic way of doing this.

The Brill’s tagger is a rule-based tagger that goes through the training data and finds out the set of tagging rules that best define the data and minimize POS tagging errors. The most important point to note here about Brill’s tagger is that the rules are not hand-crafted, but are instead found out using the corpus provided. The only feature engineering required is a set of rule templates that the model can use to come up with new features.

Let’s move ahead now and look at Stochastic POS tagging.

Stochastic Part-of-Speech Tagging

The term ‘stochastic tagger’ can refer to any number of different approaches to the problem of POS tagging. Any model which somehow incorporates frequency or probability may be properly labelled stochastic.

The simplest stochastic taggers disambiguate words based solely on the probability that a word occurs with a particular tag. In other words, the tag encountered most frequently in the training set with the word is the one assigned to an ambiguous instance of that word. The problem with this approach is that while it may yield a valid tag for a given word, it can also yield inadmissible sequences of tags.

An alternative to the word frequency approach is to calculate the probability of a given sequence of tags occurring. This is sometimes referred to as the n-gram approach, referring to the fact that the best tag for a given word is determined by the probability that it occurs with the n previous tags. This approach makes much more sense than the one defined before, because it considers the tags for individual words based on context.

The next level of complexity that can be introduced into a stochastic tagger combines the previous two approaches, using both tag sequence probabilities and word frequency measurements. This is known as the Hidden Markov Model (HMM).

Before proceeding with what is a Hidden Markov Model, let us first look at what is a Markov Model. That will better help understand the meaning of the term Hidden in HMMs.

Markov Model

Say that there are only three kinds of weather conditions, namely

Rainy

Sunny

Cloudy

Now, since our young friend we introduced above, Peter, is a small kid, he loves to play outside. He loves it when the weather is sunny, because all his friends come out to play in the sunny conditions.

He hates the rainy weather for obvious reasons.

Every day, his mother observe the weather in the morning (that is when he usually goes out to play) and like always, Peter comes up to her right after getting up and asks her to tell him what the weather is going to be like. Since she is a responsible parent, she want to answer that question as accurately as possible. But the only thing she has is a set of observations taken over multiple days as to how weather has been.

How does she make a prediction of the weather for today based on what the weather has been for the past N days?

Say you have a sequence. Something like this:

Sunny, Rainy, Cloudy, Cloudy, Sunny, Sunny, Sunny, Rainy

So, the weather for any give day can be in any of the three states.

Let’s say we decide to use a Markov Chain Model to solve this problem. Now using the data that we have, we can construct the following state diagram with the labelled probabilities.",https://cdn-images-1.medium.com/max/1200/1*f6e0uf5PX17pTceYU4rbCA.jpeg,[],https://medium.freecodecamp.org/an-introduction-to-part-of-speech-tagging-and-the-hidden-markov-model-953d45338f24?source=collection_home---6------3----------------,2018-06-08 19:31:14.123000+00:00

Neural Networks,A deep dive into part-of-speech tagging using the Viterbi algorithm,['Sachin Malhotra'],"Welcome back, Caretaker!

In case you’ve forgotten the problem we were trying to tackle in the previous article, let us revise it for you.

So there’s this naughty kid Peter and he’s going to pester his new caretaker, you!

As a caretaker, one of the most important tasks for you is to tuck Peter in bed and make sure he is sound asleep. Once you’ve tucked him in, you want to make sure that he’s actually asleep and not up to some mischief.

You cannot, however, enter the room again, as that would surely wake Peter up. All you can hear are the noises that might come from the room.

Either the room is quiet or there is noise coming from the room. These are your states.

All you have as the caretaker are:

a set of observations, which is basically a sequence containing noise or quiet over time, and

or over time, and A state diagram provided by Peter’s mom — who happens to be a neurological scientist — that contains all the different sets of probabilities that you can use to solve the problem defined below.

The problem

Given the state diagram and a sequence of N observations over time, we need to tell the state of the baby at the current point in time. Mathematically, we have N observations over times t0, t1, t2 .... tN . We want to find out if Peter would be awake or asleep, or rather which state is more probable at time tN+1 .

In case any of this seems like Greek to you, go read the previous article to brush up on the Markov Chain Model, Hidden Markov Models, and Part of Speech Tagging.

The state diagram that Peter’s mom gave you before leaving.

In that previous article, we had briefly modeled the problem of Part of Speech tagging using the Hidden Markov Model.

The problem of Peter being asleep or not is just an example problem taken up for a better understanding of some of the core concepts involved in these two articles. At the core, the articles deal with solving the Part of Speech tagging problem using the Hidden Markov Models.

So, before moving on to the Viterbi Algorithm, let’s first look at a much more detailed explanation of how the tagging problem can be modeled using HMMs.

Generative Models and the Noisy Channel Model

A lot of problems in Natural Language Processing are solved using a supervised learning approach.

Supervised problems in machine learning are defined as follows. We assume training examples (x(1), y(1)) . . . (x(m) , y(m)) , where each example consists of an input x(i) paired with a label y(i) . We use X to refer to the set of possible inputs, and Y to refer to the set of possible labels. Our task is to learn a function f : X → Y that maps any input x to a label f(x).

In tagging problems, each x(i) would be a sequence of words X1 X2 X3 …. Xn(i) , and each y(i) would be a sequence of tags Y1 Y2 Y3 … Yn(i) (we use n(i)to refer to the length of the i’th training example). X would refer to the set of all sequences x1 . . . xn, and Y would be the set of all tag sequences y1 . . . yn. Our task would be to learn a function f : X → Y that maps sentences to tag sequences.

An intuitive approach to get an estimate for this problem is to use conditional probabilities. p(y | x) which is the probability of the output y given an input x. The parameters of the model would be estimated using the training samples. Finally, given an unknown input x we would like to find

f(x) = arg max(p(y | x)) ∀y ∊ Y

This here is the conditional model to solve this generic problem given the training data. Another approach that is mostly adopted in machine learning and natural language processing is to use a generative model.

Rather than directly estimating the conditional distribution p(y|x) , in generative models we instead model the joint probability p(x, y) over all the (x, y) pairs.

We can further decompose the joint probability into simpler values using Bayes’ rule:

p(y) is the prior probability of any input belonging to the label y.

is the prior probability of any input belonging to the label y. p(x | y) is the conditional probability of input x given the label y.

We can use this decomposition and the Bayes rule to determine the conditional probability.

Remember, we wanted to estimate the function

f(x) = arg max( p(y|x) ) ∀y ∊ Y

f(x) = arg max( p(y) * p(x | y) )

The reason we skipped the denominator here is because the probability p(x) remains the same no matter what the output label being considered. And so, from a computational perspective, it is treated as a normalization constant and is normally ignored.

Models that decompose a joint probability into terms p(y) and p(x|y) are often called noisy-channel models. Intuitively, when we see a test example x, we assume that it has been generated in two steps:

first, a label y has been chosen with probability p(y) second, the example x has been generated from the distribution p(x|y). The model p(x|y) can be interpreted as a “channel” which takes a label y as its input, and corrupts it to produce x as its output.

Generative Part of Speech Tagging Model

Let us assume a finite set of words V and a finite sequence of tags K. Then the set S will be the set of all sequence, tags pairs <x1, x2, x3 ... xn, y1, y2, y3, ..., yn> such that n > 0 ∀x ∊ V and ∀y ∊ K .

A generative tagging model is then the one where

2.

Given a generative tagging model, the function that we talked about earlier from input to output becomes

Thus for any given input sequence of words, the output is the highest probability tag sequence from the model. Having defined the generative model, we need to figure out three different things:

How exactly do we define the generative model probability p(<x1, x2, x3 ... xn, y1, y2, y3, ..., yn>) How do we estimate the parameters of the model, and How do we efficiently calculate

Let us look at how we can answer these three questions side by side, once for our example problem and then for the actual problem at hand: part of speech tagging.

Defining the Generative Model

Let us first look at how we can estimate the probability p(x1 .. xn, y1 .. yn) using the HMM.

We can have any N-gram HMM which considers events in the previous window of size N.

The formulas provided hereafter are corresponding to a Trigram Hidden Markov Model.

Trigram Hidden Markov Model

A trigram Hidden Markov Model can be defined using

A finite set of states.

A sequence of observations.

q(s|u, v)

Transition probability defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations.

defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations. e(x|s)

Emission probability defined as the probability of making an observation x given that the state was s.

Then, the generative model probability would be estimated as

As for the baby sleeping problem that we are considering, we will have only two possible states: that the baby is either awake or he is asleep. The caretaker can make only two observations over time. Either there is noise coming in from the room or the room is absolutely quiet. The sequence of observations and states can be represented as follows:

Observations and States over time for the baby sleeping problem

Coming on to the part of speech tagging problem, the states would be represented by the actual tags assigned to the words. The words would be our observations. The reason we say that the tags are our states is because in a Hidden Markov Model, the states are always hidden and all we have are the set of observations that are visible to us. Along similar lines, the sequence of states and observations for the part of speech tagging problem would be

Observations and States over time for the POS tagging problem

Estimating the model’s parameters

We will assume that we have access to some training data. The training data consists of a set of examples where each example is a sequence consisting of the observations, every observation being associated with a state. Given this data, how do we estimate the parameters of the model?

Estimating the model’s parameters is done by reading various counts off of the training corpus we have, and then computing maximum likelihood estimates:

Transition probability and Emission probability for a Trigram HMM

We already know that the first term represents transition probability and the second term represents the emission probability. Let us look at what the four different counts mean in the terms above.

c(u, v, s) represents the trigram count of states u, v and s. Meaning it represents the number of times the three states u, v and s occurred together in that order in the training corpus. c(u, v) following along similar lines as that of the trigram count, this is the bigram count of states u and v given the training corpus. c(s → x) is the number of times in the training set that the state s and observation x are paired with each other. And finally, c(s) is the prior probability of an observation being labelled as the state s.

Let us look at a sample training set for the toy problem first and see the calculations for transition and emission probabilities using the same.

The BLUE markings represent the transition probability, and RED is for emission probability calculations.

Note that since the example problem only has two distinct states and two distinct observations, and given that the training set is very small, the calculations shown below for the example problem are using a bigram HMM instead of a trigram HMM.

Peter’s mother was maintaining a record of observations and states. And thus she even provided you with a training corpus to help you get the transition and emission probabilities.

Transition Probability Example:

Training Corpus

Calculations for Awake appearing after Awake

Emission Probability Example:

Training corpus

Calculations for observing ‘Quiet’ when the state is ‘Awake’

That was quite simple, since the training set was very small. Let us look at a sample training set for our actual problem of part of speech tagging. Here we can consider a trigram HMM, and we will show the calculations accordingly.

We will use the following sentences as a corpus of training data (the notation word/TAG means word tagged with a specific part-of-speech tag).

The training set that we have is a tagged corpus of sentences. Every sentence consists of words tagged with their corresponding part of speech tags. eg:- eat/VB means that the word is “eat” and the part of speech tag in this sentence in this very context is “VB” i.e. Verb Phrase. Let us look at a sample calculation for transition probability and emission probability just like we saw for the baby sleeping problem.

Transition Probability

Let’s say we want to calculate the transition probability q(IN | VB, NN). For this, we see how many times we see a trigram (VB,NN,IN) in the training corpus in that specific order. We then divide it by the total number of times we see the bigram (VB,NN) in the corpus.

Emission Probability

Let’s say we want to find out the emission probability e(an | DT). For this, we see how many times the word “an” is tagged as “DT” in the corpus and divide it by the total number of times we see the tag “DT” in the corpus.

So if you look at these calculations, it shows that calculating the model’s parameters is not computationally expensive. That is, we don’t have to do multiple passes over the training data to calculate these parameters. All we need are a bunch of different counts, and a single pass over the training corpus should provide us with that.

Let’s move on and look at the final step that we need to look at given a generative model. That step is efficiently calculating

We will be looking at the famous Viterbi Algorithm for this calculation.

Finding the most probable sequence — Viterbi Algorithm

Finally, we are going to solve the problem of finding the most likely sequence of labels given a set of observations x1 … xn. That is, we are to find out

The probability here is expressed in terms of the transition and emission probabilities that we learned how to calculate in the previous section of the article. Just to remind you, the formula for the probability of a sequence of labels given a sequence of observations over “n” time steps is

Before looking at an optimized algorithm to solve this problem, let us first look at a simple brute force approach to this problem. Basically, we need to find out the most probable label sequence given a set of observations out of a finite set of possible sequences of labels. Let’s look at the total possible number of sequences for a small example for our example problem and also for a part of speech tagging problem.

Say we have the following set of observations for the example problem.

Noise Quiet Noise

We have two possible labels {Asleep and Awake}. Some of the possible sequence of labels for the observations above are:

Awake Awake Awake

Awake Awake Asleep

Awake Asleep Awake

Awake Asleep Asleep

In all we can have ²³ = 8 possible sequences. This might not seem like very many, but if we increase the number of observations over time, the number of sequences would increase exponentially. This is the case when we only had two possible labels. What if we have more? As is the case with part of speech tagging.

For example, consider the sentence

the dog barks

and assuming that the set of possible tags are {D, N, V}, let us look at some of the possible tag sequences:

D D D

D D N

D D V

D N D

D N N

D N V ... etc

Here, we would have ³³ = 27 possible tag sequences. And as you can see, the sentence was extremely short and the number of tags weren’t very many. In practice, we can have sentences that might be much larger than just three words. Then the number of unique labels at our disposal would also be too high to follow this enumeration approach and find the best possible tag sequence this way.

So the exponential growth in the number of sequences implies that for any reasonable length sentence, the brute force approach would not work out as it would take too much time to execute.

Instead of this brute force approach, we will see that we can find the highest probable tag sequence efficiently using a dynamic programming algorithm known as the Viterbi Algorithm.

Let us first define some terms that would be useful in defining the algorithm itself. We already know that the probability of a label sequence given a set of observations can be defined in terms of the transition probability and the emission probability. Mathematically, it is

Let us look at a truncated version of this which is

and let us call this the cost of a sequence of length k.

So the definition of “r” is simply considering the first k terms off of the definition of probability where k ∊ {1..n} and for any label sequence y1…yk.

Next we have the set S(k, u, v) which is basically the set of all label sequences of length k that end with the bigram (u, v) i.e.

Finally, we define the term π(k, u, v) which is basically the sequence with the maximum cost.

The main idea behind the Viterbi Algorithm is that we can calculate the values of the term π(k, u, v) efficiently in a recursive, memoized fashion. In order to define the algorithm recursively, let us look at the base cases for the recursion.

π(0, *, *) = 1

π(0, u, v) = 0

Since we are considering a trigram HMM, we would be considering all of the trigrams as a part of the execution of the Viterbi Algorithm.

Now, we can start the first trigram window from the first three words of the sentence but then the model would miss out on those trigrams where the first word or the first two words occurred independently. For that reason, we consider two special start symbols as * and so our sentence becomes

* * x1 x2 x3 ...... xn

And the first trigram we consider then would be (*, *, x1) and the second one would be (*, x1, x2).

Now that we have all our terms in place, we can finally look at the recursive definition of the algorithm which is basically the heart of the algorithm.",https://cdn-images-1.medium.com/max/1200/1*x-5ZBtUvlD78BOMuMnMAbg.png,[],https://medium.freecodecamp.org/a-deep-dive-into-part-of-speech-tagging-using-viterbi-algorithm-17c8de32e8bc?source=collection_home---6------4----------------,2018-06-08 19:05:31.518000+00:00

Neural Networks,A quick introduction to OAuth using Passport.js – freeCodeCamp,['Arun Kumar'],"A quick introduction to OAuth using Passport.js

What is OAuth?

OAuth (Open Authorization) is an authorization protocol. A third party application can use it to access user data from a site (like Google or Twitter) without revealing their password. Sites like Quora, Medium, AirBnb and many others offer authentication using OAuth.

OAuth really makes our lives simpler by eliminating the need to remember the password of every account you create on almost any site. You just have to remember your OAuth provider’s main account password.

What is Passport.js?

Passport is a middleware which implements authentication on Express-based web applications. It provides over 500+ strategies. What are these strategies? Strategies are used to authenticate requests. Each strategy has its own npm package (such as passport-twitter, passport-google-oauth20). A strategy must be configured before usage.

Why use Passport.js?

Here are six reasons stating why you should use Passport:

It is lightweight

Easily configurable

Supports persistent sessions

Offers OAuth

Provides separate modules for each strategy

Gives you the ability to implement custom strategies

Let’s build something

To get started, we need to install passport from NPM:

npm install passport

We are going to build a simple app which grants the user access to a secret route only if they log in. I’m going to be using the passport-google-oauth20 strategy in this tutorial. Feel free to use any other strategy you prefer, but make sure to check the docs to see how it is configured.

Before continuing, we need a clientID and clientSecret. To get one, head over to https://console.developers.google.com and create a new project. Then go to Enable APIs and Services and enable the Google+ API. Select the API and click on create credentials.

Fill out the form and use the same callback URL on both the form and on your file. Make sure to read the comments on the code to figure out how everything fits together.

app.js

index.ejs

As you can see, we’ve created a /secret route, and only grant access to it if the user is authenticated. To verify whether the user is authenticated, we’ve created a middleware which checks if the request has the user object in it. Finally, to log out we used the req.logout() method provided by passport to clear the session.

Here are some resources to learn more about passport

Complete Passport.js tutorial series

Conclusion

We only saw one strategy here. There are 500+ more. I highly recommend that you skim through Passport’s official documentation and find out what else they offer. Thank you for taking your time to read this. Feel free to connect with me on LinkedIn, Twitter and GitHub. I wish you good luck!

“Do what is great, written on a computer monitor.” by Martin Shreder on Unsplash

Previous article",https://cdn-images-1.medium.com/max/1200/0*gWsdm7w5PSZNR08L,[],https://medium.freecodecamp.org/a-quick-introduction-to-oauth-using-passport-js-65ea5b621a?source=collection_home---6------5----------------,2018-06-07 22:11:44.925000+00:00

Neural Networks,How to control your randomizer in R – freeCodeCamp,['Michelle Jones'],"What happens when you need a particular type of randomization?

Overview of random number generation in R

R has at least 20 random number generator functions. Each uses a specific probability distribution to create the numbers. All require you to specify the number of random numbers you want (the above image shows 200). All are available in base R — no packages required.

Common random number generator distributions are:

normal (rnorm): default mean of 0 and standard deviation of 1

binomial (rbinom): no defaults, specify the number of trials and the probability of success on each trial

uniform (runif): default minimum value of 0 and maximum value of 1

Of the three above, only the binomial random number generator creates integers.

Why create random numbers?

Problems involving random numbers are very common — there are around 50,000 questions relating to random numbers on Stack Exchange.

But why use them?

Random numbers have many practical applications. They are used in Monte Carlo simulations. They are used in cryptography. They have been used to produce CAPTCHA content. They are used in slot machines. They have also been used for more mundane tasks such as creating a random sort order for an array of ordered data.

Problems with random numbers

Common questions include “are my random numbers actually random?” and “how can I generate non-repeated random numbers?”

Note: the latter decreases randomness, because the population of possible random numbers is decreased by one each time a random number is drawn. The method is appropriate in situations such as lotteries or bingo, where each ticket or ball can only be drawn once.

This problem brings in another problem! The randomly generated, sampling without replacement numbers must be integers. No one has ticket 5.6932 or bingo ball 0.18967.

A practical example of random number problems

Let’s take the example that I have 20 female students of the same age. I have four teaching methods that I want to trial. I only want to trial one teaching method for each student. Easy math— I need five students in each group.

But how do I do this so that each student is randomly assigned?

And how do I make sure that I only have integers produced?

And how do I do all this while using randomly generated numbers without replacement? I don’t want, for example, six students in one group, and four students in another.

First, I need to create some dummy data, in R. Let’s create that list of mock female students.

FemaleStudents <- data.frame(Names=c(""Alice"", ""Betty"", ""Carol"", ""Denise"", ""Erica"", ""Frances"", ""Gina"", ""Helen"", ""Iris"", ""Julie"", ""Katherine"",

""Lisa"", ""Michelle"", ""Ngaire"", ""Olivia"", ""Penelope"", ""Rachel"", ""Sarah"", ""Trudy"", ""Uma""))

Now we have a one-dimensional dataset of our 20 students.

We know that the runif() function doesn’t create integers. Why don’t we round the random numbers so that we only get integers and use this function? We can wrap the random number in a rounding function.

Question 1: why am I using the random uniform distribution and not another one, such as the random normal distribution?

There are five types of rounding functions in R. We will use round() .

So that we get the same results, I will set a seed for the random number generation. Each time we generate random numbers, we will use the same seed. I’ve decided on 5 as the seed. If you do not set a seed, or if you set a seed other than 5, your results will be different than mine.

set.seed(5)

FemaleStudents$Group <- round(runif(20, 1, 5))

Well, that seemed to work. We have each student allocated to a group numbered between 1 and 5.

Let’s double check our allocation.

table(FemaleStudents$Group)

1 2 3 4 5

2 6 5 4 3

Darn. Only one of the five groups has the correct number of students (Group 4). Why did this happen?

We can check the numbers actually output by runif() without rounding, and letting the output print to the console. Here, the output prints because I have not assigned the function to an object (for example, to a data.frame variable).

set.seed(5)

runif(20,1,5)

[1] 1.800858 3.740874 4.667503 2.137598 1.418601 3.804230 3.111840 4.231741 4.826001 1.441812 2.093140 2.962053 2.273616 3.236691 2.050373

[16] 1.807501 2.550103 4.551479 3.219690 4.368718

As we can see, the rounding caused our problem. But if we hadn’t rounded, each student would have been assigned to a different group.

What do we do?

sample()

sample() is now one of my favourite functions in R. Let’s see how it works.

Randomly allocate to equally sized groups (counts matter)

How can we use it to randomly assign our 20 students to four equally sized groups?

What happens if we try sample() normally?

set.seed(5)

FemaleStudents$Sample <- sample(1:5, nrow(FemaleStudents), replace=TRUE)

Question 2: what output did you get when you used table(FemaleStudents$Sample) ?

We can fix this problem by creating a vector of group numbers, and then using sampling without replacement from this vector. The rep command is used to create a range of repeated values. You can use it to repeat each number in the series, as I have used here. Number 1 is repeated four times, then number 2 is repeated four times, and so forth. You can also use it to repeat a sequence of numbers, if you use this code instead: rep(1:5,4)

OurGroups <- rep(1:5, each=4)

set.seed(5)

FemaleStudents$Sample <- sample(OurGroups, nrow(FemaleStudents), replace=FALSE)

We used our vector of numbers ( OurGroups ) to allocate our students to groups. We used sampling without replacement ( replace=FALSE ) from OurGroups because we need to use each value in that vector. We need to remove each value as we use it.

And we get the result we wanted!

table(FemaleStudents$Sample)

1 2 3 4 5

4 4 4 4 4

Question 3: why did I still set a seed?

Another advantage of sample() is that it doesn’t care about type. We can repeat the allocation using a vector of strings. This can be useful if you don’t want to keep referring back to what “1” means.

OurNamedGroups <- rep(c(""Up"", ""Down"", ""Charmed"", ""Strange"", ""Top""), each=4)

set.seed(5)

FemaleStudents$Sample2 <- sample(OurNamedGroups, nrow(FemaleStudents), replace=FALSE)

table(FemaleStudents$Sample2)

Charmed Down Strange Top Up

4 4 4 4 4

Because we used the same seed, we can see that the same student allocation was performed, irrespective of whether we used numeric or character data for the assignment.

table(FemaleStudents$Sample,FemaleStudents$Sample2)



Charmed Down Strange Top Up

1 0 0 0 0 4

2 0 4 0 0 0

3 4 0 0 0 0

4 0 0 4 0 0

5 0 0 0 4 0

Randomly allocate when group size is not restricted

Sometimes we want to randomly allocate to groups, but we don’t have a vector of groups. We are still only allocating each unit (person, sheep, block of cheese) to a single group, and we use completely random allocation.

Let’s say that our school has a new, special library room. It’s been constructed to be soundproof to give students a better studying environment. The chief librarian would like to know about the experiences of students in that room. The only problem is that the room is limited in size. The chief librarian thinks that around four students is a large enough group to provide the initial feedback.

Again, we can use sample() to pick our student groups. In this case, we have “students who will test the room” and “students who won’t test the room”. I’m going to call them “Test” and “Not test”. These labels have been chosen for being 1. short and 2. easily distinguished.

Because we did sampling without replacement earlier, we didn’t specify probabilities of assignment to groups — we simply pulled out an assignment from a vector. Now we are going to use sampling with replacement. With replacement refers to the group, not to the students.

We need to sample with replacement as we only have two groups (“Test”, “Not test”) and 20 students. If we tried to sample without replacement, our code would error.

Our code is very similar:

set.seed(5)

FemaleStudents$Library <- sample(c(""Test"", ""Not test""), nrow(FemaleStudents), replace=TRUE, prob=c(4/20,16/20))

table(FemaleStudents$Library)

Not test Test

15 5

As you can see, we allocated five students to test the room, not four. This type of result is expected when dealing with small samples. However, our allocation of students is completely random. Each student had exactly the same probability of being assigned to test the room. Whether previous students were testers or not had no impact on the allocation of the next student.

Let’s walk through some of that code.

I’ve constructed a new variable in the data.frame to collect the allocation ( Library ).

Instead of dealing with numbers for group names, I’ve used the strings I mentioned earlier. Because I’ve used strings, the c() must wrap the group names ( “Test”, “Not test” ) and each group name is separated by a comma.

Replacement has been set to TRUE .

The probability of assignment to either group must be provided. This is the prob=c(4/20,16/20) part of the sample() function. Again, note how c() is used to contain the probabilities. Also of interest is that the probabilities can be expressed as fractions, rather than decimals.

Hooray for sample()

I use sample() all the time for the work I am doing. The ability to use strings, as well as to restrict numeric output to integers (and define the desired integer range), provides me with more control than trying to use one of the random number functions.

Answers

Answer 1: I used a random uniform distribution because I wanted each value to be equally probable.

Answer 2: I got this output:

1 2 3 4 5

2 7 4 2 5

Answer 3: If we don’t set a seed value, or we use a different one, the allocation of specific students will be different. For example, when the seed is 5, Alice is allocated to group 2. If the seed is 7, Alice is allocated to group 5. Replication is important when code needs to be re-run (for example, in testing).",https://cdn-images-1.medium.com/max/1200/1*aI6mpoboOmJMKqvEU593xA.png,[],https://medium.freecodecamp.org/how-to-control-your-randomizer-in-r-852ae7d8f80c?source=collection_home---6------6----------------,2018-06-07 20:10:57.677000+00:00

Neural Networks,How to style your webpage or markdown like a Medium article — or however you want,[],"View the respective pages at: https://github.com/ryandav/link-formatter/ and https://ryandav.github.io/link-formatter/

Get started with Sass at https://sass-lang.com/guide",https://cdn-images-1.medium.com/max/1200/1*L8PQs8ubyxZVIr1EC-cZ6Q.png,[],https://medium.freecodecamp.org/style-webpage-or-markdown-like-medium-article-using-html-css-sass-bootstrap-c6f9e64c0955?source=collection_home---6------7----------------,2018-06-07 19:32:27.295000+00:00

Neural Networks,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------,2018-06-07 17:57:40.375000+00:00

Neural Networks,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------#--responses,2018-06-07 17:57:40.375000+00:00

Neural Networks,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------,2018-06-07 15:39:54.084000+00:00

Neural Networks,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------#--responses,2018-06-07 15:39:54.084000+00:00

Neural Networks,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------,2018-06-06 21:43:33.288000+00:00

Neural Networks,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------#--responses,2018-06-06 21:43:33.288000+00:00

Neural Networks,Follow these steps to solve any Dynamic Programming interview problem,['Nikola Otasevic'],"Follow these steps to solve any Dynamic Programming interview problem

Despite having significant experience building software products, many engineers feel jittery at the thought of going through a coding interview that focuses on algorithms. I’ve interviewed hundreds of engineers at Refdash, Google, and at startups I’ve been a part of, and some of the most common questions that make engineers uneasy are the ones that involve Dynamic Programming (DP).

Many tech companies like to ask DP questions in their interviews. While we can debate whether they’re effective in evaluating someone’s ability to perform in an engineering role, DP continues to be an area that trips engineers up on their way to finding a job that they love.

Dynamic Programming — Predictable and Preparable

One of the reasons why I personally believe that DP questions might not be the best way to test engineering ability is that they’re predictable and easy to pattern match. They allow us to filter much more for preparedness as opposed to engineering ability.

These questions typically seem pretty complex on the outside, and might give you an impression that a person who solves them is very good at algorithms. Similarly, people who may not be able to get over some mind-twisting concepts of DP might seem pretty weak in their knowledge of algorithms.

The reality is different, and the biggest factor in their performance is preparedness. So let’s make sure everyone is prepared for it. Once and for all.

7 Steps to solve a Dynamic Programming problem

In the rest of this post, I will go over a recipe that you can follow to figure out if a problem is a “DP problem”, as well as to figure out a solution to such a problem. Specifically, I will go through the following steps:

How to recognize a DP problem Identify problem variables Clearly express the recurrence relation Identify the base cases Decide if you want to implement it iteratively or recursively Add memoization Determine time complexity

Sample DP Problem

For the purpose of having an example for abstractions that I am going to make, let me introduce a sample problem. In each of the sections, I will refer to the problem, but you could also read the sections independently of the problem.

Problem statement:

In this problem, we’re on a crazy jumping ball, trying to stop, while avoiding spikes along the way.

Here are the rules:

1) You’re given a flat runway with a bunch of spikes in it. The runway is represented by a boolean array which indicates if a particular (discrete) spot is clear of spikes. It is True for clear and False for not clear.

Example array representation:

2) You’re given a starting speed S. S is a non-negative integer at any given point, and it indicates how much you will move forward with the next jump.

3) Every time you land on a spot, you can adjust your speed by up to 1 unit before the next jump.

4) You want to safely stop anywhere along the runway (does not need to be at the end of the array). You stop when your speed becomes 0. However, if you land on a spike at any point, your crazy bouncing ball bursts and it’s game over.

The output of your function should be a boolean indicating whether we can safely stop anywhere along the runway.

Step 1: How to recognize a Dynamic Programming problem

First, let’s make it clear that DP is essentially just an optimization technique. DP is a method for solving problems by breaking them down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions. The next time the same subproblem occurs, instead of recomputing its solution, you simply look up the previously computed solution. This saves computation time at the expense of a (hopefully) modest expenditure in storage space.

Recognizing that a problem can be solved using DP is the first and often the most difficult step in solving it. What you want to ask yourself is whether your problem solution can be expressed as a function of solutions to similar smaller problems.

In the case of our example problem, given a point on the runway, a speed, and the runway ahead, we could determine the spots where we could potentially jump next. Furthermore, it seems that whether we can stop from the current point with the current speed depends only on whether we could stop from the point we choose to go to next.

That is a great thing, because by moving forward, we shorten the runway ahead and make our problem smaller. We should be able to repeat this process all the way until we get to a point where it is obvious whether we can stop.

Recognizing a Dynamic Programming problem is often the most difficult step in solving it. Can the problem solution be expressed as a function of solutions to similar smaller problems?

Step 2: Identify problem variables

Now we have established that there is some recursive structure between our subproblems. Next, we need to express the problem in terms of the function parameters and see which of those parameters are changing.

Typically in interviews, you will have one or two changing parameters, but technically this could be any number. A classic example of a one-changing-parameter problem is “determine an n-th Fibonacci number”. Such an example for a two-changing-parameters problem is “Compute edit distance between strings”. If you’re not familiar with these problems, don’t worry about it.

A way to determine the number of changing parameters is to list examples of several subproblems and compare the parameters. Counting the number of changing parameters is valuable to determine the number of subproblems we have to solve. It’s also important in its own right in helping us strengthen the understanding of the recurrence relation from step 1.

In our example, the two parameters that could change for every subproblem are:

Array position (P) Speed (S)

One could say that the runway ahead is changing as well, but that would be redundant considering that the entire non-changing runway and the position (P) carry that information already.

Now, with these 2 changing parameters and other static parameters, we have the complete description of our sub-problems.

Identify the changing parameters and determine the number of subproblems.

Step 3: Clearly express the recurrence relation

This is an important step that many rush through in order to get into coding. Expressing the recurrence relation as clearly as possible will strengthen your problem understanding and make everything else significantly easier.

Once you figure out that the recurrence relation exists and you specify the problems in terms of parameters, this should come as a natural step. How do problems relate to each other? In other words, let’s assume that you have computed the subproblems. How would you compute the main problem?

Here is how we think about it in our sample problem:

Because you can adjust your speed by up to 1 before jumping to the next position, there are only 3 possible speeds, and therefore 3 spots in which we could be next.

More formally, if our speed is S, position P, we could go from (S, P) to:

(S, P + S); # if we do not change the speed (S — 1, P + S — 1); # if we change the speed by -1 (S + 1, P + S + 1); # if we change the speed by +1

If we can find a way to stop in any of the subproblems above, then we can also stop from (S, P). This is because we can transition from (S, P) to any of the above three options.

This is typically a fine level of understanding of the problem (plain English explanation), but you sometimes might want to express the relation mathematically as well. Let’s call a function that we’re trying to compute canStop. Then:

canStop(S, P) = canStop(S, P + S) || canStop(S — 1, P + S — 1) || canStop(S + 1, P + S + 1)

Woohoo, it seems like we have our recurrence relation!

Recurrence relation: Assuming you have computed the subproblems, how would you compute the main problem?

Step 4: Identify the base cases

A base case is a subproblem that doesn’t depend on any other subproblem. In order to find such subproblems, you typically want to try a few examples, see how your problem simplifies into smaller subproblems, and identify at what point it cannot be simplified further.

The reason a problem cannot be simplified further is that one of the parameters would become a value that is not possible given the constraints of the problem.

In our example problem, we have two changing parameters, S and P. Let’s think about what possible values of S and P might not be legal:

P should be within the bounds of the given runway P cannot be such that runway[P] is false because that would mean that we’re standing on a spike S cannot be negative, and a S==0 indicates that we’re done

Sometimes it can be a little challenging to convert assertions that we make about parameters into programmable base cases. This is because, in addition to listing the assertions if you want to make your code look concise and not check for unnecessary conditions, you also need to think about which of these conditions are even possible.

In our example:

P < 0 || P >= length of runway seems like the right thing to do. An alternative could be to consider making P == end of runway a base case. However, it is possible that a problem splits into a subproblem which goes beyond the end of the runway, so we really need to check for inequality. This seems pretty obvious. We can simply check if runway[P] is false. Similar to #1, we could simply check for S < 0 and S == 0. However, here we can reason that it is impossible for S to be < 0 because S decreases by at most 1, so it would have to go through S == 0 case beforehand. Therefore S == 0 is a sufficient base case for the S parameter.

Step 5: Decide if you want to implement it iteratively or recursively

The way we talked about the steps so far might lead you to think that we should implement the problem recursively. However, everything that we’ve talked about so far is completely agnostic to whether you decide to implement the problem recursively or iteratively. In both approaches, you would have to determine the recurrence relation and the base cases.

To decide whether to go iteratively or recursively, you want to carefully think about the trade-offs.

Stack overflow issues are typically a deal breaker and a reason why you would not want to have recursion in a (backend) production system. However, for the purposes of the interview, as long as you mention the trade-offs, you should typically be fine with either of the implementations. You should feel comfortable implementing both.

In our particular problem, I implemented both versions. Here is python code for that:

A recursive solution: (original code snippets can be found here)

An iterative solution: (original code snippets can be found here)

Step 6: Add memoization

Memoization is a technique that is closely associated with DP. It is used for storing the results of expensive function calls and returning the cached result when the same inputs occur again.

Why are we adding memoization to our recursion? We encounter the same subproblems which, without memoization, are computed repeatedly. Those repetitions very often lead to exponential time complexities.

In recursive solutions, adding memoization should feel straightforward. Let’s see why. Remember that memoization is just a cache of the function results. There are times when you want to deviate from this definition in order to squeeze out some minor optimizations, but treating memoization as a function result cache is the most intuitive way to implement it.

This means that you should:

Store your function result into your memory before every return statement Look up the memory for the function result before you start doing any other computation

Here is the code from above with added memoization (added lines are highlighted): (original code snippets can be found here)

In order to illustrate the effectiveness of memoization and different approaches, let’s do some quick tests. I will stress test all three methods that we have seen so far. Here is the set up:

I created a runway of length 1000 with spikes in random places (I chose to have a probability of a spike being in any given spot to be 20%) initSpeed = 30 I ran all functions 10 times and measured the average time of execution

Here are the results (in seconds):

You can see that the pure recursive approach takes about 500x more time than the iterative approach and about 1300x more time than the recursive approach with memoization. Note that this discrepancy would grow rapidly with the length of the runway. I encourage you to try running it yourself.

Step 7: Determine Time complexity

There are some simple rules that can make computing time complexity of a dynamic programming problem much easier. Here are two steps that you need to do:

Count the number of states — this will depend on the number of changing parameters in your problem Think about the work done per each state. In other words, if everything else but one state has been computed, how much work do you have to do to compute that last state?

In our example problem, the number of states is |P| * |S|, where

P is the set of all positions (|P| indicates the number of elements in P)

S is the set of all speeds

The work done per each state is O(1) in this problem because, given all other states, we simply have to look at 3 subproblems to determine the resulting state.

As we noted in the code before, |S| is limited by length of the runway (|P|), so we could say that the number of states is |P|² and because work done per each state is O(1), then the total time complexity is O(|P|²).

However, it seems that |S| can be further limited, because if it were really |P|, it is very clear that stopping would not be possible because you would have to jump the length of the entire runway on the first move.

So let’s see how we can put a tighter bound on |S|. Let’s call maximum speed S. Assume that we’re starting from position 0. How quickly could we stop if we were trying to stop as soon as possible and if we ignore potential spikes?

In the first iteration, we would have to come at least to the point (S-1), by adjusting our speed at zero by -1. From there we would at a minimum go by (S-2) steps forward, and so on.

For a runway of length L, the following has to hold:

=> (S-1) + (S-2) + (S-3) + ….+ 1 < L

=> S*(S-1) / 2 < L

=> S < sqrt(2L + 1)

That is the maximum speed that we could possibly have on a runway of a length L. If we had a speed higher than that, we could not stop even theoretically, irrespective of the position of the spikes.

That means that the total time complexity depends only on the length of the runway L in the following form:

O(L * sqrt(L)) which is better than O(L²)

O(L * sqrt(L)) is the upper bound on the time complexity

Awesome, you made it through! :)

The 7 steps that we went through should give you a framework for systematically solving any dynamic programming problem. I highly recommend practicing this approach on a few more problems to perfect your approach.

Here are some next steps that you can take

Extend the sample problem by trying to find a path to a stopping point. We solved a problem that tells you whether you can stop, but what if you wanted to also know the steps to take in order to stop eventually along the runway? How would you modify the existing implementation to do that? If you want to solidify your understanding of memoization, and understand that it is just a function result cache, you should read about decorators in Python or similar concepts in other languages. Think about how they would allow you to implement memoization in general for any function that you want to memoize. Work on more DP problems by following the steps we went through. You can always find a bunch of them online (ex. LeetCode or GeeksForGeeks). As you practice, keep in mind one thing: learn ideas, don’t learn problems. The number of ideas is significantly smaller and it’s an easier space to conquer which will also serve you much better.

When you feel like you’ve conquered these ideas, check out Refdash where you are interviewed by a senior engineer and get a detailed feedback on your coding, algorithms, and system design.",https://cdn-images-1.medium.com/max/1200/0*DpsbrfUM89M_LHKY.jpg,[],https://medium.freecodecamp.org/follow-these-steps-to-solve-any-dynamic-programming-interview-problem-cc98e508cd0e?source=collection_home---6------11----------------,2018-06-06 19:32:36.335000+00:00

Neural Networks,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------,2018-06-06 17:23:02.015000+00:00

Neural Networks,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------#--responses,2018-06-06 17:23:02.015000+00:00

Neural Networks,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------,2018-06-06 16:42:46.938000+00:00

Neural Networks,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------#--responses,2018-06-06 16:42:46.938000+00:00

Neural Networks,How to process textual data using TF-IDF in Python – freeCodeCamp,[],"How to process textual data using TF-IDF in Python

Computers are good with numbers, but not that much with textual data. One of the most widely used techniques to process textual data is TF-IDF. In this article, we will learn how it works and what are its features.

From our intuition, we think that the words which appear more often should have a greater weight in textual data analysis, but that’s not always the case. Words such as “the”, “will”, and “you” — called stopwords — appear the most in a corpus of text, but are of very little significance. Instead, the words which are rare are the ones that actually help in distinguishing between the data, and carry more weight.

An introduction to TF-IDF

TF-IDF stands for “Term Frequenct — Inverse Data Frequency”. First, we will learn what this term means mathematically.

Term Frequency (tf): gives us the frequency of the word in each document in the corpus. It is the ratio of number of times the word appears in a document compared to the total number of words in that document. It increases as the number of occurrences of that word within the document increases. Each document has its own tf.

Inverse Data Frequency (idf): used to calculate the weight of rare words across all documents in the corpus. The words that occur rarely in the corpus have a high IDF score. It is given by the equation below.

Combining these two we come up with the TF-IDF score (w) for a word in a document in the corpus. It is the product of tf and idf:

Let’s take an example to get a clearer understanding.

Sentence 1 : The car is driven on the road.

Sentence 2: The truck is driven on the highway.

In this example, each sentence is a separate document.

We will now calculate the TF-IDF for the above two documents, which represent our corpus.

From the above table, we can see that TF-IDF of common words was zero, which shows they are not significant. On the other hand, the TF-IDF of “car” , “truck”, “road”, and “highway” are non-zero. These words have more significance.

Using Python to calculate TF-IDF

Lets now code TF-IDF in Python from scratch. After that, we will see how we can use sklearn to automate the process.",https://cdn-images-1.medium.com/max/1200/1*JTk6iVMiZCQCr8duiaKlHQ.png,[],https://medium.freecodecamp.org/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3?source=collection_home---6------15----------------,2018-06-06 16:07:18.115000+00:00

Neural Networks,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------,2018-06-06 01:10:32.658000+00:00

Neural Networks,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------,2018-06-06 00:59:12.072000+00:00

Neural Networks,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------#--responses,2018-06-06 00:59:12.072000+00:00

Neural Networks,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------#--responses,2018-06-06 00:20:56.870000+00:00

Neural Networks,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------,2018-06-05 20:08:25.488000+00:00

Neural Networks,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------#--responses,2018-06-05 20:08:25.488000+00:00

Neural Networks,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------#--responses,2018-06-05 16:44:13.144000+00:00

Neural Networks,A deeply detailed but never definitive guide to mobile development architecture,['Jose Berardo Cunha'],"A deeply detailed but never definitive guide to mobile development architecture

Native, Web, PWA, hybrid, Cross-Compiled… what is “the best” way to develop for Android and iOS platforms? What looks reasonable? And how are you supposed to choose among the options? In this article, I’ll lay it all out so you can make an informed decision.

First things first, let me provide you with a bit of context. I am an IT senior consultant, and the idea of putting together this guide was born from discussions with one of our clients about what could be the best approach for them. Yes, just for them. And we realized that we did not have a well-defined strategy, a solid and reliable foundation, to help us come up with the right answer.

And you know what? I could not find such a guide easily anywhere on the Internet, either. Although there are several articles about this topic, none of those I came across were reasonably complete. Unfortunately the majority overlook a lot of concepts or, even worse, are essentially wrong.

Now, I’d like to take a wider look. And while I’m potentially helping someone make their own decisions, I’m also asking around the community for more thoughts on the subject.

This guide has two parts:

Mobile Development Architectural Tiers (this) How to make your decision

It's also available on YouTube as a series of 10 videos and as a free course on Udemy. There, you’ll find the same written material as here, the same videos from the YouTube series, as well as quizzes to fix all the topics and a final certification.

So let’s get started.

Introduction

When it comes to mobile platforms, it's arguable that there are just two big players: Android and iOS. Other technologies like Tizen, Blackberry, or Windows Phone are either dead or have been around for a while and have no prospects of reaching any significative market share.

A quick look at this massive duopoly might make you think that developers do not have many options when creating mobile apps. This idea can't be further from the truth, though. You can quickly spot a fistful of programming languages being used out there: C/C++, Java, Kotlin, Objective-C, Swift, JavaScript, TypeScript, C#, Dart, Ruby, and I'm pretty sure I’ve missed a few more.

The same is true of mobile development frameworks. Unless you are not a developer, or have somehow been unaware of new technologies for the last 10 years, you’ve probably heard about Cordova/PhoneGap, React Native, Xamarin, Ionic, Nativescript, or Flutter, just to name a few cross-platform solutions for mobile apps.

So let’s look at all these pieces of the architecture and break things down a bit.

TL;DR

There's no clear winner. All approaches have pros and cons, and might be either the best fit or the worst fit for your next project. In this guide, I'm classifying many different solutions into various tiers according to the distance their architectures are from the native platform.

Native Apps

To start, let's go straight to the metal. Our first architectural tier is Native Apps.

Native Apps Tier — Where you develop for each specific platform (it might be even more specific when considering NDK)

This is the tier where you must be aware of the idiosyncrasies of each platform. It’s not my intention to dig into them, I just want to mention a few things in a bit of context.

You can watch this first part on Youtube.

iOS

Starting on the iOS side, just because it's simpler, there's only Apple ruling the world. Originally, developers needed to learn Objective-C, a proprietary object-oriented variation of C with some inspiration from SmallTalk (and an insanely long-named API).

In 2014, Apple announced Swift, a multi-paradigm language, which was a lot easier than its predecessor. It's still possible to deal with Objective-C legacy code, but Swift has reached high maturity levels. So, if you're planning to learn how to natively develop for iOS, Swift is definitely where you should start.

Android

On the Android side, there are a number of different manufacturers. The vast majority of them rely upon ARM processors. But generally speaking, Android apps lay on virtual machine instances (instances of ART) to help deal with potential underlying specificities (not without many amazing tricks).

That's why, originally, the language of choice was Java. It’s not only been the most popular language in the World for almost two decades (with a few position swaps with C), but it’s also notable for its Java Virtual Machine (JVM). This empowered developers to compile their code down to an intermediate bytecode that could be read and run by the JVM.

With the Android Native Development Kit (NDK), it's also possible to develop critical parts of the app directly in native code, writing in C/C++. In this case, you have to be aware of underlying platform quirks.

Kotlin is a language unveiled by JetBrains in 2011. When it first came out, despite its flexibility and conciseness, it wasn't more than yet another JVM language with more successful competitors like Scala, Clojure, or Groovy. However, after its first major release in 2016, it rapidly started to stand out from the crowd, especially after Google announced that it would be officially supported on the Android platform at Google I/O 2017.

Kotlin is becoming Google's first class language (currently Kotlin and Java — in this order — are used throughout Android's official documentation). A total Java replacement is expected even more so now that the US Federal Appeals Court has ruled on the endless lawsuit filed by Oracle accusing Google of violating Java copyrights.

Native components

Developing in this tier, you can also leverage all native APIs and, in particular, the native components. This saves your app from having to reinvent the wheel.

I've published a video demo of how to create a simple project on Xcode (iOS) and Android Studio. If you want to check it out:

Demo of iOS and Android basic projects.

Native Apps advantages

Best performance and top user engagement

Bleeding edge native features

Notably good IDEs Android Studio / Xcode

Modern high-level languages Kotlin / Swift

Very low-level approach with NDK

Native Apps disadvantages

Two codebases to maintain

Require installation (except Android Instant Apps)

Hard to analyze SEO

Very expensive to get users to download the app

Web Apps

On the other side of the spectrum, we have Web Apps. Web Apps are essentially apps run by the browser. You don't write code targeting the platform, but rather any browser running on top of it.

Web Apps Tier — clearly on top of a browser bar targeting a beast sitting in between Android and iOS.

In this tier you’ll find an insane number of contenders jumping at each other's throats. But they all use an arsenal consisting of the same weapons: HTML, CSS, and Javascript.

Web frameworks and libraries, even when leveraging CSS pre-compilers like LESS or SASS, even Javascript pre-compiled languages like TypeScript, CoffeeScript or Flow, even symbiosis like JSX or Elm, leaving alone tools like Babel used to transpile everything to Javascript with different configurable levels of conformance with ECMAScript yearly specifications (ES6 / ES7 / ES8, or if you prefer ES2015 / ES2016 / ES2017 / ES2018).

At the end of the day, they all are HTML, CSS, and JavaScript rendered and run by the browser. There's no direct access to native APIs like camera, vibration, battery status, or file system, but some of them can be achieved via Web API's:

The big issue with Web APIs is their maturity level. Many of them are not supported by some browsers. There are differences in implementations, especially across mobile browsers.

Web App advantages

Shared code between platforms and desktop browsers

Do not require previous installations, just navigate and use

Tons of frameworks and libraries to go with them

Best for SEO

Web App disadvantages

Lower performance

Hard to get a native user experience

Require an internet connection

Not available on official app stores

API not as mature and reliable as native API

Frameworks and Web components

Angular, React, and Vue are probably the most popular web frameworks as of 2018. To be precise, however, React is considered just a library due to its flexible and less opinionated nature. Angular, on the other hand, is a strongly opinionated framework. Vue lives at some point in between them.

Angular vs React vs Vue

Angular, originally called AngularJS, was presented to the world in 2010 by Google. It quickly started to shine, due to its inversion of paradigms in comparison with other libraries from that time (like jQuery, the most popular back then). Instead of directly talking to HTML elements to manipulate the UI state, with AngularJS, templates were magically updated whenever the JavaScript model was updated.

As AngularJS became more and more popular, it also grew in purpose. It turned into a complete and opinionated framework that was one of the first that took SPAs (Single Page Apps) seriously. This growth (in both aspects) was responsible for some API bloats and performance issues.

React was created by Facebook to solve their own needs on the presentation layer. It introduced many aspects that suddenly became very popular, like virtual DOM, one-way data flow (originally named Flux, especially popular through an implementation library called Redux), and a mixture of HTML and JavaScript called JSX.

Only in 2016, after long debates and unexpected big changes, Google launched version two of its popular web framework. They called it Angular, instead of AngularJS. But, as many people already called the first version “Angular” (without the ""JS"" suffix), people started calling the new version Angular 2. That turned into a naming problem, as Google also announced that it would release new major versions every 6 months.

In my opinion, that was a mammoth mistake. I've seen this before (with Struts vs Struts 2/WebWork, for example). They have a massively popular product that appears to have reached its plateau, and it has started to be more criticized than praised. If Google decides to rebuild it from the ground up, they should never, by any means, just change its major version. How will people trust that they will not repeat it every new major version release? Version two is supposed to present breaking changes, but it doesn't mean it can be totally revamped.

Angular is a spectacular web framework, and I really feel passionate about it. However, it's a completely new beast. It does not have much to do with AngularJS. Even Vue, which is another amazing framework (probably one of the most pleasant to work with, by the way) looks more similar to AngularJS from a bird's-eye view. I believe this caused a significant movement away from Angular and contributed substantially to React's popularity.

Vue is the only one of the three most popular web frameworks that is not backed by a big company. It was actually started by a former Google developer. Due to its formidable simplicity and tiny footprint, it got attention from a massive and enthusiastic community.

Although there are more complete solutions, they all work on top of the concept of web components. There's an open specification about them currently in progress in W3C, and some interesting implementations like Polymer, Stencil and X-Tag.

In the third video of the series, I don't spend too much time discussing frameworks but discuss web component libraries:

The Web Apps tier is discussed in Part 3 of the series

Mobile Apps vs Web Apps

I’m not sure if you’ve noticed, but the order of tiers I'm presenting here follows what I think is the easiest path to learn all approaches. I started from the Native Tier, the most genuinely mobile development. Then I decided to fly directly to the other extreme to present the Web Tier, which is the tier that has been available since the first smartphones.

Only now, after elaborating on a comparison between the two edges of my diagram, will I start talking about many of the cross-platform approaches to build mobile apps.

There's a long debate between Mobile Apps vs Web Apps. Everything I say about Mobile Apps is not exclusive to the Native Tier. It is also applicable to all cross-platform tiers I present later on.

The user behavior dilemma

Users spend more time on Mobile Apps (87%) than on Mobile Websites (13%)

According to a Comscore survey in 2017, a user's fidelity to a mobile app is way more relevant than it is to mobile websites. According to an aligned article on Forbes, this is usually because of convenience (for example, home screen buttons, widgets, top notifications), speed (for example, smoother interfaces, almost instant start ups), and stored settings (for example, offline content).

Mobile Websites reach more people (8.9M monthly unique visitors against 3.3M of Mobile Apps)

On the other hand, in the same Comscore data, we learn that customers can be reached more easily from mobile websites, as they are not as much tied to their few apps of preference. If you compare the most popular websites versus the most downloaded apps, it's estimated that an average of 8.9 million unique web visitors per month access the top 1000 websites. That's almost three times more than the average unique users of the top 1000 most downloaded apps.

Distribution (Web App) x Engagement (Mobile App)

That's all about distribution vs engagement. Your web app has a higher chance of being accessed, as users are more likely to try new things when navigating through their mobile browsers. But Mobile Apps have been proven to be more engaging, and catch the users attention for much longer periods.

Now that you understand the dilemma, let's have a look at Progressive Web Apps. This is an approach so tied to the Web Apps tier that I classify it as just an addendum to Web Apps. But it's a big disruptor and a serious candidate for the most prominent new and cool thing in web and mobile development.

Progressive Web Apps

Progressive Web Apps (PWAs) are a set of tools used to give Web App users the same experience they are accustomed to when they run Mobile Apps. This means that Web Apps can leverage the potentially higher levels of distribution with more decent levels of engagement.

Progressive Web Apps addendum to Web Apps tier

Google defined three main qualifications for PWAs: they must be Reliable, Fast, and Engaging.

Features called Service Workers and the App Shell are the foundation of Progressive Web Apps. They were created to promote apps’ reliability as they are now designed to work regardless of the device’s connection status. That includes offline mode, as well as poor connections. They also provide significant perceived performance boost, as apps launch using locally cached data, which eliminates delays for synchronous content downloads.

You could consider reliability an indirect vector of engagement. Users are not affected while commuting by train, for example. They can stay engaged.

The same applies to speed. According to Google:

53% of users will abandon a site if it takes longer than 3 seconds to load!

However, being exclusively reliable and fast on load doesn't necessarily guarantee high engagement. PWAs leverage mobile-related features that used to be exclusive to mobile apps, like an “Add to Home Screen” option and Push Notifications.

When it comes to to the “Add to Home Screen” feature, you might notice that Apple has had a similar feature since the very first iPhone. Some people even argue that Progressive Web Apps are Google's fancy new name for an original Apple idea.

And you really can’t completely disagree. Some ideas are actually cycling. They come, go away, and then come back with a new name and some enhancements (for instance, Service Workers), so they can finally stick around.

On the other hand, it’s hard to completely agree. Steve Jobs’ speech about Web 2.0 + AJAX and the memorable announcement of the iPhone back in WWDC 2007 are not convincing enough to call him as the father, or even the prophet, of PWAs.

To be fair, the Add to Home Screen capability on iPhone has been nothing more than a subtle, almost hidden, feature to generate desktop icons that just start up Web Apps in fullscreen mode. It has all the burden of HTTP request-response cycles and no clear path around caches.

PWAs start from the right point. They explore how previous installations of Web Apps aren’t necessary without losing the client-side bootstrap of Mobile Apps. This means that everything a user needs for their first interaction following startup might be locally cached (read: App Shell) and kept available as soon as they hit “Add to Home Screen.”

Moving onto another well-known characteristic of PWAs, let’s talk about the super engaging (or re-engaging) feature of the Mobile Apps world: Push Notifications. They are alert-style messages that appear on the top notification bar / area, as well as on lock screens. They have the power of pulling users back to your app once they receive the notification.

To reinforce the appeal of PWAs, Google has been pulling all modern Web APIs under the PWA umbrella. So expect to see things like Payment Requests, Credential Management, WebVR, Sensors, WebAssembly, and WebRTC in the context of Progressive Web Apps. But these feature are not necessarily tied to PWAs, and some were even born before the term PWA was coined.

PWA and Apple

Apple, on the other hand, announced their first solid milestones towards PWAs only in March 2018. Although there are still some limitations, the progress is appreciable. Some of the limitations might be related to the fact that Safari has fallen behind its competitors. Others could be attributed to Apple's philosophy of tight control.

Still, Apple has a more profitable App Store than Google. Apple's asserts that more criteria on app publications brings more overall reliability, and PWAs are bound to hurt the App Store's revenue. This suggests that some limitations that seem to be intentionally imposed (like 50Mb of PWA maximum cache size) will cost more to be revoked.

Unfortunately PWAs are not perfect

Web solutions and, on different levels, all cross-platform solutions struggle to attain the excellence and comprehensiveness of Native Apps. Every new feature, and every detail particular to Android or iOS makes that native feel harder and harder to access as you distance your app from the native tier.

Overall, PWAs fix some issues in the Web Apps tier. But there are other issues that can’t be fixed by a solution working on top of a browser.

What PWAs fix

More “native” experience

Faster load times

Do not require an internet connection

Force web developers to be aware of situations where there’s no connection as well as a bad connection

Incorporate features from Mobile Apps like Push Notifications, Geolocation, or Speech Recognition

What they don’t

Inherent slowness

Not available on app stores (just yet)

Still not fully supported by all browsers

Still lack mobile features like NFC, Ambient Light, Geofencing

Also lack support for peculiarities of Android or iOS like PiP, smart app banners, launch screen widgets, and 3D touch

In the video below, I do a brief overview of PWAs.

Progressive Web Apps are introduced in the Part 4 of the series

Hybrid Apps

At this level, we begin to dive into the Mobile App world. We’ll start from the most distant tier: Hybrid Apps.

The term Hybrid is also commonly applied to all cross-platform solutions. Here, however, I’m restricting it to Apps that work inside mobile components, called WebViews.

The Hybrid Apps tier. Below the browser's line but on top of WebViews

In the demos in the second video, my purpose for adding WebView as the Hello World example was to make clear that there's a native component for each platform that is able to perform like an actual browser.

Cordova/PhoneGap

Solutions like Cordova/PhoneGap close the gap (sorry for the uninspired pun) between Web and Mobile Apps. They provide tools to package developer's HTML, JavaScript, and CSS code (as well as any extra assets like images or videos) and transform them into Mobile Apps (yes, real Android or iOS apps). These apps have their WebView exclusively to interpret and run the original web code, starting with the “index.html” file in the app’s main folder (normally called “www”). They also bridge the JavaScript code to native APIs through plugins which are partially implemented in JavaScript and partially in a native language.

So, let's make things clearer. Hybrid Apps are able to access native APIs (instead of Web APIs), but they are enclosed by the WebView. A button with Cordova must be an HTML button rendered by a WebView instead of a mobile native button.

This is the magical tier that allows companies to port their Web Apps to Mobile Apps to be shipped by app stores. So any web framework is allowed here.

Ionic

Frameworks like Ionic wrap Cordova into their own solutions. With Ionic, you don't need to use Cordova’s command line interface (CLI), because all of its commands are wrapped by the Ionic CLI.

Recently, the Ionic team decided to take the reins of the entire stack of Hybrid Apps. So they launched a proposed replacement for Cordova called Capacitor. Capacitor has support for Cordova plugins, and can also be used by a non-Ionic project.

You can watch me going through a Cordova Hello World sample in the fifth video of the series:

Hybrid Apps are in Part 5 of the series.

Hybrid Apps advantages

They are essentially web apps that are shippable to official app stores

Can be used along with any JavaScript framework / library

The code is still highly shareable across platforms

Access to native features (for instance, camera, accelerometer, contact list)

Hybrid Apps disadvantages

Struggle with performance issues and memory consumption, as web views are responsible for rendering everything on screen

Have to mimic all native UI components on top of a single web view

Harder to be accepted and published on App Store

Usually take longer to have native features available for these environments

Web Native

Web Native is a relatively new and often misunderstood tier. That's where Web Apps meet native components. Although Appcelerator (Axway) Titanium has been around a long time, there are some relatively new competitors that justify making this a completely separate category of mobile apps.

Web Native Apps don't need WebView as they talk directly to other native components

As you can see above, there's no web view to render and run your application. So, how is your JavaScript executed? Is it compiled? Well, if you consider transpilation (compilation from one language to another — for example TypeScript to JavaScript), bundling, minification, mangling, and obfuscation all together as a compilation, yes JavaScript is compiled.

But the problem is, this doesn't make your JavaScript something directly understood by Android or iOS operational systems. And, in theory, there's no native component that only serves as a JavaScript engine without the bloat of the HTML layout engine.

The strategy is to ship JavaScript engines (normally V8 for Android and JavaScriptCore for iOS) along with your code. Although they have small footprints and are very fast, they are something external that must be provided by your app.

On the other hand, this approach tends to have better UI performance, as all the components are the same (or are based on the same thing for React Native, for example) as the ones used by Native Apps.

Web Native Apps advantages

Reach both platforms with one single codebase

Roughly the same performance as native apps, as they also deal with native UI components

Tweaks are necessary, but the code is still shareable with web development

Web Native Apps disadvantages

Even with one single codebase, the developer must be aware of native components

Steeper learning curve than Hybrid / Web Apps for web developers, especially when it comes to layout

React Native

In part 6 of the series, I do a quick Hello World in React Native. This shows, on Android Studio's Layout Inspector, what components were rendered in the emulator. I compare with the previous examples, ensuring that there's no WebView whatsoever.

Web Native Apps presentation with focus on React Native in Part 6 of the series.

Nativescript

Another amazing framework that I've been particularly interested in over the last two years (I have a course on Udemy about it — in Portuguese), is Nativescript. It’s similar to React Native but is not tied to the React world (there's an unofficial integration, Nativescript-Preact, though).

With Nativescript, you can develop using vanilla JavaScript, TypeScript, Angular and, more recently, Vue. Of course you can use other frameworks, but those are the ones officially supported. It’s fairly well documented too, by the way.

Nativescript has tools like Nativescript Sidekick and Nativescript Playground, as well as project structures based on templates that can be provided by the community. This should help you in project creation, giving you the ability to start, deploy, test, and run on simulators on the cloud and iPhone devices even when you are not developing using a Mac.

In the seventh part of the series, I do a Hello World using Sidekick along with another project started from the CLI and a WhatsApp clone template I created for learning purposes.

Web Native Apps with Nativescript in Part 7 of the series.

It's important to have a look at the Layout Inspector when your app is running on an Android emulator. With Nativescript, it shows the native components (again, no WebView), and direct instances of common Android classes like TextView. This is different than React Native, which has its own classes to wrap the native components.

That's probably why Nativescript claims that there’s no delay between when a new feature is available on iOS and Android and when you can use it in a Nativescript project. For example, they posted on their blog an AR project on the same day iOS 11 was officially released with the new ARKit API.

Weex

Another framework worth mentioning in this category is Weex. It's a project developed by Alibaba, and is currently incubated at Apache Sofware Foundation (ASF). It uses common HTML tags like <div> and CSS commands inside <style> tags to call native components instead. From their documentation:

Although components in Weex look like HTML tags, you are not able to use all of them. Instead, you can only use the built-in components and your custom components.

Cross Compiled

At this level, it’s time to jump off the Web bandwagon. This is the closest tier to native development, but has the advantage of using one single codebase to target Android and iOS.

Development tiers now complete with Cross Compiled Apps

RubyMotion and Xamarin

There are solutions like RubyMotion. This is a way to write mobile apps using Ruby and compile directly to the targeted platform (as it was created using any ""native"" language).

Another option is Xamarin, where you write in C#, compile to an intermediate bytecode, and deploy your app along with an instance of the Mono common language runtime. This approach has the same drawback as Web Native (where V8 and JavaScriptCore are delivered by your app), but can also rely upon JIT compilations to optimize the app at runtime.

Flutter

Last but not least, I'd like to bring up Flutter. It’s Google's newest cool initiative for mobile development. It fits in the Cross Compiled tier because you write apps using the Dart language and compile them down to the native platform.

Flutter has innovated in some aspects. Probably the most outstanding one is the fact that it provides its own set of components.

What? Own set of components?

Yes, Flutter provides a number of different components so you can completely skip the ones from the platform. It has generic components as well as Material Design components for Android, and Cupertino components for iOS.

Rather than .Net virtual machine (as Xamarin) or JavaScript engines (as Web Native frameworks), with Flutter your app will deliver the components you decide to use.

Are they native components?

Yes, they are. Your app is native, too. Everything is compiled to the native architecture. However, bear in mind they are not the pre-existing native components.

What's the point of that?

Well, in my opinion, this solution is clever and audacious. I've been waiting to talk about advantages and disadvantages, but as it's just one particular technology, let me address them now.

One of the biggest challenges for Web Native and Cross Compiled solutions (remember, above Native but below the WebView in our tiers) is how to deal with native components. For example, an important problem is how to lay them out. That's because they were not created to be used by those external resources. Also, they were not created with a counterpart in the other platform in mind. The Android NavBar doesn't work like iOS UINavBar, for example.

With Flutter, components are created with cross-platform always in mind. So let's have a look at the pros and cons of the Cross Compiled Apps tier:

Cross Compiled Apps advantages

Reach both platforms with one single language

Roughly the same performance as native apps, as they also deal with native UI components

Cross Compiled Apps disadvantages

Slightly delayed support for the latest platform updates

Code not shareable with web development

Even with one single codebase, the developer must be aware of native components

PS: With Flutter, you’ll provide your own set of widgets along with your app's code

Mobile Apps runtime architecture",https://cdn-images-1.medium.com/max/1200/1*kHze88HBCkKt8Tw4MESC9Q.png,[],https://medium.freecodecamp.org/a-deeply-detailed-but-never-definitive-guide-to-mobile-development-architecture-6b01ce3b1528?source=collection_home---6------21----------------,2018-06-05 16:34:24.241000+00:00

Neural Networks,How to deliver a React Native app to the client – freeCodeCamp,[],"How to deliver a React Native app to the client

If you have written some React Native apps, you’ve probably noticed that the process of beta-release version generation requires many repeatable steps. This happens especially for multi-platform apps.

Let’s look at sample action steps you need to perform to deliver the beta version app to the client or tester:

Download the proper branch from the repository

Android:

Insert the APK signing key into the ./android/app/ directory

directory Build the release version

Send the app, for example via e-mail

iOS:

Launch Xcode

Change the scheme to Release

Change the jsCodeLocation value to a static main.jsbundle file path

value to a static file path Archive

Upload the app to TestFlight

As you can see, the above list contains a large number of repeatable steps. Since they are repeatable, we can automate them, right?

Possible solutions

There are several solutions for automating beta release version generation and delivering the app to the client.

Visual Studio App Center

The first solution that came to our minds at Brainhub was the use of the Visual Studio App Center. A project built by Microsoft seems to be really attractive — in addition to building the app in the cloud (free 240 minutes / month of building) and distribution among testers and the client, it also provides a platform for testing apps on many real devices, giving access to reports and screenshots of every step of the process.

However, it quickly turned out that this was not the appropriate solution for our particular project. VS App Center has limited configuration abilities, and the app’s code needs to be downloaded from the Git repository hosted on GitHub, Bitbucket, or VSTS. Due to the fact that we use GitLab, we had to rule out this solution (but it could work for your project).

HockeyApp (with Fastlane)

The next option was to use HockeyApp — a tool for app distribution and collecting crash reports and users’ feedback. The service was initially created for distribution of iOS apps using the ‘ad hoc’ method (outside of App Store), but currently it works for Android also.

HockeyApp works well as a delivery platform of software testing versions, but does not give the functionality of building the app. However, we can also use Fastlane — a tool for mobile app building process automation built by fabric.io.

Preparations

Before you start building and deploying the app, you should prepare the environment. This section describes the steps you should take first.

Automatic jsCodeLocation change

React Native documentation says that you should change jsCodeLocation to the static js bundle for the iOS release version in AppDelegate.m file. But there’s no need to do that manually every time you release the app — you can use the #ifdef DEBUG macro to do it automatically. Just replace the line containing jsCodeLocation = … with the following code.

#ifdef DEBUG

// DEV

jsCodeLocation = [[RCTBundleURLProvider sharedSettings] jsBundleURLForBundleRoot:@”index” fallbackResource:nil];

#else

// PROD

jsCodeLocation = [[NSBundle mainBundle] URLForResource:@”main” withExtension:@”jsbundle”];

#endif

Ignore helper files

During the process of building the app, there will be some helper files created. There’s no need to commit them to the repository, so just add them to the following “.gitignore” file.

# Deployment

*.cer

*.jsbundle

*.jsbundle.meta

*dSYM.zip

*.keystore

*.mobileprovision

fastlane/report.xml

APK signing key

To release an Android app, you need a signing key. To learn more about this process, look here.

When you have your key generated, move it to the “android/app” directory and remember to add *.keystore to “.gitignore”.

Fastlane + HockeyApp + Testflight

You will learn how to automatically generate an app written in React Native for Android and iOS platforms, and send it to HockeyApp (Android) and Testflight (iOS).

First, let’s install Fastlane. Make sure you have the newest version of Xcode command line tools installed.

xcode-select — install

Install Fastlane.

[sudo] gem install fastlane -NV` or `brew cask install fastlane`

Init Fastlane.

fastlane init

The command above will create the “fastlane” directory in current directory with a file called “Fastfile” that contains the Fastlane configuration.

Appfile

In the “fastlane” directory, create a file called “Appfile”, which stores data that is used across all fastlane tools, for example AppleID. It is required for the iOS build and deployment to Testflight.

Add your AppleID to “Appfile”.

Fastfile

Your beta release Fastfile might look like this.

# More documentation about how to customize your build

# can be found here:

# https://docs.fastlane.tools

# fastlane_version “2.68.0”

# Fastfile actions accept additional configuration, but

# don’t worry, fastlane will prompt you for required

# info which you can add here later

platform :ios do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

get_certificates

get_provisioning_profile(

app_identifier: “org.you.yourProject”

)

# build your iOS app

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

# TestFlight

pilot()

end

end

platform :android do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

# build the release variant

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

# upload to HockeyApp

hockey(

api_token: “YOUR_TOKEN”

)

end

end

Let’s analyze our “Fastfile” step-by-step.

The code block below will be executed after typing fastlane ios beta into the console.

platform :ios do

lane :beta do

# …

end

end

For Android , type fastlane android beta .

platform :android do

lane :beta do

# …

end

end

Ensure that the current branch is master and perform git pull to sync with the remote repository.

ensure_git_branch(

branch: “master”

)

git_pull

iOS only

Let’s increment the build number (works for iOS only). The application that is being sent to Testflight has to have a higher build number than the previous version.

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

Testflight and Ad Hoc distribution require the proper certificate and provisioning profile. There are several methods of signing apps:

match

cert and sigh

Xcode’s code signing feature

manually

In this article, cert and sigh was used. For further reading about codesigning using Fastlane, visit this site.

get_certificates

get_provisioning_profile( app_identifier: “org.you.yourProject” )

Next, there is the step of building the iOS version where we pass the params such as project path, scheme , and export_method . Export_method contains one of the following values: app-store , ad-hoc , package , enterprise , development , or developer-id .

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

The last step for iOS is sending the app to Testflight.

pilot()

Android only

Now let’s look at the Android version. There are two gradle steps: cleaning, and building the release version.

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

Now you can send the generated app to HockeyApp.

hockey(

api_token: “YOUR_TOKEN”

)

If you don’t add some required parameter, for example no iTunes Connect user in Fastfile, Fastlane will ask you for that data in the console.

HockeyApp Configuration

After signing up and signing in to HockeyApp, you will see the blue “New App” button.",https://cdn-images-1.medium.com/max/1200/1*153T3TpCccNK7hs11oRNpA.png,[],https://medium.freecodecamp.org/how-to-deliver-a-react-native-app-to-the-client-e58421e7272e?source=collection_home---6------22----------------,2018-06-05 01:26:27.937000+00:00

Neural Networks,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------,2018-06-05 00:59:03.212000+00:00

Neural Networks,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------#--responses,2018-06-05 00:59:03.212000+00:00

Neural Networks,A coffee-break introduction to time complexity of algorithms,['Vicky Lai'],"A coffee-break introduction to time complexity of algorithms

Just like writing your very first for loop, understanding time complexity is an integral milestone to learning how to write efficient complex programs. Think of it as having a superpower that allows you to know exactly what type of program might be the most efficient in a particular situation — before even running a single line of code.

The fundamental concepts of complexity analysis are well worth studying. You’ll be able to better understand how the code you’re writing will interact with the program’s input, and as a result, you’ll spend a lot less wasted time writing slow and problematic code.

It won’t take long to go over all you need to know in order to start writing more efficient programs — in fact, we can do it in about fifteen minutes. You can go grab a coffee right now (or tea, if that’s your thing) and I’ll take you through it before your coffee break is over. Go ahead, I’ll wait.

All set? Let’s do it!

What is “time complexity” anyway?

The time complexity of an algorithm is an approximation of how long that algorithm will take to process some input. It describes the efficiency of the algorithm by the magnitude of its operations. This is different than the number of times an operation repeats. I’ll expand on that later. Generally, the fewer operations the algorithm has, the faster it will be.

We write about time complexity using Big O notation, which looks something like O(n). There’s rather a lot of math involved in its formal definition, but informally we can say that Big O notation gives us our algorithm’s approximate run time in the worst case, or in other words, its upper bound. It is inherently relative and comparative.

We’re describing the algorithm’s efficiency relative to the increasing size of its input data, n. If the input is a string, then n is the length of the string. If it’s a list of integers, n is the length of the list.

It’s easiest to picture what Big O notation represents with a graph:

Lines made with the very excellent Desmos graph calculator. You can play with this graph here.

Here are the main important points to remember as you read the rest of this article:

Time complexity is an approximation

An algorithm’s time complexity approximates its worst case run time

Determining time complexity

There are different classes of complexity that we can use to quickly understand an algorithm. I’ll illustrate some of these classes using nested loops and other examples.

Polynomial time complexity

A polynomial, from the Greek poly meaning “many,” and Latin nomen meaning “name,” describes an expression comprised of constant variables, and addition, multiplication, and exponentiation to a non-negative integer power. That’s a super math-y way to say that it contains variables usually denoted by letters, and symbols that look like these:

The below classes describe polynomial algorithms. Some have food examples.

Constant

A constant time algorithm doesn’t change its running time in response to the input data. No matter the size of the data it receives, the algorithm takes the same amount of time to run. We denote this as a time complexity of O(1).

Here’s one example of a constant algorithm that takes the first item in a slice.

func takeCupcake(cupcakes []int) int {

return cupcakes[0]

}

Choice of flavours are: vanilla cupcake, strawberry cupcake, mint chocolate cupcake, lemon cupcake, and “wibbly wobbly, timey wimey” cupcake.

With this contant-time algorithm, no matter how many cupcakes are on offer, you just get the first one. Oh well. Flavours are overrated anyway.

Linear

The running duration of a linear algorithm is constant. It will process the input in n number of operations. This is often the best possible (most efficient) case for time complexity where all the data must be examined.

Here’s an example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

}

Here’s another example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// double dip chip

}

}

It doesn’t matter whether the code inside the loop executes once, twice, or any number of times. Both these loops process the input by a constant factor of n, and thus can be described as linear.

Don’t double dip in a shared bowl.

Quadratic

Now here’s an example of code with time complexity of O(n2):

func pizzaDelivery(pizzas int) {

for pizza := 0; pizza <= pizzas; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

Because there are two nested loops, or nested linear operations, the algorithm process the input n2times.

Cubic

Extending on the previous example, this code with three nested loops has time complexity of O(n3):

func pizzaDelivery(boxesDelivered int) {

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

}

Seriously though, who delivers unsliced pizza??

Logarithmic

A logarithmic algorithm is one that reduces the size of the input at every step. We denote this time complexity as O(log n), where log, the logarithm function, is this shape:

One example of this is a binary search algorithm that finds the position of an element within a sorted array. Here’s how it would work, assuming we’re trying to find the element x:

If x matches the middle element m of the array, return the position of m. If x doesn’t match m, see if m is larger or smaller than x. If larger, discard all array items greater than m. If smaller, discard all array items smaller than m. Continue by repeating steps 1 and 2 on the remaining array until x is found.

I find the clearest analogy for understanding binary search is imagining the process of locating a book in a bookstore aisle. If the books are organized by author’s last name and you want to find “Terry Pratchett,” you know you need to look for the “P” section.

You can approach the shelf at any point along the aisle and look at the author’s last name there. If you’re looking at a book by Neil Gaiman, you know you can ignore all the rest of the books to your left, since no letters that come before “G” in the alphabet happen to be “P.” You would then move down the aisle to the right any amount, and repeat this process until you’ve found the Terry Pratchett section, which should be rather sizable if you’re at any decent bookstore, because wow did he write a lot of books.

Quasilinear

Often seen with sorting algorithms, the time complexity O(n log n) can describe a data structure where each operation takes O(log n) time. One example of this is quick sort, a divide-and-conquer algorithm.

Quick sort works by dividing up an unsorted array into smaller chunks that are easier to process. It sorts the sub-arrays, and thus the whole array. Think about it like trying to put a deck of cards in order. It’s faster if you split up the cards and get five friends to help you.

Non-polynomial time complexity

The below classes of algorithms are non-polynomial.

Factorial

An algorithm with time complexity O(n!) often iterates through all permutations of the input elements. One common example is a brute-force search, seen in the traveling salesman problem. It tries to find the least costly path between a number of points by enumerating all possible permutations and finding the ones with the lowest cost.

Exponential

An exponential algorithm often also iterates through all subsets of the input elements. It is denoted O(2n) and is often seen in brute-force algorithms. It is similar to factorial time except in its rate of growth, which, as you may not be surprised to hear, is exponential. The larger the data set, the more steep the curve becomes.

In cryptography, a brute-force attack may systematically check all possible elements of a password by iterating through subsets. Using an exponential algorithm to do this, it becomes incredibly resource-expensive to brute-force crack a long password versus a shorter one. This is one reason that a long password is considered more secure than a shorter one.

There are further time complexity classes less commonly seen that I won’t cover here, but you can read about these and find examples in this handy table.

Recursion time complexity

As I described in my article explaining recursion using apple pie, a recursive function calls itself under specified conditions. Its time complexity depends on how many times the function is called and the time complexity of a single function call. In other words, it’s the product of the number of times the function runs and a single execution’s time complexity.

Here’s a recursive function that eats pies until no pies are left:

func eatPies(pies int) int {

if pies == 0 {

return pies

}

return eatPies(pies - 1)

}

The time complexity of a single execution is constant. No matter how many pies are input, the program will do the same thing: check to see if the input is 0. If so, return, and if not, call itself with one fewer pie.

The initial number of pies could be any number, and we need to process all of them, so we can describe the input as n. Thus, the time complexity of this recursive function is the product O(n).

This function’s return value is zero, plus some indigestion.

Worst case time complexity

So far, we’ve talked about the time complexity of a few nested loops and some code examples. Most algorithms, however, are built from many combinations of these. How do we determine the time complexity of an algorithm containing many of these elements strung together?

Easy. We can describe the total time complexity of the algorithm by finding the largest complexity among all of its parts. This is because the slowest part of the code is the bottleneck, and time complexity is concerned with describing the worst case for the algorithm’s run time.

Say we have a program for an office party. If our program looks like this:

package main



import ""fmt""



func takeCupcake(cupcakes []int) int {

fmt.Println(""Have cupcake number"",cupcakes[0])

return cupcakes[0]

}



func eatChips(bowlOfChips int) {

fmt.Println(""Have some chips!"")

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

fmt.Println(""No more chips."")

}



func pizzaDelivery(boxesDelivered int) {

fmt.Println(""Pizza is here!"")

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

fmt.Println(""Pizza is gone."")

}



func eatPies(pies int) int {

if pies == 0 {

fmt.Println(""Someone ate all the pies!"")

return pies

}

fmt.Println(""Eating pie..."")

return eatPies(pies - 1)

}



func main() {

takeCupcake([]int{1, 2, 3})

eatChips(23)

pizzaDelivery(3)

eatPies(3)

fmt.Println(""Food gone. Back to work!"")

}

We can describe the time complexity of all the code by the complexity of its most complex part. This program is made up of functions we’ve already seen, with the following time complexity classes:

To describe the time complexity of the entire office party program, we choose the worst case. This program would have the time complexity O(n3).

Here’s the office party soundtrack, just for fun.

Have cupcake number 1

Have some chips!

No more chips.

Pizza is here!

Pizza is gone.

Eating pie...

Eating pie...

Eating pie...

Someone ate all the pies!

Food gone. Back to work!

P vs NP, NP-complete, and NP-hard

You may come across these terms in your explorations of time complexity. Informally, P (for Polynomial time), is a class of problems that is quick to solve. NP, for Nondeterministic Polynomial time, is a class of problems where the answer can be quickly verified in polynomial time. NP encompasses P, but also another class of problems called NP-complete, for which no fast solution is known. Outside of NP, but still including NP-complete, is yet another class called NP-hard, which includes problems that no one has been able to verifiably solve with polynomial algorithms.

P vs NP Euler diagram, by Behnam Esfahbod, CC BY-SA 3.0

P versus NP is an unsolved, open question in computer science.

Anyway, you don’t generally need to know about NP and NP-hard problems to begin taking advantage of understanding time complexity. They’re a whole other Pandora’s box.

Approximate the efficiency of an algorithm before you write the code

So far, we’ve identified some different time complexity classes and how we might determine which one an algorithm falls into. So how does this help us before we’ve written any code to evaluate?

By combining a little knowledge of time complexity with an awareness of the size of our input data, we can take a guess at an efficient algorithm for processing our data within a given time constraint. We can base our estimation on the fact that a modern computer can perform some hundreds of millions of operations in a second. The following table from the Competitive Programmer’s Handbook offers some estimates on required time complexity to process the respective input size in a time limit of one second.

Keep in mind that time complexity is an approximation, and not a guarantee. We can save a lot of time and effort by immediately ruling out algorithm designs that are unlikely to suit our constraints, but we must also consider that Big O notation doesn’t account for constant factors. Here’s some code to illustrate.

The following two algorithms both have O(n) time complexity.

func makeCoffee(scoops int) {

for scoop := 0; scoop <= scoops; scoop++ {

// add instant coffee

}

}

func makeStrongCoffee(scoops int) {

for scoop := 0; scoop <= 3*scoops; scoop++ {

// add instant coffee

}

}

The first function makes a cup of coffee with the number of scoops we ask for. The second function also makes a cup of coffee, but it triples the number of scoops we ask for. To see an illustrative example, let’s ask both these functions for a cup of coffee with a million scoops.

Here’s the output of the Go test:

Benchmark_makeCoffee-4 1000000000 0.29 ns/op

Benchmark_makeStrongCoffee-4 1000000000 0.86 ns/op

Our first function, makeCoffee , completed in an average 0.29 nanoseconds. Our second function, makeStrongCoffee , completed in an average of 0.86 nanoseconds. While those may both seem like pretty small numbers, consider that the stronger coffee took nearly three times longer to make. This should make sense intuitively, since we asked it to triple the scoops. Big O notation alone wouldn’t tell you this, since the constant factor of the tripled scoops isn’t accounted for.

Improve time complexity of existing code

Becoming familiar with time complexity gives us the opportunity to write code, or refactor code, to be more efficient. To illustrate, I’ll give a concrete example of one way we can refactor a bit of code to improve its time complexity.

Let’s say a bunch of people at the office want some pie. Some people want pie more than others. The amount that everyone wants some pie is represented by an int > 0:

diners := []int{2, 88, 87, 16, 42, 10, 34, 1, 43, 56}

Unfortunately, we’re bootstrapped and there are only three forks to go around. Since we’re a cooperative bunch, the three people who want pie the most will receive the forks to eat it with. Even though they’ve all agreed on this, no one seems to want to sort themselves out and line up in an orderly fashion, so we’ll have to make do with everybody jumbled about.

Without sorting the list of diners, return the three largest integers in the slice.

Here’s a function that solves this problem and has O(n2) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// loop over three forks

for i := 1; i <= 3; i++ {

// variables to keep track of the highest integer and where it is

var max, maxIndex int

// loop over the diners slice

for n := range diners {

// if this integer is higher than max, update max and maxIndex

if diners[n] > max {

max = diners[n]

maxIndex = n

}

}

// remove the highest integer from the diners slice for the next loop

diners = append(diners[:maxIndex], diners[maxIndex+1:]...)

// keep track of who gets a fork

withForks = append(withForks, max)

}

return withForks

}

This program works, and eventually returns diners [88 87 56] . Everyone gets a little impatient while it’s running though, since it takes rather a long time (about 120 nanoseconds) just to hand out three forks, and the pie’s getting cold. How could we improve it?

By thinking about our approach in a slightly different way, we can refactor this program to have O(n) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// create variables for each fork

var first, second, third int

// loop over the diners

for i := range diners {

// assign the forks

if diners[i] > first {

third = second

second = first

first = diners[i]

} else if diners[i] > second {

third = second

second = diners[i]

} else if diners[i] > third {

third = diners[i]

}

}

// list the final result of who gets a fork

withForks = append(withForks, first, second, third)

return withForks

}

Here’s how the new program works:

Initially, diner 2 (the first in the list) is assigned the first fork. The other forks remain unassigned.

Then, diner 88 is assigned the first fork instead. Diner 2 gets the second one.

Diner 87 isn’t greater than first which is currently 88 , but it is greater than 2 who has the second fork. So, the second fork goes to 87 . Diner 2 gets the third fork.

Continuing in this violent and rapid fork exchange, diner 16 is then assigned the third fork instead of 2 , and so on.

We can add a print statement in the loop to see how the fork assignments play out:

0 0 0

2 0 0

88 2 0

88 87 2

88 87 16

88 87 42

88 87 42

88 87 42

88 87 42

88 87 43

[88 87 56]

This program is much faster, and the whole epic struggle for fork domination is over in 47 nanoseconds.

As you can see, with a little change in perspective and some refactoring, we’ve made this simple bit of code faster and more efficient.

Well, it looks like our fifteen minute coffee break is up! I hope I’ve given you a comprehensive introduction to calculating time complexity. Time to get back to work, hopefully applying your new knowledge to write more effective code! Or maybe just sound smart at your next office party. :)

Sources

“If I have seen further it is by standing on the shoulders of Giants.” –Isaac Newton, 1675",https://cdn-images-1.medium.com/max/1200/1*_YsSsyFQ5sgS8F0kiZ1USA.png,[],https://medium.freecodecamp.org/a-coffee-break-introduction-to-time-complexity-of-algorithms-64df7dd8338e?source=collection_home---6------24----------------,2018-06-04 23:44:40.970000+00:00

Data visualisation,Media – Medium,"['Ev Williams', 'Dave Pell', 'Hossein Derakhshan', 'Dawn Ennis', 'Stephan Neidenbach', 'Don Day', 'Jessie Singer', 'Tim Grierson']","Media Where the newsroom is the news.

Follow Following",https://cdn-images-1.medium.com/max/1200/1*wLhNmBWoSMvG0kyRGjDIqw@2x.jpeg,[],https://medium.com/topic/media,

Data visualisation,The Inspiration of Anthony Bourdain – Member Feature Stories – Medium,['Christine Byrne'],"One of my first great food memories comes from a trip my family took to Normandy when I was six years old. We hadn’t been sitting for two minutes when I announced to my parents, “I want the escargot.”

Dad: “You know that’s snails?”

Six-year-old me: “Yes! We just learned about them in French class, and I want the escargot!”

My parents went along, although I’m sure they expected I’d take a few bites out of stubbornness, then subtly push the dish of garlic and butter and earthy mollusk aside, hoping no one would call out my misplaced courage.

Actually, though, I ate every snail, then mopped up every bit of briny, herby garlic butter left behind. I still think about those snails and about how excited and proud I was to love them so much.

A decade after those snails, I sat on the living room couch with my dad and watched an episode of No Reservations, Anthony Bourdain’s first food travel show. I, like millions of others, was drawn to the irreverent reverence with which he seemed to approach every food he tried, to his eagerness to try anything, and to his ability to narrate the stories of different foods, cooks, and cultures in an unpretentious way that let them mostly speak for themselves. Until then, I had thought of food and travel writing and television as more marketing than storytelling, but watching No Reservations made it clear that, actually, food was not only a story in and of itself, but also a great way to anchor other stories in something tangible and universally understood. Bourdain wasn’t out to sell an experience or show how good something could be — every episode was about telling the story of things exactly as they are.

Bourdain wasn’t the first to talk about food this way, but he was the first to make me feel like maybe I could talk about food that way, too. Food was an important part of my life growing up, but not in a particularly extraordinary way that I felt would resonate. We lived abroad and traveled often, so I was massively privileged in that there was always something new to eat. I remember eating pâté for the first time on a pebble beach in Cornwall while watching my dad (try to) learn to windsurf. I remember tearing apart a slick piece of roti prata and dipping it into a Styrofoam container of curry sauce on a plastic picnic table in Mersing, Malaysia, before getting on a bum boat to an island where I’d go to summer camp for the first time. I remember my first drink: a Tiger beer at Newton Circus, another hawker center, after the closing night of our high school production of South Pacific. I remember, every year when we’d fly home to New Jersey, eating baked ziti and supermarket sheet cake at Fourth of July barbecues, both or which were exciting and special for me because I only ate them once a year. I remember the first time I ate lunch at a New York City deli and was awed by the enormity of both the sandwiches and the Snapple selection. None of this seemed like a story, though, because I wasn’t sure why anyone else would care.

Years later, as a rising college senior, I spent the summer working as a publishing intern in New York. Weeks in, I realized that my longtime goal of being a book editor was actually, definitely, not what I wanted. To keep the “I graduate in a year and now have no plan” anxiety at bay, I read more books that summer than I ever have. One of them was Anthony Bourdain’s Kitchen Confidential.

Bourdain’s 2000 memoir, as you may know, gets so much of its magic from the sense you get while reading that every story is true. I figured it would fall into the “I never want to go there, but that sure made me think and was fun to watch” category that some of the No Reservations episodes did, and that the stories about hypermasculine kitchen culture and the people who somehow ended up in it would make me laugh, think, and then move on to whatever book was next.

That’s not what happened. The first story the book tells is one of Bourdain as a fourth-grader on a European cruise with his family. He tries vichyssoise, a potato-based French soup, and is taken aback by the fact that it’s cold. “I’d eaten in restaurants before, sure,” he says, “but this was the first food I really noticed. It was the first food I enjoyed and, more important, remembered enjoying.” Reading it made me think of my snails, how adventurous they made me feel, and how they established food as something important and worth discovering. It’s a good, tame story that I could easily relate to, and I bet most people felt the same when reading it.

The thing is, the relatability of the book started and ended with that cold potato soup. The rest of the book — about restaurant kitchens and all the crass, stressful, macho, bonkers shit that happened inside them — took place in a world very, very different from mine. Even coming from Bourdain, whose stories had been making me feel welcome since I first watched him walk around Paris unironically wearing cowboy boots in the first episode of No Reservations, the book felt like something I was looking in on from the outside. Reading it piqued my curiosity in restaurant cooking but made it clear that it wasn’t something for me. The longer the stories sat with me, though, the more they started to feel like a sort of…dare.

I graduated soon after, six months earlier than planned. I was still put off by my intern experience in publishing and totally uninspired by every job option presented to me by career counselors and all the well-meaning adults in my life. (Although it was 2010 and the height of a recession, so calling them “options” is maybe a stretch.) Food writing had crossed my mind, but I didn’t figure it was something I could just jump into. I can’t really explain my sudden decision to go to culinary school — a mix of desperation, an interest in food, a burning need to be interesting and different, and a nagging curiosity about Kitchen Confidential, if I had to put it into words — but in 2010, I moved to New York and spent 10 months at the French Culinary Institute learning how to cook. It remains the most impulsive thing I’ve ever done—and the most significant.

The following two and a half years spent cooking in NYC restaurant kitchens taught me things that culinary school never could have—about cooking, stress, being a woman in a room of mostly men, and how to deal with constantly being under fire without falling apart. It’s hard to explain what it was like to walk into a restaurant kitchen, and I honestly don’t remember it clearly, but I do remember that everything I did was wrong, everywhere I was was in the way, and every time someone said something to me, I had to ask them to explain what they were talking about. It was the most underqualified and out of place I’d ever felt, even though I knew in theory that’s exactly what I was signing up for. (I’d read the book! I intentionally jumped out of my comfort zone!) It wasn’t the useless, undervalued feeling that comes with an entry-level office job; it was the feeling that I needed to apologize for even being there, for being the alien who disrupted a system that everyone else knew how to work in. Weeks went by before I was able to walk into that kitchen without absolute fear; months went by before I was able to actually contribute.

Was restaurant cooking the way Bourdain described? Not really. It was vaguely the same, sure: late nights, weekends, burn scars, characters, industry bars, some yelling, ticket boards that inexplicably but reliably went from empty to full in a matter of minutes every single night.

The actual experience of it was very different from what I’d read, though. Because it wasn’t his experience—it was mine. I was the one cramming four hours’ worth of food prep into two and a half every afternoon. I was the one at the stove, firing seven dishes from three different orders at the same time, in exactly the right order, totally on instinct. I was the one who stayed at the bar three hours too long on a Tuesday and somehow always managed to find my way on the L train. I was the one who felt disconnected from one world but totally plugged into another.

Which made me realize: A great storyteller is one who makes you want to experience stories for yourself. A great story is one that makes you think, “I wonder what it would be like to do that.” I’m not much of a storyteller these days, nor am I still a restaurant cook. I write recipes, and I write stories about how and why people should cook them, but I do so in a way that’s shaped by what I’ve learned: Recipes are like stories, kind of, and the best recipes are ones that people will actually cook. Getting someone to cook a recipe isn’t about presenting them with something they’re already familiar with, necessarily, but about making them think, “I wonder what it would be like to do that.”

It’s no secret that Anthony Bourdain was a great storyteller. I’ll miss following along with his unending curiosity about food and how it shapes us, and the world will miss the way he was able to share that curiosity in a way that was welcoming and inclusive. What I’m most grateful for, though, is that he showed me the inside of a world I’d never given a second thought to—restaurants—and painted a picture that, even though it was totally unrelatable to me, was interesting enough that I felt compelled to experience if for myself. Not many storytellers do their job so well that, after reading their stories, you actually feel moved to go out and live them.

“Food, for me, has always been an adventure,” Bourdain writes in the preface of Kitchen Confidential. For me, too, Chef. Thanks for teaching me that food is something worth exploring and that the exploration is something worth writing about.",https://cdn-images-1.medium.com/max/1200/1*65ru7KtyJDme4kUXz8Sl5Q.jpeg,[],https://medium.com/s/story/the-inspiration-of-anthony-bourdain-8d5679c2acb4?source=grid_home---------0------------------18,

Data visualisation,"Apple has no idea what’s next, so it’s just banging on the same old drum",['Owen Williams'],"Apple has no idea what’s next, so it’s just banging on the same old drum If you want to witness a company that’s simultaneously in its prime and losing control over its own narrative, look no further than WWDC, Apple’s second-most splashy event of the year, designed to offer a glimpse of the future. The annual developer event is a spectacle that I’ve watched live for almost a decade, but this year was different: it showcased a company that’s lost in the woods, playing the same old hits on repeat, in the same old format. Not only was it painful to watch, it demonstrated that Apple doesn’t really have a coherent plan, or understanding, of where it should take its core platform, let alone the ones it’s tried to build around it. It’s fine to have an off year, but what struck me was how… random it felt, and how little insight or forward thinking there was. Apple’s own platform advantages, company culture, and whatever else, seem to be pigeonholing its trajectory, driving it down a path that looks increasingly dated, and leaving me to wonder if the company is self-aware enough to see the shifting tide before it’s lost at sea. Big, slow, yearly

Apple struggled throughout 2017 to ship flagship features it promised at WWDC 2017, including Airplay 2 and iCloud Messages, delivering them quietly just days before this year’s event. Alongside a scandal about performance throttling, a series of major security slip-ups, and hardware that shipped without long-touted features, many have loudly asked what’s causing these issues — and why a company with so many engineers is fundamentally failing to ship. Performance improvements are arguably the biggest focus of iOS 12. They’ll be welcome for many users, along with several additional improvements: streamlined notifications, a new ‘shortcuts’ feature for custom buttons, usage reporting, group FaceTime, AR updates and a number of other minor improvements to create a major release, iOS 12. The company’s other platforms received similar treatment, including macOS. Apple finished dark mode, a feature it half-introduced all the way back in Yosemite, added basic functionality to Finder, threw in a new way to organize your desktop, and boom — there’s your major release, 10.14. None of these things are inherently bad — in fact, people have been complaining about the lack of improvements to things like FaceTime for years — but what’s interesting is Apple’s choice to bundle them together as a way to make them look truly meaningful, rather than just fixing many of these issues sooner, in a point release. I’m aware there’s a slew of tiny other fixes and features I haven’t listed here, but that’s my point: it’s a hodgepodge of things that have been neglected over the years after being debuted once and forgotten about. Here’s the rub: Apple could arguably ship notification improvements to iOS users tomorrow in a point release, iOS 11.5, but it won’t. Combining them provides the illusion of progress. Instead of servicing users and giving them features sooner, on a regular basis, Apple chooses to hold back simple functionality longer, for its bottom line. As Martin Bryant points out, Apple may have a timing problem: Yes, Apple needs to take the time to do ‘boring’ optimisation work on iOS, but why build iOS around these big, annual feature bumps and then disappoint people when the bumps aren’t very big?

Interestingly, the narrative here actually doesn’t make sense anymore, either. Every year, Apple takes the time to point out how dire the state of the competition is: Nobody’s Android phones get updates! Android people don’t get any the latest features! Your phones all suck! The reality is different: Android users, regardless of manufacturer, frequently get them sooner than iOS users do, because Google divorced the operating system and core application suite from one another. Google’s approach to unbundling Android has, for the most part, been quietly successful — in an unexpected way. Instead of shipping monolithic feature updates, Google’s applications are now updated via the Play Store, from the clock app to the calculator and even the camera (unless you’re Samsung). Apple has made a yearly ritual out of jabbing competitors for poor update histories, but conveniently omits the reality that improvements to Google Assistant, the built-in web browser, or even just the OS keyboard will reach billions of users in a matter of hours without needing to update the entire phone. Android’s support libraries mean developers can target older devices, with new features, regardless of whether or not they received the OS update. Meanwhile, if you find a bug in the iOS keyboard, or some weird security flaw in Safari’s web view, you hope it gets fixed in the next version of the operating system. Maybe next year, or the year after that. It depends how bad it is, or if Apple is actively maintaining the feature, as to when it’ll get serviced. Don’t get me wrong, Android has a terrible history of updates that is only now beginning to change, ten years after the fact. Google has made strides with Project Treble, which makes an end-run around the device maker itself, but it’s only in its infancy with new devices picking it up today. That’s not good enough either; but it’s gaining traction and getting things into people’s hands. For each platform update, Apple dangles a carrot. That’s the flagship feature to convince you it’s a Big Update™ worth having immediately. On macOS this year, that’s dark mode, and on iOS, the promise of performance improvements and, god forbid, actually decent notification management. Arguably the most interesting segment out of WWDC happens at the very end of the two-hour keynote: a peek at Project Marzipan, a long-term effort to unify the interface framework developers use to build apps for iOS and macOS, which is expected to ship to everyone in 2019.

From where I sit, this is an impressive, massive project that doesn’t do much more than play defense against Electron’s continued march on Apple’s territory, threatening to kill native application development altogether. Why build anything native at all, when you can write once, and run everywhere? Anti-Electron fans will run rabid at the idea, but as the technology has become more efficient and introduced lower-level API access, it only makes even more business sense. Marzipan is an audacious plan to defend against that by making it easier to build cross-platform apps. It’s a genuinely fascinating play with fewer apparent benefits in the short term over just building an Electron app, which addresses an additional billion users, allows developers to use familiar web technology and is truly write-once-run-everywhere. Over time, Marzipan may win favor with developers, but I’m not convinced it’ll stop web-based technologies swallowing native app development whole, particularly given that both Microsoft and Google have now bet their entire strategies on Progressive Web Applications, and how low the barrier of entry has come as a result of Electron’s success. Marzipan indicates something bigger, of course, such as an impending shift away from Intel chipsets entirely to some sort of custom Apple ARM-based silicon in — shock horror — a productivity form factor. If anything, what will win as a result will be that control, and what it could ship in a end-to-end device: true all-day battery? Always-on LTE with desktop class apps? If so, the message is this: lock in with us, develop for our platforms, and we’ll reward you. Don’t, and you’ll be shut out and stuck on the outside. Hey Siri, where’s the vision?

What’s clearly missing in all of this is a willingness to take risks, or go for the long view on what’s better than the status quo for Apple’s users. Instead of looking at how phone usage is changing and redesigning the nature of iOS, it’s another year of shoehorning new features into a decade-old shell. The new shortcuts feature promises to let users wire up workflows of their dreams, chaining together tasks behind a single button. Yes, this is a great improvement to iOS that addresses a problem without actually improving on the reason anyone needs this in the first place — it’s just glued onto the homescreen that’s responsible for causing the need for it in the first place. Apple could have offered up a way to surface the weather right there, deeply integrated with the lock screen, or calendar events at the top of your home screen along with the icons, but it didn’t. Instead, it slathered what appears to be a UX hack in the shape of a notification, and tries to guess when you want to see it. Google’s own developer conference, just down the street in Mountain View, was held in May and offered a clearer, if poorly highlighted, view of the future: AI is a core part of mobile devices going forward, so we’re beginning to add it everywhere. The Android alternative to Shortcuts, Slices and App Actions, surfaces the device’s best guess at your next action as a deeply integrated interface component, where you can actually see information before actually going further in, or taking an action. Want a button to order a Lyft? Great, here’s a button embedded within the system’s app tray, with the current estimated price of your ride, which orders it right now with a single tap. Much of this data is crunched on device, just like Apple’s audacious claims to privacy brag about as well, but instead of being a UX hack to add buttons that summon help, the information is already right there, on hand, without opening anything, even Assistant. Google and Apple both anticipate a future in which we use our phones less — time well spent is a core part of this driver — and as a result, it appears Google has spent a lot of time thinking about how AI can help get the right information to the user. The result is the exact button they need at the right time, with relevant information, sans the need to actually go away and do something. To facilitate this, Google is willing to rejig the UX of its devices, mess with the sea of icons, and has invested heavily in serendipitous computing with Google Home alongside this, so it can get you there faster regardless of if the phone is in your hand.

Google’s vision of the future of smartphones, mobile operating systems, and the way we’ll interact with devices over the long haul is a coherent, well-told story: get more out of your day, get the devices out of the way. It even has a fantastic page that showcases how its own ecosystem works better, together, than I’ve ever seen explained about Apple’s ecosystem on its own site. As for why all of this happens, I suspect it’s a difference in strategy and approach. Apple’s strategy has long been to monetize its existing cash cows as long as it can by throwing out new stuff to see what sticks and doubling down on that, rather than creating any sort of coherent narrative of what the future actually looks like, operating in secrecy until it somehow lands upon it. Incremental improvement is fine, but there’s a distinct lack of forward-looking, and a whole lot of looking over the fence at what everyone else is doing to bash it instead. Apples, oranges and comparing the two

It’s easy to compare and contrast Google and Apple because they are very different companies, but what they’re both claiming to do is the same: invent the future, whatever that actually might be. Their approaches, however, are increasingly diverging: Apple’s squeezing more out of less, shipping flashy features, and focusing on privacy, while Google and others have pushed further into understanding the user and getting out of their way. Most of this comes down to business model. Apple’s focus on features by piling them together drives more sales of iPhone, which drives reliable revenue on a yearly basis. Google’s is on advertising and relevance to the user, which doesn’t depend on a particular feature or thing to tout, it just needs you to love using its tools (and not mind advertising). Apple’s entire strategy over the last two decades has pivoted around the exploitation of a product line until something new comes along, then rinse and repeat. This is framed around improving your life and often actually does, even if that is by proxy. I’d argue that the company’s vision of the future isn’t to enrich, or drive progress, but to squeeze as much revenue as possible out of slick, well-designed and marketed ideas. The products it builds, the cycles they’re released in and the way that Apple’s entire software cycle works reflects this. An example of the manifestation of this is perhaps HomePod’s requirement to have a locally available iPhone to do anything interesting, leaving it crippled without one, and Animoji’s debut only to be locked away in Messages instead of somewhere like the camera.

Google, a latecomer in the game, has the luxury — and peril — of not depending on phone revenue, so it can risk it all and get weird, since it’s not fundamentally critical to the company’s continued trajectory. Microsoft has done the same, now finding itself the underdog, risked it all and moved to an ‘OS-as-a-service’ model in which it ships features when they’re ready instead of waiting for flashy releases. Apple, on the other hand, begins and ends with the iPhone today, the rest flows from there. It can’t just rip up the foundation on which its revenue exists, and Tim Cook hasn’t shown a flair for doing so. iOS is too valuable to go away and tear down to just reimagine it for fun, so it’s the status quo, with experiments like HomePod and AirPods on the side, where it can get weird and sometimes wonderful. That’s fine, because Apple has plenty of cash lying around, but it’s interesting how limiting the approach can become. As we hurtle toward peak smartphone, the cracks here are beginning to show because Apple don’t have the next big thing yet — that we know of, naturally — and it’s taking a long time to get here. We’re essentially watching the bottom of the metaphorical tube of toothpaste being squeezed, while others are trying to figure out if maybe the tube should work completely differently. AR is potentially the next platform, yes, and it’s clear that Apple is pushing forward on that in a big way, so it’s easy to imagine a scenario in which it makes sense to shift precious resources there instead of focusing on iOS which may wind up unimportant in a year or two. I’m not convinced that in the short term, such as the oft-claimed 2020 launch date of an Apple VR/AR headset, that we’ll be headed there in any meaningful capacity. I mean, Magic Leap, a bajillion dollar company building the future of AR showed off its hardware yesterday on Twitch, quipping that “you better not put it in your pocket or it’ll overheat.” I’m happy to be wrong, and I write this knowing I’ll probably be that guy who very publically crapped on the iPhone at launch later. Apple’s worth a very large amount of money, which is more than enough proof that it’s good at many things, including convincing people to buy a phone every year.",https://cdn-images-1.medium.com/max/1200/1*tIUbwrpHZPbdNPXB569wPQ.png,[],https://medium.com/@ow/apple-has-no-idea-whats-next-so-it-s-just-banging-on-the-same-old-drum-dcfd0179cf80?source=grid_home---------0------------------18,2018-06-07 13:54:23.876000+00:00

Data visualisation,Our Wedding Is Canceled Due to the Following Strongly-Held Beliefs,['Tim Sniffen'],"Hi, everyone. I know you weren’t expecting to see Keith and I out here so soon, but we have some bad news. We’re not getting married today.

Believe me, we were really looking forward to it, but recently — this morning, in fact — we learned our blessed event was in direct conflict with the strongly-held beliefs of many of the people providing our wedding services. And if they’re not happy, we’re not happy.

Let me bring you up to speed.

You may have noticed the empty display table by the reception tent as you filed in. That’s where our wedding cake would have been. For our baker, however, creating a cake to be employed in the marriage of two men would be the moral equivalent of using communion wine to make sangria.

We knew the risks when enlisting Give Us This Beignet, Our Daily Bread as our wedding baker. They’re the best in downtown Aurora, no question — sorry, Wild-Flour! — but their beliefs on same-sex marriage are no secret. We hoped they might get swept up in the joy of the occasion but last night their chief baker Jonah, applying the final bit of piping, had a vision of Billie Jean King physically dragging him away from the gates of Heaven. And if that’s not a sign, I don’t know what is.

I should add, it may not have helped that we requested our little cake figurines be surrounded by an added semi-circle of figurines, in likenesses of the bakery staff, giving us the thumbs-up.

But that’s all done with. They’ve made their wishes clear and we respect them.

Which brings me to the empty vases alongside the pews and the empty centerpiece bowls on the reception tables. We’ve known Joyce Gantz, owner of Rest On My Laurels, for years; I couldn’t imagine this day without her. What I couldn’t know was the war raging within Joyce, fervent Catholic, after she learned of the meat-laden Friday barbecues Keith and I throw for our softball team. Last night, Joyce looked deep within her heart to ask, can I lend my good name to this cursed union?

The dumpster full of imported delphinium behind Joyce’s shop can tell you the answer.

You see, what we’re learning is that these are not just goods and services; they’re not simply the imprints of Keith’s Capital One card and the resulting exchange of goods. Every item at a wedding is nothing less than the avatar of its vendor’s entire belief system. With this in mind, each rose petal my niece Stephanie was prepared to hurl down the aisle might as well have been embossed with JOYCE GANTZ APPLAUDS THEE, SATAN.

What faith-engorged entrepreneur should face such hell?

This is why the rows of steam-trays in the tent are empty, and your choice of beef tenderloin or grilled salmon — or the one plate of tempeh veggie kabob, bless you, Amy! — will never arrive. Because Something Borrowed, Something Cordon Bleu, exceptional wedding caterers and unapologetic druids, could not bear the thought of providing nourishment to a couple willing to rip two thriving Magnolia trees from their backyard last summer. From their email: “Your heretic’s feast will be served when the earth heals from your violence.” By our best guess that wouldn’t have been by 6 p.m.

We also won’t be dancing to Renèe and the Ring-tones. While Rènee was a woman of few beliefs when we booked her, she has since converted to the Egyptian cult of Bastet, and considers the choice to put our cat Banjo to sleep, rather than pay $15,000 for experimental feline jaw surgery, to be “unforgivable wickedness, worthy of disciples of Set.”

I’ve been handed this note: Lane, our photographer, turns out to be more of a Star Wars guy and doesn’t feel right legitimizing such an obviously Star Trek couple.

Blessings on your journey, Lane.

In closing, our apologies. We were so busy coordinating our big day that we forgot to coordinate the sacred truths of all players involved. I’m told many of our vendors will adopt an exhaustive three-week interview process before each sale to keep this from happening again.

We did have a lovely wedding favor created for each of you, which we might as well distribute. It’s a wooden plaque, engraved with the phrase Love Conquers All, hand-crafted by our friend Bryce Charles in the front row. Now, Bryce is something of a Packers fan, and Keith is all about the Bears, but in the spirit of friendly rivalry, we’ve always managed to put aside our differ — wait.

Bryce’s feelings are changing.

They’re moving from loosely-held to nonchalantly-held. They’re not done; from the set of Bryce’s jaw, her feelings have transitioned to intentionally-held, and finally, they’re — yup. They’re strongly-held. Dammit.

Sorry, folks. You’re on your own.",https://cdn-images-1.medium.com/focal/1200/632/50/45/0*fh1vaEnMNoMbHE42,[],https://medium.com/s/story/our-wedding-is-cancelled-due-to-the-following-strongly-held-beliefs-1fa71105660e?source=grid_home---------0------------------18,

Data visualisation,My So-Called (Millennial) Entitlement – Trust Issues – Medium,['Stephanie Georgopulos'],"I am at the San Francisco International Airport some barely recent morning, registering for a travel program called Clear when the automated kiosk assisting me makes a strange request: “Stand still while we scan your irises.” I’ve barely digested this first ask when another takes its place: this time, the kiosk wants my fingerprints. I find this slightly less alarming; I already use those to access my banking app, buy coins for my mobile games, and unlock the phone that hosts all this information in the first place. But my eyeballs — which I had only just learned could be used as ID, and from a machine at the airport, no less — my dude. Those are the windows to my soul! Ever heard of foreplay?

Clear is a private company that prescreens air travelers using biometric authentication. Becoming a member is like ordering the half-soup, half-sandwich version of TSA PreCheck: it works, if all you want is a taste and are willing to pay for it. With Clear, you don’t need your ID to go through security, but you still have to remove your shoes. You get to wait in a shorter line (sometimes), but you still have to take out your laptop. Basically, the Cleared still participate in the most annoying aspects of air travel and pay almost 10 times the PreCheck fee for the privilege.

If the worst has already happened, that means it’s survivable.

How we decided on this valuation of convenience—it’s $179 per year—is not the point, though. My point is that some random startup casually acquired my eye-prints, and some small voice is telling me I should care more than I do. Someone out there definitely cares about this, no doubt. I’m sure at least one other traveler was not sated when a brisk Google search revealed that Clear is based in her hometown and run by a female CEO, ergo it must be a secure and entirely trustworthy business.

But I was sated. It’s the future, right? What’s the worst one could do with my retinal scans? I already gave my social security number to Camel in exchange for a pack of promotional cigarettes one time (or 12). Somewhere in Midtown Manhattan, a market-research firm knows how many condoms I used in May of 2011 (give or take). And when I think about the fact that every hard document I’ve reproduced on a digital copy machine — at work, at the bodega, at the library — is saved on a hard drive somewhere (lots of somewheres, in fact), I feel a sense of hopelessness that, in its own demented way, translates to freedom.

That’s why I unlock my phone with my fingerprint. It’s also why I talk shit in front of Alexa, why I haven’t put tape over my laptop camera, and why I still have a Facebook account. I don’t expect the worst to happen.

Because the worst has already happened. It is happening, and it will continue to happen.

I find this to be an honest, useful framework. If the worst has already happened, that means it’s survivable. And if the worst is a given in the future, too, we know that ignoring it won’t make it go away. There’s opportunity in having nothing to lose. You just need the right attitude.

Or perhaps you need the right conditioning.

Imagine: You’re 11 years old when two teenagers bring guns to their high school and kill 13 people. They injure 21 more. Your sixth-grade humanities teacher explains the inexplicable to your class after lunch period. You have to imagine that this is a first for at least some of your classmates, crying over the national news. It won’t be the last.

When you’re 15, two planes crash into two towers. You know the towers; had toured them on school trips just like all the other famous Manhattan buildings for which you know the names, if not the functions. In fact, you’d visited the towers just one week before the planes hit. There had been a renaissance fair in one of the lobbies.

At 17, your high school economics teacher tells you that social security will run out before you retire. You’ve already been paying taxes for three years. In 2018, you learn that he was exaggerating, thank goodness — by 2034, retirees can expect to receive a whopping 79% of the full benefit they receive today. You will not be of retirement age until the 2050s.

And when you’re 21, the market crashes. You’ve had a bachelor’s degree for three months. It cost $100,000 to earn, all before interest. Your class valedictorian moves back in with her parents, and no, your internship is not hiring. Five years later, the unemployment rate for people your age is almost double the national average.

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

Neuroscience has confirmed that you were making sense of these events with an underdeveloped brain. Along with your emotional maturity and your hormones, it’ll be a work-in-progress until you’re around 25. And the same way the small hurts of being small can still seep into your present — the way your grandmother eyed you with disgust when you went for a second helping — the chipping away of every institution you were raised to believe in can have unintended consequences.

Me: Do you use Touch ID to unlock your phone?

Friend: Ya.

Me: Do you know anything about the technology behind it? Or like, how secure it is?

A beat. A blank stare.

Friend: No?

Me: Same.

My friends do not need to understand the technology behind touch ID any more than they need to understand black holes. They are not convinced that adjusting their social media privacy settings is some sort of moral duty, a symbolic middle finger to Facebook on behalf of all the little guys who understand internet economics to varying degrees, or not at all. Mostly, they were confused as to why any thinking person would have an assumption of security.

“It’s not that I don’t care about being hacked, or about my data being stolen or sold,” one friend tells me. “I assume that vulnerability because there are no physical systems or structures that have succeeded, so why would something that is essentially invisible do a better job than something tangible?”

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

I’ll go: I don’t expect to own a home. I don’t expect to retire well, or at all. I don’t expect anyone to give me anything I haven’t explicitly asked for, and even then. I don’t expect it will ever be affordable to continue my education in any formal way. If a package gets lost in the mail, I don’t expect to see it again. I don’t expect the government or the banks or the universities to do anything that benefits regular people. I don’t expect them to hold each other accountable on our behalf. I don’t expect them to expel abusers from their ranks, or to put my safety over their legacy. I don’t expect to feel safe in large crowds or alone late at night. And I don’t expect that my privacy will be respected, online or in general.

America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

As far as I can tell, security — whether financial, technological, physical, or emotional — is not a thing. You don’t get to decide whether some drunk asshole drinks his drunk ass off and gets behind the wheel. Likewise, you don’t get to decide if the drunk Congress or the drunk banker or all the drunk administrations of all the drunk institutions do what’s right for you. Sometimes they will do the right thing for somebody, but statistically speaking, that somebody is not you.

Sometimes the right thing comes served in a shit sandwich, or one guy does the right thing but it’s later counteracted by the next guy and just so we’re clear, it’s always a guy. Or sometimes, we learn that what we thought was the right thing was actually the wrong thing, in ways we didn’t anticipate, except for those of us who did anticipate it but were not asked or heard because we do not employ lobbyists and because the powers that be can’t listen to us until they sort out whether our bodies are legal or not.

Mark Zuckerberg’s Congressional hearing was probably the biggest mainstreaming of data privacy issues yet, and Facebook, with its many transgressions, made for an appropriate scapegoat. But I want to know why it’s Mark Zuckerberg’s fault that American adults of voting age lack the critical thinking skills to differentiate between fake Russian bot news and The Guardian. I want to know the plan for bringing internet literacy to those who are not digital natives. I want to know why the U.S. government is being celebrated for protecting our egos and baby-proofing the internet instead of telling us the truth: Dirty tricks are less likely to work on people with more education.

What happens when your brand of exceptionalism breeds millions of people who voted a sentient conspiracy theory into office? Where does the fault lie? After all, it’s not Facebook who’s spent decades underpaying teachers and closing schools in low-income neighborhoods. Facebook doesn’t have the jurisdiction to end standardized testing or combat the quiet continuation of white flight. Facebook’s biggest mistake? Profiting off of state-sanctioned dumbness.

We’re only supposed to be dumb enough to believe that the fight is red vs. blue and not top vs. bottom. We’re only supposed to be dumb enough to believe in Democracy the Concept™ without casting a critical eye toward its practical application. This is a dumbness cultivated by and for Washington, and Zuckerberg’s misusing of it for corporate gain almost blew the lid off the entire thing. Commence finger-wagging.

On an episode of his podcast Revisionist History, Malcolm Gladwell argues that we should treat education as a weak-link network, where strengthening the weakest links has the most positive outcome for all. This is in contrast to a strong-link network, where a couple of superstars at the top carry the weaker players on the bottom. He illustrates this dynamic using soccer and basketball. An average soccer team with one star player is less likely to win a match than an above-average team with no star players — soccer is a weak-link sport. Conversely, an NBA team with a superstar or two fares better than a team on which all the players are equally, decently good — basketball is a strong-link sport.

Much to its detriment, America acts like a strong-link country. It is the type of place where electing one mixed-race president means we solved racism. (Imagine if the lesson we took from electing one white man was that all white men who lack upward mobility just need to work harder.) We raise up a few undoubtedly smart and deserving people in each field, send them around the world like brand ambassadors for democracy, poster-adults for how advanced and distinguished and American we are. Meanwhile, most of us back home — 78%, in fact — are living paycheck to paycheck. Is that freedom ringing? We’ll call right back after we pay this phone bill.

These are complex problems. In addition to the 3000ish words here, I have written and cut an additional 4500 trying to make sense of it all. I remain overwhelmed by the number of solutions that contradict one another, the knowns and unknowns, the countless logical ends I haven’t considered. But I eventually found my demented silver lining: America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

While grim on its face, this perspective has pushed me to take inventory of myself, my own power. What can I do right now? Am I solving problems I actually care about, or were these problems unconsciously inherited from another time, problems propagated by those with a vested interest in resolving them with more money, more power, more loopholes? Should I devote my energy to righting a system that, by design, has only consistently benefited one demographic and has yet to even prove itself as a scalable model for a generation that’s tired of the same people making the same decisions on behalf of the most diverse country in the world?

Is that a problem? Because it feels more like an opportunity, to me: a chance to exercise this cache of personal agency I’ve been sitting on, agency I didn’t realize I had or needed as I waited for America to work. It feels like an opportunity to try something else.

More powerful than having nothing to lose is cultivating that which can’t be taken. Grace. Clarity. Purpose. The stuff that isn’t Amazon Prime-able. These are the indoor plants of our being; only you can feed them and grow them and expose them to the light. It’s a lot of responsibility, and the work involved is often unglamorous. Some people think they never have to learn to care for these things because they have the means to outsource what they wish: their plants are alive on paper though they don’t know the how or why of it. And besides, can’t you see they’re a little busy trying to colonize Mars?

A respectable goal, though I might suggest to anyone faced with the choice to try taking on the inner self before jumping ahead to outer space. There’s more to unearth in there than you might think, and we need more people to understand the potential of their own organic material. We need people who appreciate the slow growth of nothing into something, who drink up the sunlight and make the air a little more breathable than before.

Because that’s it, for most of us. That’s how we build power. That’s how we, a generation of janitors for the American dream, put our trust in something real: each other. We stop trying to control the world in our heads and in the headlines, and we start controlling ourselves. We sleep. We go to the doctor. We log off. We talk about our problems. We water our plants. We collect our neighbor’s mail when they’re out of town. We take a deep breath before reacting in anger, and question whether this particular battle is worth our energy. It’s not. Why were we fighting again? We volunteer. We water our plants. We focus on ourselves so we can eventually focus on others — in a real way, in a non-transactional way, in a way that slowly but authentically strengthens our fellow weak links. We don’t wait for permission. We get over ourselves; we stop demanding perfection; we start. We water our plants. And on weekends, we play soccer.",https://cdn-images-1.medium.com/max/1200/1*c5zNxCX34sYmYYO-yRxlbA.png,[],https://medium.com/s/trustissues/my-so-called-millennial-entitlement-9be84343c713?source=grid_home---------0------------------18,

Data visualisation,How to Cope with the End of the World – How to Cope With The End of The World – Medium,['Maria Farrell'],"We All Die, and That’s Okay

My favorite postapocalyptic novel is George R. Stewart’s 1951 Earth Abides. In it, scientist Isherwood Williams (nicknamed Ish) survives a plague and eventually starts a new family and community in the ruins of suburban California. His hope for the future is wholly invested in a child who is intellectually curious, like him, and who might be able to revive some of the old ways and technologies. It’s an observant and reflective novel, full of the “how stuff would probably work” thinking that makes science fiction the true literature of ideas.

Ish starts out as a scientist-savior of humanity, figuring there is just enough time to raise a generation to turn back the clock to before the disaster. But he ultimately has to make his peace with the fact that civilization as he knew it is dead, there will be no heroic rescue, no going back, and the people around him are mostly fine with that.

The 1950s may have been the last decade we could complacently believe the Ecclesiastes (1:4) maxim that “men come and go, but earth abides,” but Stewart’s basic message is correct.

The people who come after us don’t have to do better than us, or think well of us, for them to be essentially okay. And us all throwing a big “let’s blow it all up” hissy fit because we fucked up and we can’t bear to look at it is just teenage nihilism that we need to grow out of already. Coming to terms with what we have done means dumping the egotistical death drive of the mass shooter or far-right politician and gathering the maturity to look our individual and collective deaths straight in the eye and say, “Okay, we get it now. We get it. It’s not about us.”

Have you ever stood in a crowded place like a town square or an airport meet-and-greet and thought, “Every single person here is going to die”? Morbid, eh? More of us should do it.

I live in an early Victorian terraced house in the UK. It’s never been a tenement, so probably a hundred people have called it home in the almost two centuries it’s been standing. Nearly all of them are dead. The people are already born who’ll live there when I’m dead. The head of this country’s anachronistic state has already been born who I’ll never see on the throne and to whom I’ll seem as old as someone born in the 1930s seems to me.

We’re all going to die. The morning will come when those who have loved us put on dark clothes and cry and get on with the rest of their lives, seeing movies we’d have loved, depending on gadgets that now seem to us ridiculously unnecessary. Our deaths matter to us and those who love us, but they don’t fundamentally matter.

Once, while my husband was deployed to Afghanistan, I asked him on the phone if he was doing okay about someone we knew who’d recently been killed. “Oh, you know,” he said, “you know,” and quoted his regiment’s unofficial mantra:

Everything matters. Nothing matters terribly.

The soldier’s death mattered very, very much to him, and (not but) he and others were nonetheless carrying on their shared purpose. Otherwise, what had been the point of any of it?

What will outlive us, individually? Plastic. Perhaps some genes. The bacteria that act as a species-level enabler for everything we are. Some ideas, maybe, or songs, stories, pictures, the memories of us others hold, until they go, memorials like a community flower bed or a named scholarship, for a while, anyway. Less concretely: ways of being, a fitness for the world that those who flourish pass unremarked to their offspring via the epigenetics of love — the sunny inverse of patterns of trauma and abuse transmitted through the body, even unto the third generation. Predation.

And our species? Buildings and bones, maybe. Our nuclear waste and the warning signs we hope people of our deep future, or other species altogether, will decrypt. Snatches of radio-transmitted voices slipping through the vacuum of space. Perhaps some bacterial payload we’ll launch in a decade or so, trying to seed life on other planets, even in other solar systems. Or just the anomalous levels of carbon dioxide and methane in our atmosphere that will reveal, for a time, that complex forms of life were here.

Pride and despair are two sides of the same coin. Our collective denial and despair about the future we have built is preventing us from cracking on and sorting it out. We need to get over ourselves. The world we know will end, in both small and big ways. We ourselves will end. But that doesn’t matter, terribly.

Our mortality is the greatest enabler we have of positive, ongoing change, if only we can face it, if only we can understand that we don’t get to see the end of the movie, because, if what we do works, the movie won’t have to end. We’re not the protagonists. We’re just the foreshadowing. We need to hold the knowledge of our own deaths up to the light and turn it around to see each shining facet, then take the certainty that we are both finite and imperfect deep down inside of us—and put it to work.",https://cdn-images-1.medium.com/max/1200/0*avXWZmh3n3H7a8t8,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world/how-to-cope-with-the-end-of-the-world-2520ef9d3dbc?source=grid_home---------0------------------18,

Data visualisation,How to Cope With The End of The World – Medium,['Maria Farrell'],"COLUMN

How to Cope With The End of The World

There are moments of joy even in times of great despair. Maria Farrell explains how to deal with a darkening world, and how to plan for the end. It might be the end of the world as we know it, but it turns out we feel fine.",https://cdn-images-1.medium.com/max/1200/1*kvqwUuDCsbkAoSfaYXV1vQ@2x.png,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world,

Data visualisation,Chatbots were the next big thing: what happened? – The Startup – Medium,"['Matt Asay', 'Justin Lee']","Chatbots were the next big thing: what happened?

Oh, how the headlines blared:

“…the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”

Chatbots were The Next Big Thing.

Our hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.

And why wouldn’t they be? All the road signs pointed towards insane success.

Messaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!

Plus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.

At the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.

In fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:

“Will a single platform emerge to dominate the chatbot and personal assistant ecosystem?”

One year on, we have an answer to that question.

No.

Because there isn’t even an ecosystem for a platform to dominate.

Fooled by another hype cycle

Chatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.

The age-old hype cycle unfolded in familiar fashion…

Reverential TechCrunch articles were written.

Prophetic thought leaders like Chris Messina chimed in.

Silicon Valley salivated at the prospect of talking to smart automation.

Messenger began to overflow with bots.

Slack went through exponential growth and even launched a fund for bot investment.

Expectations built, built, and then….. It all kind of fizzled out.

The predicted paradim shift didn’t materialize.

And apps are, tellingly, still alive and well.

We look back at our breathless optimism and turn to each other, slightly baffled:

“is that it? THAT was the chatbot revolution we were promised?”

Digit’s Ethan Bloch sums up the general consensus:

“I’m not even sure if we can say ‘chatbots are dead,’ because I don’t even know if they were ever alive.”

According to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.

Text vs. Speech vs. GUI: a potted history

Bots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.

Users had to type commands manually into a machine to get anything done.

Then, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!

Meanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.

Another bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:

… so many different accents, people speaking too fast or too slowly, mumbling, umming and aahing.

Did you say “recognise speech” or “wreck a nice beach”?

The next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:

User: “Hello.”

Agent: “Hello, what’s your name?”

User: “Candy.”

Agent: “Hello, Candy!”

User: “Let’s set the clock.”

Agent: “What is the time?”

User: “The time is 11:00 AM.”

Agent sets the clock to 11:00 AM.

Pretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.

It was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.

Modern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.

Basically, we’re still trying to achieve the same innovations we were 30 years ago.

Here’s where I think we’re going wrong:

Thinking in terms of Bots vs. Apps

An oversized assumption has been that apps are ‘over’, and would be replaced by bots.

By pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.

You might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?

It’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.

Whether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.

Plus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.

A great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.

That’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.

Modern-day apps benefit from decades of research and experimentation. Why would we throw this away?

But, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.

Today’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.

Penny provides chatty advice and alerts alongside a traditional account dashboard and transaction list.

HubSpot Conversations unifies Facebook Messenger, onsite chat, social media, email and other messaging outlets into one shared inbox.

Layer gives developers the tools to create personalized messaging experiences on mobile web and desktop web as well as native apps.

The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.

Bots for the sake of bots

Does my product need a bot? Are existing platforms able to support its functionality? Do I have the patience to build a bot that’s capable of doing what I want it to?

Another problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.

For plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.

Building a bot for the sake of it, letting it loose and hoping for the best will never end well:

The totally necessary Maroon 5 chatbot in action

The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.

The advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.

That’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.

Problems arise when life refuses to fit into those boxes.

According to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.

When we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.

Remember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.

Inaccessibility

A competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.

In an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.

Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)

As Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.

“Consumer interest was never going to materialize until machine intelligence could get anywhere near human intelligence.

User interest depends upon AI that makes talking with a bot worthwhile for consumers.”

And conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.

Today’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.

And in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:

“Should Slack, Facebook, Google, Microsoft, Kik, and others have built their own built-in bots to lead the way?

Should they have gotten more proactive with their bot funds and incubators, hiring mentors to educate participants in the Way of the Bot, or supplying engineering and design resources? Funded Strategic Bot Initiatives at high-profile partners?

In my opinion yes, yes, and yes. When it comes to platforms, developers are the users; and we don’t rely on our users to understand why or how to use our products. We have to show them.”

GUI shouldn’t be dismissed

Once upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information

There’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.

Tapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.

We love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.

Conversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.

Sure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.

Humans like talking to other humans

Aiming for a human dimension in business interactions makes sense.

If there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.

Facebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.

A conversation encompasses so much more than just text.

Humans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.

As HubSpot team pinpointed:

Bots provide a scalable way to interact one-on-one with buyers. Yet, they fail when they don’t deliver an experience as efficient and delightful as the complex, multi-layered conversations people are accustomed to having with other humans on messaging apps.

People aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).

And even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.

And here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.

But is that how humans prefer to interact with machines?

Not necessarily.

At the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.

Where do we go from here?

In a way, those early-adopters weren’t entirely wrong.

People are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.

Not even close.

Computers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.

Computers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.

That’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.

For now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.

But that’s not the whole story.

Yes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.

As Bill Gates once said:

We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. Don’t let yourself be lulled into inaction.

The hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.

I believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.

Messaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.

Developers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.

And I can’t wait to see what happens next.",https://cdn-images-1.medium.com/max/1200/1*-_um8Nai0uer46tni1LETg.jpeg,[],https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=topic_page---8------0----------------,2018-06-05 15:55:36.912000+00:00

Data visualisation,Google’s AutoML will change how businesses use Machine Learning,['George Seif'],"Google’s AutoML will change how businesses use Machine Learning

Google’s AutoML is a new up-and-coming (alpha stage) cloud software suite of Machine Learning tools. It’s based on Google’s state-of-the-art research in image recognition called Neural Architecture Search (NAS). NAS is basically an algorithm that, given your specific dataset, searches for the most optimal neural network to perform a certain task on that dataset. AutoML is then a suite of machine learning tools that will allow one to easily train high-performance deep networks, without requiring the user to have any knowledge of deep learning or AI; all you need is labelled data! Google will use NAS to then find the best network for your specific dataset and task. They’ve already shown how their methods can achieve performance that is far better than that of hand-designed networks.

AutoML totally changes the whole machine learning game because for many applications, specialised skills and knowledge won’t be required. Many companies only need deep networks to do simpler tasks, such as image classification. At that point they don’t need to hire 5 machine learning PhDs; they just need someone who can handle moving around and organising their data.

There’s no doubt that this shift in how “AI” can be used by businesses will create change. But what kind of change are we looking at? Whom will this change benefit? And what will happen to all of the people jumping into the machine learning field? In this post, we’re going to breakdown what Google’s AutoML, and in general the shift towards Software 2.0, means for both businesses and developers in the machine learning field.

More development, less research for businesses

A lot of businesses in the AI space, especially start-ups, are doing relatively simple things in the context of deep learning. Most of their value is coming from their final put-together product. For example, most computer vision start-ups are using some kind of image classification network, which will actually be AutoML’s first tool in the suite. In fact, Google’s NASNet, which achieves the current state-of-the-art in image classification is already publicly available in TensorFlow! Businesses can now skip over this complex experimental-research part of the product pipeline and just use transfer learning for their task. Because there is less experimental-research, more business resources can be spent on product design, development, and the all important data.

Speaking of which…

It becomes more about product

Connecting from the first point, since more time is being spent on product design and development, companies will have faster product iteration. The main value of the company will become less about how great and cutting edge their research is and more about how well their product/technology is engineered. Is it well designed? Easy to use? Is their data pipeline set up in such a way that they can quickly and easily improve their models? These will be the new key questions for optimising their products and being able to iterate faster than their competition. Cutting edge research will also become less of a main driver of increasing the technology’s performance.

Now it’s more like…

Data and resources become critical

Now that research is a less significant part of the equation, how can companies stand out? How do you get ahead of the competition? Of course sales, marketing, and as we just discussed, product design are all very important. But the huge driver of the performance of these deep learning technologies is your data and resources. The more clean and diverse yet task-targeted data you have (i.e both quality and quantity), the more you can improve your models using software tools like AutoML. That means lots of resources for the acquisition and handling of data. All of this partially signifies us moving away from the nitty-gritty of writing tons of code.

It becomes more of…

Software 2.0: Deep learning becomes another tool in the toolbox for most

All you have to do to use Google’s AutoML is upload your labelled data and boom, you’re all set! For people who aren’t super deep (ha ha, pun) into the field, and just want to leverage the power of the technology, this is big. The application of deep learning becomes more accessible. There’s less coding, more using the tool suite. In fact, for most people, deep learning because just another tool in their toolbox. Andrej Karpathy wrote a great article on Software 2.0 and how we’re shifting from writing lots of code to more design and using tools, then letting AI do the rest.

But, considering all of this…

There’s still room for creative science and research

Even though we have these easy-to-use tools, the journey doesn’t just end! When cars were invented, we didn’t just stop making them better even though now they’re quite easy to use. And there’s still many improvements that can be made to improve current AI technologies. AI still isn’t very creative, nor can it reason, or handle complex tasks. It has the crutch of needing a ton of labelled data, which is both expensive and time consuming to acquire. Training still takes a long time to achieve top accuracy. The performance of deep learning models is good for some simple tasks, like classification, but does only fairly well, sometimes even poorly (depending on task complexity), on things like localisation. We don’t yet even fully understand deep networks internally.

All of these things present opportunities for science and research, and in particular for advancing the current AI technologies. On the business side of things, some companies, especially the tech giants (like Google, Microsoft, Facebook, Apple, Amazon) will need to innovate past current tools through science and research in order to compete. All of them can get lots of data and resources, design awesome products, do lots of sales and marketing etc. They could really use something more to set them apart, and that can come from cutting edge innovation.

That leaves us with a final question…

Is all of this good or bad?

Overall, I think this shift in how we create our AI technologies is a good thing. Most businesses will leverage existing machine learning tools, rather than create new ones since they don’t have a need for it. Near-cutting-edge AI becomes accessible to many people, and that means better technologies for all. AI is also quite an “open” field, with major figures like Andrew Ng creating very popular courses to teach people about this important new technology. Making things more accessible helps people transition with the fast-paced tech field.

Such a shift has happened many times before. Programming computers started with assembly level coding! We later moved on to things like C. Many people today consider C too complicated so they use C++. Much of the time, we don’t even need something as complex as C++, so we just use the super high level languages of Python or R! We use the tool that is most appropriate at hand. If you don’t need something super low-level, then you don’t have to use it (e.g C code optimisation, R&D of deep networks from scratch), and can simply use something more high-level and built-in (e.g Python, transfer learning, AI tools).

At the same time, continued efforts in the science and research of AI technologies is critical. We can definitely add tremendous value to the world by engineering new AI-based products. But there comes a point where new science is needed to move forward. Human creativity will always be valuable.

Conclusion

Thanks for reading! I hope you enjoyed this post and learned something new and useful about the current trend in AI technology! This is a partially opinionated piece, so I’d love to hear any responses you may have below!",https://cdn-images-1.medium.com/max/1200/1*g9BzirXxUauRO9rA_tSvnA.jpeg,[],https://towardsdatascience.com/googles-automl-will-change-how-businesses-use-machine-learning-c7d72257aba9?source=topic_page---8------1----------------,2018-05-14 14:27:41.145000+00:00

Data visualisation,Automated Feature Engineering in Python – Towards Data Science,['William Koehrsen'],"First, let’s take a look at our example data. We already saw some of the dataset above, and the complete collection of tables is as follows:

Deep feature synthesis stacks multiple transformation and aggregation operations (which are called feature primitives in the vocab of featuretools) to create features from data spread across many tables. Like most ideas in machine learning, it’s a complex method built on a foundation of simple concepts. By learning one building block at a time, we can form a good understanding of this powerful method.

Fortunately, featuretools is exactly the solution we are looking for. This open-source Python library will automatically create many features from a set of related tables. Featuretools is based on a method known as “ Deep Feature Synthesis ”, which sounds a lot more imposing than it actually is (the name comes from stacking multiple features not because it uses deep learning!).

These operations are not difficult by themselves, but if we have hundreds of variables spread across dozens of tables, this process is not feasible to do by hand. Ideally, we want a solution that can automatically perform transformations and aggregations across multiple tables and combine the resulting data into a single table. Although Pandas is a great resource, there’s only so much data manipulation we want to do by hand! (For more on manual feature engineering check out the excellent Python Data Science Handbook ).

This process involves grouping the loans table by the client, calculating the aggregations, and then merging the resulting data into the client data. Here’s how we would do that in Python using the language of Pandas .

On the other hand, aggregations are performed across tables, and use a one-to-many relationship to group observations and then calculate statistics. For example, if we have another table with information on the loans of clients, where each client may have multiple loans, we can calculate statistics such as the average, maximum, and minimum of loans for each client.

we can create features by finding the month of the joined column or taking the natural log of the income column. These are both transformations because they use information from only one table.

A transformation acts on a single table (thinking in terms of Python, a table is just a Pandas DataFrame ) by creating new features out of one or more of the existing columns. As an example, if we have the table of clients below

The process of constructing features is very time-consuming because each new feature usually requires several steps to build, especially when using information from more than one table. We can group the operations of feature creation into two categories: transformations and aggregations . Let’s look at a few examples to see these concepts in action.

Feature engineering means building additional features out of existing data which is often spread across multiple related tables. Feature engineering requires extracting the relevant information from the data and getting it into a single table which can then be used to train a machine learning model.

If we have a machine learning task, such as predicting whether a client will repay a future loan, we will want to combine all the information about clients into a single table. The tables are related (through the client_id and the loan_id variables) and we could use a series of transformations and aggregations to do this process by hand. However, we will shortly see that we can instead use featuretools to automate the process.

Entities and EntitySets

The first two concepts of featuretools are entities and entitysets. An entity is simply a table (or a DataFrame if you think in Pandas). An EntitySet is a collection of tables and the relationships between them. Think of an entityset as just another Python data structure, with its own methods and attributes.

We can create an empty entityset in featuretools using the following:

import featuretools as ft

# Create new entityset

es = ft.EntitySet(id = 'clients')

Now we have to add entities. Each entity must have an index, which is a column with all unique elements. That is, each value in the index must appear in the table only once. The index in the clients dataframe is the client_id because each client has only one row in this dataframe. We add an entity with an existing index to an entityset using the following syntax:

The loans dataframe also has a unique index, loan_id and the syntax to add this to the entityset is the same as for clients . However, for the payments dataframe, there is no unique index. When we add this entity to the entityset, we need to pass in the parameter make_index = True and specify the name of the index. Also, although featuretools will automatically infer the data type of each column in an entity, we can override this by passing in a dictionary of column types to the parameter variable_types .

For this dataframe, even though missed is an integer, this is not a numeric variable since it can only take on 2 discrete values, so we tell featuretools to treat is as a categorical variable. After adding the dataframes to the entityset, we inspect any of them:

The column types have been correctly inferred with the modification we specified. Next, we need to specify how the tables in the entityset are related.

Table Relationships

The best way to think of a relationship between two tables is the analogy of parent to child. This is a one-to-many relationship: each parent can have multiple children. In the realm of tables, a parent table has one row for every parent, but the child table may have multiple rows corresponding to multiple children of the same parent.

For example, in our dataset, the clients dataframe is a parent of the loans dataframe. Each client has only one row in clients but may have multiple rows in loans . Likewise, loans is the parent of payments because each loan will have multiple payments. The parents are linked to their children by a shared variable. When we perform aggregations, we group the child table by the parent variable and calculate statistics across the children of each parent.

To formalize a relationship in featuretools, we only need to specify the variable that links two tables together. The clients and the loans table are linked via the client_id variable and loans and payments are linked with the loan_id . The syntax for creating a relationship and adding it to the entityset are shown below:

The entityset now contains the three entities (tables) and the relationships that link these entities together. After adding entities and formalizing relationships, our entityset is complete and we are ready to make features.

Feature Primitives

Before we can quite get to deep feature synthesis, we need to understand feature primitives. We already know what these are, but we have just been calling them by different names! These are simply the basic operations that we use to form new features:

Aggregations: operations completed across a parent-to-child (one-to-many) relationship that group by the parent and calculate stats for the children. An example is grouping the loan table by the client_id and finding the maximum loan amount for each client.

table by the and finding the maximum loan amount for each client. Transformations: operations done on a single table to one or more columns. An example is taking the difference between two columns in one table or taking the absolute value of a column.

New features are created in featuretools using these primitives either by themselves or stacking multiple primitives. Below is a list of some of the feature primitives in featuretools (we can also define custom primitives):

Feature Primitives

These primitives can be used by themselves or combined to create features. To make features with specified primitives we use the ft.dfs function (standing for deep feature synthesis). We pass in the entityset , the target_entity , which is the table where we want to add the features, the selected trans_primitives (transformations), and agg_primitives (aggregations):

The result is a dataframe of new features for each client (because we made clients the target_entity ). For example, we have the month each client joined which is a transformation feature primitive:

We also have a number of aggregation primitives such as the average payment amounts for each client:

Even though we specified only a few feature primitives, featuretools created many new features by combining and stacking these primitives.

The complete dataframe has 793 columns of new features!

Deep Feature Synthesis

We now have all the pieces in place to understand deep feature synthesis (dfs). In fact, we already performed dfs in the previous function call! A deep feature is simply a feature made of stacking multiple primitives and dfs is the name of process that makes these features. The depth of a deep feature is the number of primitives required to make the feature.

For example, the MEAN(payments.payment_amount) column is a deep feature with a depth of 1 because it was created using a single aggregation. A feature with a depth of two is LAST(loans(MEAN(payments.payment_amount)) This is made by stacking two aggregations: LAST (most recent) on top of MEAN. This represents the average payment size of the most recent loan for each client.

We can stack features to any depth we want, but in practice, I have never gone beyond a depth of 2. After this point, the features are difficult to interpret, but I encourage anyone interested to try “going deeper”.",https://cdn-images-1.medium.com/max/1200/1*lg3OxWVYDsJFN-snBY7M5w.jpeg,[],https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219?source=topic_page---8------2----------------,2018-06-02 15:01:18.755000+00:00

Data visualisation,My Phone Wants Me to Say ‘Thank You’ – When Robots Rule The World – Medium,['Evan Selinger'],"Sincerely Thankful

Perhaps there’s something infantilizing about our phones “wanting” us to say thanks. It’s hard to draw a firm line between what you would say if only you put in the time to say it versus what you do say after predictive software fills in the blanks. Seeing suggestions is itself a suggestive situation. And so, while Google emphasizes that smart reply is intelligent enough to figure out if you’re more of a “thanks!” than a “thanks.” person, the fact remains that it’s a good bet that some variation of the word will be frequently presented to you.

If being offered a “thanks” seems familiar, it’s because the act resembles what parents do when they try to instill etiquette. Let’s imagine that Lil’ Johnny receives a gift and instinctively wants to run off and play with it. Before this happens, one of his parents admonishes, “Johnny, what do you say?” And so, robotically, Johnny responds, “Thank you.”

At the time of being coached, Lil’ Johnny doesn’t mean what he parrots back. The gesture is insincere, and Johnny offers it to avoid conflict that would further delay what he really wants to do. That’s okay, though. The hope is that, over time, Lil’ Johnny becomes Big Johnny, the type of person who can genuinely experience gratitude and doesn’t simply follow rules like an automaton. The parental admonitions made during childhood are supposed to be like a pair of moral training wheels that kids ultimately outgrow.

Software like smart reply isn’t designed to provide adults with a second round of moral education. But if we mindlessly use such tools on a regular basis so we can quickly move on to do other things—things that we actually care about—our gestures will merely take the form of gratitude while lacking the underlying substance.

True gratitude must be sincere.

To be truly grateful, you have to mean what you say — that is, you must recognize that someone did something for you that deserves to be acknowledged, and you must sincerely want to make the acknowledgment.

Graciousness is a virtue. If an adult passes off insincere gratitude as the sincere variety in situations where people reasonably expect a person’s words and beliefs to align, the person is behaving worse than Lil’ Johnny. Lil’ Johnny is trying to be compliant, not deceptive.

We also shouldn’t lose sight of the fact that people who in engage in rituals like keeping gratitude journals aim to be specific when offering their appreciation. They don’t just say “thanks” or use any of the other minimalist formulations that smart reply offers. Instead, people who are pursuing lives filled with intentionality are concrete about what they are grateful for, as well as why they’re grateful for it. They want to focus on what they have rather than despair or obsesses over what they lack.",https://cdn-images-1.medium.com/focal/1200/632/51/50/1*MpyyWHuRUnanCenqeG3sHA.jpeg,[],https://medium.com/s/when-robots-rule-the-world/my-phone-wants-me-to-say-thank-you-122cc15952a9?source=topic_page---8------3----------------,

Data visualisation,"In 2018, Numbers Lie and Fictions Paint Truth – Eve Weinberg – Medium",['Eve Weinberg'],"In 2018, Numbers Lie and Fictions Paint Truth Why storytelling is our best tool in disambiguating fact from fiction

I’d love to share a few of the lecturers who touched upon this topic and forever changed my understanding of the 2018 landscape of fact, fiction, and storytelling’s role in deciphering one from the other.

This summer, I had the great privilege of attending EyeO (June 3–8 2018). Innumerable topics that encompass the intersection of Art, Technology, and Data were covered, but one common thread has left an imprint on my brain. That is: the Sisyphean 21st century task of disambiguating fact from fiction. That’s right…

PART 1: NUMBERS ARE MALLEABLE

On the first day, we discussed climate science at length. We (a very self aware room of liberal, number-crunching, data-visualization-making, coastal-living, self-ascribed nerds) attempted to break down the problems with human psychology. We looked at the facts, stats, charts, and graphs; then investigated the human power of denial, dissonance, disincentivization, and the hurdles of behavioral change. After 6 hours of discussion, ideation, and reflection, feeling a bit helpless, we ended with questions that I kept with me throughout the next 3 days of lectures:

Why don’t people believe statistics?

Are stories more powerful than numbers?

Why is denial more powerful than behavioral change?

Why do lies travel faster than truth?

…And what should we do about this?

The next day, Amanda Cox enlightened us with her talk These Lines Are The Same. She showed us that data, even in simple bar graphs, can be misinterpreted depending on the viewer’s own bias. She bravely revealed to us that in her department The Upshot at The New York Times they struggle with how to best represent datasets objectively. They experiment in meaningful and educational ways. In one example she showed data from the US unemployment report. The article allows readers to look at the chart with ‘Democratic Goggles’ and ‘Republican Goggles.’

The numbers are the same, but they can easily be bent to the will of anyone with an agenda.

Then she humorously showed us our flaws in clinging to round numbers. She drove the point home with a series of charts, one here showing the likelihood that someone in the ER gets checked for a heart attack, according to their age. As Amanda points out, “nothing radical changes from the age of 39-and-three-quarters and 40, yet here is the data:",https://cdn-images-1.medium.com/max/1200/1*bJ58aYiSmkeNYJY73AQN3w.jpeg,[],https://medium.com/@evejweinberg/in-2018-numbers-lie-and-fictions-paint-truth-ea1f5cdc9abe?source=topic_page---8------0----------------,2018-06-08 22:01:41.763000+00:00

Data visualisation,The Art of Ethereal: Bringing Cellarius to Life – Genesis Thought – Medium,['Mally Anderson'],"The Art of Ethereal: Bringing Cellarius to Life

Whose future is it? Hers, and his, and theirs, and ours.

A sampling of the Cellarius faction portraits from our Ethereal Summit pop-up.

On May 11 and 12, our parent company ConsenSys hosted the third Ethereal Summit at the Knockdown Center in Queens, New York and invited Cellarius to participate, along with many other spokes from our Mesh. The creators of Ethereal wanted to build a different kind of crypto conference. Since this one explored the intersection of blockchain and the arts, we wanted to showcase that aspect of our project and spread the word in an unexpected way. We set up shop in “The Crypt,” a semi-outdoor concrete space with a distinctive patina that felt perfect for the Cellarius blockpunk aesthetic.

The Knockdown Center’s very blockpunk Crypt space. We displayed some not-yet-published art commissions.

We teamed with some artists from a group called Drawn Together NYC: Boris Rasin, Michael Scarola, Derrick Dent, and Rosalind Bunting. Drawn Together’s talented roster of artists creates design concepts, multimedia experiences, and fine art solutions for a wide range of projects and businesses, and they understood what we are going for right away.

The artists of Drawn Together NYC, from left to right: Boris Rasin, Rosalind Bunting, Derrick Dent, and Michael Scarola.

Boris, Michael, and Derrick created custom, in-universe faction portraits of Ethereal attendees. The CX Universe Guide imagines that nation-states and traditional economies will break down after the Cellarius AI seizes control of Earth’s energy sources and communication channels in 2084. In the absence of familiar institutions and technologies, people will begin to form factions according to their allegiance to Cellarius. We wanted to get attendees thinking about their own relationships to technology and start dreaming up characters to explore in the Cellarius universe. So we posed the question: which faction do you think you would be?

Boris drew background art for four different factions:

The 4 faction backgrounds, clockwise from top left: Bucolic, Elite, Ad-Hoc, Homotranscendus.

Bucolic: Bucolics are AI skeptics who reject technology and live on the peripheries of megacities, observing from the outside and farming small pockets of fertile soil. Though their process is completely manual and their harvests are meager, they feel a great satisfaction from working with their own hands, in stark contrast to the highly automated farming processes elsewhere.

Ad-Hoc: Ad-Hocs live off the Cellarius grid and make their own augmentations and tools with scrap pieces they scavenge and rework. Comprised of mostly poor and marginalized groups, they use ingenuity and what little tech they can access to get by.

Elite: The crypto-Elites of the future are pro-Cellarius and experiment with AI and aesthetic enhancements. Living in the highest levels of the megacities, Elites have access to bleeding-edge technology. They are known for having lifespans beyond the normal range of humans, and enjoy the neural boost that comes with AI coupling.

Homotranscendus: During the Reformation, it wasn’t just the home habitat that was transformed forever, but also humankind itself. The campaign was more than just re-imagining the economic machinery of the planet Earth, but also a re-imagining of the of the human brain and body. Through Cellarius-engineered advancements, the next evolution of humanity was born: Homotranscendus. Homotranscendi are fully integrated with AI and no longer depend on their human forms to express consciousness and gather information.

We even got a portrait of ConsenSys’s own Joe Lubin, who wore a custom Cellarius Ethereal t-shirt design during his keynote address (thanks, Joe!). Something tells us that Joe would be a Homotranscendus.

Future Homotranscendus Joe Lubin on Mars.

Reimagining how familiar scenarios from your own life play out in a future setting or speculating about how you might react to a superintelligent AI’s takeover of the world is a great place to start inventing your own ideas in the world of Cellarius. We hope some attendees will be inspired to start making art and stories based on their portraits!

Every single Ethereal portrait, as arranged by our designer, Octavian.

As we’ve mentioned in previous posts, we are also commissioning works from artists we admire to create the first round of content for the Cellarius universe. We decided to commission a mural that would take shape over the two days of the Summit and give attendees a behind-the-scenes look at the process of making a large-scale landscape painting. The design depicts what the Knockdown Center might look like a century from now, in 2118. Visitors to the Crypt got a chance to watch Rosalind transform the canvas from a faint pencil sketch into an impressive and detailed final product:

Rosalind’s “Knockdown Center in 2118” painting took shape over two days.

Rosalind & Boris outlined the sketch first, then Rosalind added color, starting with the future-NYC background.

We hope that the Cellarius platform will allow experienced artists and creators to get directly in touch with their fan bases and share some glimpses of their artistic process, just as Rosalind did with her live painting.

The Drawn Together NYC artists got to learn more about the possibilities of blockchain and decentralization for creatives in the process of chatting with the attendees. Michael noted, “There were so many passionate and interesting people from all over the world that came through. And they had as much fun as we did learning about and playing in the Cellarius world.” Rosalind agreed: “Probably my favorite thing I learnt about over the Summit was how Cellarius involves the creative talents of so many more artists in their company, and loved seeing some of their amazing artwork. Can’t wait to see more!”

We were also excited that the long-term goals of the Cellarius project resonated with the Drawn Together NYC artists. Derrick said, “This was probably the coolest on-site portrait job I’ve ever worked on. I had a great time learning about the Cellarius project and the potential for a sprawling, community-shaped open sci-fi world. It was even cooler to have our portrait work used as an onboarding tool for visitors. People immediately took to creating their own story within this world, and that says a lot about how exciting this could be for folks who are creatively inclined.” We couldn’t have said it better ourselves.

As Boris told us, “The more I spoke to the pop-up team and event attendees about the concept behind this project, the more it occurred to me that this is a game changer. Cellarius and the other projects from ConsenSys are sure to revolutionize our ecosystem in ways we can’t even begin to comprehend. It’s a challenge to explain exactly what this project is, because the underlying platform allows for limitless opportunities of invention, inspiration, and collaboration. Cellarius is whatever its contributors will it to be, and frankly, that’s a fundamentally crazy idea!”

That’s just the point: blockchain enthusiasts can become artists and use storytelling to push the conceptual limits of technology. Artists can use the platform to explore the possibilities of decentralization and blockchain for sharing and protecting their work. We can build it together. Cellarius is whatever our community of contributors wills it to be.",https://cdn-images-1.medium.com/max/1200/1*vL8856P7cdV84CYM_SkF0A.jpeg,[],https://medium.com/genesis-thought/the-art-of-ethereal-bringing-cellarius-to-life-ba4ae31811e7?source=topic_page---8------1----------------,2018-06-08 16:46:47.896000+00:00

Data visualisation,The curious case of the vanishing & exploding gradient,['Eniola Alese'],"The curious case of the vanishing & exploding gradient

Understanding why gradients explode or vanish and methods for dealing with the problem.

Photo by SpaceX on Unsplash

In the last post, we introduced a step by step walkthrough of RNN training and how to derive the gradients of the network weights using back propagation and the chain rule. But it turns out that during this training the RNN can suffer greatly from two problems: 1. Vanishing gradients or 2. Exploding gradients.

Why Gradients Explode or Vanish

Recall the many-to-many architecture for text generation shown below and in the introduction to RNN post, lets assume the input sequence to the network is a 20 word sentence: “I grew up in France,…….. I speak French fluently.

We can see from the example above that for the RNN to predict the word “French” which comes at the end of the sequence, it would need information from the word “France”, which occurs further back at the beginning of the sentence. This kind of dependence between sequence data is called long-term dependencies because the distance between the relevant information “France” and the point where it is needed to make a prediction “French” is very wide. Unfortunately, in practice as this distance becomes wider, RNNs have a hard time learning these dependencies because it encounters either a vanishing or exploding gradient problem.

These problems arise during training of a deep network when the gradients are being propagated back in time all the way to the initial layer. The gradients coming from the deeper layers have to go through continuous matrix multiplications because of the the chain rule, and as they approach the earlier layers, if they have small values (<1), they shrink exponentially until they vanish and make it impossible for the model to learn , this is the vanishing gradient problem. While on the other hand if they have large values (>1) they get larger and eventually blow up and crash the model, this is the exploding gradient problem

Dealing with Exploding Gradients",https://cdn-images-1.medium.com/max/1200/0*UCn2LUkacEHQxgZW,[],https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb?source=topic_page---8------3----------------,2018-06-05 22:33:57.437000+00:00

Data visualisation,How to ensure the safety of Self-Driving Cars: Part 2/5,['Jason Marks'],"How to ensure the safety of Self-Driving Cars: Part 2/5

There’s an ongoing battle between LiDAR, Automotive Radar, and Cameras (and a few others too) for the title of the self-driving car’s “eyes:”

Figure 1: McKinsey&Company Evaluation of Autonomous Vehicle Sensors

Figure 2: National Instruments Visual of ADAS Sensors

But self-driving car do more than just “see” the world. The cars also are equipped with sensors onboard that can tell the vehicle more about the surrounding world and itself. These sensors tell how fast the car is moving; the G-force acceleration experienced by the vehicle in forward-back, side-to-side, and up-and-down directions; the current steering angle; and lots more. It is a combination of these perception systems (camera, LiDAR, Radar) and sensor systems (GPS, IMU, Wheel Speed, etc) that make up the inputs to the “sense” block of the self-driving car AV stack.

Part 2: How well can a self-driving car sense the world?

Often included in the “sense” block of the AV Stack is the integration of all of the sensors, which let’s the vehicle make determinations about the environment. Examples include “there’s a pedestrian coming out of the bushes on the left side at 3 mph towards the vehicle,” or “it’s nighttime and raining,” or even “the vehicle is driving up a 10% hill while turning at a 3-degree angle.” The integration of sensors together is called “sensor fusion,” and the determination of what is going on in the environment is called many things, but commonly referred to as “Scene Understanding.”

There is a huge industry focus on developing this layer of the AV Stack. Engineers want the car to be able to see and understand the world with the “intelligence” of humans. Some of the most brilliant people are working on software algorithms that fall under the “Artificial Intelligence,” “Machine Learning,” and “Deep Learning” buckets to allow the car understand what it sees:

So, with all of these sensors and algorithms, how can we be sure that everything’s working correctly? We break each component or some grouping of the components into their inputs and outputs and verify they are doing what they were intended to do. We run tons of tests to get a bunch of data, and then run statistics on that data to prove with some confidence, that the component or group functions correctly.

Below we will break down each of the components and determine how we verify them.

Cameras

Most camera testing is done at the company that makes the camera. A camera is fundamentally a sensor that grabs a bunch of color points in space and arranges them into an image, often referred to as an image array. This image array is converted into a digital signal and is passed along to the hardware that does sensor fusion and scene understanding. Camera technology is fairly mature, and the processes for verifying that the camera converts the right picture to digital lines is well understood, so it should not be an area of concern for autonomous vehicles.

LiDAR

LiDAR systems for autonomous vehicles are relatively new, with the first player, Velodyne, only really demonstrating this capability in 2005 at the first DARPA Grand Challenge. LiDAR technology is quickly evolving, with the goal to make the LiDAR sensor economical and compact. With this technology shift, companies making LiDAR systems are having to adjust the ways they verify their systems.

LiDAR is a laser-light point-and-shoot methodology for sensing the world. A transmitter spits out a bit of light, waits for that light to bounce off an object, and since it knows how fast light travels, can determine how far away that object is by determining the time that’s passed between sending out that light and receiving it. LiDAR units can broaden their field of view by using a bunch of lasers that spin around in a circle, or more recently, as a stationary bunch of lasers that spread out along a field of view, called “Solid State LiDAR.” After all the light is received, the LiDAR system sends an array of direction and distance information back to the hardware for sensor fusion and scene understanding, referred to as a “point cloud.”

In order to verify the LiDAR system acts appropriately, an engineer can setup an artificial scene with predetermined objects a known distance away and verify the results of the LiDAR. More advanced test methodologies involve having another light source feed in light to the LiDAR being tested with a time-based pattern that represents a known field of view, and then the Engineer can compare the results of the LiDAR with the known, simulated environment. This type of testing is called “Hardware in the Loop” since there is a test system that simulates a known stimulus to the hardware under test, and the feedback from that hardware goes back to the test system, making a “loop.”

There are many more ways engineers verify the correct functionality of the LiDAR system, including stress testing the unit at various weather conditions, and ensuring that it functions appropriately with different electrical signals going to and from the unit. In all, this is can be a very involved procedure, and engineers picking LiDAR systems for their self-driving cars should do their research before selecting a unit. Suppliers will provide data on the life expectancy, accuracy, and failure expectations of their units, but engineers putting LiDAR systems in vehicles must perform their own safety tests as well.

Radar

Radar has been around forever. It is similar to LiDAR in that it is a “point-and-shoot” technology, but uses radio, or electromagnetic, waves to do this. Radar lends itself well to long-distance object detection but is not typically very precise.

So how do you test this thing? Well, it’s just like LiDAR, but since the RADAR technology is less expensive and better understood, some companies are already creating tools for this purpose:

Again, engineers need to work with Radar suppliers to make sure they stringently test their devices and that those engineers again retest the unit once it’s onboard their vehicle.

Vehicle Sensors

Vehicle sensors have been built into cars for quite some time, but only since 1993 did the International Organization of Standardization (ISO) determine that the way a sensor talks to a car will be through a digital 2-wire protocol developed by Robert Bosch Gmbh called the “CAN Bus:”

Figure 5: CAN Bus, CSS Electronics

Sensors that sit on the CAN bus are plentiful. They include accelerometers, Internal Measurement Units (IMUs), Vehicle speed sensors, wheel sensors, joint angle sensors, tire pressure, and many, many more. The ISO (ISO 11898) standard is what ensures that the makers of these sensors are verifying their sensors before they ship to a customer.

If you’re retrofitting a vehicle for automation, you’ll need to plug into that CAN bus and make sure you’re able to decipher the signals and send your own. After all, the vehicle must read these signals to operate appropriately. In a “Drive By Wire” (DBW) vehicle, there are no manual, only digital, connections between the accelerator, brake, or steering wheel and the engine and wheels. The CAN bus is what communicates the intentions of the driver to the vehicle.

If you’re building an autonomous vehicle from the ground up, you’ll need to ensure the appropriate selection and mounting of sensors. This must also be verified by driving the vehicle or simulating a drive with HIL testing, and then analyzing the results from the sensors. Same goes for any additional sensors added to an existing vehicle.

What if one of the sensors is off?

Here’s where the engineers again need to step in. Their algorithms onboard the sense layer must do a sanity check of the sensors at some predetermined interval. Adjustments should be made if necessary. There should also be some redundancy in the sensors.

If one of the sensors malfunctions or disconnects, or if your vehicle is struck and a camera moves, what happens? Well, if the system “self-calibrates,” its sensors, this should catch some of these issues. Otherwise, the system may just need to send a command to the rest of the software stack that a sensor is malfunctioning, and the rest of the AV stack can decide what to do.

Engineers need to make sure that the decision on how to handle a malfunctioning sensor is correct. Like how LiDAR is tested, an engineer can send simulated signals to the sensor fusion hardware that represent a failure of a sensor and see how the system responds (HIL). Even before that happens though, the engineer can send simulated data in software to the segment of code on a development environment to see how that code responds. This method of testing is called “Software-in-the Loop” or SIL, testing because the program that’s testing the code sends data to the software being tested and gets a response back, again making a “loop.”

All these tests are run under various conditions and a ton of data is produced. That data is categorized, labeled, and analyzed to provide a statistical determination about how well the vehicle recognized the sensor failure and how it responded.

Scene Understanding: Static or Semi-Static Objects

Ah more software running on hardware to test! The software for scene understanding can be quite complex and can even be a “black box” to many engineers developing it. Regardless, it is up to these engineers to be sure that it’s objectively safe.

An engineer testing scene understanding will verify the software at many times during development. They can even split parts of the scene, such as first checking “is there an object” then “what is that object” and even then “what does that mean for me?”

Thousands of simulations with images, LiDAR data, and Radar data can be fed in software to the scene understanding to check that the scene is correct. Often, this requires a set of “Training data” where the result is already well known (that’s a dog). A bunch of data is then analyzed, and again a statistical probability that the scene understanding was correct is provided.

Engineers can take this one step further by simulating camera, LiDAR, and Radar signals to the sensors on the vehicle and testing if the scene understanding system got the scene correct. This is the HIL approach.

To test scene understanding, engineers need tons of images and point clouds. A single one of these images takes up significant space, so a car operating in real-time would fill 4 TB of data in an hour and a half, equivalent to 250 Million pages of paper, or 83 days of watching DVDs straight (source).

Figure 6: Intel Car Data (Source)

As you can imagine, managing all this data for testing a vehicle is a big challenge. But engineers are working through this and can provide stats on just how good their scene understanding algorithms are. This should inspire the public.

Scene Understanding: Dynamic and Real-Time Objects

This is just like static objects, but now you need multiple back-to-back images and point cloud information to understand how objects are moving in space. So not only do you need to correctly identify objects, you need to know how they’re moving and where they will likely be next based on physics and reasoning. This can be especially challenging.

Just like for static data, engineers must simulate environments that are dynamic with SIL and HIL and prove the scene understanding made the right prediction. You now need series of images over time and you need to test this quite stringently, because head-on-collisions with another moving body can be deadly.

Luckily, engineers are figuring this one out too, but they need more and more data. For some of these challenges, the algorithms that engineers use are not fully mature, but there’s daily progress on that front. This is one the public should be keenly aware of.

Scene Understanding: Vehicle-Road Scenario

OK, so now you’re confident the robot “driver” of the vehicle sees the road correctly. What else does it need to do? Well, it needs to figure out the scenario of the car in space at any given time. You as a driver do this all the time. You can easily tell if you’re going up or down a hill, if you’re in a turn or going straight, or if the roads are covered in snow or clear. More complex things you may pick up on are being sucked into the back of your chair, or forced towards the windshield, or swaying off to the side based on the Gs the vehicle is imparting on you.

A vehicle can figure out all these thing by sensor fusion. It can read the linear acceleration from the IMU and tell the angle of the car and how fast it’s pitching forward/back, rolling side-to-side, or yawing through a turn.

Figure 7: SAE Axis System

A combination of perception and acceleration information can tell the inclination or bank of the road, even dips and crests. Perception and wheel speed vs vehicle speed allows the vehicle to guess the coefficient of friction between the road and tires (albeit, this one can be quite challenging).

Since we trust the sensors already, we test the ability to understand the road by simulating data to the software that represents certain road conditions (SIL), by sending simulated signals to the sensors that represents road conditions (HIL), and even by putting the vehicle on a jig, called a chassis dynamometer, and verifying the results the system spits out:

Figure 8: Meidensha Chassis Dyno (Source)

For this one, there is no ISO standard, and the Society of Automotive Engineers (SAE) have not recommended an approach to take to guarantee that the vehicle knows itself. Many autonomous vehicle companies are relying on only the perception and GPS map information to provide this information. Vehicle makers will need to get better at this in the future to ensure the safety of the vehicles, and this will be especially evident when we discuss path planning.

The Hardware that hosts the Stack

There’s another ongoing battle about the appropriate hardware to host all this software described above. Some of the many players in the game are the CPU, GPU, FPGA, ASIC, TPU, IPU, MCU, etc. They have their tradeoffs, and some of them can be loosely described by this image:

Figure 9: Silicon Alternatives (Source)

In today’s (2018) world of self-driving-car prototypes, we see most cars built using a combination of CPUs and GPUs. Though in the future, this will likely be some combination of the hardware contenders:

Figure 10, 11, 12: Adrian Colyer (Source)

So, what needs to be tested in hardware? Well, in the images above, you see a metric called “Latency” and a metric called “Power.” Latency is how long it took to for the software on the hardware to make a decision. You want to minimize this. “Power” is how much electrical energy it took to make that decision. You want to minimize this as well, because more power consumption means you can drive the car less distance, whether it’s a gas or electric vehicle. Certain decisions are higher priority than others, as we’ll also discuss in Part 3 and Part 4. For example, you need to know if there’s an emergency scenario immediately, but you may only need to check on the temperature of the outside air every couple of seconds, since temperature changes much more slowly.

You test both latency and power by giving the hardware a “load,” or some task to do while you watch it perform. You measure how much voltage and current that task consumes, and you multiply them together to get Power. You also benchmark how long it took each task to complete and you log that too.

Latency can be a double-edged sword though. You may have two pieces of hardware where one runs much faster than the other 90% of the time, but 10% of the time runs slower. The other piece of hardware always runs at the exact same time through all tests. The amount of variation in latency is called determinism. What you need for a mission-critical task is a low-latency, deterministic system. You can offload non-mission-critical items to things with higher latency and/or non-deterministic systems, ideally that consume the minimal power possible.

So, an engineer must make the right decision on the hardware selection and test it themselves to make sure they get the response they need while consuming the smallest amount of power. Lots of data again!

Conclusion

So where does this leave us? Well, it should be clear that some combination of SIL, HIL, and real-world testing is required to make sure the sensing system works appropriately. It should be also clear that to do this requires massive amounts of data, a ton of time, and a bunch of tools to help the engineers navigate all this. Some of the tests are standardized, others are not. For us to be sure the vehicle senses the world correctly, we’re going to rely on this process improving over time where each element is objectively better than a human driver.",https://cdn-images-1.medium.com/max/1200/1*ebuUG7HWL0v594-yDp46Kg.jpeg,[],https://medium.com/@olley_io/how-to-ensure-the-safety-of-self-driving-cars-part-2-5-b4eafb067534?source=topic_page---8------4----------------,2018-06-05 18:25:54.142000+00:00

Data visualisation,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------,2018-06-08 22:25:33.341000+00:00

Data visualisation,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------#--responses,2018-06-08 22:25:33.341000+00:00

Data visualisation,How to build a range slider component in React from scratch using only <div> and <span>,['Rajesh Pillai'],"How to build a range slider component in React from scratch using only <div> and <span>

In this article we will build a React range slider component step by step using only <div>. We will enable it with touch support.

What can you do with a piece of about 50 <div’s>?

Build a slider control from scratch. If this sounds interesting, then follow along.

The final output will look like the below animation.

Please do note that I have developed this component as a teaching exercise for my students of ReactJS — Beyond the Basics course on Udemy, so it may have some edge cases (which I will fix as and when encountered).

You could use an HTML5 range control and customize it. But I wanted to take a different approach and build something from scratch. And the result is what you see here.

Our slider component will be composed of the below three elements:

A slider range

The actual slider controls

The current selection range

Defining the state for our component

Let us begin by defining our state. I am only showing you the important part of the code. For the full source code, please refer to the link at the end of the article.

state = {

slots: 24,

start: 0,

end: 10,

labelMode: ""mid"", // mid, long

}

The state contains the following properties.

slots: Total slots to be drawn (in this case I am using it as a time selector, so it will have 24 hour slots)

start: The start value of the selection

end: The end value of the selection

labelMode: Currently unused. But can be used to customize the scale label rendering.

The return part of the render method

Let us now take a look at the return part of the render method. The render() method will be slowly composed of small pieces of functionality.

return (

<div>

<h2>React Slider</h2>

<div className=""example-1"">

<div className=""slider-container"">

<div className=""slider-scale"">

{scale}

</div>

<div className=""slider"">

{slider}

</div>

<div className=""slider-selected-scale"">

{currentScale}

</div>

</div>

</div>

</div>

);

For those reading on mobile, the below image may be handy, as sometimes Medium breaks the code formatting.

If you take a look at the code, there are only three important pieces:

scale variable

slider variable

currentScale variable

The three variables above will be responsible for rendering the correct parts of the overall slider.

Dissecting the render () method

Let us initialize some variables. The scale , slider and currentScale JSX will be created within the for loop defined below.

render () {

let scale = [];

let slider=[];

let currentScale = [];

let minThumb = null;

let maxThumb = null

..... // rest of the code

}

Create the JSX for the ‘scale’ variable

Creating the JSX for the scale variable is quite simple. We just loop through the slots value in the state and push a <div> to the scale array with the required CSS class for styling.

The if condition ensures that we are only printing the label for i = 0, i = 12, or i = 24 (kind of mid range). Please feel free to customize this.

for (let i = 0; i <= this.state.slots;i++) {

let label = """";



if (i == 0 || i == 12 || i == 24) {

label = i;

}



scale.push(

<div

key={i}

className=""slot-scale"">

{label}

</div>

);

Here’s the code in image format:

Create the JSX for the ‘currentScale’ variable

Let us now continue with the same for loop and create the ‘currentScale’ JSX. We are still within the same for loop, so about 24 divs will be created as per the value in this.state.slots value.

The currentScale has a class of ‘slot-scale-selected’.

let currentLabel = """";



if (i === this.state.start || i === this.state.end) {

currentLabel = i;

}



currentScale.push(

<div

key={i}

className=""slot-scale-selected"">

{currentLabel}

</div>

);

The code is pretty similar to the ‘scale’ JSX that we created.

Create the JSX for the ‘slider’ variable

Let us write a function to render the ‘slider’ jsx. The slider needs two thumbs, one for min, and one for max.

Let us first initialize the thumb variable depending on the ‘i’ value. If ‘i’ is the same as this.state.start, then we set the minThumb variable. Else if the value of ‘i’ is the same as this.state.end, then we initialize the maxThumb variable.

if (i === this.state.start) {

minThumb = <this.MinSlider />

} else if (i === this.state.end) {

maxThumb = <this.MaxSlider />

} else {

minThumb = null;

maxThumb = null;

}

Create the JSX for the ‘slider’

The important code piece here is the dragover event. This is required for the HTML drop to work correctly.

let lineClass = ""line"";



if (i >= this.state.start && i < this.state.end) {

lineClass += "" line-selected"";

}

slider.push(

<div

data-slot={i}

onDragOver={this.onDragOver}

onTouchMove = {this.onDragOver}

onTouchEnd = {this.onDrop}

onDrop = {this.onDrop}

key={i}

className=""slot"">

<div data-slot={i} className={lineClass}/>

<span className=""scale-mark""></span>

{minThumb}

{maxThumb}

</div>

);

The slider variable needs two additional pieces of features to represent the min and the max thumb on the slider.

The slider JSX has additional event handlers to deal with handling the drop event/touchend event. We will take a look at the event handlers shortly.

The ‘lineClass’ styles/renders the line on the slider, and the ‘line-selected’ class styles the currently selected range.

Let us now write the MinSlider and MaxSlider function outside the render method.

The MinSlider () function to render the min thumb

Let’s take a look at the code. The important props are the events related to drag and the draggable attribute. The draggable attribute will make this element draggable.

We are also adding the touch event handler. Refer to the link at the bottom of the article to add touch support polyfill for the HTML5 API.

MinSlider=()=> {

return (

<div data-slider=""min""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-min"">

</div>

);

}

The MaxSlider () function to render the min thumb

The MaxSlider is almost the same as the MinSlider except for the data and the className.

MaxSlider=()=> {

return (

<div data-slider=""max""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-max"">

</div>

);

}

The code image is given below for reference.

Event Handling

Let us now look at the drag/touch event handlers defined within our <div> to control the movement of the slider element.

dragover:

The dragover event is required to support the drop zone when using the HTML5 drag/drop API. The only thing we need to do here is to invoke the preventDefault on the event object.

onDragOver = (e) => {

e.preventDefault();

}

dragstart:

The dragstart enables us to store which slider is being dragged. Please note that I am not using the dataTransfer object here, but simply using an instance variable to store this.

onDragStart = (e) => {

let slider = e.target.dataset.slider;

this.sliderType = slider;

}

The value of e.target.dataset.slider is either “min” or “max,” indicating which slider is being dragged.

ondrop:

The ondrop event captures where the thumb is being dropped (on which scale).

This is the important flow in the ondrop event:

Grab the source (whether min/max thumb)

Get the slot (where the drop happens)

Validations

Update the slot (in the state)

Reset the sliderType.

onDrop = (e, target) => {

let source = this.sliderType;

let slot = Number(e.target.dataset.slot);



if (isNaN(slot)) return;



if (source === ""min"") {

if (slot >= this.state.end) return;

this.setState({

start: slot

},()=>{

console.log(this.state);

})

} else if (source === ""max"") {

if (slot <= this.state.start) return;

this.setState({

end: slot

},()=>{

console.log(this.state);

})

}

this.sliderType = null;

}

The complete source code/and demo can be seen here http://jsbin.com/remodat/edit?output

Since I am using HTML5 drag and drop features to add touch, support please add this polyfill reference to your html file.

Todos

Extract the logic to a separate Component class

Test it and and add customization.

History

21-May-2018 — First release

P.S: This component is a result of a very quick coding attempt. This will be refactored.

Promotion: If you would like to support our open source curriculum Mastering Full Stack Engineering in 12 to 20 weeks then here is a special 10$ coupon for medium readers for my upcoming live ReactJS-Beyond the basicscourse on udemy (MEDIUM_500 is the coupon code, which is already tagged in the above URL)",https://cdn-images-1.medium.com/max/1200/1*iSkeoPHBQubtAL4fV4h9xQ.png,[],https://medium.freecodecamp.org/how-to-build-a-range-slider-component-in-react-from-scratch-using-only-div-and-span-d53e1a62c4a3?source=collection_home---6------1----------------,2018-06-08 21:41:33.808000+00:00

Data visualisation,The well-kept secret behind great UX: Usability Testing,['Anant Jain'],"The well-kept secret behind great UX: Usability Testing

Whether you only have a prototype or a full-fledged product, it’s a really good idea to run monthly usability tests. These make sure that whatever you’re working on is usable and the user experience is excellent.

If you’re wondering what you can do to make your usability tests more structured and organized, this guide is for you. Let’s get started!

First off, always keep the two Golden Rules of Usability Testing in mind:

Any testing is better than no testing (with no one!) A little testing earlier is better than a lot of testing later.

In this post, I will introduce you to the kind of lightweight usability testing described in Steve Krug’s books, “Don’t Make Me Think” and “Rocket Surgery Made Easy.” Steve calls this kind of testing “Do-It-Yourself Usability Testing” since it’s supposed to be cheap, easy-to-do and takes just a morning a month.

A quick intro to usability testing

The idea behind this is to:

Find a few participants

Ask them to come in and go through a list of user flows you want to test

Observe the problems they run into

Finally, make a list of issues to fix

Sounds simple enough, but very few of us actually do it. The goal of this post is to make you confident enough to run at least one usability test session this month. I ran my first usability test only a year ago, and I must say it’s actually a lot of fun!

Before we get to the test itself, here are a few things to note:

Reserve one morning a month (say the third Thursday every month) for a round of testing, debriefing, and deciding what to fix. Test with three participants each round. Recruit loosely, and grade on a curve. You don’t need to find someone who fits the exact mould of your ideal user, since most usability problems can be uncovered by testing with just about anyone. If you are part of a big company and have the budget, you can recruit via Craigslist and offer a $50 gift card for an hour of the participant’s time. If you don’t have those kind of resources, don’t worry — you can ask your friends, your existing users, or even go to a café and ask strangers for 15 minutes of their time in exchange for buying them a coffee. If you’re doing this as part of a bigger team, get as many observers as possible to observe the tests in a separate observation room. These will be the designers, engineers, project managers, executives, etc. Or, in case of side projects, it’ll be just be you later in your room!

What happens during the test?

During a usability test, you will record the participant’s voice and their computer screen, and share both these streams live with observers in another room. A typical one-hour test can be broken down into:

Welcome (4 mins): Explain how the test will work so that the participant will know what to expect. The questions (2 mins): Ask the participant a few questions about themselves. This helps put them at ease and gives you an idea of how computer-savvy they are. The Homepage tour (3 mins): Open the Home page of your site, and ask the participant to look around and tell you what they think. This will give you an idea of how easy it is to understand your home page, as well as how familiar the participant is with your domain. The tasks (35 minutes): Watch the participant perform a series of tasks you have prepared for them beforehand. If you’re building a SaaS product and you’re testing out your subscription flow, a typical task could be to find the Pricing page, compare various plans, and Subscribe to one of the plans with a provided test credit card number. Encourage the participant to think out loud as they perform the task (see the video at the end of the post for a sample test.) It’s crucial that you let them work on their own and not ask them any leading questions, or give out any clues or assistance. Probing (5 mins): Ask the participant any questions you may have about anything that happened during the test and about any issues that people in the observation room may have. Also, answer any questions that the participant may have at this point (don’t answer them during the actual tasks since you’re testing how they’ll perform with no one around.) Wrapping Up (5 mins): Thank them for their help, and give them their gift card if you promised one while recruiting them.

The debrief

During the breaks between successive tests, ask the observers to write down the top 3 usability problems that they saw. During the debriefing, focus ruthlessly on deciding to fix the most severe problems first. Here are a few other recommendations:

Keep a separate list of low-hanging fruit. These are the problems you can typically fix with one-line code changes, but have a huge impact on task completion rates. Joel Califa calls them “tiny wins”. Here’s an example:

Resist the impulse to add things — instead, try to tweak your existing design to fix the problem.

to fix the problem. Take “new feature” requests with a grain of salt. Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature.

Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature. Ignore the problems where the user goes astray for a bit but comes back on track by themselves. These are usually not worth investing much time unless you see a pattern across multiple participants.

Good design is a delicate balance, so when fixing a problem, ensure that you aren’t introducing new ones.

Remote testing and unmoderated user testing

Remote testing is very similar to an in-person usability test, except that the participant is at their home/office and you conduct the testing via screen sharing and voice call.

Unmoderated user testing is another way to test, where you specify your website, the tasks you want the users to do, and get back video recordings of people trying to accomplish those tasks. Usertesting.com is the leader in this space, but note that a single 30-minute test costs about $50.

Resources

You can download checklists, interview script, consent form, and a demo video at Steve Krug’s site here: Downloads for Rocket Surgery Made Easy.

Here’s a Usability Test demo video from Google Ventures:

I want to thank you for reading this quick guide. This was originally published as part of the UX Design course on Commonlounge, a platform that has courses with small bite-sized lessons like these on topics ranging from Project Management to Machine Learning that deliver the most value for the time you put in.

You learn by working on real-world projects and getting feedback from industry mentors. You should check it out here!",https://cdn-images-1.medium.com/max/1200/0*UWxJWKKNLXR5c1cm,[],https://medium.freecodecamp.org/the-well-kept-secret-behind-great-ux-usability-testing-b788178a64c3?source=collection_home---6------2----------------,2018-06-08 21:25:31.335000+00:00

Data visualisation,A deep dive into part-of-speech tagging using the Viterbi algorithm,['Sachin Malhotra'],"Welcome back, Caretaker!

In case you’ve forgotten the problem we were trying to tackle in the previous article, let us revise it for you.

So there’s this naughty kid Peter and he’s going to pester his new caretaker, you!

As a caretaker, one of the most important tasks for you is to tuck Peter in bed and make sure he is sound asleep. Once you’ve tucked him in, you want to make sure that he’s actually asleep and not up to some mischief.

You cannot, however, enter the room again, as that would surely wake Peter up. All you can hear are the noises that might come from the room.

Either the room is quiet or there is noise coming from the room. These are your states.

All you have as the caretaker are:

a set of observations, which is basically a sequence containing noise or quiet over time, and

or over time, and A state diagram provided by Peter’s mom — who happens to be a neurological scientist — that contains all the different sets of probabilities that you can use to solve the problem defined below.

The problem

Given the state diagram and a sequence of N observations over time, we need to tell the state of the baby at the current point in time. Mathematically, we have N observations over times t0, t1, t2 .... tN . We want to find out if Peter would be awake or asleep, or rather which state is more probable at time tN+1 .

In case any of this seems like Greek to you, go read the previous article to brush up on the Markov Chain Model, Hidden Markov Models, and Part of Speech Tagging.

The state diagram that Peter’s mom gave you before leaving.

In that previous article, we had briefly modeled the problem of Part of Speech tagging using the Hidden Markov Model.

The problem of Peter being asleep or not is just an example problem taken up for a better understanding of some of the core concepts involved in these two articles. At the core, the articles deal with solving the Part of Speech tagging problem using the Hidden Markov Models.

So, before moving on to the Viterbi Algorithm, let’s first look at a much more detailed explanation of how the tagging problem can be modeled using HMMs.

Generative Models and the Noisy Channel Model

A lot of problems in Natural Language Processing are solved using a supervised learning approach.

Supervised problems in machine learning are defined as follows. We assume training examples (x(1), y(1)) . . . (x(m) , y(m)) , where each example consists of an input x(i) paired with a label y(i) . We use X to refer to the set of possible inputs, and Y to refer to the set of possible labels. Our task is to learn a function f : X → Y that maps any input x to a label f(x).

In tagging problems, each x(i) would be a sequence of words X1 X2 X3 …. Xn(i) , and each y(i) would be a sequence of tags Y1 Y2 Y3 … Yn(i) (we use n(i)to refer to the length of the i’th training example). X would refer to the set of all sequences x1 . . . xn, and Y would be the set of all tag sequences y1 . . . yn. Our task would be to learn a function f : X → Y that maps sentences to tag sequences.

An intuitive approach to get an estimate for this problem is to use conditional probabilities. p(y | x) which is the probability of the output y given an input x. The parameters of the model would be estimated using the training samples. Finally, given an unknown input x we would like to find

f(x) = arg max(p(y | x)) ∀y ∊ Y

This here is the conditional model to solve this generic problem given the training data. Another approach that is mostly adopted in machine learning and natural language processing is to use a generative model.

Rather than directly estimating the conditional distribution p(y|x) , in generative models we instead model the joint probability p(x, y) over all the (x, y) pairs.

We can further decompose the joint probability into simpler values using Bayes’ rule:

p(y) is the prior probability of any input belonging to the label y.

is the prior probability of any input belonging to the label y. p(x | y) is the conditional probability of input x given the label y.

We can use this decomposition and the Bayes rule to determine the conditional probability.

Remember, we wanted to estimate the function

f(x) = arg max( p(y|x) ) ∀y ∊ Y

f(x) = arg max( p(y) * p(x | y) )

The reason we skipped the denominator here is because the probability p(x) remains the same no matter what the output label being considered. And so, from a computational perspective, it is treated as a normalization constant and is normally ignored.

Models that decompose a joint probability into terms p(y) and p(x|y) are often called noisy-channel models. Intuitively, when we see a test example x, we assume that it has been generated in two steps:

first, a label y has been chosen with probability p(y) second, the example x has been generated from the distribution p(x|y). The model p(x|y) can be interpreted as a “channel” which takes a label y as its input, and corrupts it to produce x as its output.

Generative Part of Speech Tagging Model

Let us assume a finite set of words V and a finite sequence of tags K. Then the set S will be the set of all sequence, tags pairs <x1, x2, x3 ... xn, y1, y2, y3, ..., yn> such that n > 0 ∀x ∊ V and ∀y ∊ K .

A generative tagging model is then the one where

2.

Given a generative tagging model, the function that we talked about earlier from input to output becomes

Thus for any given input sequence of words, the output is the highest probability tag sequence from the model. Having defined the generative model, we need to figure out three different things:

How exactly do we define the generative model probability p(<x1, x2, x3 ... xn, y1, y2, y3, ..., yn>) How do we estimate the parameters of the model, and How do we efficiently calculate

Let us look at how we can answer these three questions side by side, once for our example problem and then for the actual problem at hand: part of speech tagging.

Defining the Generative Model

Let us first look at how we can estimate the probability p(x1 .. xn, y1 .. yn) using the HMM.

We can have any N-gram HMM which considers events in the previous window of size N.

The formulas provided hereafter are corresponding to a Trigram Hidden Markov Model.

Trigram Hidden Markov Model

A trigram Hidden Markov Model can be defined using

A finite set of states.

A sequence of observations.

q(s|u, v)

Transition probability defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations.

defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations. e(x|s)

Emission probability defined as the probability of making an observation x given that the state was s.

Then, the generative model probability would be estimated as

As for the baby sleeping problem that we are considering, we will have only two possible states: that the baby is either awake or he is asleep. The caretaker can make only two observations over time. Either there is noise coming in from the room or the room is absolutely quiet. The sequence of observations and states can be represented as follows:

Observations and States over time for the baby sleeping problem

Coming on to the part of speech tagging problem, the states would be represented by the actual tags assigned to the words. The words would be our observations. The reason we say that the tags are our states is because in a Hidden Markov Model, the states are always hidden and all we have are the set of observations that are visible to us. Along similar lines, the sequence of states and observations for the part of speech tagging problem would be

Observations and States over time for the POS tagging problem

Estimating the model’s parameters

We will assume that we have access to some training data. The training data consists of a set of examples where each example is a sequence consisting of the observations, every observation being associated with a state. Given this data, how do we estimate the parameters of the model?

Estimating the model’s parameters is done by reading various counts off of the training corpus we have, and then computing maximum likelihood estimates:

Transition probability and Emission probability for a Trigram HMM

We already know that the first term represents transition probability and the second term represents the emission probability. Let us look at what the four different counts mean in the terms above.

c(u, v, s) represents the trigram count of states u, v and s. Meaning it represents the number of times the three states u, v and s occurred together in that order in the training corpus. c(u, v) following along similar lines as that of the trigram count, this is the bigram count of states u and v given the training corpus. c(s → x) is the number of times in the training set that the state s and observation x are paired with each other. And finally, c(s) is the prior probability of an observation being labelled as the state s.

Let us look at a sample training set for the toy problem first and see the calculations for transition and emission probabilities using the same.

The BLUE markings represent the transition probability, and RED is for emission probability calculations.

Note that since the example problem only has two distinct states and two distinct observations, and given that the training set is very small, the calculations shown below for the example problem are using a bigram HMM instead of a trigram HMM.

Peter’s mother was maintaining a record of observations and states. And thus she even provided you with a training corpus to help you get the transition and emission probabilities.

Transition Probability Example:

Training Corpus

Calculations for Awake appearing after Awake

Emission Probability Example:

Training corpus

Calculations for observing ‘Quiet’ when the state is ‘Awake’

That was quite simple, since the training set was very small. Let us look at a sample training set for our actual problem of part of speech tagging. Here we can consider a trigram HMM, and we will show the calculations accordingly.

We will use the following sentences as a corpus of training data (the notation word/TAG means word tagged with a specific part-of-speech tag).

The training set that we have is a tagged corpus of sentences. Every sentence consists of words tagged with their corresponding part of speech tags. eg:- eat/VB means that the word is “eat” and the part of speech tag in this sentence in this very context is “VB” i.e. Verb Phrase. Let us look at a sample calculation for transition probability and emission probability just like we saw for the baby sleeping problem.

Transition Probability

Let’s say we want to calculate the transition probability q(IN | VB, NN). For this, we see how many times we see a trigram (VB,NN,IN) in the training corpus in that specific order. We then divide it by the total number of times we see the bigram (VB,NN) in the corpus.

Emission Probability

Let’s say we want to find out the emission probability e(an | DT). For this, we see how many times the word “an” is tagged as “DT” in the corpus and divide it by the total number of times we see the tag “DT” in the corpus.

So if you look at these calculations, it shows that calculating the model’s parameters is not computationally expensive. That is, we don’t have to do multiple passes over the training data to calculate these parameters. All we need are a bunch of different counts, and a single pass over the training corpus should provide us with that.

Let’s move on and look at the final step that we need to look at given a generative model. That step is efficiently calculating

We will be looking at the famous Viterbi Algorithm for this calculation.

Finding the most probable sequence — Viterbi Algorithm

Finally, we are going to solve the problem of finding the most likely sequence of labels given a set of observations x1 … xn. That is, we are to find out

The probability here is expressed in terms of the transition and emission probabilities that we learned how to calculate in the previous section of the article. Just to remind you, the formula for the probability of a sequence of labels given a sequence of observations over “n” time steps is

Before looking at an optimized algorithm to solve this problem, let us first look at a simple brute force approach to this problem. Basically, we need to find out the most probable label sequence given a set of observations out of a finite set of possible sequences of labels. Let’s look at the total possible number of sequences for a small example for our example problem and also for a part of speech tagging problem.

Say we have the following set of observations for the example problem.

Noise Quiet Noise

We have two possible labels {Asleep and Awake}. Some of the possible sequence of labels for the observations above are:

Awake Awake Awake

Awake Awake Asleep

Awake Asleep Awake

Awake Asleep Asleep

In all we can have ²³ = 8 possible sequences. This might not seem like very many, but if we increase the number of observations over time, the number of sequences would increase exponentially. This is the case when we only had two possible labels. What if we have more? As is the case with part of speech tagging.

For example, consider the sentence

the dog barks

and assuming that the set of possible tags are {D, N, V}, let us look at some of the possible tag sequences:

D D D

D D N

D D V

D N D

D N N

D N V ... etc

Here, we would have ³³ = 27 possible tag sequences. And as you can see, the sentence was extremely short and the number of tags weren’t very many. In practice, we can have sentences that might be much larger than just three words. Then the number of unique labels at our disposal would also be too high to follow this enumeration approach and find the best possible tag sequence this way.

So the exponential growth in the number of sequences implies that for any reasonable length sentence, the brute force approach would not work out as it would take too much time to execute.

Instead of this brute force approach, we will see that we can find the highest probable tag sequence efficiently using a dynamic programming algorithm known as the Viterbi Algorithm.

Let us first define some terms that would be useful in defining the algorithm itself. We already know that the probability of a label sequence given a set of observations can be defined in terms of the transition probability and the emission probability. Mathematically, it is

Let us look at a truncated version of this which is

and let us call this the cost of a sequence of length k.

So the definition of “r” is simply considering the first k terms off of the definition of probability where k ∊ {1..n} and for any label sequence y1…yk.

Next we have the set S(k, u, v) which is basically the set of all label sequences of length k that end with the bigram (u, v) i.e.

Finally, we define the term π(k, u, v) which is basically the sequence with the maximum cost.

The main idea behind the Viterbi Algorithm is that we can calculate the values of the term π(k, u, v) efficiently in a recursive, memoized fashion. In order to define the algorithm recursively, let us look at the base cases for the recursion.

π(0, *, *) = 1

π(0, u, v) = 0

Since we are considering a trigram HMM, we would be considering all of the trigrams as a part of the execution of the Viterbi Algorithm.

Now, we can start the first trigram window from the first three words of the sentence but then the model would miss out on those trigrams where the first word or the first two words occurred independently. For that reason, we consider two special start symbols as * and so our sentence becomes

* * x1 x2 x3 ...... xn

And the first trigram we consider then would be (*, *, x1) and the second one would be (*, x1, x2).

Now that we have all our terms in place, we can finally look at the recursive definition of the algorithm which is basically the heart of the algorithm.",https://cdn-images-1.medium.com/max/1200/1*x-5ZBtUvlD78BOMuMnMAbg.png,[],https://medium.freecodecamp.org/a-deep-dive-into-part-of-speech-tagging-using-viterbi-algorithm-17c8de32e8bc?source=collection_home---6------4----------------,2018-06-08 19:05:31.518000+00:00

Data visualisation,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------,2018-06-07 17:57:40.375000+00:00

Data visualisation,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------#--responses,2018-06-07 17:57:40.375000+00:00

Data visualisation,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------,2018-06-07 15:39:54.084000+00:00

Data visualisation,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------#--responses,2018-06-07 15:39:54.084000+00:00

Data visualisation,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------,2018-06-06 21:43:33.288000+00:00

Data visualisation,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------#--responses,2018-06-06 21:43:33.288000+00:00

Data visualisation,Follow these steps to solve any Dynamic Programming interview problem,['Nikola Otasevic'],"Follow these steps to solve any Dynamic Programming interview problem

Despite having significant experience building software products, many engineers feel jittery at the thought of going through a coding interview that focuses on algorithms. I’ve interviewed hundreds of engineers at Refdash, Google, and at startups I’ve been a part of, and some of the most common questions that make engineers uneasy are the ones that involve Dynamic Programming (DP).

Many tech companies like to ask DP questions in their interviews. While we can debate whether they’re effective in evaluating someone’s ability to perform in an engineering role, DP continues to be an area that trips engineers up on their way to finding a job that they love.

Dynamic Programming — Predictable and Preparable

One of the reasons why I personally believe that DP questions might not be the best way to test engineering ability is that they’re predictable and easy to pattern match. They allow us to filter much more for preparedness as opposed to engineering ability.

These questions typically seem pretty complex on the outside, and might give you an impression that a person who solves them is very good at algorithms. Similarly, people who may not be able to get over some mind-twisting concepts of DP might seem pretty weak in their knowledge of algorithms.

The reality is different, and the biggest factor in their performance is preparedness. So let’s make sure everyone is prepared for it. Once and for all.

7 Steps to solve a Dynamic Programming problem

In the rest of this post, I will go over a recipe that you can follow to figure out if a problem is a “DP problem”, as well as to figure out a solution to such a problem. Specifically, I will go through the following steps:

How to recognize a DP problem Identify problem variables Clearly express the recurrence relation Identify the base cases Decide if you want to implement it iteratively or recursively Add memoization Determine time complexity

Sample DP Problem

For the purpose of having an example for abstractions that I am going to make, let me introduce a sample problem. In each of the sections, I will refer to the problem, but you could also read the sections independently of the problem.

Problem statement:

In this problem, we’re on a crazy jumping ball, trying to stop, while avoiding spikes along the way.

Here are the rules:

1) You’re given a flat runway with a bunch of spikes in it. The runway is represented by a boolean array which indicates if a particular (discrete) spot is clear of spikes. It is True for clear and False for not clear.

Example array representation:

2) You’re given a starting speed S. S is a non-negative integer at any given point, and it indicates how much you will move forward with the next jump.

3) Every time you land on a spot, you can adjust your speed by up to 1 unit before the next jump.

4) You want to safely stop anywhere along the runway (does not need to be at the end of the array). You stop when your speed becomes 0. However, if you land on a spike at any point, your crazy bouncing ball bursts and it’s game over.

The output of your function should be a boolean indicating whether we can safely stop anywhere along the runway.

Step 1: How to recognize a Dynamic Programming problem

First, let’s make it clear that DP is essentially just an optimization technique. DP is a method for solving problems by breaking them down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions. The next time the same subproblem occurs, instead of recomputing its solution, you simply look up the previously computed solution. This saves computation time at the expense of a (hopefully) modest expenditure in storage space.

Recognizing that a problem can be solved using DP is the first and often the most difficult step in solving it. What you want to ask yourself is whether your problem solution can be expressed as a function of solutions to similar smaller problems.

In the case of our example problem, given a point on the runway, a speed, and the runway ahead, we could determine the spots where we could potentially jump next. Furthermore, it seems that whether we can stop from the current point with the current speed depends only on whether we could stop from the point we choose to go to next.

That is a great thing, because by moving forward, we shorten the runway ahead and make our problem smaller. We should be able to repeat this process all the way until we get to a point where it is obvious whether we can stop.

Recognizing a Dynamic Programming problem is often the most difficult step in solving it. Can the problem solution be expressed as a function of solutions to similar smaller problems?

Step 2: Identify problem variables

Now we have established that there is some recursive structure between our subproblems. Next, we need to express the problem in terms of the function parameters and see which of those parameters are changing.

Typically in interviews, you will have one or two changing parameters, but technically this could be any number. A classic example of a one-changing-parameter problem is “determine an n-th Fibonacci number”. Such an example for a two-changing-parameters problem is “Compute edit distance between strings”. If you’re not familiar with these problems, don’t worry about it.

A way to determine the number of changing parameters is to list examples of several subproblems and compare the parameters. Counting the number of changing parameters is valuable to determine the number of subproblems we have to solve. It’s also important in its own right in helping us strengthen the understanding of the recurrence relation from step 1.

In our example, the two parameters that could change for every subproblem are:

Array position (P) Speed (S)

One could say that the runway ahead is changing as well, but that would be redundant considering that the entire non-changing runway and the position (P) carry that information already.

Now, with these 2 changing parameters and other static parameters, we have the complete description of our sub-problems.

Identify the changing parameters and determine the number of subproblems.

Step 3: Clearly express the recurrence relation

This is an important step that many rush through in order to get into coding. Expressing the recurrence relation as clearly as possible will strengthen your problem understanding and make everything else significantly easier.

Once you figure out that the recurrence relation exists and you specify the problems in terms of parameters, this should come as a natural step. How do problems relate to each other? In other words, let’s assume that you have computed the subproblems. How would you compute the main problem?

Here is how we think about it in our sample problem:

Because you can adjust your speed by up to 1 before jumping to the next position, there are only 3 possible speeds, and therefore 3 spots in which we could be next.

More formally, if our speed is S, position P, we could go from (S, P) to:

(S, P + S); # if we do not change the speed (S — 1, P + S — 1); # if we change the speed by -1 (S + 1, P + S + 1); # if we change the speed by +1

If we can find a way to stop in any of the subproblems above, then we can also stop from (S, P). This is because we can transition from (S, P) to any of the above three options.

This is typically a fine level of understanding of the problem (plain English explanation), but you sometimes might want to express the relation mathematically as well. Let’s call a function that we’re trying to compute canStop. Then:

canStop(S, P) = canStop(S, P + S) || canStop(S — 1, P + S — 1) || canStop(S + 1, P + S + 1)

Woohoo, it seems like we have our recurrence relation!

Recurrence relation: Assuming you have computed the subproblems, how would you compute the main problem?

Step 4: Identify the base cases

A base case is a subproblem that doesn’t depend on any other subproblem. In order to find such subproblems, you typically want to try a few examples, see how your problem simplifies into smaller subproblems, and identify at what point it cannot be simplified further.

The reason a problem cannot be simplified further is that one of the parameters would become a value that is not possible given the constraints of the problem.

In our example problem, we have two changing parameters, S and P. Let’s think about what possible values of S and P might not be legal:

P should be within the bounds of the given runway P cannot be such that runway[P] is false because that would mean that we’re standing on a spike S cannot be negative, and a S==0 indicates that we’re done

Sometimes it can be a little challenging to convert assertions that we make about parameters into programmable base cases. This is because, in addition to listing the assertions if you want to make your code look concise and not check for unnecessary conditions, you also need to think about which of these conditions are even possible.

In our example:

P < 0 || P >= length of runway seems like the right thing to do. An alternative could be to consider making P == end of runway a base case. However, it is possible that a problem splits into a subproblem which goes beyond the end of the runway, so we really need to check for inequality. This seems pretty obvious. We can simply check if runway[P] is false. Similar to #1, we could simply check for S < 0 and S == 0. However, here we can reason that it is impossible for S to be < 0 because S decreases by at most 1, so it would have to go through S == 0 case beforehand. Therefore S == 0 is a sufficient base case for the S parameter.

Step 5: Decide if you want to implement it iteratively or recursively

The way we talked about the steps so far might lead you to think that we should implement the problem recursively. However, everything that we’ve talked about so far is completely agnostic to whether you decide to implement the problem recursively or iteratively. In both approaches, you would have to determine the recurrence relation and the base cases.

To decide whether to go iteratively or recursively, you want to carefully think about the trade-offs.

Stack overflow issues are typically a deal breaker and a reason why you would not want to have recursion in a (backend) production system. However, for the purposes of the interview, as long as you mention the trade-offs, you should typically be fine with either of the implementations. You should feel comfortable implementing both.

In our particular problem, I implemented both versions. Here is python code for that:

A recursive solution: (original code snippets can be found here)

An iterative solution: (original code snippets can be found here)

Step 6: Add memoization

Memoization is a technique that is closely associated with DP. It is used for storing the results of expensive function calls and returning the cached result when the same inputs occur again.

Why are we adding memoization to our recursion? We encounter the same subproblems which, without memoization, are computed repeatedly. Those repetitions very often lead to exponential time complexities.

In recursive solutions, adding memoization should feel straightforward. Let’s see why. Remember that memoization is just a cache of the function results. There are times when you want to deviate from this definition in order to squeeze out some minor optimizations, but treating memoization as a function result cache is the most intuitive way to implement it.

This means that you should:

Store your function result into your memory before every return statement Look up the memory for the function result before you start doing any other computation

Here is the code from above with added memoization (added lines are highlighted): (original code snippets can be found here)

In order to illustrate the effectiveness of memoization and different approaches, let’s do some quick tests. I will stress test all three methods that we have seen so far. Here is the set up:

I created a runway of length 1000 with spikes in random places (I chose to have a probability of a spike being in any given spot to be 20%) initSpeed = 30 I ran all functions 10 times and measured the average time of execution

Here are the results (in seconds):

You can see that the pure recursive approach takes about 500x more time than the iterative approach and about 1300x more time than the recursive approach with memoization. Note that this discrepancy would grow rapidly with the length of the runway. I encourage you to try running it yourself.

Step 7: Determine Time complexity

There are some simple rules that can make computing time complexity of a dynamic programming problem much easier. Here are two steps that you need to do:

Count the number of states — this will depend on the number of changing parameters in your problem Think about the work done per each state. In other words, if everything else but one state has been computed, how much work do you have to do to compute that last state?

In our example problem, the number of states is |P| * |S|, where

P is the set of all positions (|P| indicates the number of elements in P)

S is the set of all speeds

The work done per each state is O(1) in this problem because, given all other states, we simply have to look at 3 subproblems to determine the resulting state.

As we noted in the code before, |S| is limited by length of the runway (|P|), so we could say that the number of states is |P|² and because work done per each state is O(1), then the total time complexity is O(|P|²).

However, it seems that |S| can be further limited, because if it were really |P|, it is very clear that stopping would not be possible because you would have to jump the length of the entire runway on the first move.

So let’s see how we can put a tighter bound on |S|. Let’s call maximum speed S. Assume that we’re starting from position 0. How quickly could we stop if we were trying to stop as soon as possible and if we ignore potential spikes?

In the first iteration, we would have to come at least to the point (S-1), by adjusting our speed at zero by -1. From there we would at a minimum go by (S-2) steps forward, and so on.

For a runway of length L, the following has to hold:

=> (S-1) + (S-2) + (S-3) + ….+ 1 < L

=> S*(S-1) / 2 < L

=> S < sqrt(2L + 1)

That is the maximum speed that we could possibly have on a runway of a length L. If we had a speed higher than that, we could not stop even theoretically, irrespective of the position of the spikes.

That means that the total time complexity depends only on the length of the runway L in the following form:

O(L * sqrt(L)) which is better than O(L²)

O(L * sqrt(L)) is the upper bound on the time complexity

Awesome, you made it through! :)

The 7 steps that we went through should give you a framework for systematically solving any dynamic programming problem. I highly recommend practicing this approach on a few more problems to perfect your approach.

Here are some next steps that you can take

Extend the sample problem by trying to find a path to a stopping point. We solved a problem that tells you whether you can stop, but what if you wanted to also know the steps to take in order to stop eventually along the runway? How would you modify the existing implementation to do that? If you want to solidify your understanding of memoization, and understand that it is just a function result cache, you should read about decorators in Python or similar concepts in other languages. Think about how they would allow you to implement memoization in general for any function that you want to memoize. Work on more DP problems by following the steps we went through. You can always find a bunch of them online (ex. LeetCode or GeeksForGeeks). As you practice, keep in mind one thing: learn ideas, don’t learn problems. The number of ideas is significantly smaller and it’s an easier space to conquer which will also serve you much better.

When you feel like you’ve conquered these ideas, check out Refdash where you are interviewed by a senior engineer and get a detailed feedback on your coding, algorithms, and system design.",https://cdn-images-1.medium.com/max/1200/0*DpsbrfUM89M_LHKY.jpg,[],https://medium.freecodecamp.org/follow-these-steps-to-solve-any-dynamic-programming-interview-problem-cc98e508cd0e?source=collection_home---6------11----------------,2018-06-06 19:32:36.335000+00:00

Data visualisation,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------,2018-06-06 17:23:02.015000+00:00

Data visualisation,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------#--responses,2018-06-06 17:23:02.015000+00:00

Data visualisation,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------,2018-06-06 16:42:46.938000+00:00

Data visualisation,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------#--responses,2018-06-06 16:42:46.938000+00:00

Data visualisation,How to process textual data using TF-IDF in Python – freeCodeCamp,[],"How to process textual data using TF-IDF in Python

Computers are good with numbers, but not that much with textual data. One of the most widely used techniques to process textual data is TF-IDF. In this article, we will learn how it works and what are its features.

From our intuition, we think that the words which appear more often should have a greater weight in textual data analysis, but that’s not always the case. Words such as “the”, “will”, and “you” — called stopwords — appear the most in a corpus of text, but are of very little significance. Instead, the words which are rare are the ones that actually help in distinguishing between the data, and carry more weight.

An introduction to TF-IDF

TF-IDF stands for “Term Frequenct — Inverse Data Frequency”. First, we will learn what this term means mathematically.

Term Frequency (tf): gives us the frequency of the word in each document in the corpus. It is the ratio of number of times the word appears in a document compared to the total number of words in that document. It increases as the number of occurrences of that word within the document increases. Each document has its own tf.

Inverse Data Frequency (idf): used to calculate the weight of rare words across all documents in the corpus. The words that occur rarely in the corpus have a high IDF score. It is given by the equation below.

Combining these two we come up with the TF-IDF score (w) for a word in a document in the corpus. It is the product of tf and idf:

Let’s take an example to get a clearer understanding.

Sentence 1 : The car is driven on the road.

Sentence 2: The truck is driven on the highway.

In this example, each sentence is a separate document.

We will now calculate the TF-IDF for the above two documents, which represent our corpus.

From the above table, we can see that TF-IDF of common words was zero, which shows they are not significant. On the other hand, the TF-IDF of “car” , “truck”, “road”, and “highway” are non-zero. These words have more significance.

Using Python to calculate TF-IDF

Lets now code TF-IDF in Python from scratch. After that, we will see how we can use sklearn to automate the process.",https://cdn-images-1.medium.com/max/1200/1*JTk6iVMiZCQCr8duiaKlHQ.png,[],https://medium.freecodecamp.org/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3?source=collection_home---6------15----------------,2018-06-06 16:07:18.115000+00:00

Data visualisation,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------,2018-06-06 01:10:32.658000+00:00

Data visualisation,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------#--responses,2018-06-06 01:10:32.658000+00:00

Data visualisation,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------,2018-06-06 00:59:12.072000+00:00

Data visualisation,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------#--responses,2018-06-06 00:59:12.072000+00:00

Data visualisation,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------,2018-06-06 00:20:56.870000+00:00

Data visualisation,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------#--responses,2018-06-06 00:20:56.870000+00:00

Data visualisation,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------,2018-06-05 20:08:25.488000+00:00

Data visualisation,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------#--responses,2018-06-05 20:08:25.488000+00:00

Data visualisation,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------,2018-06-05 16:44:13.144000+00:00

Data visualisation,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------#--responses,2018-06-05 16:44:13.144000+00:00

Data visualisation,A deeply detailed but never definitive guide to mobile development architecture,['Jose Berardo Cunha'],"A deeply detailed but never definitive guide to mobile development architecture

Native, Web, PWA, hybrid, Cross-Compiled… what is “the best” way to develop for Android and iOS platforms? What looks reasonable? And how are you supposed to choose among the options? In this article, I’ll lay it all out so you can make an informed decision.

First things first, let me provide you with a bit of context. I am an IT senior consultant, and the idea of putting together this guide was born from discussions with one of our clients about what could be the best approach for them. Yes, just for them. And we realized that we did not have a well-defined strategy, a solid and reliable foundation, to help us come up with the right answer.

And you know what? I could not find such a guide easily anywhere on the Internet, either. Although there are several articles about this topic, none of those I came across were reasonably complete. Unfortunately the majority overlook a lot of concepts or, even worse, are essentially wrong.

Now, I’d like to take a wider look. And while I’m potentially helping someone make their own decisions, I’m also asking around the community for more thoughts on the subject.

This guide has two parts:

Mobile Development Architectural Tiers (this) How to make your decision

It's also available on YouTube as a series of 10 videos and as a free course on Udemy. There, you’ll find the same written material as here, the same videos from the YouTube series, as well as quizzes to fix all the topics and a final certification.

So let’s get started.

Introduction

When it comes to mobile platforms, it's arguable that there are just two big players: Android and iOS. Other technologies like Tizen, Blackberry, or Windows Phone are either dead or have been around for a while and have no prospects of reaching any significative market share.

A quick look at this massive duopoly might make you think that developers do not have many options when creating mobile apps. This idea can't be further from the truth, though. You can quickly spot a fistful of programming languages being used out there: C/C++, Java, Kotlin, Objective-C, Swift, JavaScript, TypeScript, C#, Dart, Ruby, and I'm pretty sure I’ve missed a few more.

The same is true of mobile development frameworks. Unless you are not a developer, or have somehow been unaware of new technologies for the last 10 years, you’ve probably heard about Cordova/PhoneGap, React Native, Xamarin, Ionic, Nativescript, or Flutter, just to name a few cross-platform solutions for mobile apps.

So let’s look at all these pieces of the architecture and break things down a bit.

TL;DR

There's no clear winner. All approaches have pros and cons, and might be either the best fit or the worst fit for your next project. In this guide, I'm classifying many different solutions into various tiers according to the distance their architectures are from the native platform.

Native Apps

To start, let's go straight to the metal. Our first architectural tier is Native Apps.

Native Apps Tier — Where you develop for each specific platform (it might be even more specific when considering NDK)

This is the tier where you must be aware of the idiosyncrasies of each platform. It’s not my intention to dig into them, I just want to mention a few things in a bit of context.

You can watch this first part on Youtube.

iOS

Starting on the iOS side, just because it's simpler, there's only Apple ruling the world. Originally, developers needed to learn Objective-C, a proprietary object-oriented variation of C with some inspiration from SmallTalk (and an insanely long-named API).

In 2014, Apple announced Swift, a multi-paradigm language, which was a lot easier than its predecessor. It's still possible to deal with Objective-C legacy code, but Swift has reached high maturity levels. So, if you're planning to learn how to natively develop for iOS, Swift is definitely where you should start.

Android

On the Android side, there are a number of different manufacturers. The vast majority of them rely upon ARM processors. But generally speaking, Android apps lay on virtual machine instances (instances of ART) to help deal with potential underlying specificities (not without many amazing tricks).

That's why, originally, the language of choice was Java. It’s not only been the most popular language in the World for almost two decades (with a few position swaps with C), but it’s also notable for its Java Virtual Machine (JVM). This empowered developers to compile their code down to an intermediate bytecode that could be read and run by the JVM.

With the Android Native Development Kit (NDK), it's also possible to develop critical parts of the app directly in native code, writing in C/C++. In this case, you have to be aware of underlying platform quirks.

Kotlin is a language unveiled by JetBrains in 2011. When it first came out, despite its flexibility and conciseness, it wasn't more than yet another JVM language with more successful competitors like Scala, Clojure, or Groovy. However, after its first major release in 2016, it rapidly started to stand out from the crowd, especially after Google announced that it would be officially supported on the Android platform at Google I/O 2017.

Kotlin is becoming Google's first class language (currently Kotlin and Java — in this order — are used throughout Android's official documentation). A total Java replacement is expected even more so now that the US Federal Appeals Court has ruled on the endless lawsuit filed by Oracle accusing Google of violating Java copyrights.

Native components

Developing in this tier, you can also leverage all native APIs and, in particular, the native components. This saves your app from having to reinvent the wheel.

I've published a video demo of how to create a simple project on Xcode (iOS) and Android Studio. If you want to check it out:

Demo of iOS and Android basic projects.

Native Apps advantages

Best performance and top user engagement

Bleeding edge native features

Notably good IDEs Android Studio / Xcode

Modern high-level languages Kotlin / Swift

Very low-level approach with NDK

Native Apps disadvantages

Two codebases to maintain

Require installation (except Android Instant Apps)

Hard to analyze SEO

Very expensive to get users to download the app

Web Apps

On the other side of the spectrum, we have Web Apps. Web Apps are essentially apps run by the browser. You don't write code targeting the platform, but rather any browser running on top of it.

Web Apps Tier — clearly on top of a browser bar targeting a beast sitting in between Android and iOS.

In this tier you’ll find an insane number of contenders jumping at each other's throats. But they all use an arsenal consisting of the same weapons: HTML, CSS, and Javascript.

Web frameworks and libraries, even when leveraging CSS pre-compilers like LESS or SASS, even Javascript pre-compiled languages like TypeScript, CoffeeScript or Flow, even symbiosis like JSX or Elm, leaving alone tools like Babel used to transpile everything to Javascript with different configurable levels of conformance with ECMAScript yearly specifications (ES6 / ES7 / ES8, or if you prefer ES2015 / ES2016 / ES2017 / ES2018).

At the end of the day, they all are HTML, CSS, and JavaScript rendered and run by the browser. There's no direct access to native APIs like camera, vibration, battery status, or file system, but some of them can be achieved via Web API's:

The big issue with Web APIs is their maturity level. Many of them are not supported by some browsers. There are differences in implementations, especially across mobile browsers.

Web App advantages

Shared code between platforms and desktop browsers

Do not require previous installations, just navigate and use

Tons of frameworks and libraries to go with them

Best for SEO

Web App disadvantages

Lower performance

Hard to get a native user experience

Require an internet connection

Not available on official app stores

API not as mature and reliable as native API

Frameworks and Web components

Angular, React, and Vue are probably the most popular web frameworks as of 2018. To be precise, however, React is considered just a library due to its flexible and less opinionated nature. Angular, on the other hand, is a strongly opinionated framework. Vue lives at some point in between them.

Angular vs React vs Vue

Angular, originally called AngularJS, was presented to the world in 2010 by Google. It quickly started to shine, due to its inversion of paradigms in comparison with other libraries from that time (like jQuery, the most popular back then). Instead of directly talking to HTML elements to manipulate the UI state, with AngularJS, templates were magically updated whenever the JavaScript model was updated.

As AngularJS became more and more popular, it also grew in purpose. It turned into a complete and opinionated framework that was one of the first that took SPAs (Single Page Apps) seriously. This growth (in both aspects) was responsible for some API bloats and performance issues.

React was created by Facebook to solve their own needs on the presentation layer. It introduced many aspects that suddenly became very popular, like virtual DOM, one-way data flow (originally named Flux, especially popular through an implementation library called Redux), and a mixture of HTML and JavaScript called JSX.

Only in 2016, after long debates and unexpected big changes, Google launched version two of its popular web framework. They called it Angular, instead of AngularJS. But, as many people already called the first version “Angular” (without the ""JS"" suffix), people started calling the new version Angular 2. That turned into a naming problem, as Google also announced that it would release new major versions every 6 months.

In my opinion, that was a mammoth mistake. I've seen this before (with Struts vs Struts 2/WebWork, for example). They have a massively popular product that appears to have reached its plateau, and it has started to be more criticized than praised. If Google decides to rebuild it from the ground up, they should never, by any means, just change its major version. How will people trust that they will not repeat it every new major version release? Version two is supposed to present breaking changes, but it doesn't mean it can be totally revamped.

Angular is a spectacular web framework, and I really feel passionate about it. However, it's a completely new beast. It does not have much to do with AngularJS. Even Vue, which is another amazing framework (probably one of the most pleasant to work with, by the way) looks more similar to AngularJS from a bird's-eye view. I believe this caused a significant movement away from Angular and contributed substantially to React's popularity.

Vue is the only one of the three most popular web frameworks that is not backed by a big company. It was actually started by a former Google developer. Due to its formidable simplicity and tiny footprint, it got attention from a massive and enthusiastic community.

Although there are more complete solutions, they all work on top of the concept of web components. There's an open specification about them currently in progress in W3C, and some interesting implementations like Polymer, Stencil and X-Tag.

In the third video of the series, I don't spend too much time discussing frameworks but discuss web component libraries:

The Web Apps tier is discussed in Part 3 of the series

Mobile Apps vs Web Apps

I’m not sure if you’ve noticed, but the order of tiers I'm presenting here follows what I think is the easiest path to learn all approaches. I started from the Native Tier, the most genuinely mobile development. Then I decided to fly directly to the other extreme to present the Web Tier, which is the tier that has been available since the first smartphones.

Only now, after elaborating on a comparison between the two edges of my diagram, will I start talking about many of the cross-platform approaches to build mobile apps.

There's a long debate between Mobile Apps vs Web Apps. Everything I say about Mobile Apps is not exclusive to the Native Tier. It is also applicable to all cross-platform tiers I present later on.

The user behavior dilemma

Users spend more time on Mobile Apps (87%) than on Mobile Websites (13%)

According to a Comscore survey in 2017, a user's fidelity to a mobile app is way more relevant than it is to mobile websites. According to an aligned article on Forbes, this is usually because of convenience (for example, home screen buttons, widgets, top notifications), speed (for example, smoother interfaces, almost instant start ups), and stored settings (for example, offline content).

Mobile Websites reach more people (8.9M monthly unique visitors against 3.3M of Mobile Apps)

On the other hand, in the same Comscore data, we learn that customers can be reached more easily from mobile websites, as they are not as much tied to their few apps of preference. If you compare the most popular websites versus the most downloaded apps, it's estimated that an average of 8.9 million unique web visitors per month access the top 1000 websites. That's almost three times more than the average unique users of the top 1000 most downloaded apps.

Distribution (Web App) x Engagement (Mobile App)

That's all about distribution vs engagement. Your web app has a higher chance of being accessed, as users are more likely to try new things when navigating through their mobile browsers. But Mobile Apps have been proven to be more engaging, and catch the users attention for much longer periods.

Now that you understand the dilemma, let's have a look at Progressive Web Apps. This is an approach so tied to the Web Apps tier that I classify it as just an addendum to Web Apps. But it's a big disruptor and a serious candidate for the most prominent new and cool thing in web and mobile development.

Progressive Web Apps

Progressive Web Apps (PWAs) are a set of tools used to give Web App users the same experience they are accustomed to when they run Mobile Apps. This means that Web Apps can leverage the potentially higher levels of distribution with more decent levels of engagement.

Progressive Web Apps addendum to Web Apps tier

Google defined three main qualifications for PWAs: they must be Reliable, Fast, and Engaging.

Features called Service Workers and the App Shell are the foundation of Progressive Web Apps. They were created to promote apps’ reliability as they are now designed to work regardless of the device’s connection status. That includes offline mode, as well as poor connections. They also provide significant perceived performance boost, as apps launch using locally cached data, which eliminates delays for synchronous content downloads.

You could consider reliability an indirect vector of engagement. Users are not affected while commuting by train, for example. They can stay engaged.

The same applies to speed. According to Google:

53% of users will abandon a site if it takes longer than 3 seconds to load!

However, being exclusively reliable and fast on load doesn't necessarily guarantee high engagement. PWAs leverage mobile-related features that used to be exclusive to mobile apps, like an “Add to Home Screen” option and Push Notifications.

When it comes to to the “Add to Home Screen” feature, you might notice that Apple has had a similar feature since the very first iPhone. Some people even argue that Progressive Web Apps are Google's fancy new name for an original Apple idea.

And you really can’t completely disagree. Some ideas are actually cycling. They come, go away, and then come back with a new name and some enhancements (for instance, Service Workers), so they can finally stick around.

On the other hand, it’s hard to completely agree. Steve Jobs’ speech about Web 2.0 + AJAX and the memorable announcement of the iPhone back in WWDC 2007 are not convincing enough to call him as the father, or even the prophet, of PWAs.

To be fair, the Add to Home Screen capability on iPhone has been nothing more than a subtle, almost hidden, feature to generate desktop icons that just start up Web Apps in fullscreen mode. It has all the burden of HTTP request-response cycles and no clear path around caches.

PWAs start from the right point. They explore how previous installations of Web Apps aren’t necessary without losing the client-side bootstrap of Mobile Apps. This means that everything a user needs for their first interaction following startup might be locally cached (read: App Shell) and kept available as soon as they hit “Add to Home Screen.”

Moving onto another well-known characteristic of PWAs, let’s talk about the super engaging (or re-engaging) feature of the Mobile Apps world: Push Notifications. They are alert-style messages that appear on the top notification bar / area, as well as on lock screens. They have the power of pulling users back to your app once they receive the notification.

To reinforce the appeal of PWAs, Google has been pulling all modern Web APIs under the PWA umbrella. So expect to see things like Payment Requests, Credential Management, WebVR, Sensors, WebAssembly, and WebRTC in the context of Progressive Web Apps. But these feature are not necessarily tied to PWAs, and some were even born before the term PWA was coined.

PWA and Apple

Apple, on the other hand, announced their first solid milestones towards PWAs only in March 2018. Although there are still some limitations, the progress is appreciable. Some of the limitations might be related to the fact that Safari has fallen behind its competitors. Others could be attributed to Apple's philosophy of tight control.

Still, Apple has a more profitable App Store than Google. Apple's asserts that more criteria on app publications brings more overall reliability, and PWAs are bound to hurt the App Store's revenue. This suggests that some limitations that seem to be intentionally imposed (like 50Mb of PWA maximum cache size) will cost more to be revoked.

Unfortunately PWAs are not perfect

Web solutions and, on different levels, all cross-platform solutions struggle to attain the excellence and comprehensiveness of Native Apps. Every new feature, and every detail particular to Android or iOS makes that native feel harder and harder to access as you distance your app from the native tier.

Overall, PWAs fix some issues in the Web Apps tier. But there are other issues that can’t be fixed by a solution working on top of a browser.

What PWAs fix

More “native” experience

Faster load times

Do not require an internet connection

Force web developers to be aware of situations where there’s no connection as well as a bad connection

Incorporate features from Mobile Apps like Push Notifications, Geolocation, or Speech Recognition

What they don’t

Inherent slowness

Not available on app stores (just yet)

Still not fully supported by all browsers

Still lack mobile features like NFC, Ambient Light, Geofencing

Also lack support for peculiarities of Android or iOS like PiP, smart app banners, launch screen widgets, and 3D touch

In the video below, I do a brief overview of PWAs.

Progressive Web Apps are introduced in the Part 4 of the series

Hybrid Apps

At this level, we begin to dive into the Mobile App world. We’ll start from the most distant tier: Hybrid Apps.

The term Hybrid is also commonly applied to all cross-platform solutions. Here, however, I’m restricting it to Apps that work inside mobile components, called WebViews.

The Hybrid Apps tier. Below the browser's line but on top of WebViews

In the demos in the second video, my purpose for adding WebView as the Hello World example was to make clear that there's a native component for each platform that is able to perform like an actual browser.

Cordova/PhoneGap

Solutions like Cordova/PhoneGap close the gap (sorry for the uninspired pun) between Web and Mobile Apps. They provide tools to package developer's HTML, JavaScript, and CSS code (as well as any extra assets like images or videos) and transform them into Mobile Apps (yes, real Android or iOS apps). These apps have their WebView exclusively to interpret and run the original web code, starting with the “index.html” file in the app’s main folder (normally called “www”). They also bridge the JavaScript code to native APIs through plugins which are partially implemented in JavaScript and partially in a native language.

So, let's make things clearer. Hybrid Apps are able to access native APIs (instead of Web APIs), but they are enclosed by the WebView. A button with Cordova must be an HTML button rendered by a WebView instead of a mobile native button.

This is the magical tier that allows companies to port their Web Apps to Mobile Apps to be shipped by app stores. So any web framework is allowed here.

Ionic

Frameworks like Ionic wrap Cordova into their own solutions. With Ionic, you don't need to use Cordova’s command line interface (CLI), because all of its commands are wrapped by the Ionic CLI.

Recently, the Ionic team decided to take the reins of the entire stack of Hybrid Apps. So they launched a proposed replacement for Cordova called Capacitor. Capacitor has support for Cordova plugins, and can also be used by a non-Ionic project.

You can watch me going through a Cordova Hello World sample in the fifth video of the series:

Hybrid Apps are in Part 5 of the series.

Hybrid Apps advantages

They are essentially web apps that are shippable to official app stores

Can be used along with any JavaScript framework / library

The code is still highly shareable across platforms

Access to native features (for instance, camera, accelerometer, contact list)

Hybrid Apps disadvantages

Struggle with performance issues and memory consumption, as web views are responsible for rendering everything on screen

Have to mimic all native UI components on top of a single web view

Harder to be accepted and published on App Store

Usually take longer to have native features available for these environments

Web Native

Web Native is a relatively new and often misunderstood tier. That's where Web Apps meet native components. Although Appcelerator (Axway) Titanium has been around a long time, there are some relatively new competitors that justify making this a completely separate category of mobile apps.

Web Native Apps don't need WebView as they talk directly to other native components

As you can see above, there's no web view to render and run your application. So, how is your JavaScript executed? Is it compiled? Well, if you consider transpilation (compilation from one language to another — for example TypeScript to JavaScript), bundling, minification, mangling, and obfuscation all together as a compilation, yes JavaScript is compiled.

But the problem is, this doesn't make your JavaScript something directly understood by Android or iOS operational systems. And, in theory, there's no native component that only serves as a JavaScript engine without the bloat of the HTML layout engine.

The strategy is to ship JavaScript engines (normally V8 for Android and JavaScriptCore for iOS) along with your code. Although they have small footprints and are very fast, they are something external that must be provided by your app.

On the other hand, this approach tends to have better UI performance, as all the components are the same (or are based on the same thing for React Native, for example) as the ones used by Native Apps.

Web Native Apps advantages

Reach both platforms with one single codebase

Roughly the same performance as native apps, as they also deal with native UI components

Tweaks are necessary, but the code is still shareable with web development

Web Native Apps disadvantages

Even with one single codebase, the developer must be aware of native components

Steeper learning curve than Hybrid / Web Apps for web developers, especially when it comes to layout

React Native

In part 6 of the series, I do a quick Hello World in React Native. This shows, on Android Studio's Layout Inspector, what components were rendered in the emulator. I compare with the previous examples, ensuring that there's no WebView whatsoever.

Web Native Apps presentation with focus on React Native in Part 6 of the series.

Nativescript

Another amazing framework that I've been particularly interested in over the last two years (I have a course on Udemy about it — in Portuguese), is Nativescript. It’s similar to React Native but is not tied to the React world (there's an unofficial integration, Nativescript-Preact, though).

With Nativescript, you can develop using vanilla JavaScript, TypeScript, Angular and, more recently, Vue. Of course you can use other frameworks, but those are the ones officially supported. It’s fairly well documented too, by the way.

Nativescript has tools like Nativescript Sidekick and Nativescript Playground, as well as project structures based on templates that can be provided by the community. This should help you in project creation, giving you the ability to start, deploy, test, and run on simulators on the cloud and iPhone devices even when you are not developing using a Mac.

In the seventh part of the series, I do a Hello World using Sidekick along with another project started from the CLI and a WhatsApp clone template I created for learning purposes.

Web Native Apps with Nativescript in Part 7 of the series.

It's important to have a look at the Layout Inspector when your app is running on an Android emulator. With Nativescript, it shows the native components (again, no WebView), and direct instances of common Android classes like TextView. This is different than React Native, which has its own classes to wrap the native components.

That's probably why Nativescript claims that there’s no delay between when a new feature is available on iOS and Android and when you can use it in a Nativescript project. For example, they posted on their blog an AR project on the same day iOS 11 was officially released with the new ARKit API.

Weex

Another framework worth mentioning in this category is Weex. It's a project developed by Alibaba, and is currently incubated at Apache Sofware Foundation (ASF). It uses common HTML tags like <div> and CSS commands inside <style> tags to call native components instead. From their documentation:

Although components in Weex look like HTML tags, you are not able to use all of them. Instead, you can only use the built-in components and your custom components.

Cross Compiled

At this level, it’s time to jump off the Web bandwagon. This is the closest tier to native development, but has the advantage of using one single codebase to target Android and iOS.

Development tiers now complete with Cross Compiled Apps

RubyMotion and Xamarin

There are solutions like RubyMotion. This is a way to write mobile apps using Ruby and compile directly to the targeted platform (as it was created using any ""native"" language).

Another option is Xamarin, where you write in C#, compile to an intermediate bytecode, and deploy your app along with an instance of the Mono common language runtime. This approach has the same drawback as Web Native (where V8 and JavaScriptCore are delivered by your app), but can also rely upon JIT compilations to optimize the app at runtime.

Flutter

Last but not least, I'd like to bring up Flutter. It’s Google's newest cool initiative for mobile development. It fits in the Cross Compiled tier because you write apps using the Dart language and compile them down to the native platform.

Flutter has innovated in some aspects. Probably the most outstanding one is the fact that it provides its own set of components.

What? Own set of components?

Yes, Flutter provides a number of different components so you can completely skip the ones from the platform. It has generic components as well as Material Design components for Android, and Cupertino components for iOS.

Rather than .Net virtual machine (as Xamarin) or JavaScript engines (as Web Native frameworks), with Flutter your app will deliver the components you decide to use.

Are they native components?

Yes, they are. Your app is native, too. Everything is compiled to the native architecture. However, bear in mind they are not the pre-existing native components.

What's the point of that?

Well, in my opinion, this solution is clever and audacious. I've been waiting to talk about advantages and disadvantages, but as it's just one particular technology, let me address them now.

One of the biggest challenges for Web Native and Cross Compiled solutions (remember, above Native but below the WebView in our tiers) is how to deal with native components. For example, an important problem is how to lay them out. That's because they were not created to be used by those external resources. Also, they were not created with a counterpart in the other platform in mind. The Android NavBar doesn't work like iOS UINavBar, for example.

With Flutter, components are created with cross-platform always in mind. So let's have a look at the pros and cons of the Cross Compiled Apps tier:

Cross Compiled Apps advantages

Reach both platforms with one single language

Roughly the same performance as native apps, as they also deal with native UI components

Cross Compiled Apps disadvantages

Slightly delayed support for the latest platform updates

Code not shareable with web development

Even with one single codebase, the developer must be aware of native components

PS: With Flutter, you’ll provide your own set of widgets along with your app's code

Mobile Apps runtime architecture",https://cdn-images-1.medium.com/max/1200/1*kHze88HBCkKt8Tw4MESC9Q.png,[],https://medium.freecodecamp.org/a-deeply-detailed-but-never-definitive-guide-to-mobile-development-architecture-6b01ce3b1528?source=collection_home---6------21----------------,2018-06-05 16:34:24.241000+00:00

Data visualisation,How to deliver a React Native app to the client – freeCodeCamp,[],"How to deliver a React Native app to the client

If you have written some React Native apps, you’ve probably noticed that the process of beta-release version generation requires many repeatable steps. This happens especially for multi-platform apps.

Let’s look at sample action steps you need to perform to deliver the beta version app to the client or tester:

Download the proper branch from the repository

Android:

Insert the APK signing key into the ./android/app/ directory

directory Build the release version

Send the app, for example via e-mail

iOS:

Launch Xcode

Change the scheme to Release

Change the jsCodeLocation value to a static main.jsbundle file path

value to a static file path Archive

Upload the app to TestFlight

As you can see, the above list contains a large number of repeatable steps. Since they are repeatable, we can automate them, right?

Possible solutions

There are several solutions for automating beta release version generation and delivering the app to the client.

Visual Studio App Center

The first solution that came to our minds at Brainhub was the use of the Visual Studio App Center. A project built by Microsoft seems to be really attractive — in addition to building the app in the cloud (free 240 minutes / month of building) and distribution among testers and the client, it also provides a platform for testing apps on many real devices, giving access to reports and screenshots of every step of the process.

However, it quickly turned out that this was not the appropriate solution for our particular project. VS App Center has limited configuration abilities, and the app’s code needs to be downloaded from the Git repository hosted on GitHub, Bitbucket, or VSTS. Due to the fact that we use GitLab, we had to rule out this solution (but it could work for your project).

HockeyApp (with Fastlane)

The next option was to use HockeyApp — a tool for app distribution and collecting crash reports and users’ feedback. The service was initially created for distribution of iOS apps using the ‘ad hoc’ method (outside of App Store), but currently it works for Android also.

HockeyApp works well as a delivery platform of software testing versions, but does not give the functionality of building the app. However, we can also use Fastlane — a tool for mobile app building process automation built by fabric.io.

Preparations

Before you start building and deploying the app, you should prepare the environment. This section describes the steps you should take first.

Automatic jsCodeLocation change

React Native documentation says that you should change jsCodeLocation to the static js bundle for the iOS release version in AppDelegate.m file. But there’s no need to do that manually every time you release the app — you can use the #ifdef DEBUG macro to do it automatically. Just replace the line containing jsCodeLocation = … with the following code.

#ifdef DEBUG

// DEV

jsCodeLocation = [[RCTBundleURLProvider sharedSettings] jsBundleURLForBundleRoot:@”index” fallbackResource:nil];

#else

// PROD

jsCodeLocation = [[NSBundle mainBundle] URLForResource:@”main” withExtension:@”jsbundle”];

#endif

Ignore helper files

During the process of building the app, there will be some helper files created. There’s no need to commit them to the repository, so just add them to the following “.gitignore” file.

# Deployment

*.cer

*.jsbundle

*.jsbundle.meta

*dSYM.zip

*.keystore

*.mobileprovision

fastlane/report.xml

APK signing key

To release an Android app, you need a signing key. To learn more about this process, look here.

When you have your key generated, move it to the “android/app” directory and remember to add *.keystore to “.gitignore”.

Fastlane + HockeyApp + Testflight

You will learn how to automatically generate an app written in React Native for Android and iOS platforms, and send it to HockeyApp (Android) and Testflight (iOS).

First, let’s install Fastlane. Make sure you have the newest version of Xcode command line tools installed.

xcode-select — install

Install Fastlane.

[sudo] gem install fastlane -NV` or `brew cask install fastlane`

Init Fastlane.

fastlane init

The command above will create the “fastlane” directory in current directory with a file called “Fastfile” that contains the Fastlane configuration.

Appfile

In the “fastlane” directory, create a file called “Appfile”, which stores data that is used across all fastlane tools, for example AppleID. It is required for the iOS build and deployment to Testflight.

Add your AppleID to “Appfile”.

Fastfile

Your beta release Fastfile might look like this.

# More documentation about how to customize your build

# can be found here:

# https://docs.fastlane.tools

# fastlane_version “2.68.0”

# Fastfile actions accept additional configuration, but

# don’t worry, fastlane will prompt you for required

# info which you can add here later

platform :ios do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

get_certificates

get_provisioning_profile(

app_identifier: “org.you.yourProject”

)

# build your iOS app

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

# TestFlight

pilot()

end

end

platform :android do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

# build the release variant

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

# upload to HockeyApp

hockey(

api_token: “YOUR_TOKEN”

)

end

end

Let’s analyze our “Fastfile” step-by-step.

The code block below will be executed after typing fastlane ios beta into the console.

platform :ios do

lane :beta do

# …

end

end

For Android , type fastlane android beta .

platform :android do

lane :beta do

# …

end

end

Ensure that the current branch is master and perform git pull to sync with the remote repository.

ensure_git_branch(

branch: “master”

)

git_pull

iOS only

Let’s increment the build number (works for iOS only). The application that is being sent to Testflight has to have a higher build number than the previous version.

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

Testflight and Ad Hoc distribution require the proper certificate and provisioning profile. There are several methods of signing apps:

match

cert and sigh

Xcode’s code signing feature

manually

In this article, cert and sigh was used. For further reading about codesigning using Fastlane, visit this site.

get_certificates

get_provisioning_profile( app_identifier: “org.you.yourProject” )

Next, there is the step of building the iOS version where we pass the params such as project path, scheme , and export_method . Export_method contains one of the following values: app-store , ad-hoc , package , enterprise , development , or developer-id .

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

The last step for iOS is sending the app to Testflight.

pilot()

Android only

Now let’s look at the Android version. There are two gradle steps: cleaning, and building the release version.

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

Now you can send the generated app to HockeyApp.

hockey(

api_token: “YOUR_TOKEN”

)

If you don’t add some required parameter, for example no iTunes Connect user in Fastfile, Fastlane will ask you for that data in the console.

HockeyApp Configuration

After signing up and signing in to HockeyApp, you will see the blue “New App” button.",https://cdn-images-1.medium.com/max/1200/1*153T3TpCccNK7hs11oRNpA.png,[],https://medium.freecodecamp.org/how-to-deliver-a-react-native-app-to-the-client-e58421e7272e?source=collection_home---6------22----------------,2018-06-05 01:26:27.937000+00:00

Data visualisation,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------,2018-06-05 00:59:03.212000+00:00

Data visualisation,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------#--responses,2018-06-05 00:59:03.212000+00:00

Data visualisation,A coffee-break introduction to time complexity of algorithms,['Vicky Lai'],"A coffee-break introduction to time complexity of algorithms

Just like writing your very first for loop, understanding time complexity is an integral milestone to learning how to write efficient complex programs. Think of it as having a superpower that allows you to know exactly what type of program might be the most efficient in a particular situation — before even running a single line of code.

The fundamental concepts of complexity analysis are well worth studying. You’ll be able to better understand how the code you’re writing will interact with the program’s input, and as a result, you’ll spend a lot less wasted time writing slow and problematic code.

It won’t take long to go over all you need to know in order to start writing more efficient programs — in fact, we can do it in about fifteen minutes. You can go grab a coffee right now (or tea, if that’s your thing) and I’ll take you through it before your coffee break is over. Go ahead, I’ll wait.

All set? Let’s do it!

What is “time complexity” anyway?

The time complexity of an algorithm is an approximation of how long that algorithm will take to process some input. It describes the efficiency of the algorithm by the magnitude of its operations. This is different than the number of times an operation repeats. I’ll expand on that later. Generally, the fewer operations the algorithm has, the faster it will be.

We write about time complexity using Big O notation, which looks something like O(n). There’s rather a lot of math involved in its formal definition, but informally we can say that Big O notation gives us our algorithm’s approximate run time in the worst case, or in other words, its upper bound. It is inherently relative and comparative.

We’re describing the algorithm’s efficiency relative to the increasing size of its input data, n. If the input is a string, then n is the length of the string. If it’s a list of integers, n is the length of the list.

It’s easiest to picture what Big O notation represents with a graph:

Lines made with the very excellent Desmos graph calculator. You can play with this graph here.

Here are the main important points to remember as you read the rest of this article:

Time complexity is an approximation

An algorithm’s time complexity approximates its worst case run time

Determining time complexity

There are different classes of complexity that we can use to quickly understand an algorithm. I’ll illustrate some of these classes using nested loops and other examples.

Polynomial time complexity

A polynomial, from the Greek poly meaning “many,” and Latin nomen meaning “name,” describes an expression comprised of constant variables, and addition, multiplication, and exponentiation to a non-negative integer power. That’s a super math-y way to say that it contains variables usually denoted by letters, and symbols that look like these:

The below classes describe polynomial algorithms. Some have food examples.

Constant

A constant time algorithm doesn’t change its running time in response to the input data. No matter the size of the data it receives, the algorithm takes the same amount of time to run. We denote this as a time complexity of O(1).

Here’s one example of a constant algorithm that takes the first item in a slice.

func takeCupcake(cupcakes []int) int {

return cupcakes[0]

}

Choice of flavours are: vanilla cupcake, strawberry cupcake, mint chocolate cupcake, lemon cupcake, and “wibbly wobbly, timey wimey” cupcake.

With this contant-time algorithm, no matter how many cupcakes are on offer, you just get the first one. Oh well. Flavours are overrated anyway.

Linear

The running duration of a linear algorithm is constant. It will process the input in n number of operations. This is often the best possible (most efficient) case for time complexity where all the data must be examined.

Here’s an example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

}

Here’s another example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// double dip chip

}

}

It doesn’t matter whether the code inside the loop executes once, twice, or any number of times. Both these loops process the input by a constant factor of n, and thus can be described as linear.

Don’t double dip in a shared bowl.

Quadratic

Now here’s an example of code with time complexity of O(n2):

func pizzaDelivery(pizzas int) {

for pizza := 0; pizza <= pizzas; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

Because there are two nested loops, or nested linear operations, the algorithm process the input n2times.

Cubic

Extending on the previous example, this code with three nested loops has time complexity of O(n3):

func pizzaDelivery(boxesDelivered int) {

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

}

Seriously though, who delivers unsliced pizza??

Logarithmic

A logarithmic algorithm is one that reduces the size of the input at every step. We denote this time complexity as O(log n), where log, the logarithm function, is this shape:

One example of this is a binary search algorithm that finds the position of an element within a sorted array. Here’s how it would work, assuming we’re trying to find the element x:

If x matches the middle element m of the array, return the position of m. If x doesn’t match m, see if m is larger or smaller than x. If larger, discard all array items greater than m. If smaller, discard all array items smaller than m. Continue by repeating steps 1 and 2 on the remaining array until x is found.

I find the clearest analogy for understanding binary search is imagining the process of locating a book in a bookstore aisle. If the books are organized by author’s last name and you want to find “Terry Pratchett,” you know you need to look for the “P” section.

You can approach the shelf at any point along the aisle and look at the author’s last name there. If you’re looking at a book by Neil Gaiman, you know you can ignore all the rest of the books to your left, since no letters that come before “G” in the alphabet happen to be “P.” You would then move down the aisle to the right any amount, and repeat this process until you’ve found the Terry Pratchett section, which should be rather sizable if you’re at any decent bookstore, because wow did he write a lot of books.

Quasilinear

Often seen with sorting algorithms, the time complexity O(n log n) can describe a data structure where each operation takes O(log n) time. One example of this is quick sort, a divide-and-conquer algorithm.

Quick sort works by dividing up an unsorted array into smaller chunks that are easier to process. It sorts the sub-arrays, and thus the whole array. Think about it like trying to put a deck of cards in order. It’s faster if you split up the cards and get five friends to help you.

Non-polynomial time complexity

The below classes of algorithms are non-polynomial.

Factorial

An algorithm with time complexity O(n!) often iterates through all permutations of the input elements. One common example is a brute-force search, seen in the traveling salesman problem. It tries to find the least costly path between a number of points by enumerating all possible permutations and finding the ones with the lowest cost.

Exponential

An exponential algorithm often also iterates through all subsets of the input elements. It is denoted O(2n) and is often seen in brute-force algorithms. It is similar to factorial time except in its rate of growth, which, as you may not be surprised to hear, is exponential. The larger the data set, the more steep the curve becomes.

In cryptography, a brute-force attack may systematically check all possible elements of a password by iterating through subsets. Using an exponential algorithm to do this, it becomes incredibly resource-expensive to brute-force crack a long password versus a shorter one. This is one reason that a long password is considered more secure than a shorter one.

There are further time complexity classes less commonly seen that I won’t cover here, but you can read about these and find examples in this handy table.

Recursion time complexity

As I described in my article explaining recursion using apple pie, a recursive function calls itself under specified conditions. Its time complexity depends on how many times the function is called and the time complexity of a single function call. In other words, it’s the product of the number of times the function runs and a single execution’s time complexity.

Here’s a recursive function that eats pies until no pies are left:

func eatPies(pies int) int {

if pies == 0 {

return pies

}

return eatPies(pies - 1)

}

The time complexity of a single execution is constant. No matter how many pies are input, the program will do the same thing: check to see if the input is 0. If so, return, and if not, call itself with one fewer pie.

The initial number of pies could be any number, and we need to process all of them, so we can describe the input as n. Thus, the time complexity of this recursive function is the product O(n).

This function’s return value is zero, plus some indigestion.

Worst case time complexity

So far, we’ve talked about the time complexity of a few nested loops and some code examples. Most algorithms, however, are built from many combinations of these. How do we determine the time complexity of an algorithm containing many of these elements strung together?

Easy. We can describe the total time complexity of the algorithm by finding the largest complexity among all of its parts. This is because the slowest part of the code is the bottleneck, and time complexity is concerned with describing the worst case for the algorithm’s run time.

Say we have a program for an office party. If our program looks like this:

package main



import ""fmt""



func takeCupcake(cupcakes []int) int {

fmt.Println(""Have cupcake number"",cupcakes[0])

return cupcakes[0]

}



func eatChips(bowlOfChips int) {

fmt.Println(""Have some chips!"")

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

fmt.Println(""No more chips."")

}



func pizzaDelivery(boxesDelivered int) {

fmt.Println(""Pizza is here!"")

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

fmt.Println(""Pizza is gone."")

}



func eatPies(pies int) int {

if pies == 0 {

fmt.Println(""Someone ate all the pies!"")

return pies

}

fmt.Println(""Eating pie..."")

return eatPies(pies - 1)

}



func main() {

takeCupcake([]int{1, 2, 3})

eatChips(23)

pizzaDelivery(3)

eatPies(3)

fmt.Println(""Food gone. Back to work!"")

}

We can describe the time complexity of all the code by the complexity of its most complex part. This program is made up of functions we’ve already seen, with the following time complexity classes:

To describe the time complexity of the entire office party program, we choose the worst case. This program would have the time complexity O(n3).

Here’s the office party soundtrack, just for fun.

Have cupcake number 1

Have some chips!

No more chips.

Pizza is here!

Pizza is gone.

Eating pie...

Eating pie...

Eating pie...

Someone ate all the pies!

Food gone. Back to work!

P vs NP, NP-complete, and NP-hard

You may come across these terms in your explorations of time complexity. Informally, P (for Polynomial time), is a class of problems that is quick to solve. NP, for Nondeterministic Polynomial time, is a class of problems where the answer can be quickly verified in polynomial time. NP encompasses P, but also another class of problems called NP-complete, for which no fast solution is known. Outside of NP, but still including NP-complete, is yet another class called NP-hard, which includes problems that no one has been able to verifiably solve with polynomial algorithms.

P vs NP Euler diagram, by Behnam Esfahbod, CC BY-SA 3.0

P versus NP is an unsolved, open question in computer science.

Anyway, you don’t generally need to know about NP and NP-hard problems to begin taking advantage of understanding time complexity. They’re a whole other Pandora’s box.

Approximate the efficiency of an algorithm before you write the code

So far, we’ve identified some different time complexity classes and how we might determine which one an algorithm falls into. So how does this help us before we’ve written any code to evaluate?

By combining a little knowledge of time complexity with an awareness of the size of our input data, we can take a guess at an efficient algorithm for processing our data within a given time constraint. We can base our estimation on the fact that a modern computer can perform some hundreds of millions of operations in a second. The following table from the Competitive Programmer’s Handbook offers some estimates on required time complexity to process the respective input size in a time limit of one second.

Keep in mind that time complexity is an approximation, and not a guarantee. We can save a lot of time and effort by immediately ruling out algorithm designs that are unlikely to suit our constraints, but we must also consider that Big O notation doesn’t account for constant factors. Here’s some code to illustrate.

The following two algorithms both have O(n) time complexity.

func makeCoffee(scoops int) {

for scoop := 0; scoop <= scoops; scoop++ {

// add instant coffee

}

}

func makeStrongCoffee(scoops int) {

for scoop := 0; scoop <= 3*scoops; scoop++ {

// add instant coffee

}

}

The first function makes a cup of coffee with the number of scoops we ask for. The second function also makes a cup of coffee, but it triples the number of scoops we ask for. To see an illustrative example, let’s ask both these functions for a cup of coffee with a million scoops.

Here’s the output of the Go test:

Benchmark_makeCoffee-4 1000000000 0.29 ns/op

Benchmark_makeStrongCoffee-4 1000000000 0.86 ns/op

Our first function, makeCoffee , completed in an average 0.29 nanoseconds. Our second function, makeStrongCoffee , completed in an average of 0.86 nanoseconds. While those may both seem like pretty small numbers, consider that the stronger coffee took nearly three times longer to make. This should make sense intuitively, since we asked it to triple the scoops. Big O notation alone wouldn’t tell you this, since the constant factor of the tripled scoops isn’t accounted for.

Improve time complexity of existing code

Becoming familiar with time complexity gives us the opportunity to write code, or refactor code, to be more efficient. To illustrate, I’ll give a concrete example of one way we can refactor a bit of code to improve its time complexity.

Let’s say a bunch of people at the office want some pie. Some people want pie more than others. The amount that everyone wants some pie is represented by an int > 0:

diners := []int{2, 88, 87, 16, 42, 10, 34, 1, 43, 56}

Unfortunately, we’re bootstrapped and there are only three forks to go around. Since we’re a cooperative bunch, the three people who want pie the most will receive the forks to eat it with. Even though they’ve all agreed on this, no one seems to want to sort themselves out and line up in an orderly fashion, so we’ll have to make do with everybody jumbled about.

Without sorting the list of diners, return the three largest integers in the slice.

Here’s a function that solves this problem and has O(n2) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// loop over three forks

for i := 1; i <= 3; i++ {

// variables to keep track of the highest integer and where it is

var max, maxIndex int

// loop over the diners slice

for n := range diners {

// if this integer is higher than max, update max and maxIndex

if diners[n] > max {

max = diners[n]

maxIndex = n

}

}

// remove the highest integer from the diners slice for the next loop

diners = append(diners[:maxIndex], diners[maxIndex+1:]...)

// keep track of who gets a fork

withForks = append(withForks, max)

}

return withForks

}

This program works, and eventually returns diners [88 87 56] . Everyone gets a little impatient while it’s running though, since it takes rather a long time (about 120 nanoseconds) just to hand out three forks, and the pie’s getting cold. How could we improve it?

By thinking about our approach in a slightly different way, we can refactor this program to have O(n) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// create variables for each fork

var first, second, third int

// loop over the diners

for i := range diners {

// assign the forks

if diners[i] > first {

third = second

second = first

first = diners[i]

} else if diners[i] > second {

third = second

second = diners[i]

} else if diners[i] > third {

third = diners[i]

}

}

// list the final result of who gets a fork

withForks = append(withForks, first, second, third)

return withForks

}

Here’s how the new program works:

Initially, diner 2 (the first in the list) is assigned the first fork. The other forks remain unassigned.

Then, diner 88 is assigned the first fork instead. Diner 2 gets the second one.

Diner 87 isn’t greater than first which is currently 88 , but it is greater than 2 who has the second fork. So, the second fork goes to 87 . Diner 2 gets the third fork.

Continuing in this violent and rapid fork exchange, diner 16 is then assigned the third fork instead of 2 , and so on.

We can add a print statement in the loop to see how the fork assignments play out:

0 0 0

2 0 0

88 2 0

88 87 2

88 87 16

88 87 42

88 87 42

88 87 42

88 87 42

88 87 43

[88 87 56]

This program is much faster, and the whole epic struggle for fork domination is over in 47 nanoseconds.

As you can see, with a little change in perspective and some refactoring, we’ve made this simple bit of code faster and more efficient.

Well, it looks like our fifteen minute coffee break is up! I hope I’ve given you a comprehensive introduction to calculating time complexity. Time to get back to work, hopefully applying your new knowledge to write more effective code! Or maybe just sound smart at your next office party. :)

Sources

“If I have seen further it is by standing on the shoulders of Giants.” –Isaac Newton, 1675",https://cdn-images-1.medium.com/max/1200/1*_YsSsyFQ5sgS8F0kiZ1USA.png,[],https://medium.freecodecamp.org/a-coffee-break-introduction-to-time-complexity-of-algorithms-64df7dd8338e?source=collection_home---6------24----------------,2018-06-04 23:44:40.970000+00:00

Big Data,Media – Medium,"['Ev Williams', 'Dave Pell', 'Hossein Derakhshan', 'Dawn Ennis', 'Stephan Neidenbach', 'Don Day', 'Jessie Singer', 'Tim Grierson']","Media Where the newsroom is the news.

Follow Following",https://cdn-images-1.medium.com/max/1200/1*wLhNmBWoSMvG0kyRGjDIqw@2x.jpeg,[],https://medium.com/topic/media,

Big Data,The Inspiration of Anthony Bourdain – Member Feature Stories – Medium,['Christine Byrne'],"One of my first great food memories comes from a trip my family took to Normandy when I was six years old. We hadn’t been sitting for two minutes when I announced to my parents, “I want the escargot.”

Dad: “You know that’s snails?”

Six-year-old me: “Yes! We just learned about them in French class, and I want the escargot!”

My parents went along, although I’m sure they expected I’d take a few bites out of stubbornness, then subtly push the dish of garlic and butter and earthy mollusk aside, hoping no one would call out my misplaced courage.

Actually, though, I ate every snail, then mopped up every bit of briny, herby garlic butter left behind. I still think about those snails and about how excited and proud I was to love them so much.

A decade after those snails, I sat on the living room couch with my dad and watched an episode of No Reservations, Anthony Bourdain’s first food travel show. I, like millions of others, was drawn to the irreverent reverence with which he seemed to approach every food he tried, to his eagerness to try anything, and to his ability to narrate the stories of different foods, cooks, and cultures in an unpretentious way that let them mostly speak for themselves. Until then, I had thought of food and travel writing and television as more marketing than storytelling, but watching No Reservations made it clear that, actually, food was not only a story in and of itself, but also a great way to anchor other stories in something tangible and universally understood. Bourdain wasn’t out to sell an experience or show how good something could be — every episode was about telling the story of things exactly as they are.

Bourdain wasn’t the first to talk about food this way, but he was the first to make me feel like maybe I could talk about food that way, too. Food was an important part of my life growing up, but not in a particularly extraordinary way that I felt would resonate. We lived abroad and traveled often, so I was massively privileged in that there was always something new to eat. I remember eating pâté for the first time on a pebble beach in Cornwall while watching my dad (try to) learn to windsurf. I remember tearing apart a slick piece of roti prata and dipping it into a Styrofoam container of curry sauce on a plastic picnic table in Mersing, Malaysia, before getting on a bum boat to an island where I’d go to summer camp for the first time. I remember my first drink: a Tiger beer at Newton Circus, another hawker center, after the closing night of our high school production of South Pacific. I remember, every year when we’d fly home to New Jersey, eating baked ziti and supermarket sheet cake at Fourth of July barbecues, both or which were exciting and special for me because I only ate them once a year. I remember the first time I ate lunch at a New York City deli and was awed by the enormity of both the sandwiches and the Snapple selection. None of this seemed like a story, though, because I wasn’t sure why anyone else would care.

Years later, as a rising college senior, I spent the summer working as a publishing intern in New York. Weeks in, I realized that my longtime goal of being a book editor was actually, definitely, not what I wanted. To keep the “I graduate in a year and now have no plan” anxiety at bay, I read more books that summer than I ever have. One of them was Anthony Bourdain’s Kitchen Confidential.

Bourdain’s 2000 memoir, as you may know, gets so much of its magic from the sense you get while reading that every story is true. I figured it would fall into the “I never want to go there, but that sure made me think and was fun to watch” category that some of the No Reservations episodes did, and that the stories about hypermasculine kitchen culture and the people who somehow ended up in it would make me laugh, think, and then move on to whatever book was next.

That’s not what happened. The first story the book tells is one of Bourdain as a fourth-grader on a European cruise with his family. He tries vichyssoise, a potato-based French soup, and is taken aback by the fact that it’s cold. “I’d eaten in restaurants before, sure,” he says, “but this was the first food I really noticed. It was the first food I enjoyed and, more important, remembered enjoying.” Reading it made me think of my snails, how adventurous they made me feel, and how they established food as something important and worth discovering. It’s a good, tame story that I could easily relate to, and I bet most people felt the same when reading it.

The thing is, the relatability of the book started and ended with that cold potato soup. The rest of the book — about restaurant kitchens and all the crass, stressful, macho, bonkers shit that happened inside them — took place in a world very, very different from mine. Even coming from Bourdain, whose stories had been making me feel welcome since I first watched him walk around Paris unironically wearing cowboy boots in the first episode of No Reservations, the book felt like something I was looking in on from the outside. Reading it piqued my curiosity in restaurant cooking but made it clear that it wasn’t something for me. The longer the stories sat with me, though, the more they started to feel like a sort of…dare.

I graduated soon after, six months earlier than planned. I was still put off by my intern experience in publishing and totally uninspired by every job option presented to me by career counselors and all the well-meaning adults in my life. (Although it was 2010 and the height of a recession, so calling them “options” is maybe a stretch.) Food writing had crossed my mind, but I didn’t figure it was something I could just jump into. I can’t really explain my sudden decision to go to culinary school — a mix of desperation, an interest in food, a burning need to be interesting and different, and a nagging curiosity about Kitchen Confidential, if I had to put it into words — but in 2010, I moved to New York and spent 10 months at the French Culinary Institute learning how to cook. It remains the most impulsive thing I’ve ever done—and the most significant.

The following two and a half years spent cooking in NYC restaurant kitchens taught me things that culinary school never could have—about cooking, stress, being a woman in a room of mostly men, and how to deal with constantly being under fire without falling apart. It’s hard to explain what it was like to walk into a restaurant kitchen, and I honestly don’t remember it clearly, but I do remember that everything I did was wrong, everywhere I was was in the way, and every time someone said something to me, I had to ask them to explain what they were talking about. It was the most underqualified and out of place I’d ever felt, even though I knew in theory that’s exactly what I was signing up for. (I’d read the book! I intentionally jumped out of my comfort zone!) It wasn’t the useless, undervalued feeling that comes with an entry-level office job; it was the feeling that I needed to apologize for even being there, for being the alien who disrupted a system that everyone else knew how to work in. Weeks went by before I was able to walk into that kitchen without absolute fear; months went by before I was able to actually contribute.

Was restaurant cooking the way Bourdain described? Not really. It was vaguely the same, sure: late nights, weekends, burn scars, characters, industry bars, some yelling, ticket boards that inexplicably but reliably went from empty to full in a matter of minutes every single night.

The actual experience of it was very different from what I’d read, though. Because it wasn’t his experience—it was mine. I was the one cramming four hours’ worth of food prep into two and a half every afternoon. I was the one at the stove, firing seven dishes from three different orders at the same time, in exactly the right order, totally on instinct. I was the one who stayed at the bar three hours too long on a Tuesday and somehow always managed to find my way on the L train. I was the one who felt disconnected from one world but totally plugged into another.

Which made me realize: A great storyteller is one who makes you want to experience stories for yourself. A great story is one that makes you think, “I wonder what it would be like to do that.” I’m not much of a storyteller these days, nor am I still a restaurant cook. I write recipes, and I write stories about how and why people should cook them, but I do so in a way that’s shaped by what I’ve learned: Recipes are like stories, kind of, and the best recipes are ones that people will actually cook. Getting someone to cook a recipe isn’t about presenting them with something they’re already familiar with, necessarily, but about making them think, “I wonder what it would be like to do that.”

It’s no secret that Anthony Bourdain was a great storyteller. I’ll miss following along with his unending curiosity about food and how it shapes us, and the world will miss the way he was able to share that curiosity in a way that was welcoming and inclusive. What I’m most grateful for, though, is that he showed me the inside of a world I’d never given a second thought to—restaurants—and painted a picture that, even though it was totally unrelatable to me, was interesting enough that I felt compelled to experience if for myself. Not many storytellers do their job so well that, after reading their stories, you actually feel moved to go out and live them.

“Food, for me, has always been an adventure,” Bourdain writes in the preface of Kitchen Confidential. For me, too, Chef. Thanks for teaching me that food is something worth exploring and that the exploration is something worth writing about.",https://cdn-images-1.medium.com/max/1200/1*65ru7KtyJDme4kUXz8Sl5Q.jpeg,[],https://medium.com/s/story/the-inspiration-of-anthony-bourdain-8d5679c2acb4?source=grid_home---------0------------------18,

Big Data,"Apple has no idea what’s next, so it’s just banging on the same old drum",['Owen Williams'],"Apple has no idea what’s next, so it’s just banging on the same old drum If you want to witness a company that’s simultaneously in its prime and losing control over its own narrative, look no further than WWDC, Apple’s second-most splashy event of the year, designed to offer a glimpse of the future. The annual developer event is a spectacle that I’ve watched live for almost a decade, but this year was different: it showcased a company that’s lost in the woods, playing the same old hits on repeat, in the same old format. Not only was it painful to watch, it demonstrated that Apple doesn’t really have a coherent plan, or understanding, of where it should take its core platform, let alone the ones it’s tried to build around it. It’s fine to have an off year, but what struck me was how… random it felt, and how little insight or forward thinking there was. Apple’s own platform advantages, company culture, and whatever else, seem to be pigeonholing its trajectory, driving it down a path that looks increasingly dated, and leaving me to wonder if the company is self-aware enough to see the shifting tide before it’s lost at sea. Big, slow, yearly

Apple struggled throughout 2017 to ship flagship features it promised at WWDC 2017, including Airplay 2 and iCloud Messages, delivering them quietly just days before this year’s event. Alongside a scandal about performance throttling, a series of major security slip-ups, and hardware that shipped without long-touted features, many have loudly asked what’s causing these issues — and why a company with so many engineers is fundamentally failing to ship. Performance improvements are arguably the biggest focus of iOS 12. They’ll be welcome for many users, along with several additional improvements: streamlined notifications, a new ‘shortcuts’ feature for custom buttons, usage reporting, group FaceTime, AR updates and a number of other minor improvements to create a major release, iOS 12. The company’s other platforms received similar treatment, including macOS. Apple finished dark mode, a feature it half-introduced all the way back in Yosemite, added basic functionality to Finder, threw in a new way to organize your desktop, and boom — there’s your major release, 10.14. None of these things are inherently bad — in fact, people have been complaining about the lack of improvements to things like FaceTime for years — but what’s interesting is Apple’s choice to bundle them together as a way to make them look truly meaningful, rather than just fixing many of these issues sooner, in a point release. I’m aware there’s a slew of tiny other fixes and features I haven’t listed here, but that’s my point: it’s a hodgepodge of things that have been neglected over the years after being debuted once and forgotten about. Here’s the rub: Apple could arguably ship notification improvements to iOS users tomorrow in a point release, iOS 11.5, but it won’t. Combining them provides the illusion of progress. Instead of servicing users and giving them features sooner, on a regular basis, Apple chooses to hold back simple functionality longer, for its bottom line. As Martin Bryant points out, Apple may have a timing problem: Yes, Apple needs to take the time to do ‘boring’ optimisation work on iOS, but why build iOS around these big, annual feature bumps and then disappoint people when the bumps aren’t very big?

Interestingly, the narrative here actually doesn’t make sense anymore, either. Every year, Apple takes the time to point out how dire the state of the competition is: Nobody’s Android phones get updates! Android people don’t get any the latest features! Your phones all suck! The reality is different: Android users, regardless of manufacturer, frequently get them sooner than iOS users do, because Google divorced the operating system and core application suite from one another. Google’s approach to unbundling Android has, for the most part, been quietly successful — in an unexpected way. Instead of shipping monolithic feature updates, Google’s applications are now updated via the Play Store, from the clock app to the calculator and even the camera (unless you’re Samsung). Apple has made a yearly ritual out of jabbing competitors for poor update histories, but conveniently omits the reality that improvements to Google Assistant, the built-in web browser, or even just the OS keyboard will reach billions of users in a matter of hours without needing to update the entire phone. Android’s support libraries mean developers can target older devices, with new features, regardless of whether or not they received the OS update. Meanwhile, if you find a bug in the iOS keyboard, or some weird security flaw in Safari’s web view, you hope it gets fixed in the next version of the operating system. Maybe next year, or the year after that. It depends how bad it is, or if Apple is actively maintaining the feature, as to when it’ll get serviced. Don’t get me wrong, Android has a terrible history of updates that is only now beginning to change, ten years after the fact. Google has made strides with Project Treble, which makes an end-run around the device maker itself, but it’s only in its infancy with new devices picking it up today. That’s not good enough either; but it’s gaining traction and getting things into people’s hands. For each platform update, Apple dangles a carrot. That’s the flagship feature to convince you it’s a Big Update™ worth having immediately. On macOS this year, that’s dark mode, and on iOS, the promise of performance improvements and, god forbid, actually decent notification management. Arguably the most interesting segment out of WWDC happens at the very end of the two-hour keynote: a peek at Project Marzipan, a long-term effort to unify the interface framework developers use to build apps for iOS and macOS, which is expected to ship to everyone in 2019.

From where I sit, this is an impressive, massive project that doesn’t do much more than play defense against Electron’s continued march on Apple’s territory, threatening to kill native application development altogether. Why build anything native at all, when you can write once, and run everywhere? Anti-Electron fans will run rabid at the idea, but as the technology has become more efficient and introduced lower-level API access, it only makes even more business sense. Marzipan is an audacious plan to defend against that by making it easier to build cross-platform apps. It’s a genuinely fascinating play with fewer apparent benefits in the short term over just building an Electron app, which addresses an additional billion users, allows developers to use familiar web technology and is truly write-once-run-everywhere. Over time, Marzipan may win favor with developers, but I’m not convinced it’ll stop web-based technologies swallowing native app development whole, particularly given that both Microsoft and Google have now bet their entire strategies on Progressive Web Applications, and how low the barrier of entry has come as a result of Electron’s success. Marzipan indicates something bigger, of course, such as an impending shift away from Intel chipsets entirely to some sort of custom Apple ARM-based silicon in — shock horror — a productivity form factor. If anything, what will win as a result will be that control, and what it could ship in a end-to-end device: true all-day battery? Always-on LTE with desktop class apps? If so, the message is this: lock in with us, develop for our platforms, and we’ll reward you. Don’t, and you’ll be shut out and stuck on the outside. Hey Siri, where’s the vision?

What’s clearly missing in all of this is a willingness to take risks, or go for the long view on what’s better than the status quo for Apple’s users. Instead of looking at how phone usage is changing and redesigning the nature of iOS, it’s another year of shoehorning new features into a decade-old shell. The new shortcuts feature promises to let users wire up workflows of their dreams, chaining together tasks behind a single button. Yes, this is a great improvement to iOS that addresses a problem without actually improving on the reason anyone needs this in the first place — it’s just glued onto the homescreen that’s responsible for causing the need for it in the first place. Apple could have offered up a way to surface the weather right there, deeply integrated with the lock screen, or calendar events at the top of your home screen along with the icons, but it didn’t. Instead, it slathered what appears to be a UX hack in the shape of a notification, and tries to guess when you want to see it. Google’s own developer conference, just down the street in Mountain View, was held in May and offered a clearer, if poorly highlighted, view of the future: AI is a core part of mobile devices going forward, so we’re beginning to add it everywhere. The Android alternative to Shortcuts, Slices and App Actions, surfaces the device’s best guess at your next action as a deeply integrated interface component, where you can actually see information before actually going further in, or taking an action. Want a button to order a Lyft? Great, here’s a button embedded within the system’s app tray, with the current estimated price of your ride, which orders it right now with a single tap. Much of this data is crunched on device, just like Apple’s audacious claims to privacy brag about as well, but instead of being a UX hack to add buttons that summon help, the information is already right there, on hand, without opening anything, even Assistant. Google and Apple both anticipate a future in which we use our phones less — time well spent is a core part of this driver — and as a result, it appears Google has spent a lot of time thinking about how AI can help get the right information to the user. The result is the exact button they need at the right time, with relevant information, sans the need to actually go away and do something. To facilitate this, Google is willing to rejig the UX of its devices, mess with the sea of icons, and has invested heavily in serendipitous computing with Google Home alongside this, so it can get you there faster regardless of if the phone is in your hand.

Google’s vision of the future of smartphones, mobile operating systems, and the way we’ll interact with devices over the long haul is a coherent, well-told story: get more out of your day, get the devices out of the way. It even has a fantastic page that showcases how its own ecosystem works better, together, than I’ve ever seen explained about Apple’s ecosystem on its own site. As for why all of this happens, I suspect it’s a difference in strategy and approach. Apple’s strategy has long been to monetize its existing cash cows as long as it can by throwing out new stuff to see what sticks and doubling down on that, rather than creating any sort of coherent narrative of what the future actually looks like, operating in secrecy until it somehow lands upon it. Incremental improvement is fine, but there’s a distinct lack of forward-looking, and a whole lot of looking over the fence at what everyone else is doing to bash it instead. Apples, oranges and comparing the two

It’s easy to compare and contrast Google and Apple because they are very different companies, but what they’re both claiming to do is the same: invent the future, whatever that actually might be. Their approaches, however, are increasingly diverging: Apple’s squeezing more out of less, shipping flashy features, and focusing on privacy, while Google and others have pushed further into understanding the user and getting out of their way. Most of this comes down to business model. Apple’s focus on features by piling them together drives more sales of iPhone, which drives reliable revenue on a yearly basis. Google’s is on advertising and relevance to the user, which doesn’t depend on a particular feature or thing to tout, it just needs you to love using its tools (and not mind advertising). Apple’s entire strategy over the last two decades has pivoted around the exploitation of a product line until something new comes along, then rinse and repeat. This is framed around improving your life and often actually does, even if that is by proxy. I’d argue that the company’s vision of the future isn’t to enrich, or drive progress, but to squeeze as much revenue as possible out of slick, well-designed and marketed ideas. The products it builds, the cycles they’re released in and the way that Apple’s entire software cycle works reflects this. An example of the manifestation of this is perhaps HomePod’s requirement to have a locally available iPhone to do anything interesting, leaving it crippled without one, and Animoji’s debut only to be locked away in Messages instead of somewhere like the camera.

Google, a latecomer in the game, has the luxury — and peril — of not depending on phone revenue, so it can risk it all and get weird, since it’s not fundamentally critical to the company’s continued trajectory. Microsoft has done the same, now finding itself the underdog, risked it all and moved to an ‘OS-as-a-service’ model in which it ships features when they’re ready instead of waiting for flashy releases. Apple, on the other hand, begins and ends with the iPhone today, the rest flows from there. It can’t just rip up the foundation on which its revenue exists, and Tim Cook hasn’t shown a flair for doing so. iOS is too valuable to go away and tear down to just reimagine it for fun, so it’s the status quo, with experiments like HomePod and AirPods on the side, where it can get weird and sometimes wonderful. That’s fine, because Apple has plenty of cash lying around, but it’s interesting how limiting the approach can become. As we hurtle toward peak smartphone, the cracks here are beginning to show because Apple don’t have the next big thing yet — that we know of, naturally — and it’s taking a long time to get here. We’re essentially watching the bottom of the metaphorical tube of toothpaste being squeezed, while others are trying to figure out if maybe the tube should work completely differently. AR is potentially the next platform, yes, and it’s clear that Apple is pushing forward on that in a big way, so it’s easy to imagine a scenario in which it makes sense to shift precious resources there instead of focusing on iOS which may wind up unimportant in a year or two. I’m not convinced that in the short term, such as the oft-claimed 2020 launch date of an Apple VR/AR headset, that we’ll be headed there in any meaningful capacity. I mean, Magic Leap, a bajillion dollar company building the future of AR showed off its hardware yesterday on Twitch, quipping that “you better not put it in your pocket or it’ll overheat.” I’m happy to be wrong, and I write this knowing I’ll probably be that guy who very publically crapped on the iPhone at launch later. Apple’s worth a very large amount of money, which is more than enough proof that it’s good at many things, including convincing people to buy a phone every year.",https://cdn-images-1.medium.com/max/1200/1*tIUbwrpHZPbdNPXB569wPQ.png,[],https://medium.com/@ow/apple-has-no-idea-whats-next-so-it-s-just-banging-on-the-same-old-drum-dcfd0179cf80?source=grid_home---------0------------------18,2018-06-07 13:54:23.876000+00:00

Big Data,Our Wedding Is Canceled Due to the Following Strongly-Held Beliefs,['Tim Sniffen'],"Hi, everyone. I know you weren’t expecting to see Keith and I out here so soon, but we have some bad news. We’re not getting married today.

Believe me, we were really looking forward to it, but recently — this morning, in fact — we learned our blessed event was in direct conflict with the strongly-held beliefs of many of the people providing our wedding services. And if they’re not happy, we’re not happy.

Let me bring you up to speed.

You may have noticed the empty display table by the reception tent as you filed in. That’s where our wedding cake would have been. For our baker, however, creating a cake to be employed in the marriage of two men would be the moral equivalent of using communion wine to make sangria.

We knew the risks when enlisting Give Us This Beignet, Our Daily Bread as our wedding baker. They’re the best in downtown Aurora, no question — sorry, Wild-Flour! — but their beliefs on same-sex marriage are no secret. We hoped they might get swept up in the joy of the occasion but last night their chief baker Jonah, applying the final bit of piping, had a vision of Billie Jean King physically dragging him away from the gates of Heaven. And if that’s not a sign, I don’t know what is.

I should add, it may not have helped that we requested our little cake figurines be surrounded by an added semi-circle of figurines, in likenesses of the bakery staff, giving us the thumbs-up.

But that’s all done with. They’ve made their wishes clear and we respect them.

Which brings me to the empty vases alongside the pews and the empty centerpiece bowls on the reception tables. We’ve known Joyce Gantz, owner of Rest On My Laurels, for years; I couldn’t imagine this day without her. What I couldn’t know was the war raging within Joyce, fervent Catholic, after she learned of the meat-laden Friday barbecues Keith and I throw for our softball team. Last night, Joyce looked deep within her heart to ask, can I lend my good name to this cursed union?

The dumpster full of imported delphinium behind Joyce’s shop can tell you the answer.

You see, what we’re learning is that these are not just goods and services; they’re not simply the imprints of Keith’s Capital One card and the resulting exchange of goods. Every item at a wedding is nothing less than the avatar of its vendor’s entire belief system. With this in mind, each rose petal my niece Stephanie was prepared to hurl down the aisle might as well have been embossed with JOYCE GANTZ APPLAUDS THEE, SATAN.

What faith-engorged entrepreneur should face such hell?

This is why the rows of steam-trays in the tent are empty, and your choice of beef tenderloin or grilled salmon — or the one plate of tempeh veggie kabob, bless you, Amy! — will never arrive. Because Something Borrowed, Something Cordon Bleu, exceptional wedding caterers and unapologetic druids, could not bear the thought of providing nourishment to a couple willing to rip two thriving Magnolia trees from their backyard last summer. From their email: “Your heretic’s feast will be served when the earth heals from your violence.” By our best guess that wouldn’t have been by 6 p.m.

We also won’t be dancing to Renèe and the Ring-tones. While Rènee was a woman of few beliefs when we booked her, she has since converted to the Egyptian cult of Bastet, and considers the choice to put our cat Banjo to sleep, rather than pay $15,000 for experimental feline jaw surgery, to be “unforgivable wickedness, worthy of disciples of Set.”

I’ve been handed this note: Lane, our photographer, turns out to be more of a Star Wars guy and doesn’t feel right legitimizing such an obviously Star Trek couple.

Blessings on your journey, Lane.

In closing, our apologies. We were so busy coordinating our big day that we forgot to coordinate the sacred truths of all players involved. I’m told many of our vendors will adopt an exhaustive three-week interview process before each sale to keep this from happening again.

We did have a lovely wedding favor created for each of you, which we might as well distribute. It’s a wooden plaque, engraved with the phrase Love Conquers All, hand-crafted by our friend Bryce Charles in the front row. Now, Bryce is something of a Packers fan, and Keith is all about the Bears, but in the spirit of friendly rivalry, we’ve always managed to put aside our differ — wait.

Bryce’s feelings are changing.

They’re moving from loosely-held to nonchalantly-held. They’re not done; from the set of Bryce’s jaw, her feelings have transitioned to intentionally-held, and finally, they’re — yup. They’re strongly-held. Dammit.

Sorry, folks. You’re on your own.",https://cdn-images-1.medium.com/focal/1200/632/50/45/0*fh1vaEnMNoMbHE42,[],https://medium.com/s/story/our-wedding-is-cancelled-due-to-the-following-strongly-held-beliefs-1fa71105660e?source=grid_home---------0------------------18,

Big Data,My So-Called (Millennial) Entitlement – Trust Issues – Medium,['Stephanie Georgopulos'],"I am at the San Francisco International Airport some barely recent morning, registering for a travel program called Clear when the automated kiosk assisting me makes a strange request: “Stand still while we scan your irises.” I’ve barely digested this first ask when another takes its place: this time, the kiosk wants my fingerprints. I find this slightly less alarming; I already use those to access my banking app, buy coins for my mobile games, and unlock the phone that hosts all this information in the first place. But my eyeballs — which I had only just learned could be used as ID, and from a machine at the airport, no less — my dude. Those are the windows to my soul! Ever heard of foreplay?

Clear is a private company that prescreens air travelers using biometric authentication. Becoming a member is like ordering the half-soup, half-sandwich version of TSA PreCheck: it works, if all you want is a taste and are willing to pay for it. With Clear, you don’t need your ID to go through security, but you still have to remove your shoes. You get to wait in a shorter line (sometimes), but you still have to take out your laptop. Basically, the Cleared still participate in the most annoying aspects of air travel and pay almost 10 times the PreCheck fee for the privilege.

If the worst has already happened, that means it’s survivable.

How we decided on this valuation of convenience—it’s $179 per year—is not the point, though. My point is that some random startup casually acquired my eye-prints, and some small voice is telling me I should care more than I do. Someone out there definitely cares about this, no doubt. I’m sure at least one other traveler was not sated when a brisk Google search revealed that Clear is based in her hometown and run by a female CEO, ergo it must be a secure and entirely trustworthy business.

But I was sated. It’s the future, right? What’s the worst one could do with my retinal scans? I already gave my social security number to Camel in exchange for a pack of promotional cigarettes one time (or 12). Somewhere in Midtown Manhattan, a market-research firm knows how many condoms I used in May of 2011 (give or take). And when I think about the fact that every hard document I’ve reproduced on a digital copy machine — at work, at the bodega, at the library — is saved on a hard drive somewhere (lots of somewheres, in fact), I feel a sense of hopelessness that, in its own demented way, translates to freedom.

That’s why I unlock my phone with my fingerprint. It’s also why I talk shit in front of Alexa, why I haven’t put tape over my laptop camera, and why I still have a Facebook account. I don’t expect the worst to happen.

Because the worst has already happened. It is happening, and it will continue to happen.

I find this to be an honest, useful framework. If the worst has already happened, that means it’s survivable. And if the worst is a given in the future, too, we know that ignoring it won’t make it go away. There’s opportunity in having nothing to lose. You just need the right attitude.

Or perhaps you need the right conditioning.

Imagine: You’re 11 years old when two teenagers bring guns to their high school and kill 13 people. They injure 21 more. Your sixth-grade humanities teacher explains the inexplicable to your class after lunch period. You have to imagine that this is a first for at least some of your classmates, crying over the national news. It won’t be the last.

When you’re 15, two planes crash into two towers. You know the towers; had toured them on school trips just like all the other famous Manhattan buildings for which you know the names, if not the functions. In fact, you’d visited the towers just one week before the planes hit. There had been a renaissance fair in one of the lobbies.

At 17, your high school economics teacher tells you that social security will run out before you retire. You’ve already been paying taxes for three years. In 2018, you learn that he was exaggerating, thank goodness — by 2034, retirees can expect to receive a whopping 79% of the full benefit they receive today. You will not be of retirement age until the 2050s.

And when you’re 21, the market crashes. You’ve had a bachelor’s degree for three months. It cost $100,000 to earn, all before interest. Your class valedictorian moves back in with her parents, and no, your internship is not hiring. Five years later, the unemployment rate for people your age is almost double the national average.

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

Neuroscience has confirmed that you were making sense of these events with an underdeveloped brain. Along with your emotional maturity and your hormones, it’ll be a work-in-progress until you’re around 25. And the same way the small hurts of being small can still seep into your present — the way your grandmother eyed you with disgust when you went for a second helping — the chipping away of every institution you were raised to believe in can have unintended consequences.

Me: Do you use Touch ID to unlock your phone?

Friend: Ya.

Me: Do you know anything about the technology behind it? Or like, how secure it is?

A beat. A blank stare.

Friend: No?

Me: Same.

My friends do not need to understand the technology behind touch ID any more than they need to understand black holes. They are not convinced that adjusting their social media privacy settings is some sort of moral duty, a symbolic middle finger to Facebook on behalf of all the little guys who understand internet economics to varying degrees, or not at all. Mostly, they were confused as to why any thinking person would have an assumption of security.

“It’s not that I don’t care about being hacked, or about my data being stolen or sold,” one friend tells me. “I assume that vulnerability because there are no physical systems or structures that have succeeded, so why would something that is essentially invisible do a better job than something tangible?”

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

I’ll go: I don’t expect to own a home. I don’t expect to retire well, or at all. I don’t expect anyone to give me anything I haven’t explicitly asked for, and even then. I don’t expect it will ever be affordable to continue my education in any formal way. If a package gets lost in the mail, I don’t expect to see it again. I don’t expect the government or the banks or the universities to do anything that benefits regular people. I don’t expect them to hold each other accountable on our behalf. I don’t expect them to expel abusers from their ranks, or to put my safety over their legacy. I don’t expect to feel safe in large crowds or alone late at night. And I don’t expect that my privacy will be respected, online or in general.

America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

As far as I can tell, security — whether financial, technological, physical, or emotional — is not a thing. You don’t get to decide whether some drunk asshole drinks his drunk ass off and gets behind the wheel. Likewise, you don’t get to decide if the drunk Congress or the drunk banker or all the drunk administrations of all the drunk institutions do what’s right for you. Sometimes they will do the right thing for somebody, but statistically speaking, that somebody is not you.

Sometimes the right thing comes served in a shit sandwich, or one guy does the right thing but it’s later counteracted by the next guy and just so we’re clear, it’s always a guy. Or sometimes, we learn that what we thought was the right thing was actually the wrong thing, in ways we didn’t anticipate, except for those of us who did anticipate it but were not asked or heard because we do not employ lobbyists and because the powers that be can’t listen to us until they sort out whether our bodies are legal or not.

Mark Zuckerberg’s Congressional hearing was probably the biggest mainstreaming of data privacy issues yet, and Facebook, with its many transgressions, made for an appropriate scapegoat. But I want to know why it’s Mark Zuckerberg’s fault that American adults of voting age lack the critical thinking skills to differentiate between fake Russian bot news and The Guardian. I want to know the plan for bringing internet literacy to those who are not digital natives. I want to know why the U.S. government is being celebrated for protecting our egos and baby-proofing the internet instead of telling us the truth: Dirty tricks are less likely to work on people with more education.

What happens when your brand of exceptionalism breeds millions of people who voted a sentient conspiracy theory into office? Where does the fault lie? After all, it’s not Facebook who’s spent decades underpaying teachers and closing schools in low-income neighborhoods. Facebook doesn’t have the jurisdiction to end standardized testing or combat the quiet continuation of white flight. Facebook’s biggest mistake? Profiting off of state-sanctioned dumbness.

We’re only supposed to be dumb enough to believe that the fight is red vs. blue and not top vs. bottom. We’re only supposed to be dumb enough to believe in Democracy the Concept™ without casting a critical eye toward its practical application. This is a dumbness cultivated by and for Washington, and Zuckerberg’s misusing of it for corporate gain almost blew the lid off the entire thing. Commence finger-wagging.

On an episode of his podcast Revisionist History, Malcolm Gladwell argues that we should treat education as a weak-link network, where strengthening the weakest links has the most positive outcome for all. This is in contrast to a strong-link network, where a couple of superstars at the top carry the weaker players on the bottom. He illustrates this dynamic using soccer and basketball. An average soccer team with one star player is less likely to win a match than an above-average team with no star players — soccer is a weak-link sport. Conversely, an NBA team with a superstar or two fares better than a team on which all the players are equally, decently good — basketball is a strong-link sport.

Much to its detriment, America acts like a strong-link country. It is the type of place where electing one mixed-race president means we solved racism. (Imagine if the lesson we took from electing one white man was that all white men who lack upward mobility just need to work harder.) We raise up a few undoubtedly smart and deserving people in each field, send them around the world like brand ambassadors for democracy, poster-adults for how advanced and distinguished and American we are. Meanwhile, most of us back home — 78%, in fact — are living paycheck to paycheck. Is that freedom ringing? We’ll call right back after we pay this phone bill.

These are complex problems. In addition to the 3000ish words here, I have written and cut an additional 4500 trying to make sense of it all. I remain overwhelmed by the number of solutions that contradict one another, the knowns and unknowns, the countless logical ends I haven’t considered. But I eventually found my demented silver lining: America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

While grim on its face, this perspective has pushed me to take inventory of myself, my own power. What can I do right now? Am I solving problems I actually care about, or were these problems unconsciously inherited from another time, problems propagated by those with a vested interest in resolving them with more money, more power, more loopholes? Should I devote my energy to righting a system that, by design, has only consistently benefited one demographic and has yet to even prove itself as a scalable model for a generation that’s tired of the same people making the same decisions on behalf of the most diverse country in the world?

Is that a problem? Because it feels more like an opportunity, to me: a chance to exercise this cache of personal agency I’ve been sitting on, agency I didn’t realize I had or needed as I waited for America to work. It feels like an opportunity to try something else.

More powerful than having nothing to lose is cultivating that which can’t be taken. Grace. Clarity. Purpose. The stuff that isn’t Amazon Prime-able. These are the indoor plants of our being; only you can feed them and grow them and expose them to the light. It’s a lot of responsibility, and the work involved is often unglamorous. Some people think they never have to learn to care for these things because they have the means to outsource what they wish: their plants are alive on paper though they don’t know the how or why of it. And besides, can’t you see they’re a little busy trying to colonize Mars?

A respectable goal, though I might suggest to anyone faced with the choice to try taking on the inner self before jumping ahead to outer space. There’s more to unearth in there than you might think, and we need more people to understand the potential of their own organic material. We need people who appreciate the slow growth of nothing into something, who drink up the sunlight and make the air a little more breathable than before.

Because that’s it, for most of us. That’s how we build power. That’s how we, a generation of janitors for the American dream, put our trust in something real: each other. We stop trying to control the world in our heads and in the headlines, and we start controlling ourselves. We sleep. We go to the doctor. We log off. We talk about our problems. We water our plants. We collect our neighbor’s mail when they’re out of town. We take a deep breath before reacting in anger, and question whether this particular battle is worth our energy. It’s not. Why were we fighting again? We volunteer. We water our plants. We focus on ourselves so we can eventually focus on others — in a real way, in a non-transactional way, in a way that slowly but authentically strengthens our fellow weak links. We don’t wait for permission. We get over ourselves; we stop demanding perfection; we start. We water our plants. And on weekends, we play soccer.",https://cdn-images-1.medium.com/max/1200/1*c5zNxCX34sYmYYO-yRxlbA.png,[],https://medium.com/s/trustissues/my-so-called-millennial-entitlement-9be84343c713?source=grid_home---------0------------------18,

Big Data,How to Cope with the End of the World – How to Cope With The End of The World – Medium,['Maria Farrell'],"We All Die, and That’s Okay

My favorite postapocalyptic novel is George R. Stewart’s 1951 Earth Abides. In it, scientist Isherwood Williams (nicknamed Ish) survives a plague and eventually starts a new family and community in the ruins of suburban California. His hope for the future is wholly invested in a child who is intellectually curious, like him, and who might be able to revive some of the old ways and technologies. It’s an observant and reflective novel, full of the “how stuff would probably work” thinking that makes science fiction the true literature of ideas.

Ish starts out as a scientist-savior of humanity, figuring there is just enough time to raise a generation to turn back the clock to before the disaster. But he ultimately has to make his peace with the fact that civilization as he knew it is dead, there will be no heroic rescue, no going back, and the people around him are mostly fine with that.

The 1950s may have been the last decade we could complacently believe the Ecclesiastes (1:4) maxim that “men come and go, but earth abides,” but Stewart’s basic message is correct.

The people who come after us don’t have to do better than us, or think well of us, for them to be essentially okay. And us all throwing a big “let’s blow it all up” hissy fit because we fucked up and we can’t bear to look at it is just teenage nihilism that we need to grow out of already. Coming to terms with what we have done means dumping the egotistical death drive of the mass shooter or far-right politician and gathering the maturity to look our individual and collective deaths straight in the eye and say, “Okay, we get it now. We get it. It’s not about us.”

Have you ever stood in a crowded place like a town square or an airport meet-and-greet and thought, “Every single person here is going to die”? Morbid, eh? More of us should do it.

I live in an early Victorian terraced house in the UK. It’s never been a tenement, so probably a hundred people have called it home in the almost two centuries it’s been standing. Nearly all of them are dead. The people are already born who’ll live there when I’m dead. The head of this country’s anachronistic state has already been born who I’ll never see on the throne and to whom I’ll seem as old as someone born in the 1930s seems to me.

We’re all going to die. The morning will come when those who have loved us put on dark clothes and cry and get on with the rest of their lives, seeing movies we’d have loved, depending on gadgets that now seem to us ridiculously unnecessary. Our deaths matter to us and those who love us, but they don’t fundamentally matter.

Once, while my husband was deployed to Afghanistan, I asked him on the phone if he was doing okay about someone we knew who’d recently been killed. “Oh, you know,” he said, “you know,” and quoted his regiment’s unofficial mantra:

Everything matters. Nothing matters terribly.

The soldier’s death mattered very, very much to him, and (not but) he and others were nonetheless carrying on their shared purpose. Otherwise, what had been the point of any of it?

What will outlive us, individually? Plastic. Perhaps some genes. The bacteria that act as a species-level enabler for everything we are. Some ideas, maybe, or songs, stories, pictures, the memories of us others hold, until they go, memorials like a community flower bed or a named scholarship, for a while, anyway. Less concretely: ways of being, a fitness for the world that those who flourish pass unremarked to their offspring via the epigenetics of love — the sunny inverse of patterns of trauma and abuse transmitted through the body, even unto the third generation. Predation.

And our species? Buildings and bones, maybe. Our nuclear waste and the warning signs we hope people of our deep future, or other species altogether, will decrypt. Snatches of radio-transmitted voices slipping through the vacuum of space. Perhaps some bacterial payload we’ll launch in a decade or so, trying to seed life on other planets, even in other solar systems. Or just the anomalous levels of carbon dioxide and methane in our atmosphere that will reveal, for a time, that complex forms of life were here.

Pride and despair are two sides of the same coin. Our collective denial and despair about the future we have built is preventing us from cracking on and sorting it out. We need to get over ourselves. The world we know will end, in both small and big ways. We ourselves will end. But that doesn’t matter, terribly.

Our mortality is the greatest enabler we have of positive, ongoing change, if only we can face it, if only we can understand that we don’t get to see the end of the movie, because, if what we do works, the movie won’t have to end. We’re not the protagonists. We’re just the foreshadowing. We need to hold the knowledge of our own deaths up to the light and turn it around to see each shining facet, then take the certainty that we are both finite and imperfect deep down inside of us—and put it to work.",https://cdn-images-1.medium.com/max/1200/0*avXWZmh3n3H7a8t8,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world/how-to-cope-with-the-end-of-the-world-2520ef9d3dbc?source=grid_home---------0------------------18,

Big Data,How to Cope With The End of The World – Medium,['Maria Farrell'],"COLUMN

How to Cope With The End of The World

There are moments of joy even in times of great despair. Maria Farrell explains how to deal with a darkening world, and how to plan for the end. It might be the end of the world as we know it, but it turns out we feel fine.",https://cdn-images-1.medium.com/max/1200/1*kvqwUuDCsbkAoSfaYXV1vQ@2x.png,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world,

Big Data,Chatbots were the next big thing: what happened? – The Startup – Medium,"['Matt Asay', 'Justin Lee']","Chatbots were the next big thing: what happened?

Oh, how the headlines blared:

“…the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”

Chatbots were The Next Big Thing.

Our hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.

And why wouldn’t they be? All the road signs pointed towards insane success.

Messaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!

Plus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.

At the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.

In fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:

“Will a single platform emerge to dominate the chatbot and personal assistant ecosystem?”

One year on, we have an answer to that question.

No.

Because there isn’t even an ecosystem for a platform to dominate.

Fooled by another hype cycle

Chatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.

The age-old hype cycle unfolded in familiar fashion…

Reverential TechCrunch articles were written.

Prophetic thought leaders like Chris Messina chimed in.

Silicon Valley salivated at the prospect of talking to smart automation.

Messenger began to overflow with bots.

Slack went through exponential growth and even launched a fund for bot investment.

Expectations built, built, and then….. It all kind of fizzled out.

The predicted paradim shift didn’t materialize.

And apps are, tellingly, still alive and well.

We look back at our breathless optimism and turn to each other, slightly baffled:

“is that it? THAT was the chatbot revolution we were promised?”

Digit’s Ethan Bloch sums up the general consensus:

“I’m not even sure if we can say ‘chatbots are dead,’ because I don’t even know if they were ever alive.”

According to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.

Text vs. Speech vs. GUI: a potted history

Bots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.

Users had to type commands manually into a machine to get anything done.

Then, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!

Meanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.

Another bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:

… so many different accents, people speaking too fast or too slowly, mumbling, umming and aahing.

Did you say “recognise speech” or “wreck a nice beach”?

The next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:

User: “Hello.”

Agent: “Hello, what’s your name?”

User: “Candy.”

Agent: “Hello, Candy!”

User: “Let’s set the clock.”

Agent: “What is the time?”

User: “The time is 11:00 AM.”

Agent sets the clock to 11:00 AM.

Pretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.

It was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.

Modern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.

Basically, we’re still trying to achieve the same innovations we were 30 years ago.

Here’s where I think we’re going wrong:

Thinking in terms of Bots vs. Apps

An oversized assumption has been that apps are ‘over’, and would be replaced by bots.

By pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.

You might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?

It’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.

Whether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.

Plus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.

A great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.

That’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.

Modern-day apps benefit from decades of research and experimentation. Why would we throw this away?

But, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.

Today’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.

Penny provides chatty advice and alerts alongside a traditional account dashboard and transaction list.

HubSpot Conversations unifies Facebook Messenger, onsite chat, social media, email and other messaging outlets into one shared inbox.

Layer gives developers the tools to create personalized messaging experiences on mobile web and desktop web as well as native apps.

The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.

Bots for the sake of bots

Does my product need a bot? Are existing platforms able to support its functionality? Do I have the patience to build a bot that’s capable of doing what I want it to?

Another problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.

For plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.

Building a bot for the sake of it, letting it loose and hoping for the best will never end well:

The totally necessary Maroon 5 chatbot in action

The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.

The advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.

That’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.

Problems arise when life refuses to fit into those boxes.

According to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.

When we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.

Remember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.

Inaccessibility

A competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.

In an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.

Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)

As Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.

“Consumer interest was never going to materialize until machine intelligence could get anywhere near human intelligence.

User interest depends upon AI that makes talking with a bot worthwhile for consumers.”

And conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.

Today’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.

And in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:

“Should Slack, Facebook, Google, Microsoft, Kik, and others have built their own built-in bots to lead the way?

Should they have gotten more proactive with their bot funds and incubators, hiring mentors to educate participants in the Way of the Bot, or supplying engineering and design resources? Funded Strategic Bot Initiatives at high-profile partners?

In my opinion yes, yes, and yes. When it comes to platforms, developers are the users; and we don’t rely on our users to understand why or how to use our products. We have to show them.”

GUI shouldn’t be dismissed

Once upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information

There’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.

Tapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.

We love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.

Conversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.

Sure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.

Humans like talking to other humans

Aiming for a human dimension in business interactions makes sense.

If there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.

Facebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.

A conversation encompasses so much more than just text.

Humans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.

As HubSpot team pinpointed:

Bots provide a scalable way to interact one-on-one with buyers. Yet, they fail when they don’t deliver an experience as efficient and delightful as the complex, multi-layered conversations people are accustomed to having with other humans on messaging apps.

People aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).

And even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.

And here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.

But is that how humans prefer to interact with machines?

Not necessarily.

At the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.

Where do we go from here?

In a way, those early-adopters weren’t entirely wrong.

People are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.

Not even close.

Computers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.

Computers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.

That’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.

For now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.

But that’s not the whole story.

Yes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.

As Bill Gates once said:

We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. Don’t let yourself be lulled into inaction.

The hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.

I believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.

Messaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.

Developers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.

And I can’t wait to see what happens next.",https://cdn-images-1.medium.com/max/1200/1*-_um8Nai0uer46tni1LETg.jpeg,[],https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=topic_page---8------0----------------,2018-06-05 15:55:36.912000+00:00

Big Data,Google’s AutoML will change how businesses use Machine Learning,['George Seif'],"Google’s AutoML will change how businesses use Machine Learning

Google’s AutoML is a new up-and-coming (alpha stage) cloud software suite of Machine Learning tools. It’s based on Google’s state-of-the-art research in image recognition called Neural Architecture Search (NAS). NAS is basically an algorithm that, given your specific dataset, searches for the most optimal neural network to perform a certain task on that dataset. AutoML is then a suite of machine learning tools that will allow one to easily train high-performance deep networks, without requiring the user to have any knowledge of deep learning or AI; all you need is labelled data! Google will use NAS to then find the best network for your specific dataset and task. They’ve already shown how their methods can achieve performance that is far better than that of hand-designed networks.

AutoML totally changes the whole machine learning game because for many applications, specialised skills and knowledge won’t be required. Many companies only need deep networks to do simpler tasks, such as image classification. At that point they don’t need to hire 5 machine learning PhDs; they just need someone who can handle moving around and organising their data.

There’s no doubt that this shift in how “AI” can be used by businesses will create change. But what kind of change are we looking at? Whom will this change benefit? And what will happen to all of the people jumping into the machine learning field? In this post, we’re going to breakdown what Google’s AutoML, and in general the shift towards Software 2.0, means for both businesses and developers in the machine learning field.

More development, less research for businesses

A lot of businesses in the AI space, especially start-ups, are doing relatively simple things in the context of deep learning. Most of their value is coming from their final put-together product. For example, most computer vision start-ups are using some kind of image classification network, which will actually be AutoML’s first tool in the suite. In fact, Google’s NASNet, which achieves the current state-of-the-art in image classification is already publicly available in TensorFlow! Businesses can now skip over this complex experimental-research part of the product pipeline and just use transfer learning for their task. Because there is less experimental-research, more business resources can be spent on product design, development, and the all important data.

Speaking of which…

It becomes more about product

Connecting from the first point, since more time is being spent on product design and development, companies will have faster product iteration. The main value of the company will become less about how great and cutting edge their research is and more about how well their product/technology is engineered. Is it well designed? Easy to use? Is their data pipeline set up in such a way that they can quickly and easily improve their models? These will be the new key questions for optimising their products and being able to iterate faster than their competition. Cutting edge research will also become less of a main driver of increasing the technology’s performance.

Now it’s more like…

Data and resources become critical

Now that research is a less significant part of the equation, how can companies stand out? How do you get ahead of the competition? Of course sales, marketing, and as we just discussed, product design are all very important. But the huge driver of the performance of these deep learning technologies is your data and resources. The more clean and diverse yet task-targeted data you have (i.e both quality and quantity), the more you can improve your models using software tools like AutoML. That means lots of resources for the acquisition and handling of data. All of this partially signifies us moving away from the nitty-gritty of writing tons of code.

It becomes more of…

Software 2.0: Deep learning becomes another tool in the toolbox for most

All you have to do to use Google’s AutoML is upload your labelled data and boom, you’re all set! For people who aren’t super deep (ha ha, pun) into the field, and just want to leverage the power of the technology, this is big. The application of deep learning becomes more accessible. There’s less coding, more using the tool suite. In fact, for most people, deep learning because just another tool in their toolbox. Andrej Karpathy wrote a great article on Software 2.0 and how we’re shifting from writing lots of code to more design and using tools, then letting AI do the rest.

But, considering all of this…

There’s still room for creative science and research

Even though we have these easy-to-use tools, the journey doesn’t just end! When cars were invented, we didn’t just stop making them better even though now they’re quite easy to use. And there’s still many improvements that can be made to improve current AI technologies. AI still isn’t very creative, nor can it reason, or handle complex tasks. It has the crutch of needing a ton of labelled data, which is both expensive and time consuming to acquire. Training still takes a long time to achieve top accuracy. The performance of deep learning models is good for some simple tasks, like classification, but does only fairly well, sometimes even poorly (depending on task complexity), on things like localisation. We don’t yet even fully understand deep networks internally.

All of these things present opportunities for science and research, and in particular for advancing the current AI technologies. On the business side of things, some companies, especially the tech giants (like Google, Microsoft, Facebook, Apple, Amazon) will need to innovate past current tools through science and research in order to compete. All of them can get lots of data and resources, design awesome products, do lots of sales and marketing etc. They could really use something more to set them apart, and that can come from cutting edge innovation.

That leaves us with a final question…

Is all of this good or bad?

Overall, I think this shift in how we create our AI technologies is a good thing. Most businesses will leverage existing machine learning tools, rather than create new ones since they don’t have a need for it. Near-cutting-edge AI becomes accessible to many people, and that means better technologies for all. AI is also quite an “open” field, with major figures like Andrew Ng creating very popular courses to teach people about this important new technology. Making things more accessible helps people transition with the fast-paced tech field.

Such a shift has happened many times before. Programming computers started with assembly level coding! We later moved on to things like C. Many people today consider C too complicated so they use C++. Much of the time, we don’t even need something as complex as C++, so we just use the super high level languages of Python or R! We use the tool that is most appropriate at hand. If you don’t need something super low-level, then you don’t have to use it (e.g C code optimisation, R&D of deep networks from scratch), and can simply use something more high-level and built-in (e.g Python, transfer learning, AI tools).

At the same time, continued efforts in the science and research of AI technologies is critical. We can definitely add tremendous value to the world by engineering new AI-based products. But there comes a point where new science is needed to move forward. Human creativity will always be valuable.

Conclusion

Thanks for reading! I hope you enjoyed this post and learned something new and useful about the current trend in AI technology! This is a partially opinionated piece, so I’d love to hear any responses you may have below!",https://cdn-images-1.medium.com/max/1200/1*g9BzirXxUauRO9rA_tSvnA.jpeg,[],https://towardsdatascience.com/googles-automl-will-change-how-businesses-use-machine-learning-c7d72257aba9?source=topic_page---8------1----------------,2018-05-14 14:27:41.145000+00:00

Big Data,Automated Feature Engineering in Python – Towards Data Science,['William Koehrsen'],"First, let’s take a look at our example data. We already saw some of the dataset above, and the complete collection of tables is as follows:

Deep feature synthesis stacks multiple transformation and aggregation operations (which are called feature primitives in the vocab of featuretools) to create features from data spread across many tables. Like most ideas in machine learning, it’s a complex method built on a foundation of simple concepts. By learning one building block at a time, we can form a good understanding of this powerful method.

Fortunately, featuretools is exactly the solution we are looking for. This open-source Python library will automatically create many features from a set of related tables. Featuretools is based on a method known as “ Deep Feature Synthesis ”, which sounds a lot more imposing than it actually is (the name comes from stacking multiple features not because it uses deep learning!).

These operations are not difficult by themselves, but if we have hundreds of variables spread across dozens of tables, this process is not feasible to do by hand. Ideally, we want a solution that can automatically perform transformations and aggregations across multiple tables and combine the resulting data into a single table. Although Pandas is a great resource, there’s only so much data manipulation we want to do by hand! (For more on manual feature engineering check out the excellent Python Data Science Handbook ).

This process involves grouping the loans table by the client, calculating the aggregations, and then merging the resulting data into the client data. Here’s how we would do that in Python using the language of Pandas .

On the other hand, aggregations are performed across tables, and use a one-to-many relationship to group observations and then calculate statistics. For example, if we have another table with information on the loans of clients, where each client may have multiple loans, we can calculate statistics such as the average, maximum, and minimum of loans for each client.

we can create features by finding the month of the joined column or taking the natural log of the income column. These are both transformations because they use information from only one table.

A transformation acts on a single table (thinking in terms of Python, a table is just a Pandas DataFrame ) by creating new features out of one or more of the existing columns. As an example, if we have the table of clients below

The process of constructing features is very time-consuming because each new feature usually requires several steps to build, especially when using information from more than one table. We can group the operations of feature creation into two categories: transformations and aggregations . Let’s look at a few examples to see these concepts in action.

Feature engineering means building additional features out of existing data which is often spread across multiple related tables. Feature engineering requires extracting the relevant information from the data and getting it into a single table which can then be used to train a machine learning model.

If we have a machine learning task, such as predicting whether a client will repay a future loan, we will want to combine all the information about clients into a single table. The tables are related (through the client_id and the loan_id variables) and we could use a series of transformations and aggregations to do this process by hand. However, we will shortly see that we can instead use featuretools to automate the process.

Entities and EntitySets

The first two concepts of featuretools are entities and entitysets. An entity is simply a table (or a DataFrame if you think in Pandas). An EntitySet is a collection of tables and the relationships between them. Think of an entityset as just another Python data structure, with its own methods and attributes.

We can create an empty entityset in featuretools using the following:

import featuretools as ft

# Create new entityset

es = ft.EntitySet(id = 'clients')

Now we have to add entities. Each entity must have an index, which is a column with all unique elements. That is, each value in the index must appear in the table only once. The index in the clients dataframe is the client_id because each client has only one row in this dataframe. We add an entity with an existing index to an entityset using the following syntax:

The loans dataframe also has a unique index, loan_id and the syntax to add this to the entityset is the same as for clients . However, for the payments dataframe, there is no unique index. When we add this entity to the entityset, we need to pass in the parameter make_index = True and specify the name of the index. Also, although featuretools will automatically infer the data type of each column in an entity, we can override this by passing in a dictionary of column types to the parameter variable_types .

For this dataframe, even though missed is an integer, this is not a numeric variable since it can only take on 2 discrete values, so we tell featuretools to treat is as a categorical variable. After adding the dataframes to the entityset, we inspect any of them:

The column types have been correctly inferred with the modification we specified. Next, we need to specify how the tables in the entityset are related.

Table Relationships

The best way to think of a relationship between two tables is the analogy of parent to child. This is a one-to-many relationship: each parent can have multiple children. In the realm of tables, a parent table has one row for every parent, but the child table may have multiple rows corresponding to multiple children of the same parent.

For example, in our dataset, the clients dataframe is a parent of the loans dataframe. Each client has only one row in clients but may have multiple rows in loans . Likewise, loans is the parent of payments because each loan will have multiple payments. The parents are linked to their children by a shared variable. When we perform aggregations, we group the child table by the parent variable and calculate statistics across the children of each parent.

To formalize a relationship in featuretools, we only need to specify the variable that links two tables together. The clients and the loans table are linked via the client_id variable and loans and payments are linked with the loan_id . The syntax for creating a relationship and adding it to the entityset are shown below:

The entityset now contains the three entities (tables) and the relationships that link these entities together. After adding entities and formalizing relationships, our entityset is complete and we are ready to make features.

Feature Primitives

Before we can quite get to deep feature synthesis, we need to understand feature primitives. We already know what these are, but we have just been calling them by different names! These are simply the basic operations that we use to form new features:

Aggregations: operations completed across a parent-to-child (one-to-many) relationship that group by the parent and calculate stats for the children. An example is grouping the loan table by the client_id and finding the maximum loan amount for each client.

table by the and finding the maximum loan amount for each client. Transformations: operations done on a single table to one or more columns. An example is taking the difference between two columns in one table or taking the absolute value of a column.

New features are created in featuretools using these primitives either by themselves or stacking multiple primitives. Below is a list of some of the feature primitives in featuretools (we can also define custom primitives):

Feature Primitives

These primitives can be used by themselves or combined to create features. To make features with specified primitives we use the ft.dfs function (standing for deep feature synthesis). We pass in the entityset , the target_entity , which is the table where we want to add the features, the selected trans_primitives (transformations), and agg_primitives (aggregations):

The result is a dataframe of new features for each client (because we made clients the target_entity ). For example, we have the month each client joined which is a transformation feature primitive:

We also have a number of aggregation primitives such as the average payment amounts for each client:

Even though we specified only a few feature primitives, featuretools created many new features by combining and stacking these primitives.

The complete dataframe has 793 columns of new features!

Deep Feature Synthesis

We now have all the pieces in place to understand deep feature synthesis (dfs). In fact, we already performed dfs in the previous function call! A deep feature is simply a feature made of stacking multiple primitives and dfs is the name of process that makes these features. The depth of a deep feature is the number of primitives required to make the feature.

For example, the MEAN(payments.payment_amount) column is a deep feature with a depth of 1 because it was created using a single aggregation. A feature with a depth of two is LAST(loans(MEAN(payments.payment_amount)) This is made by stacking two aggregations: LAST (most recent) on top of MEAN. This represents the average payment size of the most recent loan for each client.

We can stack features to any depth we want, but in practice, I have never gone beyond a depth of 2. After this point, the features are difficult to interpret, but I encourage anyone interested to try “going deeper”.",https://cdn-images-1.medium.com/max/1200/1*lg3OxWVYDsJFN-snBY7M5w.jpeg,[],https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219?source=topic_page---8------2----------------,2018-06-02 15:01:18.755000+00:00

Big Data,My Phone Wants Me to Say ‘Thank You’ – When Robots Rule The World – Medium,['Evan Selinger'],"Sincerely Thankful

Perhaps there’s something infantilizing about our phones “wanting” us to say thanks. It’s hard to draw a firm line between what you would say if only you put in the time to say it versus what you do say after predictive software fills in the blanks. Seeing suggestions is itself a suggestive situation. And so, while Google emphasizes that smart reply is intelligent enough to figure out if you’re more of a “thanks!” than a “thanks.” person, the fact remains that it’s a good bet that some variation of the word will be frequently presented to you.

If being offered a “thanks” seems familiar, it’s because the act resembles what parents do when they try to instill etiquette. Let’s imagine that Lil’ Johnny receives a gift and instinctively wants to run off and play with it. Before this happens, one of his parents admonishes, “Johnny, what do you say?” And so, robotically, Johnny responds, “Thank you.”

At the time of being coached, Lil’ Johnny doesn’t mean what he parrots back. The gesture is insincere, and Johnny offers it to avoid conflict that would further delay what he really wants to do. That’s okay, though. The hope is that, over time, Lil’ Johnny becomes Big Johnny, the type of person who can genuinely experience gratitude and doesn’t simply follow rules like an automaton. The parental admonitions made during childhood are supposed to be like a pair of moral training wheels that kids ultimately outgrow.

Software like smart reply isn’t designed to provide adults with a second round of moral education. But if we mindlessly use such tools on a regular basis so we can quickly move on to do other things—things that we actually care about—our gestures will merely take the form of gratitude while lacking the underlying substance.

True gratitude must be sincere.

To be truly grateful, you have to mean what you say — that is, you must recognize that someone did something for you that deserves to be acknowledged, and you must sincerely want to make the acknowledgment.

Graciousness is a virtue. If an adult passes off insincere gratitude as the sincere variety in situations where people reasonably expect a person’s words and beliefs to align, the person is behaving worse than Lil’ Johnny. Lil’ Johnny is trying to be compliant, not deceptive.

We also shouldn’t lose sight of the fact that people who in engage in rituals like keeping gratitude journals aim to be specific when offering their appreciation. They don’t just say “thanks” or use any of the other minimalist formulations that smart reply offers. Instead, people who are pursuing lives filled with intentionality are concrete about what they are grateful for, as well as why they’re grateful for it. They want to focus on what they have rather than despair or obsesses over what they lack.",https://cdn-images-1.medium.com/focal/1200/632/51/50/1*MpyyWHuRUnanCenqeG3sHA.jpeg,[],https://medium.com/s/when-robots-rule-the-world/my-phone-wants-me-to-say-thank-you-122cc15952a9?source=topic_page---8------3----------------,

Big Data,"In 2018, Numbers Lie and Fictions Paint Truth – Eve Weinberg – Medium",['Eve Weinberg'],"In 2018, Numbers Lie and Fictions Paint Truth Why storytelling is our best tool in disambiguating fact from fiction

I’d love to share a few of the lecturers who touched upon this topic and forever changed my understanding of the 2018 landscape of fact, fiction, and storytelling’s role in deciphering one from the other.

This summer, I had the great privilege of attending EyeO (June 3–8 2018). Innumerable topics that encompass the intersection of Art, Technology, and Data were covered, but one common thread has left an imprint on my brain. That is: the Sisyphean 21st century task of disambiguating fact from fiction. That’s right…

PART 1: NUMBERS ARE MALLEABLE

On the first day, we discussed climate science at length. We (a very self aware room of liberal, number-crunching, data-visualization-making, coastal-living, self-ascribed nerds) attempted to break down the problems with human psychology. We looked at the facts, stats, charts, and graphs; then investigated the human power of denial, dissonance, disincentivization, and the hurdles of behavioral change. After 6 hours of discussion, ideation, and reflection, feeling a bit helpless, we ended with questions that I kept with me throughout the next 3 days of lectures:

Why don’t people believe statistics?

Are stories more powerful than numbers?

Why is denial more powerful than behavioral change?

Why do lies travel faster than truth?

…And what should we do about this?

The next day, Amanda Cox enlightened us with her talk These Lines Are The Same. She showed us that data, even in simple bar graphs, can be misinterpreted depending on the viewer’s own bias. She bravely revealed to us that in her department The Upshot at The New York Times they struggle with how to best represent datasets objectively. They experiment in meaningful and educational ways. In one example she showed data from the US unemployment report. The article allows readers to look at the chart with ‘Democratic Goggles’ and ‘Republican Goggles.’

The numbers are the same, but they can easily be bent to the will of anyone with an agenda.

Then she humorously showed us our flaws in clinging to round numbers. She drove the point home with a series of charts, one here showing the likelihood that someone in the ER gets checked for a heart attack, according to their age. As Amanda points out, “nothing radical changes from the age of 39-and-three-quarters and 40, yet here is the data:",https://cdn-images-1.medium.com/max/1200/1*bJ58aYiSmkeNYJY73AQN3w.jpeg,[],https://medium.com/@evejweinberg/in-2018-numbers-lie-and-fictions-paint-truth-ea1f5cdc9abe?source=topic_page---8------0----------------,2018-06-08 22:01:41.763000+00:00

Big Data,The Art of Ethereal: Bringing Cellarius to Life – Genesis Thought – Medium,['Mally Anderson'],"The Art of Ethereal: Bringing Cellarius to Life

Whose future is it? Hers, and his, and theirs, and ours.

A sampling of the Cellarius faction portraits from our Ethereal Summit pop-up.

On May 11 and 12, our parent company ConsenSys hosted the third Ethereal Summit at the Knockdown Center in Queens, New York and invited Cellarius to participate, along with many other spokes from our Mesh. The creators of Ethereal wanted to build a different kind of crypto conference. Since this one explored the intersection of blockchain and the arts, we wanted to showcase that aspect of our project and spread the word in an unexpected way. We set up shop in “The Crypt,” a semi-outdoor concrete space with a distinctive patina that felt perfect for the Cellarius blockpunk aesthetic.

The Knockdown Center’s very blockpunk Crypt space. We displayed some not-yet-published art commissions.

We teamed with some artists from a group called Drawn Together NYC: Boris Rasin, Michael Scarola, Derrick Dent, and Rosalind Bunting. Drawn Together’s talented roster of artists creates design concepts, multimedia experiences, and fine art solutions for a wide range of projects and businesses, and they understood what we are going for right away.

The artists of Drawn Together NYC, from left to right: Boris Rasin, Rosalind Bunting, Derrick Dent, and Michael Scarola.

Boris, Michael, and Derrick created custom, in-universe faction portraits of Ethereal attendees. The CX Universe Guide imagines that nation-states and traditional economies will break down after the Cellarius AI seizes control of Earth’s energy sources and communication channels in 2084. In the absence of familiar institutions and technologies, people will begin to form factions according to their allegiance to Cellarius. We wanted to get attendees thinking about their own relationships to technology and start dreaming up characters to explore in the Cellarius universe. So we posed the question: which faction do you think you would be?

Boris drew background art for four different factions:

The 4 faction backgrounds, clockwise from top left: Bucolic, Elite, Ad-Hoc, Homotranscendus.

Bucolic: Bucolics are AI skeptics who reject technology and live on the peripheries of megacities, observing from the outside and farming small pockets of fertile soil. Though their process is completely manual and their harvests are meager, they feel a great satisfaction from working with their own hands, in stark contrast to the highly automated farming processes elsewhere.

Ad-Hoc: Ad-Hocs live off the Cellarius grid and make their own augmentations and tools with scrap pieces they scavenge and rework. Comprised of mostly poor and marginalized groups, they use ingenuity and what little tech they can access to get by.

Elite: The crypto-Elites of the future are pro-Cellarius and experiment with AI and aesthetic enhancements. Living in the highest levels of the megacities, Elites have access to bleeding-edge technology. They are known for having lifespans beyond the normal range of humans, and enjoy the neural boost that comes with AI coupling.

Homotranscendus: During the Reformation, it wasn’t just the home habitat that was transformed forever, but also humankind itself. The campaign was more than just re-imagining the economic machinery of the planet Earth, but also a re-imagining of the of the human brain and body. Through Cellarius-engineered advancements, the next evolution of humanity was born: Homotranscendus. Homotranscendi are fully integrated with AI and no longer depend on their human forms to express consciousness and gather information.

We even got a portrait of ConsenSys’s own Joe Lubin, who wore a custom Cellarius Ethereal t-shirt design during his keynote address (thanks, Joe!). Something tells us that Joe would be a Homotranscendus.

Future Homotranscendus Joe Lubin on Mars.

Reimagining how familiar scenarios from your own life play out in a future setting or speculating about how you might react to a superintelligent AI’s takeover of the world is a great place to start inventing your own ideas in the world of Cellarius. We hope some attendees will be inspired to start making art and stories based on their portraits!

Every single Ethereal portrait, as arranged by our designer, Octavian.

As we’ve mentioned in previous posts, we are also commissioning works from artists we admire to create the first round of content for the Cellarius universe. We decided to commission a mural that would take shape over the two days of the Summit and give attendees a behind-the-scenes look at the process of making a large-scale landscape painting. The design depicts what the Knockdown Center might look like a century from now, in 2118. Visitors to the Crypt got a chance to watch Rosalind transform the canvas from a faint pencil sketch into an impressive and detailed final product:

Rosalind’s “Knockdown Center in 2118” painting took shape over two days.

Rosalind & Boris outlined the sketch first, then Rosalind added color, starting with the future-NYC background.

We hope that the Cellarius platform will allow experienced artists and creators to get directly in touch with their fan bases and share some glimpses of their artistic process, just as Rosalind did with her live painting.

The Drawn Together NYC artists got to learn more about the possibilities of blockchain and decentralization for creatives in the process of chatting with the attendees. Michael noted, “There were so many passionate and interesting people from all over the world that came through. And they had as much fun as we did learning about and playing in the Cellarius world.” Rosalind agreed: “Probably my favorite thing I learnt about over the Summit was how Cellarius involves the creative talents of so many more artists in their company, and loved seeing some of their amazing artwork. Can’t wait to see more!”

We were also excited that the long-term goals of the Cellarius project resonated with the Drawn Together NYC artists. Derrick said, “This was probably the coolest on-site portrait job I’ve ever worked on. I had a great time learning about the Cellarius project and the potential for a sprawling, community-shaped open sci-fi world. It was even cooler to have our portrait work used as an onboarding tool for visitors. People immediately took to creating their own story within this world, and that says a lot about how exciting this could be for folks who are creatively inclined.” We couldn’t have said it better ourselves.

As Boris told us, “The more I spoke to the pop-up team and event attendees about the concept behind this project, the more it occurred to me that this is a game changer. Cellarius and the other projects from ConsenSys are sure to revolutionize our ecosystem in ways we can’t even begin to comprehend. It’s a challenge to explain exactly what this project is, because the underlying platform allows for limitless opportunities of invention, inspiration, and collaboration. Cellarius is whatever its contributors will it to be, and frankly, that’s a fundamentally crazy idea!”

That’s just the point: blockchain enthusiasts can become artists and use storytelling to push the conceptual limits of technology. Artists can use the platform to explore the possibilities of decentralization and blockchain for sharing and protecting their work. We can build it together. Cellarius is whatever our community of contributors wills it to be.",https://cdn-images-1.medium.com/max/1200/1*vL8856P7cdV84CYM_SkF0A.jpeg,[],https://medium.com/genesis-thought/the-art-of-ethereal-bringing-cellarius-to-life-ba4ae31811e7?source=topic_page---8------1----------------,2018-06-08 16:46:47.896000+00:00

Big Data,The curious case of the vanishing & exploding gradient,['Eniola Alese'],"The curious case of the vanishing & exploding gradient

Understanding why gradients explode or vanish and methods for dealing with the problem.

Photo by SpaceX on Unsplash

In the last post, we introduced a step by step walkthrough of RNN training and how to derive the gradients of the network weights using back propagation and the chain rule. But it turns out that during this training the RNN can suffer greatly from two problems: 1. Vanishing gradients or 2. Exploding gradients.

Why Gradients Explode or Vanish

Recall the many-to-many architecture for text generation shown below and in the introduction to RNN post, lets assume the input sequence to the network is a 20 word sentence: “I grew up in France,…….. I speak French fluently.

We can see from the example above that for the RNN to predict the word “French” which comes at the end of the sequence, it would need information from the word “France”, which occurs further back at the beginning of the sentence. This kind of dependence between sequence data is called long-term dependencies because the distance between the relevant information “France” and the point where it is needed to make a prediction “French” is very wide. Unfortunately, in practice as this distance becomes wider, RNNs have a hard time learning these dependencies because it encounters either a vanishing or exploding gradient problem.

These problems arise during training of a deep network when the gradients are being propagated back in time all the way to the initial layer. The gradients coming from the deeper layers have to go through continuous matrix multiplications because of the the chain rule, and as they approach the earlier layers, if they have small values (<1), they shrink exponentially until they vanish and make it impossible for the model to learn , this is the vanishing gradient problem. While on the other hand if they have large values (>1) they get larger and eventually blow up and crash the model, this is the exploding gradient problem

Dealing with Exploding Gradients",https://cdn-images-1.medium.com/max/1200/0*UCn2LUkacEHQxgZW,[],https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb?source=topic_page---8------3----------------,2018-06-05 22:33:57.437000+00:00

Big Data,How to ensure the safety of Self-Driving Cars: Part 2/5,['Jason Marks'],"How to ensure the safety of Self-Driving Cars: Part 2/5

There’s an ongoing battle between LiDAR, Automotive Radar, and Cameras (and a few others too) for the title of the self-driving car’s “eyes:”

Figure 1: McKinsey&Company Evaluation of Autonomous Vehicle Sensors

Figure 2: National Instruments Visual of ADAS Sensors

But self-driving car do more than just “see” the world. The cars also are equipped with sensors onboard that can tell the vehicle more about the surrounding world and itself. These sensors tell how fast the car is moving; the G-force acceleration experienced by the vehicle in forward-back, side-to-side, and up-and-down directions; the current steering angle; and lots more. It is a combination of these perception systems (camera, LiDAR, Radar) and sensor systems (GPS, IMU, Wheel Speed, etc) that make up the inputs to the “sense” block of the self-driving car AV stack.

Part 2: How well can a self-driving car sense the world?

Often included in the “sense” block of the AV Stack is the integration of all of the sensors, which let’s the vehicle make determinations about the environment. Examples include “there’s a pedestrian coming out of the bushes on the left side at 3 mph towards the vehicle,” or “it’s nighttime and raining,” or even “the vehicle is driving up a 10% hill while turning at a 3-degree angle.” The integration of sensors together is called “sensor fusion,” and the determination of what is going on in the environment is called many things, but commonly referred to as “Scene Understanding.”

There is a huge industry focus on developing this layer of the AV Stack. Engineers want the car to be able to see and understand the world with the “intelligence” of humans. Some of the most brilliant people are working on software algorithms that fall under the “Artificial Intelligence,” “Machine Learning,” and “Deep Learning” buckets to allow the car understand what it sees:

So, with all of these sensors and algorithms, how can we be sure that everything’s working correctly? We break each component or some grouping of the components into their inputs and outputs and verify they are doing what they were intended to do. We run tons of tests to get a bunch of data, and then run statistics on that data to prove with some confidence, that the component or group functions correctly.

Below we will break down each of the components and determine how we verify them.

Cameras

Most camera testing is done at the company that makes the camera. A camera is fundamentally a sensor that grabs a bunch of color points in space and arranges them into an image, often referred to as an image array. This image array is converted into a digital signal and is passed along to the hardware that does sensor fusion and scene understanding. Camera technology is fairly mature, and the processes for verifying that the camera converts the right picture to digital lines is well understood, so it should not be an area of concern for autonomous vehicles.

LiDAR

LiDAR systems for autonomous vehicles are relatively new, with the first player, Velodyne, only really demonstrating this capability in 2005 at the first DARPA Grand Challenge. LiDAR technology is quickly evolving, with the goal to make the LiDAR sensor economical and compact. With this technology shift, companies making LiDAR systems are having to adjust the ways they verify their systems.

LiDAR is a laser-light point-and-shoot methodology for sensing the world. A transmitter spits out a bit of light, waits for that light to bounce off an object, and since it knows how fast light travels, can determine how far away that object is by determining the time that’s passed between sending out that light and receiving it. LiDAR units can broaden their field of view by using a bunch of lasers that spin around in a circle, or more recently, as a stationary bunch of lasers that spread out along a field of view, called “Solid State LiDAR.” After all the light is received, the LiDAR system sends an array of direction and distance information back to the hardware for sensor fusion and scene understanding, referred to as a “point cloud.”

In order to verify the LiDAR system acts appropriately, an engineer can setup an artificial scene with predetermined objects a known distance away and verify the results of the LiDAR. More advanced test methodologies involve having another light source feed in light to the LiDAR being tested with a time-based pattern that represents a known field of view, and then the Engineer can compare the results of the LiDAR with the known, simulated environment. This type of testing is called “Hardware in the Loop” since there is a test system that simulates a known stimulus to the hardware under test, and the feedback from that hardware goes back to the test system, making a “loop.”

There are many more ways engineers verify the correct functionality of the LiDAR system, including stress testing the unit at various weather conditions, and ensuring that it functions appropriately with different electrical signals going to and from the unit. In all, this is can be a very involved procedure, and engineers picking LiDAR systems for their self-driving cars should do their research before selecting a unit. Suppliers will provide data on the life expectancy, accuracy, and failure expectations of their units, but engineers putting LiDAR systems in vehicles must perform their own safety tests as well.

Radar

Radar has been around forever. It is similar to LiDAR in that it is a “point-and-shoot” technology, but uses radio, or electromagnetic, waves to do this. Radar lends itself well to long-distance object detection but is not typically very precise.

So how do you test this thing? Well, it’s just like LiDAR, but since the RADAR technology is less expensive and better understood, some companies are already creating tools for this purpose:

Again, engineers need to work with Radar suppliers to make sure they stringently test their devices and that those engineers again retest the unit once it’s onboard their vehicle.

Vehicle Sensors

Vehicle sensors have been built into cars for quite some time, but only since 1993 did the International Organization of Standardization (ISO) determine that the way a sensor talks to a car will be through a digital 2-wire protocol developed by Robert Bosch Gmbh called the “CAN Bus:”

Figure 5: CAN Bus, CSS Electronics

Sensors that sit on the CAN bus are plentiful. They include accelerometers, Internal Measurement Units (IMUs), Vehicle speed sensors, wheel sensors, joint angle sensors, tire pressure, and many, many more. The ISO (ISO 11898) standard is what ensures that the makers of these sensors are verifying their sensors before they ship to a customer.

If you’re retrofitting a vehicle for automation, you’ll need to plug into that CAN bus and make sure you’re able to decipher the signals and send your own. After all, the vehicle must read these signals to operate appropriately. In a “Drive By Wire” (DBW) vehicle, there are no manual, only digital, connections between the accelerator, brake, or steering wheel and the engine and wheels. The CAN bus is what communicates the intentions of the driver to the vehicle.

If you’re building an autonomous vehicle from the ground up, you’ll need to ensure the appropriate selection and mounting of sensors. This must also be verified by driving the vehicle or simulating a drive with HIL testing, and then analyzing the results from the sensors. Same goes for any additional sensors added to an existing vehicle.

What if one of the sensors is off?

Here’s where the engineers again need to step in. Their algorithms onboard the sense layer must do a sanity check of the sensors at some predetermined interval. Adjustments should be made if necessary. There should also be some redundancy in the sensors.

If one of the sensors malfunctions or disconnects, or if your vehicle is struck and a camera moves, what happens? Well, if the system “self-calibrates,” its sensors, this should catch some of these issues. Otherwise, the system may just need to send a command to the rest of the software stack that a sensor is malfunctioning, and the rest of the AV stack can decide what to do.

Engineers need to make sure that the decision on how to handle a malfunctioning sensor is correct. Like how LiDAR is tested, an engineer can send simulated signals to the sensor fusion hardware that represent a failure of a sensor and see how the system responds (HIL). Even before that happens though, the engineer can send simulated data in software to the segment of code on a development environment to see how that code responds. This method of testing is called “Software-in-the Loop” or SIL, testing because the program that’s testing the code sends data to the software being tested and gets a response back, again making a “loop.”

All these tests are run under various conditions and a ton of data is produced. That data is categorized, labeled, and analyzed to provide a statistical determination about how well the vehicle recognized the sensor failure and how it responded.

Scene Understanding: Static or Semi-Static Objects

Ah more software running on hardware to test! The software for scene understanding can be quite complex and can even be a “black box” to many engineers developing it. Regardless, it is up to these engineers to be sure that it’s objectively safe.

An engineer testing scene understanding will verify the software at many times during development. They can even split parts of the scene, such as first checking “is there an object” then “what is that object” and even then “what does that mean for me?”

Thousands of simulations with images, LiDAR data, and Radar data can be fed in software to the scene understanding to check that the scene is correct. Often, this requires a set of “Training data” where the result is already well known (that’s a dog). A bunch of data is then analyzed, and again a statistical probability that the scene understanding was correct is provided.

Engineers can take this one step further by simulating camera, LiDAR, and Radar signals to the sensors on the vehicle and testing if the scene understanding system got the scene correct. This is the HIL approach.

To test scene understanding, engineers need tons of images and point clouds. A single one of these images takes up significant space, so a car operating in real-time would fill 4 TB of data in an hour and a half, equivalent to 250 Million pages of paper, or 83 days of watching DVDs straight (source).

Figure 6: Intel Car Data (Source)

As you can imagine, managing all this data for testing a vehicle is a big challenge. But engineers are working through this and can provide stats on just how good their scene understanding algorithms are. This should inspire the public.

Scene Understanding: Dynamic and Real-Time Objects

This is just like static objects, but now you need multiple back-to-back images and point cloud information to understand how objects are moving in space. So not only do you need to correctly identify objects, you need to know how they’re moving and where they will likely be next based on physics and reasoning. This can be especially challenging.

Just like for static data, engineers must simulate environments that are dynamic with SIL and HIL and prove the scene understanding made the right prediction. You now need series of images over time and you need to test this quite stringently, because head-on-collisions with another moving body can be deadly.

Luckily, engineers are figuring this one out too, but they need more and more data. For some of these challenges, the algorithms that engineers use are not fully mature, but there’s daily progress on that front. This is one the public should be keenly aware of.

Scene Understanding: Vehicle-Road Scenario

OK, so now you’re confident the robot “driver” of the vehicle sees the road correctly. What else does it need to do? Well, it needs to figure out the scenario of the car in space at any given time. You as a driver do this all the time. You can easily tell if you’re going up or down a hill, if you’re in a turn or going straight, or if the roads are covered in snow or clear. More complex things you may pick up on are being sucked into the back of your chair, or forced towards the windshield, or swaying off to the side based on the Gs the vehicle is imparting on you.

A vehicle can figure out all these thing by sensor fusion. It can read the linear acceleration from the IMU and tell the angle of the car and how fast it’s pitching forward/back, rolling side-to-side, or yawing through a turn.

Figure 7: SAE Axis System

A combination of perception and acceleration information can tell the inclination or bank of the road, even dips and crests. Perception and wheel speed vs vehicle speed allows the vehicle to guess the coefficient of friction between the road and tires (albeit, this one can be quite challenging).

Since we trust the sensors already, we test the ability to understand the road by simulating data to the software that represents certain road conditions (SIL), by sending simulated signals to the sensors that represents road conditions (HIL), and even by putting the vehicle on a jig, called a chassis dynamometer, and verifying the results the system spits out:

Figure 8: Meidensha Chassis Dyno (Source)

For this one, there is no ISO standard, and the Society of Automotive Engineers (SAE) have not recommended an approach to take to guarantee that the vehicle knows itself. Many autonomous vehicle companies are relying on only the perception and GPS map information to provide this information. Vehicle makers will need to get better at this in the future to ensure the safety of the vehicles, and this will be especially evident when we discuss path planning.

The Hardware that hosts the Stack

There’s another ongoing battle about the appropriate hardware to host all this software described above. Some of the many players in the game are the CPU, GPU, FPGA, ASIC, TPU, IPU, MCU, etc. They have their tradeoffs, and some of them can be loosely described by this image:

Figure 9: Silicon Alternatives (Source)

In today’s (2018) world of self-driving-car prototypes, we see most cars built using a combination of CPUs and GPUs. Though in the future, this will likely be some combination of the hardware contenders:

Figure 10, 11, 12: Adrian Colyer (Source)

So, what needs to be tested in hardware? Well, in the images above, you see a metric called “Latency” and a metric called “Power.” Latency is how long it took to for the software on the hardware to make a decision. You want to minimize this. “Power” is how much electrical energy it took to make that decision. You want to minimize this as well, because more power consumption means you can drive the car less distance, whether it’s a gas or electric vehicle. Certain decisions are higher priority than others, as we’ll also discuss in Part 3 and Part 4. For example, you need to know if there’s an emergency scenario immediately, but you may only need to check on the temperature of the outside air every couple of seconds, since temperature changes much more slowly.

You test both latency and power by giving the hardware a “load,” or some task to do while you watch it perform. You measure how much voltage and current that task consumes, and you multiply them together to get Power. You also benchmark how long it took each task to complete and you log that too.

Latency can be a double-edged sword though. You may have two pieces of hardware where one runs much faster than the other 90% of the time, but 10% of the time runs slower. The other piece of hardware always runs at the exact same time through all tests. The amount of variation in latency is called determinism. What you need for a mission-critical task is a low-latency, deterministic system. You can offload non-mission-critical items to things with higher latency and/or non-deterministic systems, ideally that consume the minimal power possible.

So, an engineer must make the right decision on the hardware selection and test it themselves to make sure they get the response they need while consuming the smallest amount of power. Lots of data again!

Conclusion

So where does this leave us? Well, it should be clear that some combination of SIL, HIL, and real-world testing is required to make sure the sensing system works appropriately. It should be also clear that to do this requires massive amounts of data, a ton of time, and a bunch of tools to help the engineers navigate all this. Some of the tests are standardized, others are not. For us to be sure the vehicle senses the world correctly, we’re going to rely on this process improving over time where each element is objectively better than a human driver.",https://cdn-images-1.medium.com/max/1200/1*ebuUG7HWL0v594-yDp46Kg.jpeg,[],https://medium.com/@olley_io/how-to-ensure-the-safety-of-self-driving-cars-part-2-5-b4eafb067534?source=topic_page---8------4----------------,2018-06-05 18:25:54.142000+00:00

Big Data,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------,2018-06-08 22:25:33.341000+00:00

Big Data,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------#--responses,2018-06-08 22:25:33.341000+00:00

Big Data,How to build a range slider component in React from scratch using only <div> and <span>,['Rajesh Pillai'],"How to build a range slider component in React from scratch using only <div> and <span>

In this article we will build a React range slider component step by step using only <div>. We will enable it with touch support.

What can you do with a piece of about 50 <div’s>?

Build a slider control from scratch. If this sounds interesting, then follow along.

The final output will look like the below animation.

Please do note that I have developed this component as a teaching exercise for my students of ReactJS — Beyond the Basics course on Udemy, so it may have some edge cases (which I will fix as and when encountered).

You could use an HTML5 range control and customize it. But I wanted to take a different approach and build something from scratch. And the result is what you see here.

Our slider component will be composed of the below three elements:

A slider range

The actual slider controls

The current selection range

Defining the state for our component

Let us begin by defining our state. I am only showing you the important part of the code. For the full source code, please refer to the link at the end of the article.

state = {

slots: 24,

start: 0,

end: 10,

labelMode: ""mid"", // mid, long

}

The state contains the following properties.

slots: Total slots to be drawn (in this case I am using it as a time selector, so it will have 24 hour slots)

start: The start value of the selection

end: The end value of the selection

labelMode: Currently unused. But can be used to customize the scale label rendering.

The return part of the render method

Let us now take a look at the return part of the render method. The render() method will be slowly composed of small pieces of functionality.

return (

<div>

<h2>React Slider</h2>

<div className=""example-1"">

<div className=""slider-container"">

<div className=""slider-scale"">

{scale}

</div>

<div className=""slider"">

{slider}

</div>

<div className=""slider-selected-scale"">

{currentScale}

</div>

</div>

</div>

</div>

);

For those reading on mobile, the below image may be handy, as sometimes Medium breaks the code formatting.

If you take a look at the code, there are only three important pieces:

scale variable

slider variable

currentScale variable

The three variables above will be responsible for rendering the correct parts of the overall slider.

Dissecting the render () method

Let us initialize some variables. The scale , slider and currentScale JSX will be created within the for loop defined below.

render () {

let scale = [];

let slider=[];

let currentScale = [];

let minThumb = null;

let maxThumb = null

..... // rest of the code

}

Create the JSX for the ‘scale’ variable

Creating the JSX for the scale variable is quite simple. We just loop through the slots value in the state and push a <div> to the scale array with the required CSS class for styling.

The if condition ensures that we are only printing the label for i = 0, i = 12, or i = 24 (kind of mid range). Please feel free to customize this.

for (let i = 0; i <= this.state.slots;i++) {

let label = """";



if (i == 0 || i == 12 || i == 24) {

label = i;

}



scale.push(

<div

key={i}

className=""slot-scale"">

{label}

</div>

);

Here’s the code in image format:

Create the JSX for the ‘currentScale’ variable

Let us now continue with the same for loop and create the ‘currentScale’ JSX. We are still within the same for loop, so about 24 divs will be created as per the value in this.state.slots value.

The currentScale has a class of ‘slot-scale-selected’.

let currentLabel = """";



if (i === this.state.start || i === this.state.end) {

currentLabel = i;

}



currentScale.push(

<div

key={i}

className=""slot-scale-selected"">

{currentLabel}

</div>

);

The code is pretty similar to the ‘scale’ JSX that we created.

Create the JSX for the ‘slider’ variable

Let us write a function to render the ‘slider’ jsx. The slider needs two thumbs, one for min, and one for max.

Let us first initialize the thumb variable depending on the ‘i’ value. If ‘i’ is the same as this.state.start, then we set the minThumb variable. Else if the value of ‘i’ is the same as this.state.end, then we initialize the maxThumb variable.

if (i === this.state.start) {

minThumb = <this.MinSlider />

} else if (i === this.state.end) {

maxThumb = <this.MaxSlider />

} else {

minThumb = null;

maxThumb = null;

}

Create the JSX for the ‘slider’

The important code piece here is the dragover event. This is required for the HTML drop to work correctly.

let lineClass = ""line"";



if (i >= this.state.start && i < this.state.end) {

lineClass += "" line-selected"";

}

slider.push(

<div

data-slot={i}

onDragOver={this.onDragOver}

onTouchMove = {this.onDragOver}

onTouchEnd = {this.onDrop}

onDrop = {this.onDrop}

key={i}

className=""slot"">

<div data-slot={i} className={lineClass}/>

<span className=""scale-mark""></span>

{minThumb}

{maxThumb}

</div>

);

The slider variable needs two additional pieces of features to represent the min and the max thumb on the slider.

The slider JSX has additional event handlers to deal with handling the drop event/touchend event. We will take a look at the event handlers shortly.

The ‘lineClass’ styles/renders the line on the slider, and the ‘line-selected’ class styles the currently selected range.

Let us now write the MinSlider and MaxSlider function outside the render method.

The MinSlider () function to render the min thumb

Let’s take a look at the code. The important props are the events related to drag and the draggable attribute. The draggable attribute will make this element draggable.

We are also adding the touch event handler. Refer to the link at the bottom of the article to add touch support polyfill for the HTML5 API.

MinSlider=()=> {

return (

<div data-slider=""min""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-min"">

</div>

);

}

The MaxSlider () function to render the min thumb

The MaxSlider is almost the same as the MinSlider except for the data and the className.

MaxSlider=()=> {

return (

<div data-slider=""max""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-max"">

</div>

);

}

The code image is given below for reference.

Event Handling

Let us now look at the drag/touch event handlers defined within our <div> to control the movement of the slider element.

dragover:

The dragover event is required to support the drop zone when using the HTML5 drag/drop API. The only thing we need to do here is to invoke the preventDefault on the event object.

onDragOver = (e) => {

e.preventDefault();

}

dragstart:

The dragstart enables us to store which slider is being dragged. Please note that I am not using the dataTransfer object here, but simply using an instance variable to store this.

onDragStart = (e) => {

let slider = e.target.dataset.slider;

this.sliderType = slider;

}

The value of e.target.dataset.slider is either “min” or “max,” indicating which slider is being dragged.

ondrop:

The ondrop event captures where the thumb is being dropped (on which scale).

This is the important flow in the ondrop event:

Grab the source (whether min/max thumb)

Get the slot (where the drop happens)

Validations

Update the slot (in the state)

Reset the sliderType.

onDrop = (e, target) => {

let source = this.sliderType;

let slot = Number(e.target.dataset.slot);



if (isNaN(slot)) return;



if (source === ""min"") {

if (slot >= this.state.end) return;

this.setState({

start: slot

},()=>{

console.log(this.state);

})

} else if (source === ""max"") {

if (slot <= this.state.start) return;

this.setState({

end: slot

},()=>{

console.log(this.state);

})

}

this.sliderType = null;

}

The complete source code/and demo can be seen here http://jsbin.com/remodat/edit?output

Since I am using HTML5 drag and drop features to add touch, support please add this polyfill reference to your html file.

Todos

Extract the logic to a separate Component class

Test it and and add customization.

History

21-May-2018 — First release

P.S: This component is a result of a very quick coding attempt. This will be refactored.

Promotion: If you would like to support our open source curriculum Mastering Full Stack Engineering in 12 to 20 weeks then here is a special 10$ coupon for medium readers for my upcoming live ReactJS-Beyond the basicscourse on udemy (MEDIUM_500 is the coupon code, which is already tagged in the above URL)",https://cdn-images-1.medium.com/max/1200/1*iSkeoPHBQubtAL4fV4h9xQ.png,[],https://medium.freecodecamp.org/how-to-build-a-range-slider-component-in-react-from-scratch-using-only-div-and-span-d53e1a62c4a3?source=collection_home---6------1----------------,2018-06-08 21:41:33.808000+00:00

Big Data,The well-kept secret behind great UX: Usability Testing,['Anant Jain'],"The well-kept secret behind great UX: Usability Testing

Whether you only have a prototype or a full-fledged product, it’s a really good idea to run monthly usability tests. These make sure that whatever you’re working on is usable and the user experience is excellent.

If you’re wondering what you can do to make your usability tests more structured and organized, this guide is for you. Let’s get started!

First off, always keep the two Golden Rules of Usability Testing in mind:

Any testing is better than no testing (with no one!) A little testing earlier is better than a lot of testing later.

In this post, I will introduce you to the kind of lightweight usability testing described in Steve Krug’s books, “Don’t Make Me Think” and “Rocket Surgery Made Easy.” Steve calls this kind of testing “Do-It-Yourself Usability Testing” since it’s supposed to be cheap, easy-to-do and takes just a morning a month.

A quick intro to usability testing

The idea behind this is to:

Find a few participants

Ask them to come in and go through a list of user flows you want to test

Observe the problems they run into

Finally, make a list of issues to fix

Sounds simple enough, but very few of us actually do it. The goal of this post is to make you confident enough to run at least one usability test session this month. I ran my first usability test only a year ago, and I must say it’s actually a lot of fun!

Before we get to the test itself, here are a few things to note:

Reserve one morning a month (say the third Thursday every month) for a round of testing, debriefing, and deciding what to fix. Test with three participants each round. Recruit loosely, and grade on a curve. You don’t need to find someone who fits the exact mould of your ideal user, since most usability problems can be uncovered by testing with just about anyone. If you are part of a big company and have the budget, you can recruit via Craigslist and offer a $50 gift card for an hour of the participant’s time. If you don’t have those kind of resources, don’t worry — you can ask your friends, your existing users, or even go to a café and ask strangers for 15 minutes of their time in exchange for buying them a coffee. If you’re doing this as part of a bigger team, get as many observers as possible to observe the tests in a separate observation room. These will be the designers, engineers, project managers, executives, etc. Or, in case of side projects, it’ll be just be you later in your room!

What happens during the test?

During a usability test, you will record the participant’s voice and their computer screen, and share both these streams live with observers in another room. A typical one-hour test can be broken down into:

Welcome (4 mins): Explain how the test will work so that the participant will know what to expect. The questions (2 mins): Ask the participant a few questions about themselves. This helps put them at ease and gives you an idea of how computer-savvy they are. The Homepage tour (3 mins): Open the Home page of your site, and ask the participant to look around and tell you what they think. This will give you an idea of how easy it is to understand your home page, as well as how familiar the participant is with your domain. The tasks (35 minutes): Watch the participant perform a series of tasks you have prepared for them beforehand. If you’re building a SaaS product and you’re testing out your subscription flow, a typical task could be to find the Pricing page, compare various plans, and Subscribe to one of the plans with a provided test credit card number. Encourage the participant to think out loud as they perform the task (see the video at the end of the post for a sample test.) It’s crucial that you let them work on their own and not ask them any leading questions, or give out any clues or assistance. Probing (5 mins): Ask the participant any questions you may have about anything that happened during the test and about any issues that people in the observation room may have. Also, answer any questions that the participant may have at this point (don’t answer them during the actual tasks since you’re testing how they’ll perform with no one around.) Wrapping Up (5 mins): Thank them for their help, and give them their gift card if you promised one while recruiting them.

The debrief

During the breaks between successive tests, ask the observers to write down the top 3 usability problems that they saw. During the debriefing, focus ruthlessly on deciding to fix the most severe problems first. Here are a few other recommendations:

Keep a separate list of low-hanging fruit. These are the problems you can typically fix with one-line code changes, but have a huge impact on task completion rates. Joel Califa calls them “tiny wins”. Here’s an example:

Resist the impulse to add things — instead, try to tweak your existing design to fix the problem.

to fix the problem. Take “new feature” requests with a grain of salt. Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature.

Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature. Ignore the problems where the user goes astray for a bit but comes back on track by themselves. These are usually not worth investing much time unless you see a pattern across multiple participants.

Good design is a delicate balance, so when fixing a problem, ensure that you aren’t introducing new ones.

Remote testing and unmoderated user testing

Remote testing is very similar to an in-person usability test, except that the participant is at their home/office and you conduct the testing via screen sharing and voice call.

Unmoderated user testing is another way to test, where you specify your website, the tasks you want the users to do, and get back video recordings of people trying to accomplish those tasks. Usertesting.com is the leader in this space, but note that a single 30-minute test costs about $50.

Resources

You can download checklists, interview script, consent form, and a demo video at Steve Krug’s site here: Downloads for Rocket Surgery Made Easy.

Here’s a Usability Test demo video from Google Ventures:

I want to thank you for reading this quick guide. This was originally published as part of the UX Design course on Commonlounge, a platform that has courses with small bite-sized lessons like these on topics ranging from Project Management to Machine Learning that deliver the most value for the time you put in.

You learn by working on real-world projects and getting feedback from industry mentors. You should check it out here!",https://cdn-images-1.medium.com/max/1200/0*UWxJWKKNLXR5c1cm,[],https://medium.freecodecamp.org/the-well-kept-secret-behind-great-ux-usability-testing-b788178a64c3?source=collection_home---6------2----------------,2018-06-08 21:25:31.335000+00:00

Big Data,An introduction to part-of-speech tagging and the Hidden Markov Model,['Divya Godayal'],"Let’s go back into the times when we had no language to communicate. The only way we had was sign language. That’s how we usually communicate with our dog at home, right? When we tell him, “We love you, Jimmy,” he responds by wagging his tail. This doesn’t mean he knows what we are actually saying. Instead, his response is simply because he understands the language of emotions and gestures more than words.

We as humans have developed an understanding of a lot of nuances of the natural language more than any animal on this planet. That is why when we say “I LOVE you, honey” vs when we say “Lets make LOVE, honey” we mean different things. Since we understand the basic difference between the two phrases, our responses are very different. It is these very intricacies in natural language understanding that we want to teach to a machine.

What this could mean is when your future robot dog hears “I love you, Jimmy”, he would know LOVE is a Verb. He would also realize that it’s an emotion that we are expressing to which he would respond in a certain way. And maybe when you are telling your partner “Lets make LOVE”, the dog would just stay out of your business 😛.

This is just an example of how teaching a robot to communicate in a language known to us can make things easier.

The primary use case being highlighted in this example is how important it is to understand the difference in the usage of the word LOVE, in different contexts.

Part-of-Speech Tagging

From a very small age, we have been made accustomed to identifying part of speech tags. For example, reading a sentence and being able to identify what words act as nouns, pronouns, verbs, adverbs, and so on. All these are referred to as the part of speech tags.

Let’s look at the Wikipedia definition for them:

In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging or word-category disambiguation, is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context — i.e., its relationship with adjacent and related words in a phrase, sentence, or paragraph. A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.

Identifying part of speech tags is much more complicated than simply mapping words to their part of speech tags. This is because POS tagging is not something that is generic. It is quite possible for a single word to have a different part of speech tag in different sentences based on different contexts. That is why it is impossible to have a generic mapping for POS tags.

As you can see, it is not possible to manually find out different part-of-speech tags for a given corpus. New types of contexts and new words keep coming up in dictionaries in various languages, and manual POS tagging is not scalable in itself. That is why we rely on machine-based POS tagging.

Before proceeding further and looking at how part-of-speech tagging is done, we should look at why POS tagging is necessary and where it can be used.

Why Part-of-Speech tagging?

Part-of-Speech tagging in itself may not be the solution to any particular NLP problem. It is however something that is done as a pre-requisite to simplify a lot of different problems. Let us consider a few applications of POS tagging in various NLP tasks.

Text to Speech Conversion

Let us look at the following sentence:

They refuse to permit us to obtain the refuse permit.

The word refuse is being used twice in this sentence and has two different meanings here. refUSE (/rəˈfyo͞oz/)is a verb meaning “deny,” while REFuse(/ˈrefˌyo͞os/) is a noun meaning “trash” (that is, they are not homophones). Thus, we need to know which word is being used in order to pronounce the text correctly. (For this reason, text-to-speech systems usually perform POS-tagging.)

Have a look at the part-of-speech tags generated for this very sentence by the NLTK package.

>>> text = word_tokenize(""They refuse to permit us to obtain the refuse permit"")

>>> nltk.pos_tag(text)

[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'),

('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]

As we can see from the results provided by the NLTK package, POS tags for both refUSE and REFuse are different. Using these two different POS tags for our text to speech converter can come up with a different set of sounds.

Similarly, let us look at yet another classical application of POS tagging: word sense disambiguation.

Word Sense Disambiguation

Let’s talk about this kid called Peter. Since his mother is a neurological scientist, she didn’t send him to school. His life was devoid of science and math.

One day she conducted an experiment, and made him sit for a math class. Even though he didn’t have any prior subject knowledge, Peter thought he aced his first test. His mother then took an example from the test and published it as below. (Kudos to her!)

Word-sense Disambiguation example — My son Peter’s first Maths problem.

Words often occur in different senses as different parts of speech. For example:

She saw a bear.

Your efforts will bear fruit.

The word bear in the above sentences has completely different senses, but more importantly one is a noun and other is a verb. Rudimentary word sense disambiguation is possible if you can tag words with their POS tags.

Word-sense disambiguation (WSD) is identifying which sense of a word (that is, which meaning) is used in a sentence, when the word has multiple meanings.

Try to think of the multiple meanings for this sentence:

Time flies like an arrow

Here are the various interpretations of the given sentence. The meaning and hence the part-of-speech might vary for each word.

Part-of-speech tags define the meaning of a sentence based on the context

As we can clearly see, there are multiple interpretations possible for the given sentence. Different interpretations yield different kinds of part of speech tags for the words.This information, if available to us, can help us find out the exact version / interpretation of the sentence and then we can proceed from there.

The above example shows us that a single sentence can have three different POS tag sequences assigned to it that are equally likely. That means that it is very important to know what specific meaning is being conveyed by the given sentence whenever it’s appearing. This is word sense disambiguation, as we are trying to find out THE sequence.

These are just two of the numerous applications where we would require POS tagging. There are other applications as well which require POS tagging, like Question Answering, Speech Recognition, Machine Translation, and so on.

Now that we have a basic knowledge of different applications of POS tagging, let us look at how we can go about actually assigning POS tags to all the words in our corpus.

Types of POS taggers

POS-tagging algorithms fall into two distinctive groups:

Rule-Based POS Taggers

Stochastic POS Taggers

E. Brill’s tagger, one of the first and most widely used English POS-taggers, employs rule-based algorithms. Let us first look at a very brief overview of what rule-based tagging is all about.

Rule-Based Tagging

Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods.

Typical rule-based approaches use contextual information to assign tags to unknown or ambiguous words. Disambiguation is done by analyzing the linguistic features of the word, its preceding word, its following word, and other aspects.

For example, if the preceding word is an article, then the word in question must be a noun. This information is coded in the form of rules.

Example of a rule:

If an ambiguous/unknown word X is preceded by a determiner and followed by a noun, tag it as an adjective.

Defining a set of rules manually is an extremely cumbersome process and is not scalable at all. So we need some automatic way of doing this.

The Brill’s tagger is a rule-based tagger that goes through the training data and finds out the set of tagging rules that best define the data and minimize POS tagging errors. The most important point to note here about Brill’s tagger is that the rules are not hand-crafted, but are instead found out using the corpus provided. The only feature engineering required is a set of rule templates that the model can use to come up with new features.

Let’s move ahead now and look at Stochastic POS tagging.

Stochastic Part-of-Speech Tagging

The term ‘stochastic tagger’ can refer to any number of different approaches to the problem of POS tagging. Any model which somehow incorporates frequency or probability may be properly labelled stochastic.

The simplest stochastic taggers disambiguate words based solely on the probability that a word occurs with a particular tag. In other words, the tag encountered most frequently in the training set with the word is the one assigned to an ambiguous instance of that word. The problem with this approach is that while it may yield a valid tag for a given word, it can also yield inadmissible sequences of tags.

An alternative to the word frequency approach is to calculate the probability of a given sequence of tags occurring. This is sometimes referred to as the n-gram approach, referring to the fact that the best tag for a given word is determined by the probability that it occurs with the n previous tags. This approach makes much more sense than the one defined before, because it considers the tags for individual words based on context.

The next level of complexity that can be introduced into a stochastic tagger combines the previous two approaches, using both tag sequence probabilities and word frequency measurements. This is known as the Hidden Markov Model (HMM).

Before proceeding with what is a Hidden Markov Model, let us first look at what is a Markov Model. That will better help understand the meaning of the term Hidden in HMMs.

Markov Model

Say that there are only three kinds of weather conditions, namely

Rainy

Sunny

Cloudy

Now, since our young friend we introduced above, Peter, is a small kid, he loves to play outside. He loves it when the weather is sunny, because all his friends come out to play in the sunny conditions.

He hates the rainy weather for obvious reasons.

Every day, his mother observe the weather in the morning (that is when he usually goes out to play) and like always, Peter comes up to her right after getting up and asks her to tell him what the weather is going to be like. Since she is a responsible parent, she want to answer that question as accurately as possible. But the only thing she has is a set of observations taken over multiple days as to how weather has been.

How does she make a prediction of the weather for today based on what the weather has been for the past N days?

Say you have a sequence. Something like this:

Sunny, Rainy, Cloudy, Cloudy, Sunny, Sunny, Sunny, Rainy

So, the weather for any give day can be in any of the three states.

Let’s say we decide to use a Markov Chain Model to solve this problem. Now using the data that we have, we can construct the following state diagram with the labelled probabilities.",https://cdn-images-1.medium.com/max/1200/1*f6e0uf5PX17pTceYU4rbCA.jpeg,[],https://medium.freecodecamp.org/an-introduction-to-part-of-speech-tagging-and-the-hidden-markov-model-953d45338f24?source=collection_home---6------3----------------,2018-06-08 19:31:14.123000+00:00

Big Data,A deep dive into part-of-speech tagging using the Viterbi algorithm,['Sachin Malhotra'],"Welcome back, Caretaker!

In case you’ve forgotten the problem we were trying to tackle in the previous article, let us revise it for you.

So there’s this naughty kid Peter and he’s going to pester his new caretaker, you!

As a caretaker, one of the most important tasks for you is to tuck Peter in bed and make sure he is sound asleep. Once you’ve tucked him in, you want to make sure that he’s actually asleep and not up to some mischief.

You cannot, however, enter the room again, as that would surely wake Peter up. All you can hear are the noises that might come from the room.

Either the room is quiet or there is noise coming from the room. These are your states.

All you have as the caretaker are:

a set of observations, which is basically a sequence containing noise or quiet over time, and

or over time, and A state diagram provided by Peter’s mom — who happens to be a neurological scientist — that contains all the different sets of probabilities that you can use to solve the problem defined below.

The problem

Given the state diagram and a sequence of N observations over time, we need to tell the state of the baby at the current point in time. Mathematically, we have N observations over times t0, t1, t2 .... tN . We want to find out if Peter would be awake or asleep, or rather which state is more probable at time tN+1 .

In case any of this seems like Greek to you, go read the previous article to brush up on the Markov Chain Model, Hidden Markov Models, and Part of Speech Tagging.

The state diagram that Peter’s mom gave you before leaving.

In that previous article, we had briefly modeled the problem of Part of Speech tagging using the Hidden Markov Model.

The problem of Peter being asleep or not is just an example problem taken up for a better understanding of some of the core concepts involved in these two articles. At the core, the articles deal with solving the Part of Speech tagging problem using the Hidden Markov Models.

So, before moving on to the Viterbi Algorithm, let’s first look at a much more detailed explanation of how the tagging problem can be modeled using HMMs.

Generative Models and the Noisy Channel Model

A lot of problems in Natural Language Processing are solved using a supervised learning approach.

Supervised problems in machine learning are defined as follows. We assume training examples (x(1), y(1)) . . . (x(m) , y(m)) , where each example consists of an input x(i) paired with a label y(i) . We use X to refer to the set of possible inputs, and Y to refer to the set of possible labels. Our task is to learn a function f : X → Y that maps any input x to a label f(x).

In tagging problems, each x(i) would be a sequence of words X1 X2 X3 …. Xn(i) , and each y(i) would be a sequence of tags Y1 Y2 Y3 … Yn(i) (we use n(i)to refer to the length of the i’th training example). X would refer to the set of all sequences x1 . . . xn, and Y would be the set of all tag sequences y1 . . . yn. Our task would be to learn a function f : X → Y that maps sentences to tag sequences.

An intuitive approach to get an estimate for this problem is to use conditional probabilities. p(y | x) which is the probability of the output y given an input x. The parameters of the model would be estimated using the training samples. Finally, given an unknown input x we would like to find

f(x) = arg max(p(y | x)) ∀y ∊ Y

This here is the conditional model to solve this generic problem given the training data. Another approach that is mostly adopted in machine learning and natural language processing is to use a generative model.

Rather than directly estimating the conditional distribution p(y|x) , in generative models we instead model the joint probability p(x, y) over all the (x, y) pairs.

We can further decompose the joint probability into simpler values using Bayes’ rule:

p(y) is the prior probability of any input belonging to the label y.

is the prior probability of any input belonging to the label y. p(x | y) is the conditional probability of input x given the label y.

We can use this decomposition and the Bayes rule to determine the conditional probability.

Remember, we wanted to estimate the function

f(x) = arg max( p(y|x) ) ∀y ∊ Y

f(x) = arg max( p(y) * p(x | y) )

The reason we skipped the denominator here is because the probability p(x) remains the same no matter what the output label being considered. And so, from a computational perspective, it is treated as a normalization constant and is normally ignored.

Models that decompose a joint probability into terms p(y) and p(x|y) are often called noisy-channel models. Intuitively, when we see a test example x, we assume that it has been generated in two steps:

first, a label y has been chosen with probability p(y) second, the example x has been generated from the distribution p(x|y). The model p(x|y) can be interpreted as a “channel” which takes a label y as its input, and corrupts it to produce x as its output.

Generative Part of Speech Tagging Model

Let us assume a finite set of words V and a finite sequence of tags K. Then the set S will be the set of all sequence, tags pairs <x1, x2, x3 ... xn, y1, y2, y3, ..., yn> such that n > 0 ∀x ∊ V and ∀y ∊ K .

A generative tagging model is then the one where

2.

Given a generative tagging model, the function that we talked about earlier from input to output becomes

Thus for any given input sequence of words, the output is the highest probability tag sequence from the model. Having defined the generative model, we need to figure out three different things:

How exactly do we define the generative model probability p(<x1, x2, x3 ... xn, y1, y2, y3, ..., yn>) How do we estimate the parameters of the model, and How do we efficiently calculate

Let us look at how we can answer these three questions side by side, once for our example problem and then for the actual problem at hand: part of speech tagging.

Defining the Generative Model

Let us first look at how we can estimate the probability p(x1 .. xn, y1 .. yn) using the HMM.

We can have any N-gram HMM which considers events in the previous window of size N.

The formulas provided hereafter are corresponding to a Trigram Hidden Markov Model.

Trigram Hidden Markov Model

A trigram Hidden Markov Model can be defined using

A finite set of states.

A sequence of observations.

q(s|u, v)

Transition probability defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations.

defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations. e(x|s)

Emission probability defined as the probability of making an observation x given that the state was s.

Then, the generative model probability would be estimated as

As for the baby sleeping problem that we are considering, we will have only two possible states: that the baby is either awake or he is asleep. The caretaker can make only two observations over time. Either there is noise coming in from the room or the room is absolutely quiet. The sequence of observations and states can be represented as follows:

Observations and States over time for the baby sleeping problem

Coming on to the part of speech tagging problem, the states would be represented by the actual tags assigned to the words. The words would be our observations. The reason we say that the tags are our states is because in a Hidden Markov Model, the states are always hidden and all we have are the set of observations that are visible to us. Along similar lines, the sequence of states and observations for the part of speech tagging problem would be

Observations and States over time for the POS tagging problem

Estimating the model’s parameters

We will assume that we have access to some training data. The training data consists of a set of examples where each example is a sequence consisting of the observations, every observation being associated with a state. Given this data, how do we estimate the parameters of the model?

Estimating the model’s parameters is done by reading various counts off of the training corpus we have, and then computing maximum likelihood estimates:

Transition probability and Emission probability for a Trigram HMM

We already know that the first term represents transition probability and the second term represents the emission probability. Let us look at what the four different counts mean in the terms above.

c(u, v, s) represents the trigram count of states u, v and s. Meaning it represents the number of times the three states u, v and s occurred together in that order in the training corpus. c(u, v) following along similar lines as that of the trigram count, this is the bigram count of states u and v given the training corpus. c(s → x) is the number of times in the training set that the state s and observation x are paired with each other. And finally, c(s) is the prior probability of an observation being labelled as the state s.

Let us look at a sample training set for the toy problem first and see the calculations for transition and emission probabilities using the same.

The BLUE markings represent the transition probability, and RED is for emission probability calculations.

Note that since the example problem only has two distinct states and two distinct observations, and given that the training set is very small, the calculations shown below for the example problem are using a bigram HMM instead of a trigram HMM.

Peter’s mother was maintaining a record of observations and states. And thus she even provided you with a training corpus to help you get the transition and emission probabilities.

Transition Probability Example:

Training Corpus

Calculations for Awake appearing after Awake

Emission Probability Example:

Training corpus

Calculations for observing ‘Quiet’ when the state is ‘Awake’

That was quite simple, since the training set was very small. Let us look at a sample training set for our actual problem of part of speech tagging. Here we can consider a trigram HMM, and we will show the calculations accordingly.

We will use the following sentences as a corpus of training data (the notation word/TAG means word tagged with a specific part-of-speech tag).

The training set that we have is a tagged corpus of sentences. Every sentence consists of words tagged with their corresponding part of speech tags. eg:- eat/VB means that the word is “eat” and the part of speech tag in this sentence in this very context is “VB” i.e. Verb Phrase. Let us look at a sample calculation for transition probability and emission probability just like we saw for the baby sleeping problem.

Transition Probability

Let’s say we want to calculate the transition probability q(IN | VB, NN). For this, we see how many times we see a trigram (VB,NN,IN) in the training corpus in that specific order. We then divide it by the total number of times we see the bigram (VB,NN) in the corpus.

Emission Probability

Let’s say we want to find out the emission probability e(an | DT). For this, we see how many times the word “an” is tagged as “DT” in the corpus and divide it by the total number of times we see the tag “DT” in the corpus.

So if you look at these calculations, it shows that calculating the model’s parameters is not computationally expensive. That is, we don’t have to do multiple passes over the training data to calculate these parameters. All we need are a bunch of different counts, and a single pass over the training corpus should provide us with that.

Let’s move on and look at the final step that we need to look at given a generative model. That step is efficiently calculating

We will be looking at the famous Viterbi Algorithm for this calculation.

Finding the most probable sequence — Viterbi Algorithm

Finally, we are going to solve the problem of finding the most likely sequence of labels given a set of observations x1 … xn. That is, we are to find out

The probability here is expressed in terms of the transition and emission probabilities that we learned how to calculate in the previous section of the article. Just to remind you, the formula for the probability of a sequence of labels given a sequence of observations over “n” time steps is

Before looking at an optimized algorithm to solve this problem, let us first look at a simple brute force approach to this problem. Basically, we need to find out the most probable label sequence given a set of observations out of a finite set of possible sequences of labels. Let’s look at the total possible number of sequences for a small example for our example problem and also for a part of speech tagging problem.

Say we have the following set of observations for the example problem.

Noise Quiet Noise

We have two possible labels {Asleep and Awake}. Some of the possible sequence of labels for the observations above are:

Awake Awake Awake

Awake Awake Asleep

Awake Asleep Awake

Awake Asleep Asleep

In all we can have ²³ = 8 possible sequences. This might not seem like very many, but if we increase the number of observations over time, the number of sequences would increase exponentially. This is the case when we only had two possible labels. What if we have more? As is the case with part of speech tagging.

For example, consider the sentence

the dog barks

and assuming that the set of possible tags are {D, N, V}, let us look at some of the possible tag sequences:

D D D

D D N

D D V

D N D

D N N

D N V ... etc

Here, we would have ³³ = 27 possible tag sequences. And as you can see, the sentence was extremely short and the number of tags weren’t very many. In practice, we can have sentences that might be much larger than just three words. Then the number of unique labels at our disposal would also be too high to follow this enumeration approach and find the best possible tag sequence this way.

So the exponential growth in the number of sequences implies that for any reasonable length sentence, the brute force approach would not work out as it would take too much time to execute.

Instead of this brute force approach, we will see that we can find the highest probable tag sequence efficiently using a dynamic programming algorithm known as the Viterbi Algorithm.

Let us first define some terms that would be useful in defining the algorithm itself. We already know that the probability of a label sequence given a set of observations can be defined in terms of the transition probability and the emission probability. Mathematically, it is

Let us look at a truncated version of this which is

and let us call this the cost of a sequence of length k.

So the definition of “r” is simply considering the first k terms off of the definition of probability where k ∊ {1..n} and for any label sequence y1…yk.

Next we have the set S(k, u, v) which is basically the set of all label sequences of length k that end with the bigram (u, v) i.e.

Finally, we define the term π(k, u, v) which is basically the sequence with the maximum cost.

The main idea behind the Viterbi Algorithm is that we can calculate the values of the term π(k, u, v) efficiently in a recursive, memoized fashion. In order to define the algorithm recursively, let us look at the base cases for the recursion.

π(0, *, *) = 1

π(0, u, v) = 0

Since we are considering a trigram HMM, we would be considering all of the trigrams as a part of the execution of the Viterbi Algorithm.

Now, we can start the first trigram window from the first three words of the sentence but then the model would miss out on those trigrams where the first word or the first two words occurred independently. For that reason, we consider two special start symbols as * and so our sentence becomes

* * x1 x2 x3 ...... xn

And the first trigram we consider then would be (*, *, x1) and the second one would be (*, x1, x2).

Now that we have all our terms in place, we can finally look at the recursive definition of the algorithm which is basically the heart of the algorithm.",https://cdn-images-1.medium.com/max/1200/1*x-5ZBtUvlD78BOMuMnMAbg.png,[],https://medium.freecodecamp.org/a-deep-dive-into-part-of-speech-tagging-using-viterbi-algorithm-17c8de32e8bc?source=collection_home---6------4----------------,2018-06-08 19:05:31.518000+00:00

Big Data,A quick introduction to OAuth using Passport.js – freeCodeCamp,['Arun Kumar'],"A quick introduction to OAuth using Passport.js

What is OAuth?

OAuth (Open Authorization) is an authorization protocol. A third party application can use it to access user data from a site (like Google or Twitter) without revealing their password. Sites like Quora, Medium, AirBnb and many others offer authentication using OAuth.

OAuth really makes our lives simpler by eliminating the need to remember the password of every account you create on almost any site. You just have to remember your OAuth provider’s main account password.

What is Passport.js?

Passport is a middleware which implements authentication on Express-based web applications. It provides over 500+ strategies. What are these strategies? Strategies are used to authenticate requests. Each strategy has its own npm package (such as passport-twitter, passport-google-oauth20). A strategy must be configured before usage.

Why use Passport.js?

Here are six reasons stating why you should use Passport:

It is lightweight

Easily configurable

Supports persistent sessions

Offers OAuth

Provides separate modules for each strategy

Gives you the ability to implement custom strategies

Let’s build something

To get started, we need to install passport from NPM:

npm install passport

We are going to build a simple app which grants the user access to a secret route only if they log in. I’m going to be using the passport-google-oauth20 strategy in this tutorial. Feel free to use any other strategy you prefer, but make sure to check the docs to see how it is configured.

Before continuing, we need a clientID and clientSecret. To get one, head over to https://console.developers.google.com and create a new project. Then go to Enable APIs and Services and enable the Google+ API. Select the API and click on create credentials.

Fill out the form and use the same callback URL on both the form and on your file. Make sure to read the comments on the code to figure out how everything fits together.

app.js

index.ejs

As you can see, we’ve created a /secret route, and only grant access to it if the user is authenticated. To verify whether the user is authenticated, we’ve created a middleware which checks if the request has the user object in it. Finally, to log out we used the req.logout() method provided by passport to clear the session.

Here are some resources to learn more about passport

Complete Passport.js tutorial series

Conclusion

We only saw one strategy here. There are 500+ more. I highly recommend that you skim through Passport’s official documentation and find out what else they offer. Thank you for taking your time to read this. Feel free to connect with me on LinkedIn, Twitter and GitHub. I wish you good luck!

“Do what is great, written on a computer monitor.” by Martin Shreder on Unsplash

Previous article",https://cdn-images-1.medium.com/max/1200/0*gWsdm7w5PSZNR08L,[],https://medium.freecodecamp.org/a-quick-introduction-to-oauth-using-passport-js-65ea5b621a?source=collection_home---6------5----------------,2018-06-07 22:11:44.925000+00:00

Big Data,How to control your randomizer in R – freeCodeCamp,['Michelle Jones'],"What happens when you need a particular type of randomization?

Overview of random number generation in R

R has at least 20 random number generator functions. Each uses a specific probability distribution to create the numbers. All require you to specify the number of random numbers you want (the above image shows 200). All are available in base R — no packages required.

Common random number generator distributions are:

normal (rnorm): default mean of 0 and standard deviation of 1

binomial (rbinom): no defaults, specify the number of trials and the probability of success on each trial

uniform (runif): default minimum value of 0 and maximum value of 1

Of the three above, only the binomial random number generator creates integers.

Why create random numbers?

Problems involving random numbers are very common — there are around 50,000 questions relating to random numbers on Stack Exchange.

But why use them?

Random numbers have many practical applications. They are used in Monte Carlo simulations. They are used in cryptography. They have been used to produce CAPTCHA content. They are used in slot machines. They have also been used for more mundane tasks such as creating a random sort order for an array of ordered data.

Problems with random numbers

Common questions include “are my random numbers actually random?” and “how can I generate non-repeated random numbers?”

Note: the latter decreases randomness, because the population of possible random numbers is decreased by one each time a random number is drawn. The method is appropriate in situations such as lotteries or bingo, where each ticket or ball can only be drawn once.

This problem brings in another problem! The randomly generated, sampling without replacement numbers must be integers. No one has ticket 5.6932 or bingo ball 0.18967.

A practical example of random number problems

Let’s take the example that I have 20 female students of the same age. I have four teaching methods that I want to trial. I only want to trial one teaching method for each student. Easy math— I need five students in each group.

But how do I do this so that each student is randomly assigned?

And how do I make sure that I only have integers produced?

And how do I do all this while using randomly generated numbers without replacement? I don’t want, for example, six students in one group, and four students in another.

First, I need to create some dummy data, in R. Let’s create that list of mock female students.

FemaleStudents <- data.frame(Names=c(""Alice"", ""Betty"", ""Carol"", ""Denise"", ""Erica"", ""Frances"", ""Gina"", ""Helen"", ""Iris"", ""Julie"", ""Katherine"",

""Lisa"", ""Michelle"", ""Ngaire"", ""Olivia"", ""Penelope"", ""Rachel"", ""Sarah"", ""Trudy"", ""Uma""))

Now we have a one-dimensional dataset of our 20 students.

We know that the runif() function doesn’t create integers. Why don’t we round the random numbers so that we only get integers and use this function? We can wrap the random number in a rounding function.

Question 1: why am I using the random uniform distribution and not another one, such as the random normal distribution?

There are five types of rounding functions in R. We will use round() .

So that we get the same results, I will set a seed for the random number generation. Each time we generate random numbers, we will use the same seed. I’ve decided on 5 as the seed. If you do not set a seed, or if you set a seed other than 5, your results will be different than mine.

set.seed(5)

FemaleStudents$Group <- round(runif(20, 1, 5))

Well, that seemed to work. We have each student allocated to a group numbered between 1 and 5.

Let’s double check our allocation.

table(FemaleStudents$Group)

1 2 3 4 5

2 6 5 4 3

Darn. Only one of the five groups has the correct number of students (Group 4). Why did this happen?

We can check the numbers actually output by runif() without rounding, and letting the output print to the console. Here, the output prints because I have not assigned the function to an object (for example, to a data.frame variable).

set.seed(5)

runif(20,1,5)

[1] 1.800858 3.740874 4.667503 2.137598 1.418601 3.804230 3.111840 4.231741 4.826001 1.441812 2.093140 2.962053 2.273616 3.236691 2.050373

[16] 1.807501 2.550103 4.551479 3.219690 4.368718

As we can see, the rounding caused our problem. But if we hadn’t rounded, each student would have been assigned to a different group.

What do we do?

sample()

sample() is now one of my favourite functions in R. Let’s see how it works.

Randomly allocate to equally sized groups (counts matter)

How can we use it to randomly assign our 20 students to four equally sized groups?

What happens if we try sample() normally?

set.seed(5)

FemaleStudents$Sample <- sample(1:5, nrow(FemaleStudents), replace=TRUE)

Question 2: what output did you get when you used table(FemaleStudents$Sample) ?

We can fix this problem by creating a vector of group numbers, and then using sampling without replacement from this vector. The rep command is used to create a range of repeated values. You can use it to repeat each number in the series, as I have used here. Number 1 is repeated four times, then number 2 is repeated four times, and so forth. You can also use it to repeat a sequence of numbers, if you use this code instead: rep(1:5,4)

OurGroups <- rep(1:5, each=4)

set.seed(5)

FemaleStudents$Sample <- sample(OurGroups, nrow(FemaleStudents), replace=FALSE)

We used our vector of numbers ( OurGroups ) to allocate our students to groups. We used sampling without replacement ( replace=FALSE ) from OurGroups because we need to use each value in that vector. We need to remove each value as we use it.

And we get the result we wanted!

table(FemaleStudents$Sample)

1 2 3 4 5

4 4 4 4 4

Question 3: why did I still set a seed?

Another advantage of sample() is that it doesn’t care about type. We can repeat the allocation using a vector of strings. This can be useful if you don’t want to keep referring back to what “1” means.

OurNamedGroups <- rep(c(""Up"", ""Down"", ""Charmed"", ""Strange"", ""Top""), each=4)

set.seed(5)

FemaleStudents$Sample2 <- sample(OurNamedGroups, nrow(FemaleStudents), replace=FALSE)

table(FemaleStudents$Sample2)

Charmed Down Strange Top Up

4 4 4 4 4

Because we used the same seed, we can see that the same student allocation was performed, irrespective of whether we used numeric or character data for the assignment.

table(FemaleStudents$Sample,FemaleStudents$Sample2)



Charmed Down Strange Top Up

1 0 0 0 0 4

2 0 4 0 0 0

3 4 0 0 0 0

4 0 0 4 0 0

5 0 0 0 4 0

Randomly allocate when group size is not restricted

Sometimes we want to randomly allocate to groups, but we don’t have a vector of groups. We are still only allocating each unit (person, sheep, block of cheese) to a single group, and we use completely random allocation.

Let’s say that our school has a new, special library room. It’s been constructed to be soundproof to give students a better studying environment. The chief librarian would like to know about the experiences of students in that room. The only problem is that the room is limited in size. The chief librarian thinks that around four students is a large enough group to provide the initial feedback.

Again, we can use sample() to pick our student groups. In this case, we have “students who will test the room” and “students who won’t test the room”. I’m going to call them “Test” and “Not test”. These labels have been chosen for being 1. short and 2. easily distinguished.

Because we did sampling without replacement earlier, we didn’t specify probabilities of assignment to groups — we simply pulled out an assignment from a vector. Now we are going to use sampling with replacement. With replacement refers to the group, not to the students.

We need to sample with replacement as we only have two groups (“Test”, “Not test”) and 20 students. If we tried to sample without replacement, our code would error.

Our code is very similar:

set.seed(5)

FemaleStudents$Library <- sample(c(""Test"", ""Not test""), nrow(FemaleStudents), replace=TRUE, prob=c(4/20,16/20))

table(FemaleStudents$Library)

Not test Test

15 5

As you can see, we allocated five students to test the room, not four. This type of result is expected when dealing with small samples. However, our allocation of students is completely random. Each student had exactly the same probability of being assigned to test the room. Whether previous students were testers or not had no impact on the allocation of the next student.

Let’s walk through some of that code.

I’ve constructed a new variable in the data.frame to collect the allocation ( Library ).

Instead of dealing with numbers for group names, I’ve used the strings I mentioned earlier. Because I’ve used strings, the c() must wrap the group names ( “Test”, “Not test” ) and each group name is separated by a comma.

Replacement has been set to TRUE .

The probability of assignment to either group must be provided. This is the prob=c(4/20,16/20) part of the sample() function. Again, note how c() is used to contain the probabilities. Also of interest is that the probabilities can be expressed as fractions, rather than decimals.

Hooray for sample()

I use sample() all the time for the work I am doing. The ability to use strings, as well as to restrict numeric output to integers (and define the desired integer range), provides me with more control than trying to use one of the random number functions.

Answers

Answer 1: I used a random uniform distribution because I wanted each value to be equally probable.

Answer 2: I got this output:

1 2 3 4 5

2 7 4 2 5

Answer 3: If we don’t set a seed value, or we use a different one, the allocation of specific students will be different. For example, when the seed is 5, Alice is allocated to group 2. If the seed is 7, Alice is allocated to group 5. Replication is important when code needs to be re-run (for example, in testing).",https://cdn-images-1.medium.com/max/1200/1*aI6mpoboOmJMKqvEU593xA.png,[],https://medium.freecodecamp.org/how-to-control-your-randomizer-in-r-852ae7d8f80c?source=collection_home---6------6----------------,2018-06-07 20:10:57.677000+00:00

Big Data,How to style your webpage or markdown like a Medium article — or however you want,[],"View the respective pages at: https://github.com/ryandav/link-formatter/ and https://ryandav.github.io/link-formatter/

Get started with Sass at https://sass-lang.com/guide",https://cdn-images-1.medium.com/max/1200/1*L8PQs8ubyxZVIr1EC-cZ6Q.png,[],https://medium.freecodecamp.org/style-webpage-or-markdown-like-medium-article-using-html-css-sass-bootstrap-c6f9e64c0955?source=collection_home---6------7----------------,2018-06-07 19:32:27.295000+00:00

Big Data,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------,2018-06-07 17:57:40.375000+00:00

Big Data,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------#--responses,2018-06-07 17:57:40.375000+00:00

Big Data,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------,2018-06-07 15:39:54.084000+00:00

Big Data,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------#--responses,2018-06-07 15:39:54.084000+00:00

Big Data,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------,2018-06-06 21:43:33.288000+00:00

Big Data,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------#--responses,2018-06-06 21:43:33.288000+00:00

Big Data,Follow these steps to solve any Dynamic Programming interview problem,['Nikola Otasevic'],"Follow these steps to solve any Dynamic Programming interview problem

Despite having significant experience building software products, many engineers feel jittery at the thought of going through a coding interview that focuses on algorithms. I’ve interviewed hundreds of engineers at Refdash, Google, and at startups I’ve been a part of, and some of the most common questions that make engineers uneasy are the ones that involve Dynamic Programming (DP).

Many tech companies like to ask DP questions in their interviews. While we can debate whether they’re effective in evaluating someone’s ability to perform in an engineering role, DP continues to be an area that trips engineers up on their way to finding a job that they love.

Dynamic Programming — Predictable and Preparable

One of the reasons why I personally believe that DP questions might not be the best way to test engineering ability is that they’re predictable and easy to pattern match. They allow us to filter much more for preparedness as opposed to engineering ability.

These questions typically seem pretty complex on the outside, and might give you an impression that a person who solves them is very good at algorithms. Similarly, people who may not be able to get over some mind-twisting concepts of DP might seem pretty weak in their knowledge of algorithms.

The reality is different, and the biggest factor in their performance is preparedness. So let’s make sure everyone is prepared for it. Once and for all.

7 Steps to solve a Dynamic Programming problem

In the rest of this post, I will go over a recipe that you can follow to figure out if a problem is a “DP problem”, as well as to figure out a solution to such a problem. Specifically, I will go through the following steps:

How to recognize a DP problem Identify problem variables Clearly express the recurrence relation Identify the base cases Decide if you want to implement it iteratively or recursively Add memoization Determine time complexity

Sample DP Problem

For the purpose of having an example for abstractions that I am going to make, let me introduce a sample problem. In each of the sections, I will refer to the problem, but you could also read the sections independently of the problem.

Problem statement:

In this problem, we’re on a crazy jumping ball, trying to stop, while avoiding spikes along the way.

Here are the rules:

1) You’re given a flat runway with a bunch of spikes in it. The runway is represented by a boolean array which indicates if a particular (discrete) spot is clear of spikes. It is True for clear and False for not clear.

Example array representation:

2) You’re given a starting speed S. S is a non-negative integer at any given point, and it indicates how much you will move forward with the next jump.

3) Every time you land on a spot, you can adjust your speed by up to 1 unit before the next jump.

4) You want to safely stop anywhere along the runway (does not need to be at the end of the array). You stop when your speed becomes 0. However, if you land on a spike at any point, your crazy bouncing ball bursts and it’s game over.

The output of your function should be a boolean indicating whether we can safely stop anywhere along the runway.

Step 1: How to recognize a Dynamic Programming problem

First, let’s make it clear that DP is essentially just an optimization technique. DP is a method for solving problems by breaking them down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions. The next time the same subproblem occurs, instead of recomputing its solution, you simply look up the previously computed solution. This saves computation time at the expense of a (hopefully) modest expenditure in storage space.

Recognizing that a problem can be solved using DP is the first and often the most difficult step in solving it. What you want to ask yourself is whether your problem solution can be expressed as a function of solutions to similar smaller problems.

In the case of our example problem, given a point on the runway, a speed, and the runway ahead, we could determine the spots where we could potentially jump next. Furthermore, it seems that whether we can stop from the current point with the current speed depends only on whether we could stop from the point we choose to go to next.

That is a great thing, because by moving forward, we shorten the runway ahead and make our problem smaller. We should be able to repeat this process all the way until we get to a point where it is obvious whether we can stop.

Recognizing a Dynamic Programming problem is often the most difficult step in solving it. Can the problem solution be expressed as a function of solutions to similar smaller problems?

Step 2: Identify problem variables

Now we have established that there is some recursive structure between our subproblems. Next, we need to express the problem in terms of the function parameters and see which of those parameters are changing.

Typically in interviews, you will have one or two changing parameters, but technically this could be any number. A classic example of a one-changing-parameter problem is “determine an n-th Fibonacci number”. Such an example for a two-changing-parameters problem is “Compute edit distance between strings”. If you’re not familiar with these problems, don’t worry about it.

A way to determine the number of changing parameters is to list examples of several subproblems and compare the parameters. Counting the number of changing parameters is valuable to determine the number of subproblems we have to solve. It’s also important in its own right in helping us strengthen the understanding of the recurrence relation from step 1.

In our example, the two parameters that could change for every subproblem are:

Array position (P) Speed (S)

One could say that the runway ahead is changing as well, but that would be redundant considering that the entire non-changing runway and the position (P) carry that information already.

Now, with these 2 changing parameters and other static parameters, we have the complete description of our sub-problems.

Identify the changing parameters and determine the number of subproblems.

Step 3: Clearly express the recurrence relation

This is an important step that many rush through in order to get into coding. Expressing the recurrence relation as clearly as possible will strengthen your problem understanding and make everything else significantly easier.

Once you figure out that the recurrence relation exists and you specify the problems in terms of parameters, this should come as a natural step. How do problems relate to each other? In other words, let’s assume that you have computed the subproblems. How would you compute the main problem?

Here is how we think about it in our sample problem:

Because you can adjust your speed by up to 1 before jumping to the next position, there are only 3 possible speeds, and therefore 3 spots in which we could be next.

More formally, if our speed is S, position P, we could go from (S, P) to:

(S, P + S); # if we do not change the speed (S — 1, P + S — 1); # if we change the speed by -1 (S + 1, P + S + 1); # if we change the speed by +1

If we can find a way to stop in any of the subproblems above, then we can also stop from (S, P). This is because we can transition from (S, P) to any of the above three options.

This is typically a fine level of understanding of the problem (plain English explanation), but you sometimes might want to express the relation mathematically as well. Let’s call a function that we’re trying to compute canStop. Then:

canStop(S, P) = canStop(S, P + S) || canStop(S — 1, P + S — 1) || canStop(S + 1, P + S + 1)

Woohoo, it seems like we have our recurrence relation!

Recurrence relation: Assuming you have computed the subproblems, how would you compute the main problem?

Step 4: Identify the base cases

A base case is a subproblem that doesn’t depend on any other subproblem. In order to find such subproblems, you typically want to try a few examples, see how your problem simplifies into smaller subproblems, and identify at what point it cannot be simplified further.

The reason a problem cannot be simplified further is that one of the parameters would become a value that is not possible given the constraints of the problem.

In our example problem, we have two changing parameters, S and P. Let’s think about what possible values of S and P might not be legal:

P should be within the bounds of the given runway P cannot be such that runway[P] is false because that would mean that we’re standing on a spike S cannot be negative, and a S==0 indicates that we’re done

Sometimes it can be a little challenging to convert assertions that we make about parameters into programmable base cases. This is because, in addition to listing the assertions if you want to make your code look concise and not check for unnecessary conditions, you also need to think about which of these conditions are even possible.

In our example:

P < 0 || P >= length of runway seems like the right thing to do. An alternative could be to consider making P == end of runway a base case. However, it is possible that a problem splits into a subproblem which goes beyond the end of the runway, so we really need to check for inequality. This seems pretty obvious. We can simply check if runway[P] is false. Similar to #1, we could simply check for S < 0 and S == 0. However, here we can reason that it is impossible for S to be < 0 because S decreases by at most 1, so it would have to go through S == 0 case beforehand. Therefore S == 0 is a sufficient base case for the S parameter.

Step 5: Decide if you want to implement it iteratively or recursively

The way we talked about the steps so far might lead you to think that we should implement the problem recursively. However, everything that we’ve talked about so far is completely agnostic to whether you decide to implement the problem recursively or iteratively. In both approaches, you would have to determine the recurrence relation and the base cases.

To decide whether to go iteratively or recursively, you want to carefully think about the trade-offs.

Stack overflow issues are typically a deal breaker and a reason why you would not want to have recursion in a (backend) production system. However, for the purposes of the interview, as long as you mention the trade-offs, you should typically be fine with either of the implementations. You should feel comfortable implementing both.

In our particular problem, I implemented both versions. Here is python code for that:

A recursive solution: (original code snippets can be found here)

An iterative solution: (original code snippets can be found here)

Step 6: Add memoization

Memoization is a technique that is closely associated with DP. It is used for storing the results of expensive function calls and returning the cached result when the same inputs occur again.

Why are we adding memoization to our recursion? We encounter the same subproblems which, without memoization, are computed repeatedly. Those repetitions very often lead to exponential time complexities.

In recursive solutions, adding memoization should feel straightforward. Let’s see why. Remember that memoization is just a cache of the function results. There are times when you want to deviate from this definition in order to squeeze out some minor optimizations, but treating memoization as a function result cache is the most intuitive way to implement it.

This means that you should:

Store your function result into your memory before every return statement Look up the memory for the function result before you start doing any other computation

Here is the code from above with added memoization (added lines are highlighted): (original code snippets can be found here)

In order to illustrate the effectiveness of memoization and different approaches, let’s do some quick tests. I will stress test all three methods that we have seen so far. Here is the set up:

I created a runway of length 1000 with spikes in random places (I chose to have a probability of a spike being in any given spot to be 20%) initSpeed = 30 I ran all functions 10 times and measured the average time of execution

Here are the results (in seconds):

You can see that the pure recursive approach takes about 500x more time than the iterative approach and about 1300x more time than the recursive approach with memoization. Note that this discrepancy would grow rapidly with the length of the runway. I encourage you to try running it yourself.

Step 7: Determine Time complexity

There are some simple rules that can make computing time complexity of a dynamic programming problem much easier. Here are two steps that you need to do:

Count the number of states — this will depend on the number of changing parameters in your problem Think about the work done per each state. In other words, if everything else but one state has been computed, how much work do you have to do to compute that last state?

In our example problem, the number of states is |P| * |S|, where

P is the set of all positions (|P| indicates the number of elements in P)

S is the set of all speeds

The work done per each state is O(1) in this problem because, given all other states, we simply have to look at 3 subproblems to determine the resulting state.

As we noted in the code before, |S| is limited by length of the runway (|P|), so we could say that the number of states is |P|² and because work done per each state is O(1), then the total time complexity is O(|P|²).

However, it seems that |S| can be further limited, because if it were really |P|, it is very clear that stopping would not be possible because you would have to jump the length of the entire runway on the first move.

So let’s see how we can put a tighter bound on |S|. Let’s call maximum speed S. Assume that we’re starting from position 0. How quickly could we stop if we were trying to stop as soon as possible and if we ignore potential spikes?

In the first iteration, we would have to come at least to the point (S-1), by adjusting our speed at zero by -1. From there we would at a minimum go by (S-2) steps forward, and so on.

For a runway of length L, the following has to hold:

=> (S-1) + (S-2) + (S-3) + ….+ 1 < L

=> S*(S-1) / 2 < L

=> S < sqrt(2L + 1)

That is the maximum speed that we could possibly have on a runway of a length L. If we had a speed higher than that, we could not stop even theoretically, irrespective of the position of the spikes.

That means that the total time complexity depends only on the length of the runway L in the following form:

O(L * sqrt(L)) which is better than O(L²)

O(L * sqrt(L)) is the upper bound on the time complexity

Awesome, you made it through! :)

The 7 steps that we went through should give you a framework for systematically solving any dynamic programming problem. I highly recommend practicing this approach on a few more problems to perfect your approach.

Here are some next steps that you can take

Extend the sample problem by trying to find a path to a stopping point. We solved a problem that tells you whether you can stop, but what if you wanted to also know the steps to take in order to stop eventually along the runway? How would you modify the existing implementation to do that? If you want to solidify your understanding of memoization, and understand that it is just a function result cache, you should read about decorators in Python or similar concepts in other languages. Think about how they would allow you to implement memoization in general for any function that you want to memoize. Work on more DP problems by following the steps we went through. You can always find a bunch of them online (ex. LeetCode or GeeksForGeeks). As you practice, keep in mind one thing: learn ideas, don’t learn problems. The number of ideas is significantly smaller and it’s an easier space to conquer which will also serve you much better.

When you feel like you’ve conquered these ideas, check out Refdash where you are interviewed by a senior engineer and get a detailed feedback on your coding, algorithms, and system design.",https://cdn-images-1.medium.com/max/1200/0*DpsbrfUM89M_LHKY.jpg,[],https://medium.freecodecamp.org/follow-these-steps-to-solve-any-dynamic-programming-interview-problem-cc98e508cd0e?source=collection_home---6------11----------------,2018-06-06 19:32:36.335000+00:00

Big Data,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------,2018-06-06 17:23:02.015000+00:00

Big Data,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------#--responses,2018-06-06 16:42:46.938000+00:00

Big Data,How to process textual data using TF-IDF in Python – freeCodeCamp,[],"How to process textual data using TF-IDF in Python

Computers are good with numbers, but not that much with textual data. One of the most widely used techniques to process textual data is TF-IDF. In this article, we will learn how it works and what are its features.

From our intuition, we think that the words which appear more often should have a greater weight in textual data analysis, but that’s not always the case. Words such as “the”, “will”, and “you” — called stopwords — appear the most in a corpus of text, but are of very little significance. Instead, the words which are rare are the ones that actually help in distinguishing between the data, and carry more weight.

An introduction to TF-IDF

TF-IDF stands for “Term Frequenct — Inverse Data Frequency”. First, we will learn what this term means mathematically.

Term Frequency (tf): gives us the frequency of the word in each document in the corpus. It is the ratio of number of times the word appears in a document compared to the total number of words in that document. It increases as the number of occurrences of that word within the document increases. Each document has its own tf.

Inverse Data Frequency (idf): used to calculate the weight of rare words across all documents in the corpus. The words that occur rarely in the corpus have a high IDF score. It is given by the equation below.

Combining these two we come up with the TF-IDF score (w) for a word in a document in the corpus. It is the product of tf and idf:

Let’s take an example to get a clearer understanding.

Sentence 1 : The car is driven on the road.

Sentence 2: The truck is driven on the highway.

In this example, each sentence is a separate document.

We will now calculate the TF-IDF for the above two documents, which represent our corpus.

From the above table, we can see that TF-IDF of common words was zero, which shows they are not significant. On the other hand, the TF-IDF of “car” , “truck”, “road”, and “highway” are non-zero. These words have more significance.

Using Python to calculate TF-IDF

Lets now code TF-IDF in Python from scratch. After that, we will see how we can use sklearn to automate the process.",https://cdn-images-1.medium.com/max/1200/1*JTk6iVMiZCQCr8duiaKlHQ.png,[],https://medium.freecodecamp.org/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3?source=collection_home---6------15----------------,2018-06-06 16:07:18.115000+00:00

Big Data,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------,2018-06-06 01:10:32.658000+00:00

Big Data,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------#--responses,2018-06-06 01:10:32.658000+00:00

Big Data,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------,2018-06-06 00:59:12.072000+00:00

Big Data,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------#--responses,2018-06-06 00:59:12.072000+00:00

Big Data,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------,2018-06-06 00:20:56.870000+00:00

Big Data,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------#--responses,2018-06-06 00:20:56.870000+00:00

Big Data,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------,2018-06-05 20:08:25.488000+00:00

Big Data,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------#--responses,2018-06-05 20:08:25.488000+00:00

Big Data,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------,2018-06-05 16:44:13.144000+00:00

Big Data,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------#--responses,2018-06-05 16:44:13.144000+00:00

Big Data,A deeply detailed but never definitive guide to mobile development architecture,['Jose Berardo Cunha'],"A deeply detailed but never definitive guide to mobile development architecture

Native, Web, PWA, hybrid, Cross-Compiled… what is “the best” way to develop for Android and iOS platforms? What looks reasonable? And how are you supposed to choose among the options? In this article, I’ll lay it all out so you can make an informed decision.

First things first, let me provide you with a bit of context. I am an IT senior consultant, and the idea of putting together this guide was born from discussions with one of our clients about what could be the best approach for them. Yes, just for them. And we realized that we did not have a well-defined strategy, a solid and reliable foundation, to help us come up with the right answer.

And you know what? I could not find such a guide easily anywhere on the Internet, either. Although there are several articles about this topic, none of those I came across were reasonably complete. Unfortunately the majority overlook a lot of concepts or, even worse, are essentially wrong.

Now, I’d like to take a wider look. And while I’m potentially helping someone make their own decisions, I’m also asking around the community for more thoughts on the subject.

This guide has two parts:

Mobile Development Architectural Tiers (this) How to make your decision

It's also available on YouTube as a series of 10 videos and as a free course on Udemy. There, you’ll find the same written material as here, the same videos from the YouTube series, as well as quizzes to fix all the topics and a final certification.

So let’s get started.

Introduction

When it comes to mobile platforms, it's arguable that there are just two big players: Android and iOS. Other technologies like Tizen, Blackberry, or Windows Phone are either dead or have been around for a while and have no prospects of reaching any significative market share.

A quick look at this massive duopoly might make you think that developers do not have many options when creating mobile apps. This idea can't be further from the truth, though. You can quickly spot a fistful of programming languages being used out there: C/C++, Java, Kotlin, Objective-C, Swift, JavaScript, TypeScript, C#, Dart, Ruby, and I'm pretty sure I’ve missed a few more.

The same is true of mobile development frameworks. Unless you are not a developer, or have somehow been unaware of new technologies for the last 10 years, you’ve probably heard about Cordova/PhoneGap, React Native, Xamarin, Ionic, Nativescript, or Flutter, just to name a few cross-platform solutions for mobile apps.

So let’s look at all these pieces of the architecture and break things down a bit.

TL;DR

There's no clear winner. All approaches have pros and cons, and might be either the best fit or the worst fit for your next project. In this guide, I'm classifying many different solutions into various tiers according to the distance their architectures are from the native platform.

Native Apps

To start, let's go straight to the metal. Our first architectural tier is Native Apps.

Native Apps Tier — Where you develop for each specific platform (it might be even more specific when considering NDK)

This is the tier where you must be aware of the idiosyncrasies of each platform. It’s not my intention to dig into them, I just want to mention a few things in a bit of context.

You can watch this first part on Youtube.

iOS

Starting on the iOS side, just because it's simpler, there's only Apple ruling the world. Originally, developers needed to learn Objective-C, a proprietary object-oriented variation of C with some inspiration from SmallTalk (and an insanely long-named API).

In 2014, Apple announced Swift, a multi-paradigm language, which was a lot easier than its predecessor. It's still possible to deal with Objective-C legacy code, but Swift has reached high maturity levels. So, if you're planning to learn how to natively develop for iOS, Swift is definitely where you should start.

Android

On the Android side, there are a number of different manufacturers. The vast majority of them rely upon ARM processors. But generally speaking, Android apps lay on virtual machine instances (instances of ART) to help deal with potential underlying specificities (not without many amazing tricks).

That's why, originally, the language of choice was Java. It’s not only been the most popular language in the World for almost two decades (with a few position swaps with C), but it’s also notable for its Java Virtual Machine (JVM). This empowered developers to compile their code down to an intermediate bytecode that could be read and run by the JVM.

With the Android Native Development Kit (NDK), it's also possible to develop critical parts of the app directly in native code, writing in C/C++. In this case, you have to be aware of underlying platform quirks.

Kotlin is a language unveiled by JetBrains in 2011. When it first came out, despite its flexibility and conciseness, it wasn't more than yet another JVM language with more successful competitors like Scala, Clojure, or Groovy. However, after its first major release in 2016, it rapidly started to stand out from the crowd, especially after Google announced that it would be officially supported on the Android platform at Google I/O 2017.

Kotlin is becoming Google's first class language (currently Kotlin and Java — in this order — are used throughout Android's official documentation). A total Java replacement is expected even more so now that the US Federal Appeals Court has ruled on the endless lawsuit filed by Oracle accusing Google of violating Java copyrights.

Native components

Developing in this tier, you can also leverage all native APIs and, in particular, the native components. This saves your app from having to reinvent the wheel.

I've published a video demo of how to create a simple project on Xcode (iOS) and Android Studio. If you want to check it out:

Demo of iOS and Android basic projects.

Native Apps advantages

Best performance and top user engagement

Bleeding edge native features

Notably good IDEs Android Studio / Xcode

Modern high-level languages Kotlin / Swift

Very low-level approach with NDK

Native Apps disadvantages

Two codebases to maintain

Require installation (except Android Instant Apps)

Hard to analyze SEO

Very expensive to get users to download the app

Web Apps

On the other side of the spectrum, we have Web Apps. Web Apps are essentially apps run by the browser. You don't write code targeting the platform, but rather any browser running on top of it.

Web Apps Tier — clearly on top of a browser bar targeting a beast sitting in between Android and iOS.

In this tier you’ll find an insane number of contenders jumping at each other's throats. But they all use an arsenal consisting of the same weapons: HTML, CSS, and Javascript.

Web frameworks and libraries, even when leveraging CSS pre-compilers like LESS or SASS, even Javascript pre-compiled languages like TypeScript, CoffeeScript or Flow, even symbiosis like JSX or Elm, leaving alone tools like Babel used to transpile everything to Javascript with different configurable levels of conformance with ECMAScript yearly specifications (ES6 / ES7 / ES8, or if you prefer ES2015 / ES2016 / ES2017 / ES2018).

At the end of the day, they all are HTML, CSS, and JavaScript rendered and run by the browser. There's no direct access to native APIs like camera, vibration, battery status, or file system, but some of them can be achieved via Web API's:

The big issue with Web APIs is their maturity level. Many of them are not supported by some browsers. There are differences in implementations, especially across mobile browsers.

Web App advantages

Shared code between platforms and desktop browsers

Do not require previous installations, just navigate and use

Tons of frameworks and libraries to go with them

Best for SEO

Web App disadvantages

Lower performance

Hard to get a native user experience

Require an internet connection

Not available on official app stores

API not as mature and reliable as native API

Frameworks and Web components

Angular, React, and Vue are probably the most popular web frameworks as of 2018. To be precise, however, React is considered just a library due to its flexible and less opinionated nature. Angular, on the other hand, is a strongly opinionated framework. Vue lives at some point in between them.

Angular vs React vs Vue

Angular, originally called AngularJS, was presented to the world in 2010 by Google. It quickly started to shine, due to its inversion of paradigms in comparison with other libraries from that time (like jQuery, the most popular back then). Instead of directly talking to HTML elements to manipulate the UI state, with AngularJS, templates were magically updated whenever the JavaScript model was updated.

As AngularJS became more and more popular, it also grew in purpose. It turned into a complete and opinionated framework that was one of the first that took SPAs (Single Page Apps) seriously. This growth (in both aspects) was responsible for some API bloats and performance issues.

React was created by Facebook to solve their own needs on the presentation layer. It introduced many aspects that suddenly became very popular, like virtual DOM, one-way data flow (originally named Flux, especially popular through an implementation library called Redux), and a mixture of HTML and JavaScript called JSX.

Only in 2016, after long debates and unexpected big changes, Google launched version two of its popular web framework. They called it Angular, instead of AngularJS. But, as many people already called the first version “Angular” (without the ""JS"" suffix), people started calling the new version Angular 2. That turned into a naming problem, as Google also announced that it would release new major versions every 6 months.

In my opinion, that was a mammoth mistake. I've seen this before (with Struts vs Struts 2/WebWork, for example). They have a massively popular product that appears to have reached its plateau, and it has started to be more criticized than praised. If Google decides to rebuild it from the ground up, they should never, by any means, just change its major version. How will people trust that they will not repeat it every new major version release? Version two is supposed to present breaking changes, but it doesn't mean it can be totally revamped.

Angular is a spectacular web framework, and I really feel passionate about it. However, it's a completely new beast. It does not have much to do with AngularJS. Even Vue, which is another amazing framework (probably one of the most pleasant to work with, by the way) looks more similar to AngularJS from a bird's-eye view. I believe this caused a significant movement away from Angular and contributed substantially to React's popularity.

Vue is the only one of the three most popular web frameworks that is not backed by a big company. It was actually started by a former Google developer. Due to its formidable simplicity and tiny footprint, it got attention from a massive and enthusiastic community.

Although there are more complete solutions, they all work on top of the concept of web components. There's an open specification about them currently in progress in W3C, and some interesting implementations like Polymer, Stencil and X-Tag.

In the third video of the series, I don't spend too much time discussing frameworks but discuss web component libraries:

The Web Apps tier is discussed in Part 3 of the series

Mobile Apps vs Web Apps

I’m not sure if you’ve noticed, but the order of tiers I'm presenting here follows what I think is the easiest path to learn all approaches. I started from the Native Tier, the most genuinely mobile development. Then I decided to fly directly to the other extreme to present the Web Tier, which is the tier that has been available since the first smartphones.

Only now, after elaborating on a comparison between the two edges of my diagram, will I start talking about many of the cross-platform approaches to build mobile apps.

There's a long debate between Mobile Apps vs Web Apps. Everything I say about Mobile Apps is not exclusive to the Native Tier. It is also applicable to all cross-platform tiers I present later on.

The user behavior dilemma

Users spend more time on Mobile Apps (87%) than on Mobile Websites (13%)

According to a Comscore survey in 2017, a user's fidelity to a mobile app is way more relevant than it is to mobile websites. According to an aligned article on Forbes, this is usually because of convenience (for example, home screen buttons, widgets, top notifications), speed (for example, smoother interfaces, almost instant start ups), and stored settings (for example, offline content).

Mobile Websites reach more people (8.9M monthly unique visitors against 3.3M of Mobile Apps)

On the other hand, in the same Comscore data, we learn that customers can be reached more easily from mobile websites, as they are not as much tied to their few apps of preference. If you compare the most popular websites versus the most downloaded apps, it's estimated that an average of 8.9 million unique web visitors per month access the top 1000 websites. That's almost three times more than the average unique users of the top 1000 most downloaded apps.

Distribution (Web App) x Engagement (Mobile App)

That's all about distribution vs engagement. Your web app has a higher chance of being accessed, as users are more likely to try new things when navigating through their mobile browsers. But Mobile Apps have been proven to be more engaging, and catch the users attention for much longer periods.

Now that you understand the dilemma, let's have a look at Progressive Web Apps. This is an approach so tied to the Web Apps tier that I classify it as just an addendum to Web Apps. But it's a big disruptor and a serious candidate for the most prominent new and cool thing in web and mobile development.

Progressive Web Apps

Progressive Web Apps (PWAs) are a set of tools used to give Web App users the same experience they are accustomed to when they run Mobile Apps. This means that Web Apps can leverage the potentially higher levels of distribution with more decent levels of engagement.

Progressive Web Apps addendum to Web Apps tier

Google defined three main qualifications for PWAs: they must be Reliable, Fast, and Engaging.

Features called Service Workers and the App Shell are the foundation of Progressive Web Apps. They were created to promote apps’ reliability as they are now designed to work regardless of the device’s connection status. That includes offline mode, as well as poor connections. They also provide significant perceived performance boost, as apps launch using locally cached data, which eliminates delays for synchronous content downloads.

You could consider reliability an indirect vector of engagement. Users are not affected while commuting by train, for example. They can stay engaged.

The same applies to speed. According to Google:

53% of users will abandon a site if it takes longer than 3 seconds to load!

However, being exclusively reliable and fast on load doesn't necessarily guarantee high engagement. PWAs leverage mobile-related features that used to be exclusive to mobile apps, like an “Add to Home Screen” option and Push Notifications.

When it comes to to the “Add to Home Screen” feature, you might notice that Apple has had a similar feature since the very first iPhone. Some people even argue that Progressive Web Apps are Google's fancy new name for an original Apple idea.

And you really can’t completely disagree. Some ideas are actually cycling. They come, go away, and then come back with a new name and some enhancements (for instance, Service Workers), so they can finally stick around.

On the other hand, it’s hard to completely agree. Steve Jobs’ speech about Web 2.0 + AJAX and the memorable announcement of the iPhone back in WWDC 2007 are not convincing enough to call him as the father, or even the prophet, of PWAs.

To be fair, the Add to Home Screen capability on iPhone has been nothing more than a subtle, almost hidden, feature to generate desktop icons that just start up Web Apps in fullscreen mode. It has all the burden of HTTP request-response cycles and no clear path around caches.

PWAs start from the right point. They explore how previous installations of Web Apps aren’t necessary without losing the client-side bootstrap of Mobile Apps. This means that everything a user needs for their first interaction following startup might be locally cached (read: App Shell) and kept available as soon as they hit “Add to Home Screen.”

Moving onto another well-known characteristic of PWAs, let’s talk about the super engaging (or re-engaging) feature of the Mobile Apps world: Push Notifications. They are alert-style messages that appear on the top notification bar / area, as well as on lock screens. They have the power of pulling users back to your app once they receive the notification.

To reinforce the appeal of PWAs, Google has been pulling all modern Web APIs under the PWA umbrella. So expect to see things like Payment Requests, Credential Management, WebVR, Sensors, WebAssembly, and WebRTC in the context of Progressive Web Apps. But these feature are not necessarily tied to PWAs, and some were even born before the term PWA was coined.

PWA and Apple

Apple, on the other hand, announced their first solid milestones towards PWAs only in March 2018. Although there are still some limitations, the progress is appreciable. Some of the limitations might be related to the fact that Safari has fallen behind its competitors. Others could be attributed to Apple's philosophy of tight control.

Still, Apple has a more profitable App Store than Google. Apple's asserts that more criteria on app publications brings more overall reliability, and PWAs are bound to hurt the App Store's revenue. This suggests that some limitations that seem to be intentionally imposed (like 50Mb of PWA maximum cache size) will cost more to be revoked.

Unfortunately PWAs are not perfect

Web solutions and, on different levels, all cross-platform solutions struggle to attain the excellence and comprehensiveness of Native Apps. Every new feature, and every detail particular to Android or iOS makes that native feel harder and harder to access as you distance your app from the native tier.

Overall, PWAs fix some issues in the Web Apps tier. But there are other issues that can’t be fixed by a solution working on top of a browser.

What PWAs fix

More “native” experience

Faster load times

Do not require an internet connection

Force web developers to be aware of situations where there’s no connection as well as a bad connection

Incorporate features from Mobile Apps like Push Notifications, Geolocation, or Speech Recognition

What they don’t

Inherent slowness

Not available on app stores (just yet)

Still not fully supported by all browsers

Still lack mobile features like NFC, Ambient Light, Geofencing

Also lack support for peculiarities of Android or iOS like PiP, smart app banners, launch screen widgets, and 3D touch

In the video below, I do a brief overview of PWAs.

Progressive Web Apps are introduced in the Part 4 of the series

Hybrid Apps

At this level, we begin to dive into the Mobile App world. We’ll start from the most distant tier: Hybrid Apps.

The term Hybrid is also commonly applied to all cross-platform solutions. Here, however, I’m restricting it to Apps that work inside mobile components, called WebViews.

The Hybrid Apps tier. Below the browser's line but on top of WebViews

In the demos in the second video, my purpose for adding WebView as the Hello World example was to make clear that there's a native component for each platform that is able to perform like an actual browser.

Cordova/PhoneGap

Solutions like Cordova/PhoneGap close the gap (sorry for the uninspired pun) between Web and Mobile Apps. They provide tools to package developer's HTML, JavaScript, and CSS code (as well as any extra assets like images or videos) and transform them into Mobile Apps (yes, real Android or iOS apps). These apps have their WebView exclusively to interpret and run the original web code, starting with the “index.html” file in the app’s main folder (normally called “www”). They also bridge the JavaScript code to native APIs through plugins which are partially implemented in JavaScript and partially in a native language.

So, let's make things clearer. Hybrid Apps are able to access native APIs (instead of Web APIs), but they are enclosed by the WebView. A button with Cordova must be an HTML button rendered by a WebView instead of a mobile native button.

This is the magical tier that allows companies to port their Web Apps to Mobile Apps to be shipped by app stores. So any web framework is allowed here.

Ionic

Frameworks like Ionic wrap Cordova into their own solutions. With Ionic, you don't need to use Cordova’s command line interface (CLI), because all of its commands are wrapped by the Ionic CLI.

Recently, the Ionic team decided to take the reins of the entire stack of Hybrid Apps. So they launched a proposed replacement for Cordova called Capacitor. Capacitor has support for Cordova plugins, and can also be used by a non-Ionic project.

You can watch me going through a Cordova Hello World sample in the fifth video of the series:

Hybrid Apps are in Part 5 of the series.

Hybrid Apps advantages

They are essentially web apps that are shippable to official app stores

Can be used along with any JavaScript framework / library

The code is still highly shareable across platforms

Access to native features (for instance, camera, accelerometer, contact list)

Hybrid Apps disadvantages

Struggle with performance issues and memory consumption, as web views are responsible for rendering everything on screen

Have to mimic all native UI components on top of a single web view

Harder to be accepted and published on App Store

Usually take longer to have native features available for these environments

Web Native

Web Native is a relatively new and often misunderstood tier. That's where Web Apps meet native components. Although Appcelerator (Axway) Titanium has been around a long time, there are some relatively new competitors that justify making this a completely separate category of mobile apps.

Web Native Apps don't need WebView as they talk directly to other native components

As you can see above, there's no web view to render and run your application. So, how is your JavaScript executed? Is it compiled? Well, if you consider transpilation (compilation from one language to another — for example TypeScript to JavaScript), bundling, minification, mangling, and obfuscation all together as a compilation, yes JavaScript is compiled.

But the problem is, this doesn't make your JavaScript something directly understood by Android or iOS operational systems. And, in theory, there's no native component that only serves as a JavaScript engine without the bloat of the HTML layout engine.

The strategy is to ship JavaScript engines (normally V8 for Android and JavaScriptCore for iOS) along with your code. Although they have small footprints and are very fast, they are something external that must be provided by your app.

On the other hand, this approach tends to have better UI performance, as all the components are the same (or are based on the same thing for React Native, for example) as the ones used by Native Apps.

Web Native Apps advantages

Reach both platforms with one single codebase

Roughly the same performance as native apps, as they also deal with native UI components

Tweaks are necessary, but the code is still shareable with web development

Web Native Apps disadvantages

Even with one single codebase, the developer must be aware of native components

Steeper learning curve than Hybrid / Web Apps for web developers, especially when it comes to layout

React Native

In part 6 of the series, I do a quick Hello World in React Native. This shows, on Android Studio's Layout Inspector, what components were rendered in the emulator. I compare with the previous examples, ensuring that there's no WebView whatsoever.

Web Native Apps presentation with focus on React Native in Part 6 of the series.

Nativescript

Another amazing framework that I've been particularly interested in over the last two years (I have a course on Udemy about it — in Portuguese), is Nativescript. It’s similar to React Native but is not tied to the React world (there's an unofficial integration, Nativescript-Preact, though).

With Nativescript, you can develop using vanilla JavaScript, TypeScript, Angular and, more recently, Vue. Of course you can use other frameworks, but those are the ones officially supported. It’s fairly well documented too, by the way.

Nativescript has tools like Nativescript Sidekick and Nativescript Playground, as well as project structures based on templates that can be provided by the community. This should help you in project creation, giving you the ability to start, deploy, test, and run on simulators on the cloud and iPhone devices even when you are not developing using a Mac.

In the seventh part of the series, I do a Hello World using Sidekick along with another project started from the CLI and a WhatsApp clone template I created for learning purposes.

Web Native Apps with Nativescript in Part 7 of the series.

It's important to have a look at the Layout Inspector when your app is running on an Android emulator. With Nativescript, it shows the native components (again, no WebView), and direct instances of common Android classes like TextView. This is different than React Native, which has its own classes to wrap the native components.

That's probably why Nativescript claims that there’s no delay between when a new feature is available on iOS and Android and when you can use it in a Nativescript project. For example, they posted on their blog an AR project on the same day iOS 11 was officially released with the new ARKit API.

Weex

Another framework worth mentioning in this category is Weex. It's a project developed by Alibaba, and is currently incubated at Apache Sofware Foundation (ASF). It uses common HTML tags like <div> and CSS commands inside <style> tags to call native components instead. From their documentation:

Although components in Weex look like HTML tags, you are not able to use all of them. Instead, you can only use the built-in components and your custom components.

Cross Compiled

At this level, it’s time to jump off the Web bandwagon. This is the closest tier to native development, but has the advantage of using one single codebase to target Android and iOS.

Development tiers now complete with Cross Compiled Apps

RubyMotion and Xamarin

There are solutions like RubyMotion. This is a way to write mobile apps using Ruby and compile directly to the targeted platform (as it was created using any ""native"" language).

Another option is Xamarin, where you write in C#, compile to an intermediate bytecode, and deploy your app along with an instance of the Mono common language runtime. This approach has the same drawback as Web Native (where V8 and JavaScriptCore are delivered by your app), but can also rely upon JIT compilations to optimize the app at runtime.

Flutter

Last but not least, I'd like to bring up Flutter. It’s Google's newest cool initiative for mobile development. It fits in the Cross Compiled tier because you write apps using the Dart language and compile them down to the native platform.

Flutter has innovated in some aspects. Probably the most outstanding one is the fact that it provides its own set of components.

What? Own set of components?

Yes, Flutter provides a number of different components so you can completely skip the ones from the platform. It has generic components as well as Material Design components for Android, and Cupertino components for iOS.

Rather than .Net virtual machine (as Xamarin) or JavaScript engines (as Web Native frameworks), with Flutter your app will deliver the components you decide to use.

Are they native components?

Yes, they are. Your app is native, too. Everything is compiled to the native architecture. However, bear in mind they are not the pre-existing native components.

What's the point of that?

Well, in my opinion, this solution is clever and audacious. I've been waiting to talk about advantages and disadvantages, but as it's just one particular technology, let me address them now.

One of the biggest challenges for Web Native and Cross Compiled solutions (remember, above Native but below the WebView in our tiers) is how to deal with native components. For example, an important problem is how to lay them out. That's because they were not created to be used by those external resources. Also, they were not created with a counterpart in the other platform in mind. The Android NavBar doesn't work like iOS UINavBar, for example.

With Flutter, components are created with cross-platform always in mind. So let's have a look at the pros and cons of the Cross Compiled Apps tier:

Cross Compiled Apps advantages

Reach both platforms with one single language

Roughly the same performance as native apps, as they also deal with native UI components

Cross Compiled Apps disadvantages

Slightly delayed support for the latest platform updates

Code not shareable with web development

Even with one single codebase, the developer must be aware of native components

PS: With Flutter, you’ll provide your own set of widgets along with your app's code

Mobile Apps runtime architecture",https://cdn-images-1.medium.com/max/1200/1*kHze88HBCkKt8Tw4MESC9Q.png,[],https://medium.freecodecamp.org/a-deeply-detailed-but-never-definitive-guide-to-mobile-development-architecture-6b01ce3b1528?source=collection_home---6------21----------------,2018-06-05 16:34:24.241000+00:00

Big Data,How to deliver a React Native app to the client – freeCodeCamp,[],"How to deliver a React Native app to the client

If you have written some React Native apps, you’ve probably noticed that the process of beta-release version generation requires many repeatable steps. This happens especially for multi-platform apps.

Let’s look at sample action steps you need to perform to deliver the beta version app to the client or tester:

Download the proper branch from the repository

Android:

Insert the APK signing key into the ./android/app/ directory

directory Build the release version

Send the app, for example via e-mail

iOS:

Launch Xcode

Change the scheme to Release

Change the jsCodeLocation value to a static main.jsbundle file path

value to a static file path Archive

Upload the app to TestFlight

As you can see, the above list contains a large number of repeatable steps. Since they are repeatable, we can automate them, right?

Possible solutions

There are several solutions for automating beta release version generation and delivering the app to the client.

Visual Studio App Center

The first solution that came to our minds at Brainhub was the use of the Visual Studio App Center. A project built by Microsoft seems to be really attractive — in addition to building the app in the cloud (free 240 minutes / month of building) and distribution among testers and the client, it also provides a platform for testing apps on many real devices, giving access to reports and screenshots of every step of the process.

However, it quickly turned out that this was not the appropriate solution for our particular project. VS App Center has limited configuration abilities, and the app’s code needs to be downloaded from the Git repository hosted on GitHub, Bitbucket, or VSTS. Due to the fact that we use GitLab, we had to rule out this solution (but it could work for your project).

HockeyApp (with Fastlane)

The next option was to use HockeyApp — a tool for app distribution and collecting crash reports and users’ feedback. The service was initially created for distribution of iOS apps using the ‘ad hoc’ method (outside of App Store), but currently it works for Android also.

HockeyApp works well as a delivery platform of software testing versions, but does not give the functionality of building the app. However, we can also use Fastlane — a tool for mobile app building process automation built by fabric.io.

Preparations

Before you start building and deploying the app, you should prepare the environment. This section describes the steps you should take first.

Automatic jsCodeLocation change

React Native documentation says that you should change jsCodeLocation to the static js bundle for the iOS release version in AppDelegate.m file. But there’s no need to do that manually every time you release the app — you can use the #ifdef DEBUG macro to do it automatically. Just replace the line containing jsCodeLocation = … with the following code.

#ifdef DEBUG

// DEV

jsCodeLocation = [[RCTBundleURLProvider sharedSettings] jsBundleURLForBundleRoot:@”index” fallbackResource:nil];

#else

// PROD

jsCodeLocation = [[NSBundle mainBundle] URLForResource:@”main” withExtension:@”jsbundle”];

#endif

Ignore helper files

During the process of building the app, there will be some helper files created. There’s no need to commit them to the repository, so just add them to the following “.gitignore” file.

# Deployment

*.cer

*.jsbundle

*.jsbundle.meta

*dSYM.zip

*.keystore

*.mobileprovision

fastlane/report.xml

APK signing key

To release an Android app, you need a signing key. To learn more about this process, look here.

When you have your key generated, move it to the “android/app” directory and remember to add *.keystore to “.gitignore”.

Fastlane + HockeyApp + Testflight

You will learn how to automatically generate an app written in React Native for Android and iOS platforms, and send it to HockeyApp (Android) and Testflight (iOS).

First, let’s install Fastlane. Make sure you have the newest version of Xcode command line tools installed.

xcode-select — install

Install Fastlane.

[sudo] gem install fastlane -NV` or `brew cask install fastlane`

Init Fastlane.

fastlane init

The command above will create the “fastlane” directory in current directory with a file called “Fastfile” that contains the Fastlane configuration.

Appfile

In the “fastlane” directory, create a file called “Appfile”, which stores data that is used across all fastlane tools, for example AppleID. It is required for the iOS build and deployment to Testflight.

Add your AppleID to “Appfile”.

Fastfile

Your beta release Fastfile might look like this.

# More documentation about how to customize your build

# can be found here:

# https://docs.fastlane.tools

# fastlane_version “2.68.0”

# Fastfile actions accept additional configuration, but

# don’t worry, fastlane will prompt you for required

# info which you can add here later

platform :ios do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

get_certificates

get_provisioning_profile(

app_identifier: “org.you.yourProject”

)

# build your iOS app

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

# TestFlight

pilot()

end

end

platform :android do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

# build the release variant

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

# upload to HockeyApp

hockey(

api_token: “YOUR_TOKEN”

)

end

end

Let’s analyze our “Fastfile” step-by-step.

The code block below will be executed after typing fastlane ios beta into the console.

platform :ios do

lane :beta do

# …

end

end

For Android , type fastlane android beta .

platform :android do

lane :beta do

# …

end

end

Ensure that the current branch is master and perform git pull to sync with the remote repository.

ensure_git_branch(

branch: “master”

)

git_pull

iOS only

Let’s increment the build number (works for iOS only). The application that is being sent to Testflight has to have a higher build number than the previous version.

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

Testflight and Ad Hoc distribution require the proper certificate and provisioning profile. There are several methods of signing apps:

match

cert and sigh

Xcode’s code signing feature

manually

In this article, cert and sigh was used. For further reading about codesigning using Fastlane, visit this site.

get_certificates

get_provisioning_profile( app_identifier: “org.you.yourProject” )

Next, there is the step of building the iOS version where we pass the params such as project path, scheme , and export_method . Export_method contains one of the following values: app-store , ad-hoc , package , enterprise , development , or developer-id .

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

The last step for iOS is sending the app to Testflight.

pilot()

Android only

Now let’s look at the Android version. There are two gradle steps: cleaning, and building the release version.

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

Now you can send the generated app to HockeyApp.

hockey(

api_token: “YOUR_TOKEN”

)

If you don’t add some required parameter, for example no iTunes Connect user in Fastfile, Fastlane will ask you for that data in the console.

HockeyApp Configuration

After signing up and signing in to HockeyApp, you will see the blue “New App” button.",https://cdn-images-1.medium.com/max/1200/1*153T3TpCccNK7hs11oRNpA.png,[],https://medium.freecodecamp.org/how-to-deliver-a-react-native-app-to-the-client-e58421e7272e?source=collection_home---6------22----------------,2018-06-05 01:26:27.937000+00:00

Big Data,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------,2018-06-05 00:59:03.212000+00:00

Big Data,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------#--responses,2018-06-05 00:59:03.212000+00:00

Big Data,A coffee-break introduction to time complexity of algorithms,['Vicky Lai'],"A coffee-break introduction to time complexity of algorithms

Just like writing your very first for loop, understanding time complexity is an integral milestone to learning how to write efficient complex programs. Think of it as having a superpower that allows you to know exactly what type of program might be the most efficient in a particular situation — before even running a single line of code.

The fundamental concepts of complexity analysis are well worth studying. You’ll be able to better understand how the code you’re writing will interact with the program’s input, and as a result, you’ll spend a lot less wasted time writing slow and problematic code.

It won’t take long to go over all you need to know in order to start writing more efficient programs — in fact, we can do it in about fifteen minutes. You can go grab a coffee right now (or tea, if that’s your thing) and I’ll take you through it before your coffee break is over. Go ahead, I’ll wait.

All set? Let’s do it!

What is “time complexity” anyway?

The time complexity of an algorithm is an approximation of how long that algorithm will take to process some input. It describes the efficiency of the algorithm by the magnitude of its operations. This is different than the number of times an operation repeats. I’ll expand on that later. Generally, the fewer operations the algorithm has, the faster it will be.

We write about time complexity using Big O notation, which looks something like O(n). There’s rather a lot of math involved in its formal definition, but informally we can say that Big O notation gives us our algorithm’s approximate run time in the worst case, or in other words, its upper bound. It is inherently relative and comparative.

We’re describing the algorithm’s efficiency relative to the increasing size of its input data, n. If the input is a string, then n is the length of the string. If it’s a list of integers, n is the length of the list.

It’s easiest to picture what Big O notation represents with a graph:

Lines made with the very excellent Desmos graph calculator. You can play with this graph here.

Here are the main important points to remember as you read the rest of this article:

Time complexity is an approximation

An algorithm’s time complexity approximates its worst case run time

Determining time complexity

There are different classes of complexity that we can use to quickly understand an algorithm. I’ll illustrate some of these classes using nested loops and other examples.

Polynomial time complexity

A polynomial, from the Greek poly meaning “many,” and Latin nomen meaning “name,” describes an expression comprised of constant variables, and addition, multiplication, and exponentiation to a non-negative integer power. That’s a super math-y way to say that it contains variables usually denoted by letters, and symbols that look like these:

The below classes describe polynomial algorithms. Some have food examples.

Constant

A constant time algorithm doesn’t change its running time in response to the input data. No matter the size of the data it receives, the algorithm takes the same amount of time to run. We denote this as a time complexity of O(1).

Here’s one example of a constant algorithm that takes the first item in a slice.

func takeCupcake(cupcakes []int) int {

return cupcakes[0]

}

Choice of flavours are: vanilla cupcake, strawberry cupcake, mint chocolate cupcake, lemon cupcake, and “wibbly wobbly, timey wimey” cupcake.

With this contant-time algorithm, no matter how many cupcakes are on offer, you just get the first one. Oh well. Flavours are overrated anyway.

Linear

The running duration of a linear algorithm is constant. It will process the input in n number of operations. This is often the best possible (most efficient) case for time complexity where all the data must be examined.

Here’s an example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

}

Here’s another example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// double dip chip

}

}

It doesn’t matter whether the code inside the loop executes once, twice, or any number of times. Both these loops process the input by a constant factor of n, and thus can be described as linear.

Don’t double dip in a shared bowl.

Quadratic

Now here’s an example of code with time complexity of O(n2):

func pizzaDelivery(pizzas int) {

for pizza := 0; pizza <= pizzas; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

Because there are two nested loops, or nested linear operations, the algorithm process the input n2times.

Cubic

Extending on the previous example, this code with three nested loops has time complexity of O(n3):

func pizzaDelivery(boxesDelivered int) {

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

}

Seriously though, who delivers unsliced pizza??

Logarithmic

A logarithmic algorithm is one that reduces the size of the input at every step. We denote this time complexity as O(log n), where log, the logarithm function, is this shape:

One example of this is a binary search algorithm that finds the position of an element within a sorted array. Here’s how it would work, assuming we’re trying to find the element x:

If x matches the middle element m of the array, return the position of m. If x doesn’t match m, see if m is larger or smaller than x. If larger, discard all array items greater than m. If smaller, discard all array items smaller than m. Continue by repeating steps 1 and 2 on the remaining array until x is found.

I find the clearest analogy for understanding binary search is imagining the process of locating a book in a bookstore aisle. If the books are organized by author’s last name and you want to find “Terry Pratchett,” you know you need to look for the “P” section.

You can approach the shelf at any point along the aisle and look at the author’s last name there. If you’re looking at a book by Neil Gaiman, you know you can ignore all the rest of the books to your left, since no letters that come before “G” in the alphabet happen to be “P.” You would then move down the aisle to the right any amount, and repeat this process until you’ve found the Terry Pratchett section, which should be rather sizable if you’re at any decent bookstore, because wow did he write a lot of books.

Quasilinear

Often seen with sorting algorithms, the time complexity O(n log n) can describe a data structure where each operation takes O(log n) time. One example of this is quick sort, a divide-and-conquer algorithm.

Quick sort works by dividing up an unsorted array into smaller chunks that are easier to process. It sorts the sub-arrays, and thus the whole array. Think about it like trying to put a deck of cards in order. It’s faster if you split up the cards and get five friends to help you.

Non-polynomial time complexity

The below classes of algorithms are non-polynomial.

Factorial

An algorithm with time complexity O(n!) often iterates through all permutations of the input elements. One common example is a brute-force search, seen in the traveling salesman problem. It tries to find the least costly path between a number of points by enumerating all possible permutations and finding the ones with the lowest cost.

Exponential

An exponential algorithm often also iterates through all subsets of the input elements. It is denoted O(2n) and is often seen in brute-force algorithms. It is similar to factorial time except in its rate of growth, which, as you may not be surprised to hear, is exponential. The larger the data set, the more steep the curve becomes.

In cryptography, a brute-force attack may systematically check all possible elements of a password by iterating through subsets. Using an exponential algorithm to do this, it becomes incredibly resource-expensive to brute-force crack a long password versus a shorter one. This is one reason that a long password is considered more secure than a shorter one.

There are further time complexity classes less commonly seen that I won’t cover here, but you can read about these and find examples in this handy table.

Recursion time complexity

As I described in my article explaining recursion using apple pie, a recursive function calls itself under specified conditions. Its time complexity depends on how many times the function is called and the time complexity of a single function call. In other words, it’s the product of the number of times the function runs and a single execution’s time complexity.

Here’s a recursive function that eats pies until no pies are left:

func eatPies(pies int) int {

if pies == 0 {

return pies

}

return eatPies(pies - 1)

}

The time complexity of a single execution is constant. No matter how many pies are input, the program will do the same thing: check to see if the input is 0. If so, return, and if not, call itself with one fewer pie.

The initial number of pies could be any number, and we need to process all of them, so we can describe the input as n. Thus, the time complexity of this recursive function is the product O(n).

This function’s return value is zero, plus some indigestion.

Worst case time complexity

So far, we’ve talked about the time complexity of a few nested loops and some code examples. Most algorithms, however, are built from many combinations of these. How do we determine the time complexity of an algorithm containing many of these elements strung together?

Easy. We can describe the total time complexity of the algorithm by finding the largest complexity among all of its parts. This is because the slowest part of the code is the bottleneck, and time complexity is concerned with describing the worst case for the algorithm’s run time.

Say we have a program for an office party. If our program looks like this:

package main



import ""fmt""



func takeCupcake(cupcakes []int) int {

fmt.Println(""Have cupcake number"",cupcakes[0])

return cupcakes[0]

}



func eatChips(bowlOfChips int) {

fmt.Println(""Have some chips!"")

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

fmt.Println(""No more chips."")

}



func pizzaDelivery(boxesDelivered int) {

fmt.Println(""Pizza is here!"")

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

fmt.Println(""Pizza is gone."")

}



func eatPies(pies int) int {

if pies == 0 {

fmt.Println(""Someone ate all the pies!"")

return pies

}

fmt.Println(""Eating pie..."")

return eatPies(pies - 1)

}



func main() {

takeCupcake([]int{1, 2, 3})

eatChips(23)

pizzaDelivery(3)

eatPies(3)

fmt.Println(""Food gone. Back to work!"")

}

We can describe the time complexity of all the code by the complexity of its most complex part. This program is made up of functions we’ve already seen, with the following time complexity classes:

To describe the time complexity of the entire office party program, we choose the worst case. This program would have the time complexity O(n3).

Here’s the office party soundtrack, just for fun.

Have cupcake number 1

Have some chips!

No more chips.

Pizza is here!

Pizza is gone.

Eating pie...

Eating pie...

Eating pie...

Someone ate all the pies!

Food gone. Back to work!

P vs NP, NP-complete, and NP-hard

You may come across these terms in your explorations of time complexity. Informally, P (for Polynomial time), is a class of problems that is quick to solve. NP, for Nondeterministic Polynomial time, is a class of problems where the answer can be quickly verified in polynomial time. NP encompasses P, but also another class of problems called NP-complete, for which no fast solution is known. Outside of NP, but still including NP-complete, is yet another class called NP-hard, which includes problems that no one has been able to verifiably solve with polynomial algorithms.

P vs NP Euler diagram, by Behnam Esfahbod, CC BY-SA 3.0

P versus NP is an unsolved, open question in computer science.

Anyway, you don’t generally need to know about NP and NP-hard problems to begin taking advantage of understanding time complexity. They’re a whole other Pandora’s box.

Approximate the efficiency of an algorithm before you write the code

So far, we’ve identified some different time complexity classes and how we might determine which one an algorithm falls into. So how does this help us before we’ve written any code to evaluate?

By combining a little knowledge of time complexity with an awareness of the size of our input data, we can take a guess at an efficient algorithm for processing our data within a given time constraint. We can base our estimation on the fact that a modern computer can perform some hundreds of millions of operations in a second. The following table from the Competitive Programmer’s Handbook offers some estimates on required time complexity to process the respective input size in a time limit of one second.

Keep in mind that time complexity is an approximation, and not a guarantee. We can save a lot of time and effort by immediately ruling out algorithm designs that are unlikely to suit our constraints, but we must also consider that Big O notation doesn’t account for constant factors. Here’s some code to illustrate.

The following two algorithms both have O(n) time complexity.

func makeCoffee(scoops int) {

for scoop := 0; scoop <= scoops; scoop++ {

// add instant coffee

}

}

func makeStrongCoffee(scoops int) {

for scoop := 0; scoop <= 3*scoops; scoop++ {

// add instant coffee

}

}

The first function makes a cup of coffee with the number of scoops we ask for. The second function also makes a cup of coffee, but it triples the number of scoops we ask for. To see an illustrative example, let’s ask both these functions for a cup of coffee with a million scoops.

Here’s the output of the Go test:

Benchmark_makeCoffee-4 1000000000 0.29 ns/op

Benchmark_makeStrongCoffee-4 1000000000 0.86 ns/op

Our first function, makeCoffee , completed in an average 0.29 nanoseconds. Our second function, makeStrongCoffee , completed in an average of 0.86 nanoseconds. While those may both seem like pretty small numbers, consider that the stronger coffee took nearly three times longer to make. This should make sense intuitively, since we asked it to triple the scoops. Big O notation alone wouldn’t tell you this, since the constant factor of the tripled scoops isn’t accounted for.

Improve time complexity of existing code

Becoming familiar with time complexity gives us the opportunity to write code, or refactor code, to be more efficient. To illustrate, I’ll give a concrete example of one way we can refactor a bit of code to improve its time complexity.

Let’s say a bunch of people at the office want some pie. Some people want pie more than others. The amount that everyone wants some pie is represented by an int > 0:

diners := []int{2, 88, 87, 16, 42, 10, 34, 1, 43, 56}

Unfortunately, we’re bootstrapped and there are only three forks to go around. Since we’re a cooperative bunch, the three people who want pie the most will receive the forks to eat it with. Even though they’ve all agreed on this, no one seems to want to sort themselves out and line up in an orderly fashion, so we’ll have to make do with everybody jumbled about.

Without sorting the list of diners, return the three largest integers in the slice.

Here’s a function that solves this problem and has O(n2) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// loop over three forks

for i := 1; i <= 3; i++ {

// variables to keep track of the highest integer and where it is

var max, maxIndex int

// loop over the diners slice

for n := range diners {

// if this integer is higher than max, update max and maxIndex

if diners[n] > max {

max = diners[n]

maxIndex = n

}

}

// remove the highest integer from the diners slice for the next loop

diners = append(diners[:maxIndex], diners[maxIndex+1:]...)

// keep track of who gets a fork

withForks = append(withForks, max)

}

return withForks

}

This program works, and eventually returns diners [88 87 56] . Everyone gets a little impatient while it’s running though, since it takes rather a long time (about 120 nanoseconds) just to hand out three forks, and the pie’s getting cold. How could we improve it?

By thinking about our approach in a slightly different way, we can refactor this program to have O(n) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// create variables for each fork

var first, second, third int

// loop over the diners

for i := range diners {

// assign the forks

if diners[i] > first {

third = second

second = first

first = diners[i]

} else if diners[i] > second {

third = second

second = diners[i]

} else if diners[i] > third {

third = diners[i]

}

}

// list the final result of who gets a fork

withForks = append(withForks, first, second, third)

return withForks

}

Here’s how the new program works:

Initially, diner 2 (the first in the list) is assigned the first fork. The other forks remain unassigned.

Then, diner 88 is assigned the first fork instead. Diner 2 gets the second one.

Diner 87 isn’t greater than first which is currently 88 , but it is greater than 2 who has the second fork. So, the second fork goes to 87 . Diner 2 gets the third fork.

Continuing in this violent and rapid fork exchange, diner 16 is then assigned the third fork instead of 2 , and so on.

We can add a print statement in the loop to see how the fork assignments play out:

0 0 0

2 0 0

88 2 0

88 87 2

88 87 16

88 87 42

88 87 42

88 87 42

88 87 42

88 87 43

[88 87 56]

This program is much faster, and the whole epic struggle for fork domination is over in 47 nanoseconds.

As you can see, with a little change in perspective and some refactoring, we’ve made this simple bit of code faster and more efficient.

Well, it looks like our fifteen minute coffee break is up! I hope I’ve given you a comprehensive introduction to calculating time complexity. Time to get back to work, hopefully applying your new knowledge to write more effective code! Or maybe just sound smart at your next office party. :)

Sources

“If I have seen further it is by standing on the shoulders of Giants.” –Isaac Newton, 1675",https://cdn-images-1.medium.com/max/1200/1*_YsSsyFQ5sgS8F0kiZ1USA.png,[],https://medium.freecodecamp.org/a-coffee-break-introduction-to-time-complexity-of-algorithms-64df7dd8338e?source=collection_home---6------24----------------,2018-06-04 23:44:40.970000+00:00

Data,Media – Medium,"['Ev Williams', 'Dave Pell', 'Hossein Derakhshan', 'Dawn Ennis', 'Don Day', 'Jessie Singer', 'Tim Grierson', 'Melissa Chu']","Media Where the newsroom is the news.

Follow Following",https://cdn-images-1.medium.com/max/1200/1*wLhNmBWoSMvG0kyRGjDIqw@2x.jpeg,[],https://medium.com/topic/media,

Data,The Inspiration of Anthony Bourdain – Member Feature Stories – Medium,['Christine Byrne'],"One of my first great food memories comes from a trip my family took to Normandy when I was six years old. We hadn’t been sitting for two minutes when I announced to my parents, “I want the escargot.”

Dad: “You know that’s snails?”

Six-year-old me: “Yes! We just learned about them in French class, and I want the escargot!”

My parents went along, although I’m sure they expected I’d take a few bites out of stubbornness, then subtly push the dish of garlic and butter and earthy mollusk aside, hoping no one would call out my misplaced courage.

Actually, though, I ate every snail, then mopped up every bit of briny, herby garlic butter left behind. I still think about those snails and about how excited and proud I was to love them so much.

A decade after those snails, I sat on the living room couch with my dad and watched an episode of No Reservations, Anthony Bourdain’s first food travel show. I, like millions of others, was drawn to the irreverent reverence with which he seemed to approach every food he tried, to his eagerness to try anything, and to his ability to narrate the stories of different foods, cooks, and cultures in an unpretentious way that let them mostly speak for themselves. Until then, I had thought of food and travel writing and television as more marketing than storytelling, but watching No Reservations made it clear that, actually, food was not only a story in and of itself, but also a great way to anchor other stories in something tangible and universally understood. Bourdain wasn’t out to sell an experience or show how good something could be — every episode was about telling the story of things exactly as they are.

Bourdain wasn’t the first to talk about food this way, but he was the first to make me feel like maybe I could talk about food that way, too. Food was an important part of my life growing up, but not in a particularly extraordinary way that I felt would resonate. We lived abroad and traveled often, so I was massively privileged in that there was always something new to eat. I remember eating pâté for the first time on a pebble beach in Cornwall while watching my dad (try to) learn to windsurf. I remember tearing apart a slick piece of roti prata and dipping it into a Styrofoam container of curry sauce on a plastic picnic table in Mersing, Malaysia, before getting on a bum boat to an island where I’d go to summer camp for the first time. I remember my first drink: a Tiger beer at Newton Circus, another hawker center, after the closing night of our high school production of South Pacific. I remember, every year when we’d fly home to New Jersey, eating baked ziti and supermarket sheet cake at Fourth of July barbecues, both or which were exciting and special for me because I only ate them once a year. I remember the first time I ate lunch at a New York City deli and was awed by the enormity of both the sandwiches and the Snapple selection. None of this seemed like a story, though, because I wasn’t sure why anyone else would care.

Years later, as a rising college senior, I spent the summer working as a publishing intern in New York. Weeks in, I realized that my longtime goal of being a book editor was actually, definitely, not what I wanted. To keep the “I graduate in a year and now have no plan” anxiety at bay, I read more books that summer than I ever have. One of them was Anthony Bourdain’s Kitchen Confidential.

Bourdain’s 2000 memoir, as you may know, gets so much of its magic from the sense you get while reading that every story is true. I figured it would fall into the “I never want to go there, but that sure made me think and was fun to watch” category that some of the No Reservations episodes did, and that the stories about hypermasculine kitchen culture and the people who somehow ended up in it would make me laugh, think, and then move on to whatever book was next.

That’s not what happened. The first story the book tells is one of Bourdain as a fourth-grader on a European cruise with his family. He tries vichyssoise, a potato-based French soup, and is taken aback by the fact that it’s cold. “I’d eaten in restaurants before, sure,” he says, “but this was the first food I really noticed. It was the first food I enjoyed and, more important, remembered enjoying.” Reading it made me think of my snails, how adventurous they made me feel, and how they established food as something important and worth discovering. It’s a good, tame story that I could easily relate to, and I bet most people felt the same when reading it.

The thing is, the relatability of the book started and ended with that cold potato soup. The rest of the book — about restaurant kitchens and all the crass, stressful, macho, bonkers shit that happened inside them — took place in a world very, very different from mine. Even coming from Bourdain, whose stories had been making me feel welcome since I first watched him walk around Paris unironically wearing cowboy boots in the first episode of No Reservations, the book felt like something I was looking in on from the outside. Reading it piqued my curiosity in restaurant cooking but made it clear that it wasn’t something for me. The longer the stories sat with me, though, the more they started to feel like a sort of…dare.

I graduated soon after, six months earlier than planned. I was still put off by my intern experience in publishing and totally uninspired by every job option presented to me by career counselors and all the well-meaning adults in my life. (Although it was 2010 and the height of a recession, so calling them “options” is maybe a stretch.) Food writing had crossed my mind, but I didn’t figure it was something I could just jump into. I can’t really explain my sudden decision to go to culinary school — a mix of desperation, an interest in food, a burning need to be interesting and different, and a nagging curiosity about Kitchen Confidential, if I had to put it into words — but in 2010, I moved to New York and spent 10 months at the French Culinary Institute learning how to cook. It remains the most impulsive thing I’ve ever done—and the most significant.

The following two and a half years spent cooking in NYC restaurant kitchens taught me things that culinary school never could have—about cooking, stress, being a woman in a room of mostly men, and how to deal with constantly being under fire without falling apart. It’s hard to explain what it was like to walk into a restaurant kitchen, and I honestly don’t remember it clearly, but I do remember that everything I did was wrong, everywhere I was was in the way, and every time someone said something to me, I had to ask them to explain what they were talking about. It was the most underqualified and out of place I’d ever felt, even though I knew in theory that’s exactly what I was signing up for. (I’d read the book! I intentionally jumped out of my comfort zone!) It wasn’t the useless, undervalued feeling that comes with an entry-level office job; it was the feeling that I needed to apologize for even being there, for being the alien who disrupted a system that everyone else knew how to work in. Weeks went by before I was able to walk into that kitchen without absolute fear; months went by before I was able to actually contribute.

Was restaurant cooking the way Bourdain described? Not really. It was vaguely the same, sure: late nights, weekends, burn scars, characters, industry bars, some yelling, ticket boards that inexplicably but reliably went from empty to full in a matter of minutes every single night.

The actual experience of it was very different from what I’d read, though. Because it wasn’t his experience—it was mine. I was the one cramming four hours’ worth of food prep into two and a half every afternoon. I was the one at the stove, firing seven dishes from three different orders at the same time, in exactly the right order, totally on instinct. I was the one who stayed at the bar three hours too long on a Tuesday and somehow always managed to find my way on the L train. I was the one who felt disconnected from one world but totally plugged into another.

Which made me realize: A great storyteller is one who makes you want to experience stories for yourself. A great story is one that makes you think, “I wonder what it would be like to do that.” I’m not much of a storyteller these days, nor am I still a restaurant cook. I write recipes, and I write stories about how and why people should cook them, but I do so in a way that’s shaped by what I’ve learned: Recipes are like stories, kind of, and the best recipes are ones that people will actually cook. Getting someone to cook a recipe isn’t about presenting them with something they’re already familiar with, necessarily, but about making them think, “I wonder what it would be like to do that.”

It’s no secret that Anthony Bourdain was a great storyteller. I’ll miss following along with his unending curiosity about food and how it shapes us, and the world will miss the way he was able to share that curiosity in a way that was welcoming and inclusive. What I’m most grateful for, though, is that he showed me the inside of a world I’d never given a second thought to—restaurants—and painted a picture that, even though it was totally unrelatable to me, was interesting enough that I felt compelled to experience if for myself. Not many storytellers do their job so well that, after reading their stories, you actually feel moved to go out and live them.

“Food, for me, has always been an adventure,” Bourdain writes in the preface of Kitchen Confidential. For me, too, Chef. Thanks for teaching me that food is something worth exploring and that the exploration is something worth writing about.",https://cdn-images-1.medium.com/max/1200/1*65ru7KtyJDme4kUXz8Sl5Q.jpeg,[],https://medium.com/s/story/the-inspiration-of-anthony-bourdain-8d5679c2acb4?source=grid_home---------0------------------18,

Data,"Apple has no idea what’s next, so it’s just banging on the same old drum",['Owen Williams'],"Apple has no idea what’s next, so it’s just banging on the same old drum If you want to witness a company that’s simultaneously in its prime and losing control over its own narrative, look no further than WWDC, Apple’s second-most splashy event of the year, designed to offer a glimpse of the future. The annual developer event is a spectacle that I’ve watched live for almost a decade, but this year was different: it showcased a company that’s lost in the woods, playing the same old hits on repeat, in the same old format. Not only was it painful to watch, it demonstrated that Apple doesn’t really have a coherent plan, or understanding, of where it should take its core platform, let alone the ones it’s tried to build around it. It’s fine to have an off year, but what struck me was how… random it felt, and how little insight or forward thinking there was. Apple’s own platform advantages, company culture, and whatever else, seem to be pigeonholing its trajectory, driving it down a path that looks increasingly dated, and leaving me to wonder if the company is self-aware enough to see the shifting tide before it’s lost at sea. Big, slow, yearly

Apple struggled throughout 2017 to ship flagship features it promised at WWDC 2017, including Airplay 2 and iCloud Messages, delivering them quietly just days before this year’s event. Alongside a scandal about performance throttling, a series of major security slip-ups, and hardware that shipped without long-touted features, many have loudly asked what’s causing these issues — and why a company with so many engineers is fundamentally failing to ship. Performance improvements are arguably the biggest focus of iOS 12. They’ll be welcome for many users, along with several additional improvements: streamlined notifications, a new ‘shortcuts’ feature for custom buttons, usage reporting, group FaceTime, AR updates and a number of other minor improvements to create a major release, iOS 12. The company’s other platforms received similar treatment, including macOS. Apple finished dark mode, a feature it half-introduced all the way back in Yosemite, added basic functionality to Finder, threw in a new way to organize your desktop, and boom — there’s your major release, 10.14. None of these things are inherently bad — in fact, people have been complaining about the lack of improvements to things like FaceTime for years — but what’s interesting is Apple’s choice to bundle them together as a way to make them look truly meaningful, rather than just fixing many of these issues sooner, in a point release. I’m aware there’s a slew of tiny other fixes and features I haven’t listed here, but that’s my point: it’s a hodgepodge of things that have been neglected over the years after being debuted once and forgotten about. Here’s the rub: Apple could arguably ship notification improvements to iOS users tomorrow in a point release, iOS 11.5, but it won’t. Combining them provides the illusion of progress. Instead of servicing users and giving them features sooner, on a regular basis, Apple chooses to hold back simple functionality longer, for its bottom line. As Martin Bryant points out, Apple may have a timing problem: Yes, Apple needs to take the time to do ‘boring’ optimisation work on iOS, but why build iOS around these big, annual feature bumps and then disappoint people when the bumps aren’t very big?

Interestingly, the narrative here actually doesn’t make sense anymore, either. Every year, Apple takes the time to point out how dire the state of the competition is: Nobody’s Android phones get updates! Android people don’t get any the latest features! Your phones all suck! The reality is different: Android users, regardless of manufacturer, frequently get them sooner than iOS users do, because Google divorced the operating system and core application suite from one another. Google’s approach to unbundling Android has, for the most part, been quietly successful — in an unexpected way. Instead of shipping monolithic feature updates, Google’s applications are now updated via the Play Store, from the clock app to the calculator and even the camera (unless you’re Samsung). Apple has made a yearly ritual out of jabbing competitors for poor update histories, but conveniently omits the reality that improvements to Google Assistant, the built-in web browser, or even just the OS keyboard will reach billions of users in a matter of hours without needing to update the entire phone. Android’s support libraries mean developers can target older devices, with new features, regardless of whether or not they received the OS update. Meanwhile, if you find a bug in the iOS keyboard, or some weird security flaw in Safari’s web view, you hope it gets fixed in the next version of the operating system. Maybe next year, or the year after that. It depends how bad it is, or if Apple is actively maintaining the feature, as to when it’ll get serviced. Don’t get me wrong, Android has a terrible history of updates that is only now beginning to change, ten years after the fact. Google has made strides with Project Treble, which makes an end-run around the device maker itself, but it’s only in its infancy with new devices picking it up today. That’s not good enough either; but it’s gaining traction and getting things into people’s hands. For each platform update, Apple dangles a carrot. That’s the flagship feature to convince you it’s a Big Update™ worth having immediately. On macOS this year, that’s dark mode, and on iOS, the promise of performance improvements and, god forbid, actually decent notification management. Arguably the most interesting segment out of WWDC happens at the very end of the two-hour keynote: a peek at Project Marzipan, a long-term effort to unify the interface framework developers use to build apps for iOS and macOS, which is expected to ship to everyone in 2019.

From where I sit, this is an impressive, massive project that doesn’t do much more than play defense against Electron’s continued march on Apple’s territory, threatening to kill native application development altogether. Why build anything native at all, when you can write once, and run everywhere? Anti-Electron fans will run rabid at the idea, but as the technology has become more efficient and introduced lower-level API access, it only makes even more business sense. Marzipan is an audacious plan to defend against that by making it easier to build cross-platform apps. It’s a genuinely fascinating play with fewer apparent benefits in the short term over just building an Electron app, which addresses an additional billion users, allows developers to use familiar web technology and is truly write-once-run-everywhere. Over time, Marzipan may win favor with developers, but I’m not convinced it’ll stop web-based technologies swallowing native app development whole, particularly given that both Microsoft and Google have now bet their entire strategies on Progressive Web Applications, and how low the barrier of entry has come as a result of Electron’s success. Marzipan indicates something bigger, of course, such as an impending shift away from Intel chipsets entirely to some sort of custom Apple ARM-based silicon in — shock horror — a productivity form factor. If anything, what will win as a result will be that control, and what it could ship in a end-to-end device: true all-day battery? Always-on LTE with desktop class apps? If so, the message is this: lock in with us, develop for our platforms, and we’ll reward you. Don’t, and you’ll be shut out and stuck on the outside. Hey Siri, where’s the vision?

What’s clearly missing in all of this is a willingness to take risks, or go for the long view on what’s better than the status quo for Apple’s users. Instead of looking at how phone usage is changing and redesigning the nature of iOS, it’s another year of shoehorning new features into a decade-old shell. The new shortcuts feature promises to let users wire up workflows of their dreams, chaining together tasks behind a single button. Yes, this is a great improvement to iOS that addresses a problem without actually improving on the reason anyone needs this in the first place — it’s just glued onto the homescreen that’s responsible for causing the need for it in the first place. Apple could have offered up a way to surface the weather right there, deeply integrated with the lock screen, or calendar events at the top of your home screen along with the icons, but it didn’t. Instead, it slathered what appears to be a UX hack in the shape of a notification, and tries to guess when you want to see it. Google’s own developer conference, just down the street in Mountain View, was held in May and offered a clearer, if poorly highlighted, view of the future: AI is a core part of mobile devices going forward, so we’re beginning to add it everywhere. The Android alternative to Shortcuts, Slices and App Actions, surfaces the device’s best guess at your next action as a deeply integrated interface component, where you can actually see information before actually going further in, or taking an action. Want a button to order a Lyft? Great, here’s a button embedded within the system’s app tray, with the current estimated price of your ride, which orders it right now with a single tap. Much of this data is crunched on device, just like Apple’s audacious claims to privacy brag about as well, but instead of being a UX hack to add buttons that summon help, the information is already right there, on hand, without opening anything, even Assistant. Google and Apple both anticipate a future in which we use our phones less — time well spent is a core part of this driver — and as a result, it appears Google has spent a lot of time thinking about how AI can help get the right information to the user. The result is the exact button they need at the right time, with relevant information, sans the need to actually go away and do something. To facilitate this, Google is willing to rejig the UX of its devices, mess with the sea of icons, and has invested heavily in serendipitous computing with Google Home alongside this, so it can get you there faster regardless of if the phone is in your hand.

Google’s vision of the future of smartphones, mobile operating systems, and the way we’ll interact with devices over the long haul is a coherent, well-told story: get more out of your day, get the devices out of the way. It even has a fantastic page that showcases how its own ecosystem works better, together, than I’ve ever seen explained about Apple’s ecosystem on its own site. As for why all of this happens, I suspect it’s a difference in strategy and approach. Apple’s strategy has long been to monetize its existing cash cows as long as it can by throwing out new stuff to see what sticks and doubling down on that, rather than creating any sort of coherent narrative of what the future actually looks like, operating in secrecy until it somehow lands upon it. Incremental improvement is fine, but there’s a distinct lack of forward-looking, and a whole lot of looking over the fence at what everyone else is doing to bash it instead. Apples, oranges and comparing the two

It’s easy to compare and contrast Google and Apple because they are very different companies, but what they’re both claiming to do is the same: invent the future, whatever that actually might be. Their approaches, however, are increasingly diverging: Apple’s squeezing more out of less, shipping flashy features, and focusing on privacy, while Google and others have pushed further into understanding the user and getting out of their way. Most of this comes down to business model. Apple’s focus on features by piling them together drives more sales of iPhone, which drives reliable revenue on a yearly basis. Google’s is on advertising and relevance to the user, which doesn’t depend on a particular feature or thing to tout, it just needs you to love using its tools (and not mind advertising). Apple’s entire strategy over the last two decades has pivoted around the exploitation of a product line until something new comes along, then rinse and repeat. This is framed around improving your life and often actually does, even if that is by proxy. I’d argue that the company’s vision of the future isn’t to enrich, or drive progress, but to squeeze as much revenue as possible out of slick, well-designed and marketed ideas. The products it builds, the cycles they’re released in and the way that Apple’s entire software cycle works reflects this. An example of the manifestation of this is perhaps HomePod’s requirement to have a locally available iPhone to do anything interesting, leaving it crippled without one, and Animoji’s debut only to be locked away in Messages instead of somewhere like the camera.

Google, a latecomer in the game, has the luxury — and peril — of not depending on phone revenue, so it can risk it all and get weird, since it’s not fundamentally critical to the company’s continued trajectory. Microsoft has done the same, now finding itself the underdog, risked it all and moved to an ‘OS-as-a-service’ model in which it ships features when they’re ready instead of waiting for flashy releases. Apple, on the other hand, begins and ends with the iPhone today, the rest flows from there. It can’t just rip up the foundation on which its revenue exists, and Tim Cook hasn’t shown a flair for doing so. iOS is too valuable to go away and tear down to just reimagine it for fun, so it’s the status quo, with experiments like HomePod and AirPods on the side, where it can get weird and sometimes wonderful. That’s fine, because Apple has plenty of cash lying around, but it’s interesting how limiting the approach can become. As we hurtle toward peak smartphone, the cracks here are beginning to show because Apple don’t have the next big thing yet — that we know of, naturally — and it’s taking a long time to get here. We’re essentially watching the bottom of the metaphorical tube of toothpaste being squeezed, while others are trying to figure out if maybe the tube should work completely differently. AR is potentially the next platform, yes, and it’s clear that Apple is pushing forward on that in a big way, so it’s easy to imagine a scenario in which it makes sense to shift precious resources there instead of focusing on iOS which may wind up unimportant in a year or two. I’m not convinced that in the short term, such as the oft-claimed 2020 launch date of an Apple VR/AR headset, that we’ll be headed there in any meaningful capacity. I mean, Magic Leap, a bajillion dollar company building the future of AR showed off its hardware yesterday on Twitch, quipping that “you better not put it in your pocket or it’ll overheat.” I’m happy to be wrong, and I write this knowing I’ll probably be that guy who very publically crapped on the iPhone at launch later. Apple’s worth a very large amount of money, which is more than enough proof that it’s good at many things, including convincing people to buy a phone every year.",https://cdn-images-1.medium.com/max/1200/1*tIUbwrpHZPbdNPXB569wPQ.png,[],https://medium.com/@ow/apple-has-no-idea-whats-next-so-it-s-just-banging-on-the-same-old-drum-dcfd0179cf80?source=grid_home---------0------------------18,2018-06-07 13:54:23.876000+00:00

Data,Our Wedding Is Canceled Due to the Following Strongly-Held Beliefs,['Tim Sniffen'],"Hi, everyone. I know you weren’t expecting to see Keith and I out here so soon, but we have some bad news. We’re not getting married today.

Believe me, we were really looking forward to it, but recently — this morning, in fact — we learned our blessed event was in direct conflict with the strongly-held beliefs of many of the people providing our wedding services. And if they’re not happy, we’re not happy.

Let me bring you up to speed.

You may have noticed the empty display table by the reception tent as you filed in. That’s where our wedding cake would have been. For our baker, however, creating a cake to be employed in the marriage of two men would be the moral equivalent of using communion wine to make sangria.

We knew the risks when enlisting Give Us This Beignet, Our Daily Bread as our wedding baker. They’re the best in downtown Aurora, no question — sorry, Wild-Flour! — but their beliefs on same-sex marriage are no secret. We hoped they might get swept up in the joy of the occasion but last night their chief baker Jonah, applying the final bit of piping, had a vision of Billie Jean King physically dragging him away from the gates of Heaven. And if that’s not a sign, I don’t know what is.

I should add, it may not have helped that we requested our little cake figurines be surrounded by an added semi-circle of figurines, in likenesses of the bakery staff, giving us the thumbs-up.

But that’s all done with. They’ve made their wishes clear and we respect them.

Which brings me to the empty vases alongside the pews and the empty centerpiece bowls on the reception tables. We’ve known Joyce Gantz, owner of Rest On My Laurels, for years; I couldn’t imagine this day without her. What I couldn’t know was the war raging within Joyce, fervent Catholic, after she learned of the meat-laden Friday barbecues Keith and I throw for our softball team. Last night, Joyce looked deep within her heart to ask, can I lend my good name to this cursed union?

The dumpster full of imported delphinium behind Joyce’s shop can tell you the answer.

You see, what we’re learning is that these are not just goods and services; they’re not simply the imprints of Keith’s Capital One card and the resulting exchange of goods. Every item at a wedding is nothing less than the avatar of its vendor’s entire belief system. With this in mind, each rose petal my niece Stephanie was prepared to hurl down the aisle might as well have been embossed with JOYCE GANTZ APPLAUDS THEE, SATAN.

What faith-engorged entrepreneur should face such hell?

This is why the rows of steam-trays in the tent are empty, and your choice of beef tenderloin or grilled salmon — or the one plate of tempeh veggie kabob, bless you, Amy! — will never arrive. Because Something Borrowed, Something Cordon Bleu, exceptional wedding caterers and unapologetic druids, could not bear the thought of providing nourishment to a couple willing to rip two thriving Magnolia trees from their backyard last summer. From their email: “Your heretic’s feast will be served when the earth heals from your violence.” By our best guess that wouldn’t have been by 6 p.m.

We also won’t be dancing to Renèe and the Ring-tones. While Rènee was a woman of few beliefs when we booked her, she has since converted to the Egyptian cult of Bastet, and considers the choice to put our cat Banjo to sleep, rather than pay $15,000 for experimental feline jaw surgery, to be “unforgivable wickedness, worthy of disciples of Set.”

I’ve been handed this note: Lane, our photographer, turns out to be more of a Star Wars guy and doesn’t feel right legitimizing such an obviously Star Trek couple.

Blessings on your journey, Lane.

In closing, our apologies. We were so busy coordinating our big day that we forgot to coordinate the sacred truths of all players involved. I’m told many of our vendors will adopt an exhaustive three-week interview process before each sale to keep this from happening again.

We did have a lovely wedding favor created for each of you, which we might as well distribute. It’s a wooden plaque, engraved with the phrase Love Conquers All, hand-crafted by our friend Bryce Charles in the front row. Now, Bryce is something of a Packers fan, and Keith is all about the Bears, but in the spirit of friendly rivalry, we’ve always managed to put aside our differ — wait.

Bryce’s feelings are changing.

They’re moving from loosely-held to nonchalantly-held. They’re not done; from the set of Bryce’s jaw, her feelings have transitioned to intentionally-held, and finally, they’re — yup. They’re strongly-held. Dammit.

Sorry, folks. You’re on your own.",https://cdn-images-1.medium.com/focal/1200/632/50/45/0*fh1vaEnMNoMbHE42,[],https://medium.com/s/story/our-wedding-is-cancelled-due-to-the-following-strongly-held-beliefs-1fa71105660e?source=grid_home---------0------------------18,

Data,My So-Called (Millennial) Entitlement – Trust Issues – Medium,['Stephanie Georgopulos'],"I am at the San Francisco International Airport some barely recent morning, registering for a travel program called Clear when the automated kiosk assisting me makes a strange request: “Stand still while we scan your irises.” I’ve barely digested this first ask when another takes its place: this time, the kiosk wants my fingerprints. I find this slightly less alarming; I already use those to access my banking app, buy coins for my mobile games, and unlock the phone that hosts all this information in the first place. But my eyeballs — which I had only just learned could be used as ID, and from a machine at the airport, no less — my dude. Those are the windows to my soul! Ever heard of foreplay?

Clear is a private company that prescreens air travelers using biometric authentication. Becoming a member is like ordering the half-soup, half-sandwich version of TSA PreCheck: it works, if all you want is a taste and are willing to pay for it. With Clear, you don’t need your ID to go through security, but you still have to remove your shoes. You get to wait in a shorter line (sometimes), but you still have to take out your laptop. Basically, the Cleared still participate in the most annoying aspects of air travel and pay almost 10 times the PreCheck fee for the privilege.

If the worst has already happened, that means it’s survivable.

How we decided on this valuation of convenience—it’s $179 per year—is not the point, though. My point is that some random startup casually acquired my eye-prints, and some small voice is telling me I should care more than I do. Someone out there definitely cares about this, no doubt. I’m sure at least one other traveler was not sated when a brisk Google search revealed that Clear is based in her hometown and run by a female CEO, ergo it must be a secure and entirely trustworthy business.

But I was sated. It’s the future, right? What’s the worst one could do with my retinal scans? I already gave my social security number to Camel in exchange for a pack of promotional cigarettes one time (or 12). Somewhere in Midtown Manhattan, a market-research firm knows how many condoms I used in May of 2011 (give or take). And when I think about the fact that every hard document I’ve reproduced on a digital copy machine — at work, at the bodega, at the library — is saved on a hard drive somewhere (lots of somewheres, in fact), I feel a sense of hopelessness that, in its own demented way, translates to freedom.

That’s why I unlock my phone with my fingerprint. It’s also why I talk shit in front of Alexa, why I haven’t put tape over my laptop camera, and why I still have a Facebook account. I don’t expect the worst to happen.

Because the worst has already happened. It is happening, and it will continue to happen.

I find this to be an honest, useful framework. If the worst has already happened, that means it’s survivable. And if the worst is a given in the future, too, we know that ignoring it won’t make it go away. There’s opportunity in having nothing to lose. You just need the right attitude.

Or perhaps you need the right conditioning.

Imagine: You’re 11 years old when two teenagers bring guns to their high school and kill 13 people. They injure 21 more. Your sixth-grade humanities teacher explains the inexplicable to your class after lunch period. You have to imagine that this is a first for at least some of your classmates, crying over the national news. It won’t be the last.

When you’re 15, two planes crash into two towers. You know the towers; had toured them on school trips just like all the other famous Manhattan buildings for which you know the names, if not the functions. In fact, you’d visited the towers just one week before the planes hit. There had been a renaissance fair in one of the lobbies.

At 17, your high school economics teacher tells you that social security will run out before you retire. You’ve already been paying taxes for three years. In 2018, you learn that he was exaggerating, thank goodness — by 2034, retirees can expect to receive a whopping 79% of the full benefit they receive today. You will not be of retirement age until the 2050s.

And when you’re 21, the market crashes. You’ve had a bachelor’s degree for three months. It cost $100,000 to earn, all before interest. Your class valedictorian moves back in with her parents, and no, your internship is not hiring. Five years later, the unemployment rate for people your age is almost double the national average.

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

Neuroscience has confirmed that you were making sense of these events with an underdeveloped brain. Along with your emotional maturity and your hormones, it’ll be a work-in-progress until you’re around 25. And the same way the small hurts of being small can still seep into your present — the way your grandmother eyed you with disgust when you went for a second helping — the chipping away of every institution you were raised to believe in can have unintended consequences.

Me: Do you use Touch ID to unlock your phone?

Friend: Ya.

Me: Do you know anything about the technology behind it? Or like, how secure it is?

A beat. A blank stare.

Friend: No?

Me: Same.

My friends do not need to understand the technology behind touch ID any more than they need to understand black holes. They are not convinced that adjusting their social media privacy settings is some sort of moral duty, a symbolic middle finger to Facebook on behalf of all the little guys who understand internet economics to varying degrees, or not at all. Mostly, they were confused as to why any thinking person would have an assumption of security.

“It’s not that I don’t care about being hacked, or about my data being stolen or sold,” one friend tells me. “I assume that vulnerability because there are no physical systems or structures that have succeeded, so why would something that is essentially invisible do a better job than something tangible?”

Millennials are known as entitled, but as a group, I don’t think we could have lower expectations.

I’ll go: I don’t expect to own a home. I don’t expect to retire well, or at all. I don’t expect anyone to give me anything I haven’t explicitly asked for, and even then. I don’t expect it will ever be affordable to continue my education in any formal way. If a package gets lost in the mail, I don’t expect to see it again. I don’t expect the government or the banks or the universities to do anything that benefits regular people. I don’t expect them to hold each other accountable on our behalf. I don’t expect them to expel abusers from their ranks, or to put my safety over their legacy. I don’t expect to feel safe in large crowds or alone late at night. And I don’t expect that my privacy will be respected, online or in general.

America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

As far as I can tell, security — whether financial, technological, physical, or emotional — is not a thing. You don’t get to decide whether some drunk asshole drinks his drunk ass off and gets behind the wheel. Likewise, you don’t get to decide if the drunk Congress or the drunk banker or all the drunk administrations of all the drunk institutions do what’s right for you. Sometimes they will do the right thing for somebody, but statistically speaking, that somebody is not you.

Sometimes the right thing comes served in a shit sandwich, or one guy does the right thing but it’s later counteracted by the next guy and just so we’re clear, it’s always a guy. Or sometimes, we learn that what we thought was the right thing was actually the wrong thing, in ways we didn’t anticipate, except for those of us who did anticipate it but were not asked or heard because we do not employ lobbyists and because the powers that be can’t listen to us until they sort out whether our bodies are legal or not.

Mark Zuckerberg’s Congressional hearing was probably the biggest mainstreaming of data privacy issues yet, and Facebook, with its many transgressions, made for an appropriate scapegoat. But I want to know why it’s Mark Zuckerberg’s fault that American adults of voting age lack the critical thinking skills to differentiate between fake Russian bot news and The Guardian. I want to know the plan for bringing internet literacy to those who are not digital natives. I want to know why the U.S. government is being celebrated for protecting our egos and baby-proofing the internet instead of telling us the truth: Dirty tricks are less likely to work on people with more education.

What happens when your brand of exceptionalism breeds millions of people who voted a sentient conspiracy theory into office? Where does the fault lie? After all, it’s not Facebook who’s spent decades underpaying teachers and closing schools in low-income neighborhoods. Facebook doesn’t have the jurisdiction to end standardized testing or combat the quiet continuation of white flight. Facebook’s biggest mistake? Profiting off of state-sanctioned dumbness.

We’re only supposed to be dumb enough to believe that the fight is red vs. blue and not top vs. bottom. We’re only supposed to be dumb enough to believe in Democracy the Concept™ without casting a critical eye toward its practical application. This is a dumbness cultivated by and for Washington, and Zuckerberg’s misusing of it for corporate gain almost blew the lid off the entire thing. Commence finger-wagging.

On an episode of his podcast Revisionist History, Malcolm Gladwell argues that we should treat education as a weak-link network, where strengthening the weakest links has the most positive outcome for all. This is in contrast to a strong-link network, where a couple of superstars at the top carry the weaker players on the bottom. He illustrates this dynamic using soccer and basketball. An average soccer team with one star player is less likely to win a match than an above-average team with no star players — soccer is a weak-link sport. Conversely, an NBA team with a superstar or two fares better than a team on which all the players are equally, decently good — basketball is a strong-link sport.

Much to its detriment, America acts like a strong-link country. It is the type of place where electing one mixed-race president means we solved racism. (Imagine if the lesson we took from electing one white man was that all white men who lack upward mobility just need to work harder.) We raise up a few undoubtedly smart and deserving people in each field, send them around the world like brand ambassadors for democracy, poster-adults for how advanced and distinguished and American we are. Meanwhile, most of us back home — 78%, in fact — are living paycheck to paycheck. Is that freedom ringing? We’ll call right back after we pay this phone bill.

These are complex problems. In addition to the 3000ish words here, I have written and cut an additional 4500 trying to make sense of it all. I remain overwhelmed by the number of solutions that contradict one another, the knowns and unknowns, the countless logical ends I haven’t considered. But I eventually found my demented silver lining: America only cares about what the superstars are up to. The rest of us, from the benches to the bleachers, are left to our own devices. And we can play whatever games we want.

While grim on its face, this perspective has pushed me to take inventory of myself, my own power. What can I do right now? Am I solving problems I actually care about, or were these problems unconsciously inherited from another time, problems propagated by those with a vested interest in resolving them with more money, more power, more loopholes? Should I devote my energy to righting a system that, by design, has only consistently benefited one demographic and has yet to even prove itself as a scalable model for a generation that’s tired of the same people making the same decisions on behalf of the most diverse country in the world?

Is that a problem? Because it feels more like an opportunity, to me: a chance to exercise this cache of personal agency I’ve been sitting on, agency I didn’t realize I had or needed as I waited for America to work. It feels like an opportunity to try something else.

More powerful than having nothing to lose is cultivating that which can’t be taken. Grace. Clarity. Purpose. The stuff that isn’t Amazon Prime-able. These are the indoor plants of our being; only you can feed them and grow them and expose them to the light. It’s a lot of responsibility, and the work involved is often unglamorous. Some people think they never have to learn to care for these things because they have the means to outsource what they wish: their plants are alive on paper though they don’t know the how or why of it. And besides, can’t you see they’re a little busy trying to colonize Mars?

A respectable goal, though I might suggest to anyone faced with the choice to try taking on the inner self before jumping ahead to outer space. There’s more to unearth in there than you might think, and we need more people to understand the potential of their own organic material. We need people who appreciate the slow growth of nothing into something, who drink up the sunlight and make the air a little more breathable than before.

Because that’s it, for most of us. That’s how we build power. That’s how we, a generation of janitors for the American dream, put our trust in something real: each other. We stop trying to control the world in our heads and in the headlines, and we start controlling ourselves. We sleep. We go to the doctor. We log off. We talk about our problems. We water our plants. We collect our neighbor’s mail when they’re out of town. We take a deep breath before reacting in anger, and question whether this particular battle is worth our energy. It’s not. Why were we fighting again? We volunteer. We water our plants. We focus on ourselves so we can eventually focus on others — in a real way, in a non-transactional way, in a way that slowly but authentically strengthens our fellow weak links. We don’t wait for permission. We get over ourselves; we stop demanding perfection; we start. We water our plants. And on weekends, we play soccer.",https://cdn-images-1.medium.com/max/1200/1*c5zNxCX34sYmYYO-yRxlbA.png,[],https://medium.com/s/trustissues/my-so-called-millennial-entitlement-9be84343c713?source=grid_home---------0------------------18,

Data,How to Cope with the End of the World – How to Cope With The End of The World – Medium,['Maria Farrell'],"We All Die, and That’s Okay

My favorite postapocalyptic novel is George R. Stewart’s 1951 Earth Abides. In it, scientist Isherwood Williams (nicknamed Ish) survives a plague and eventually starts a new family and community in the ruins of suburban California. His hope for the future is wholly invested in a child who is intellectually curious, like him, and who might be able to revive some of the old ways and technologies. It’s an observant and reflective novel, full of the “how stuff would probably work” thinking that makes science fiction the true literature of ideas.

Ish starts out as a scientist-savior of humanity, figuring there is just enough time to raise a generation to turn back the clock to before the disaster. But he ultimately has to make his peace with the fact that civilization as he knew it is dead, there will be no heroic rescue, no going back, and the people around him are mostly fine with that.

The 1950s may have been the last decade we could complacently believe the Ecclesiastes (1:4) maxim that “men come and go, but earth abides,” but Stewart’s basic message is correct.

The people who come after us don’t have to do better than us, or think well of us, for them to be essentially okay. And us all throwing a big “let’s blow it all up” hissy fit because we fucked up and we can’t bear to look at it is just teenage nihilism that we need to grow out of already. Coming to terms with what we have done means dumping the egotistical death drive of the mass shooter or far-right politician and gathering the maturity to look our individual and collective deaths straight in the eye and say, “Okay, we get it now. We get it. It’s not about us.”

Have you ever stood in a crowded place like a town square or an airport meet-and-greet and thought, “Every single person here is going to die”? Morbid, eh? More of us should do it.

I live in an early Victorian terraced house in the UK. It’s never been a tenement, so probably a hundred people have called it home in the almost two centuries it’s been standing. Nearly all of them are dead. The people are already born who’ll live there when I’m dead. The head of this country’s anachronistic state has already been born who I’ll never see on the throne and to whom I’ll seem as old as someone born in the 1930s seems to me.

We’re all going to die. The morning will come when those who have loved us put on dark clothes and cry and get on with the rest of their lives, seeing movies we’d have loved, depending on gadgets that now seem to us ridiculously unnecessary. Our deaths matter to us and those who love us, but they don’t fundamentally matter.

Once, while my husband was deployed to Afghanistan, I asked him on the phone if he was doing okay about someone we knew who’d recently been killed. “Oh, you know,” he said, “you know,” and quoted his regiment’s unofficial mantra:

Everything matters. Nothing matters terribly.

The soldier’s death mattered very, very much to him, and (not but) he and others were nonetheless carrying on their shared purpose. Otherwise, what had been the point of any of it?

What will outlive us, individually? Plastic. Perhaps some genes. The bacteria that act as a species-level enabler for everything we are. Some ideas, maybe, or songs, stories, pictures, the memories of us others hold, until they go, memorials like a community flower bed or a named scholarship, for a while, anyway. Less concretely: ways of being, a fitness for the world that those who flourish pass unremarked to their offspring via the epigenetics of love — the sunny inverse of patterns of trauma and abuse transmitted through the body, even unto the third generation. Predation.

And our species? Buildings and bones, maybe. Our nuclear waste and the warning signs we hope people of our deep future, or other species altogether, will decrypt. Snatches of radio-transmitted voices slipping through the vacuum of space. Perhaps some bacterial payload we’ll launch in a decade or so, trying to seed life on other planets, even in other solar systems. Or just the anomalous levels of carbon dioxide and methane in our atmosphere that will reveal, for a time, that complex forms of life were here.

Pride and despair are two sides of the same coin. Our collective denial and despair about the future we have built is preventing us from cracking on and sorting it out. We need to get over ourselves. The world we know will end, in both small and big ways. We ourselves will end. But that doesn’t matter, terribly.

Our mortality is the greatest enabler we have of positive, ongoing change, if only we can face it, if only we can understand that we don’t get to see the end of the movie, because, if what we do works, the movie won’t have to end. We’re not the protagonists. We’re just the foreshadowing. We need to hold the knowledge of our own deaths up to the light and turn it around to see each shining facet, then take the certainty that we are both finite and imperfect deep down inside of us—and put it to work.",https://cdn-images-1.medium.com/max/1200/0*avXWZmh3n3H7a8t8,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world/how-to-cope-with-the-end-of-the-world-2520ef9d3dbc?source=grid_home---------0------------------18,

Data,How to Cope With The End of The World – Medium,['Maria Farrell'],"COLUMN

How to Cope With The End of The World

There are moments of joy even in times of great despair. Maria Farrell explains how to deal with a darkening world, and how to plan for the end. It might be the end of the world as we know it, but it turns out we feel fine.",https://cdn-images-1.medium.com/max/1200/1*kvqwUuDCsbkAoSfaYXV1vQ@2x.png,[],https://medium.com/s/how-to-cope-with-the-end-of-the-world,

Data,Chatbots were the next big thing: what happened? – The Startup – Medium,"['Matt Asay', 'Justin Lee']","Chatbots were the next big thing: what happened?

Oh, how the headlines blared:

“…the 2016 bot paradigm shift is going to be far more disruptive and interesting than the last decade’s move from Web to mobile apps.”

Chatbots were The Next Big Thing.

Our hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.

And why wouldn’t they be? All the road signs pointed towards insane success.

Messaging was huge! Conversational marketing was a sizzling new buzzword! WeChat! China!

Plus, it was becoming clear that supply massively exceeded demand when it came to those pesky, hard-to-build apps.

At the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.

In fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:

“Will a single platform emerge to dominate the chatbot and personal assistant ecosystem?”

One year on, we have an answer to that question.

No.

Because there isn’t even an ecosystem for a platform to dominate.

Fooled by another hype cycle

Chatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.

The age-old hype cycle unfolded in familiar fashion…

Reverential TechCrunch articles were written.

Prophetic thought leaders like Chris Messina chimed in.

Silicon Valley salivated at the prospect of talking to smart automation.

Messenger began to overflow with bots.

Slack went through exponential growth and even launched a fund for bot investment.

Expectations built, built, and then….. It all kind of fizzled out.

The predicted paradim shift didn’t materialize.

And apps are, tellingly, still alive and well.

We look back at our breathless optimism and turn to each other, slightly baffled:

“is that it? THAT was the chatbot revolution we were promised?”

Digit’s Ethan Bloch sums up the general consensus:

“I’m not even sure if we can say ‘chatbots are dead,’ because I don’t even know if they were ever alive.”

According to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.

Text vs. Speech vs. GUI: a potted history

Bots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.

Users had to type commands manually into a machine to get anything done.

Then, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!

Meanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.

Another bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:

… so many different accents, people speaking too fast or too slowly, mumbling, umming and aahing.

Did you say “recognise speech” or “wreck a nice beach”?

The next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:

User: “Hello.”

Agent: “Hello, what’s your name?”

User: “Candy.”

Agent: “Hello, Candy!”

User: “Let’s set the clock.”

Agent: “What is the time?”

User: “The time is 11:00 AM.”

Agent sets the clock to 11:00 AM.

Pretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.

It was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.

Modern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.

Basically, we’re still trying to achieve the same innovations we were 30 years ago.

Here’s where I think we’re going wrong:

Thinking in terms of Bots vs. Apps

An oversized assumption has been that apps are ‘over’, and would be replaced by bots.

By pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.

You might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?

It’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.

Whether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.

Plus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.

A great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.

That’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.

Modern-day apps benefit from decades of research and experimentation. Why would we throw this away?

But, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.

Today’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.

Penny provides chatty advice and alerts alongside a traditional account dashboard and transaction list.

HubSpot Conversations unifies Facebook Messenger, onsite chat, social media, email and other messaging outlets into one shared inbox.

Layer gives developers the tools to create personalized messaging experiences on mobile web and desktop web as well as native apps.

The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.

Bots for the sake of bots

Does my product need a bot? Are existing platforms able to support its functionality? Do I have the patience to build a bot that’s capable of doing what I want it to?

Another problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.

For plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.

Building a bot for the sake of it, letting it loose and hoping for the best will never end well:

The totally necessary Maroon 5 chatbot in action

The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.

The advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.

That’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.

Problems arise when life refuses to fit into those boxes.

According to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.

When we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.

Remember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.

Inaccessibility

A competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.

In an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.

Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)

As Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.

“Consumer interest was never going to materialize until machine intelligence could get anywhere near human intelligence.

User interest depends upon AI that makes talking with a bot worthwhile for consumers.”

And conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.

Today’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.

And in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:

“Should Slack, Facebook, Google, Microsoft, Kik, and others have built their own built-in bots to lead the way?

Should they have gotten more proactive with their bot funds and incubators, hiring mentors to educate participants in the Way of the Bot, or supplying engineering and design resources? Funded Strategic Bot Initiatives at high-profile partners?

In my opinion yes, yes, and yes. When it comes to platforms, developers are the users; and we don’t rely on our users to understand why or how to use our products. We have to show them.”

GUI shouldn’t be dismissed

Once upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information

There’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.

Tapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.

We love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.

Conversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.

Sure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.

Humans like talking to other humans

Aiming for a human dimension in business interactions makes sense.

If there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.

Facebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.

A conversation encompasses so much more than just text.

Humans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.

As HubSpot team pinpointed:

Bots provide a scalable way to interact one-on-one with buyers. Yet, they fail when they don’t deliver an experience as efficient and delightful as the complex, multi-layered conversations people are accustomed to having with other humans on messaging apps.

People aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).

And even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.

And here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.

But is that how humans prefer to interact with machines?

Not necessarily.

At the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.

Where do we go from here?

In a way, those early-adopters weren’t entirely wrong.

People are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.

Not even close.

Computers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.

Computers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.

That’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.

For now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.

But that’s not the whole story.

Yes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.

As Bill Gates once said:

We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten. Don’t let yourself be lulled into inaction.

The hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.

I believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.

Messaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.

Developers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.

And I can’t wait to see what happens next.",https://cdn-images-1.medium.com/max/1200/1*-_um8Nai0uer46tni1LETg.jpeg,[],https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=topic_page---8------0----------------,2018-06-05 15:55:36.912000+00:00

Data,Google’s AutoML will change how businesses use Machine Learning,['George Seif'],"Google’s AutoML will change how businesses use Machine Learning

Google’s AutoML is a new up-and-coming (alpha stage) cloud software suite of Machine Learning tools. It’s based on Google’s state-of-the-art research in image recognition called Neural Architecture Search (NAS). NAS is basically an algorithm that, given your specific dataset, searches for the most optimal neural network to perform a certain task on that dataset. AutoML is then a suite of machine learning tools that will allow one to easily train high-performance deep networks, without requiring the user to have any knowledge of deep learning or AI; all you need is labelled data! Google will use NAS to then find the best network for your specific dataset and task. They’ve already shown how their methods can achieve performance that is far better than that of hand-designed networks.

AutoML totally changes the whole machine learning game because for many applications, specialised skills and knowledge won’t be required. Many companies only need deep networks to do simpler tasks, such as image classification. At that point they don’t need to hire 5 machine learning PhDs; they just need someone who can handle moving around and organising their data.

There’s no doubt that this shift in how “AI” can be used by businesses will create change. But what kind of change are we looking at? Whom will this change benefit? And what will happen to all of the people jumping into the machine learning field? In this post, we’re going to breakdown what Google’s AutoML, and in general the shift towards Software 2.0, means for both businesses and developers in the machine learning field.

More development, less research for businesses

A lot of businesses in the AI space, especially start-ups, are doing relatively simple things in the context of deep learning. Most of their value is coming from their final put-together product. For example, most computer vision start-ups are using some kind of image classification network, which will actually be AutoML’s first tool in the suite. In fact, Google’s NASNet, which achieves the current state-of-the-art in image classification is already publicly available in TensorFlow! Businesses can now skip over this complex experimental-research part of the product pipeline and just use transfer learning for their task. Because there is less experimental-research, more business resources can be spent on product design, development, and the all important data.

Speaking of which…

It becomes more about product

Connecting from the first point, since more time is being spent on product design and development, companies will have faster product iteration. The main value of the company will become less about how great and cutting edge their research is and more about how well their product/technology is engineered. Is it well designed? Easy to use? Is their data pipeline set up in such a way that they can quickly and easily improve their models? These will be the new key questions for optimising their products and being able to iterate faster than their competition. Cutting edge research will also become less of a main driver of increasing the technology’s performance.

Now it’s more like…

Data and resources become critical

Now that research is a less significant part of the equation, how can companies stand out? How do you get ahead of the competition? Of course sales, marketing, and as we just discussed, product design are all very important. But the huge driver of the performance of these deep learning technologies is your data and resources. The more clean and diverse yet task-targeted data you have (i.e both quality and quantity), the more you can improve your models using software tools like AutoML. That means lots of resources for the acquisition and handling of data. All of this partially signifies us moving away from the nitty-gritty of writing tons of code.

It becomes more of…

Software 2.0: Deep learning becomes another tool in the toolbox for most

All you have to do to use Google’s AutoML is upload your labelled data and boom, you’re all set! For people who aren’t super deep (ha ha, pun) into the field, and just want to leverage the power of the technology, this is big. The application of deep learning becomes more accessible. There’s less coding, more using the tool suite. In fact, for most people, deep learning because just another tool in their toolbox. Andrej Karpathy wrote a great article on Software 2.0 and how we’re shifting from writing lots of code to more design and using tools, then letting AI do the rest.

But, considering all of this…

There’s still room for creative science and research

Even though we have these easy-to-use tools, the journey doesn’t just end! When cars were invented, we didn’t just stop making them better even though now they’re quite easy to use. And there’s still many improvements that can be made to improve current AI technologies. AI still isn’t very creative, nor can it reason, or handle complex tasks. It has the crutch of needing a ton of labelled data, which is both expensive and time consuming to acquire. Training still takes a long time to achieve top accuracy. The performance of deep learning models is good for some simple tasks, like classification, but does only fairly well, sometimes even poorly (depending on task complexity), on things like localisation. We don’t yet even fully understand deep networks internally.

All of these things present opportunities for science and research, and in particular for advancing the current AI technologies. On the business side of things, some companies, especially the tech giants (like Google, Microsoft, Facebook, Apple, Amazon) will need to innovate past current tools through science and research in order to compete. All of them can get lots of data and resources, design awesome products, do lots of sales and marketing etc. They could really use something more to set them apart, and that can come from cutting edge innovation.

That leaves us with a final question…

Is all of this good or bad?

Overall, I think this shift in how we create our AI technologies is a good thing. Most businesses will leverage existing machine learning tools, rather than create new ones since they don’t have a need for it. Near-cutting-edge AI becomes accessible to many people, and that means better technologies for all. AI is also quite an “open” field, with major figures like Andrew Ng creating very popular courses to teach people about this important new technology. Making things more accessible helps people transition with the fast-paced tech field.

Such a shift has happened many times before. Programming computers started with assembly level coding! We later moved on to things like C. Many people today consider C too complicated so they use C++. Much of the time, we don’t even need something as complex as C++, so we just use the super high level languages of Python or R! We use the tool that is most appropriate at hand. If you don’t need something super low-level, then you don’t have to use it (e.g C code optimisation, R&D of deep networks from scratch), and can simply use something more high-level and built-in (e.g Python, transfer learning, AI tools).

At the same time, continued efforts in the science and research of AI technologies is critical. We can definitely add tremendous value to the world by engineering new AI-based products. But there comes a point where new science is needed to move forward. Human creativity will always be valuable.

Conclusion

Thanks for reading! I hope you enjoyed this post and learned something new and useful about the current trend in AI technology! This is a partially opinionated piece, so I’d love to hear any responses you may have below!",https://cdn-images-1.medium.com/max/1200/1*g9BzirXxUauRO9rA_tSvnA.jpeg,[],https://towardsdatascience.com/googles-automl-will-change-how-businesses-use-machine-learning-c7d72257aba9?source=topic_page---8------1----------------,2018-05-14 14:27:41.145000+00:00

Data,Automated Feature Engineering in Python – Towards Data Science,['William Koehrsen'],"First, let’s take a look at our example data. We already saw some of the dataset above, and the complete collection of tables is as follows:

Deep feature synthesis stacks multiple transformation and aggregation operations (which are called feature primitives in the vocab of featuretools) to create features from data spread across many tables. Like most ideas in machine learning, it’s a complex method built on a foundation of simple concepts. By learning one building block at a time, we can form a good understanding of this powerful method.

Fortunately, featuretools is exactly the solution we are looking for. This open-source Python library will automatically create many features from a set of related tables. Featuretools is based on a method known as “ Deep Feature Synthesis ”, which sounds a lot more imposing than it actually is (the name comes from stacking multiple features not because it uses deep learning!).

These operations are not difficult by themselves, but if we have hundreds of variables spread across dozens of tables, this process is not feasible to do by hand. Ideally, we want a solution that can automatically perform transformations and aggregations across multiple tables and combine the resulting data into a single table. Although Pandas is a great resource, there’s only so much data manipulation we want to do by hand! (For more on manual feature engineering check out the excellent Python Data Science Handbook ).

This process involves grouping the loans table by the client, calculating the aggregations, and then merging the resulting data into the client data. Here’s how we would do that in Python using the language of Pandas .

On the other hand, aggregations are performed across tables, and use a one-to-many relationship to group observations and then calculate statistics. For example, if we have another table with information on the loans of clients, where each client may have multiple loans, we can calculate statistics such as the average, maximum, and minimum of loans for each client.

we can create features by finding the month of the joined column or taking the natural log of the income column. These are both transformations because they use information from only one table.

A transformation acts on a single table (thinking in terms of Python, a table is just a Pandas DataFrame ) by creating new features out of one or more of the existing columns. As an example, if we have the table of clients below

The process of constructing features is very time-consuming because each new feature usually requires several steps to build, especially when using information from more than one table. We can group the operations of feature creation into two categories: transformations and aggregations . Let’s look at a few examples to see these concepts in action.

Feature engineering means building additional features out of existing data which is often spread across multiple related tables. Feature engineering requires extracting the relevant information from the data and getting it into a single table which can then be used to train a machine learning model.

If we have a machine learning task, such as predicting whether a client will repay a future loan, we will want to combine all the information about clients into a single table. The tables are related (through the client_id and the loan_id variables) and we could use a series of transformations and aggregations to do this process by hand. However, we will shortly see that we can instead use featuretools to automate the process.

Entities and EntitySets

The first two concepts of featuretools are entities and entitysets. An entity is simply a table (or a DataFrame if you think in Pandas). An EntitySet is a collection of tables and the relationships between them. Think of an entityset as just another Python data structure, with its own methods and attributes.

We can create an empty entityset in featuretools using the following:

import featuretools as ft

# Create new entityset

es = ft.EntitySet(id = 'clients')

Now we have to add entities. Each entity must have an index, which is a column with all unique elements. That is, each value in the index must appear in the table only once. The index in the clients dataframe is the client_id because each client has only one row in this dataframe. We add an entity with an existing index to an entityset using the following syntax:

The loans dataframe also has a unique index, loan_id and the syntax to add this to the entityset is the same as for clients . However, for the payments dataframe, there is no unique index. When we add this entity to the entityset, we need to pass in the parameter make_index = True and specify the name of the index. Also, although featuretools will automatically infer the data type of each column in an entity, we can override this by passing in a dictionary of column types to the parameter variable_types .

For this dataframe, even though missed is an integer, this is not a numeric variable since it can only take on 2 discrete values, so we tell featuretools to treat is as a categorical variable. After adding the dataframes to the entityset, we inspect any of them:

The column types have been correctly inferred with the modification we specified. Next, we need to specify how the tables in the entityset are related.

Table Relationships

The best way to think of a relationship between two tables is the analogy of parent to child. This is a one-to-many relationship: each parent can have multiple children. In the realm of tables, a parent table has one row for every parent, but the child table may have multiple rows corresponding to multiple children of the same parent.

For example, in our dataset, the clients dataframe is a parent of the loans dataframe. Each client has only one row in clients but may have multiple rows in loans . Likewise, loans is the parent of payments because each loan will have multiple payments. The parents are linked to their children by a shared variable. When we perform aggregations, we group the child table by the parent variable and calculate statistics across the children of each parent.

To formalize a relationship in featuretools, we only need to specify the variable that links two tables together. The clients and the loans table are linked via the client_id variable and loans and payments are linked with the loan_id . The syntax for creating a relationship and adding it to the entityset are shown below:

The entityset now contains the three entities (tables) and the relationships that link these entities together. After adding entities and formalizing relationships, our entityset is complete and we are ready to make features.

Feature Primitives

Before we can quite get to deep feature synthesis, we need to understand feature primitives. We already know what these are, but we have just been calling them by different names! These are simply the basic operations that we use to form new features:

Aggregations: operations completed across a parent-to-child (one-to-many) relationship that group by the parent and calculate stats for the children. An example is grouping the loan table by the client_id and finding the maximum loan amount for each client.

table by the and finding the maximum loan amount for each client. Transformations: operations done on a single table to one or more columns. An example is taking the difference between two columns in one table or taking the absolute value of a column.

New features are created in featuretools using these primitives either by themselves or stacking multiple primitives. Below is a list of some of the feature primitives in featuretools (we can also define custom primitives):

Feature Primitives

These primitives can be used by themselves or combined to create features. To make features with specified primitives we use the ft.dfs function (standing for deep feature synthesis). We pass in the entityset , the target_entity , which is the table where we want to add the features, the selected trans_primitives (transformations), and agg_primitives (aggregations):

The result is a dataframe of new features for each client (because we made clients the target_entity ). For example, we have the month each client joined which is a transformation feature primitive:

We also have a number of aggregation primitives such as the average payment amounts for each client:

Even though we specified only a few feature primitives, featuretools created many new features by combining and stacking these primitives.

The complete dataframe has 793 columns of new features!

Deep Feature Synthesis

We now have all the pieces in place to understand deep feature synthesis (dfs). In fact, we already performed dfs in the previous function call! A deep feature is simply a feature made of stacking multiple primitives and dfs is the name of process that makes these features. The depth of a deep feature is the number of primitives required to make the feature.

For example, the MEAN(payments.payment_amount) column is a deep feature with a depth of 1 because it was created using a single aggregation. A feature with a depth of two is LAST(loans(MEAN(payments.payment_amount)) This is made by stacking two aggregations: LAST (most recent) on top of MEAN. This represents the average payment size of the most recent loan for each client.

We can stack features to any depth we want, but in practice, I have never gone beyond a depth of 2. After this point, the features are difficult to interpret, but I encourage anyone interested to try “going deeper”.",https://cdn-images-1.medium.com/max/1200/1*lg3OxWVYDsJFN-snBY7M5w.jpeg,[],https://towardsdatascience.com/automated-feature-engineering-in-python-99baf11cc219?source=topic_page---8------2----------------,2018-06-02 15:01:18.755000+00:00

Data,My Phone Wants Me to Say ‘Thank You’ – When Robots Rule The World – Medium,['Evan Selinger'],"Sincerely Thankful

Perhaps there’s something infantilizing about our phones “wanting” us to say thanks. It’s hard to draw a firm line between what you would say if only you put in the time to say it versus what you do say after predictive software fills in the blanks. Seeing suggestions is itself a suggestive situation. And so, while Google emphasizes that smart reply is intelligent enough to figure out if you’re more of a “thanks!” than a “thanks.” person, the fact remains that it’s a good bet that some variation of the word will be frequently presented to you.

If being offered a “thanks” seems familiar, it’s because the act resembles what parents do when they try to instill etiquette. Let’s imagine that Lil’ Johnny receives a gift and instinctively wants to run off and play with it. Before this happens, one of his parents admonishes, “Johnny, what do you say?” And so, robotically, Johnny responds, “Thank you.”

At the time of being coached, Lil’ Johnny doesn’t mean what he parrots back. The gesture is insincere, and Johnny offers it to avoid conflict that would further delay what he really wants to do. That’s okay, though. The hope is that, over time, Lil’ Johnny becomes Big Johnny, the type of person who can genuinely experience gratitude and doesn’t simply follow rules like an automaton. The parental admonitions made during childhood are supposed to be like a pair of moral training wheels that kids ultimately outgrow.

Software like smart reply isn’t designed to provide adults with a second round of moral education. But if we mindlessly use such tools on a regular basis so we can quickly move on to do other things—things that we actually care about—our gestures will merely take the form of gratitude while lacking the underlying substance.

True gratitude must be sincere.

To be truly grateful, you have to mean what you say — that is, you must recognize that someone did something for you that deserves to be acknowledged, and you must sincerely want to make the acknowledgment.

Graciousness is a virtue. If an adult passes off insincere gratitude as the sincere variety in situations where people reasonably expect a person’s words and beliefs to align, the person is behaving worse than Lil’ Johnny. Lil’ Johnny is trying to be compliant, not deceptive.

We also shouldn’t lose sight of the fact that people who in engage in rituals like keeping gratitude journals aim to be specific when offering their appreciation. They don’t just say “thanks” or use any of the other minimalist formulations that smart reply offers. Instead, people who are pursuing lives filled with intentionality are concrete about what they are grateful for, as well as why they’re grateful for it. They want to focus on what they have rather than despair or obsesses over what they lack.",https://cdn-images-1.medium.com/focal/1200/632/51/50/1*MpyyWHuRUnanCenqeG3sHA.jpeg,[],https://medium.com/s/when-robots-rule-the-world/my-phone-wants-me-to-say-thank-you-122cc15952a9?source=topic_page---8------3----------------,

Data,"In 2018, Numbers Lie and Fictions Paint Truth – Eve Weinberg – Medium",['Eve Weinberg'],"In 2018, Numbers Lie and Fictions Paint Truth Why storytelling is our best tool in disambiguating fact from fiction

I’d love to share a few of the lecturers who touched upon this topic and forever changed my understanding of the 2018 landscape of fact, fiction, and storytelling’s role in deciphering one from the other.

This summer, I had the great privilege of attending EyeO (June 3–8 2018). Innumerable topics that encompass the intersection of Art, Technology, and Data were covered, but one common thread has left an imprint on my brain. That is: the Sisyphean 21st century task of disambiguating fact from fiction. That’s right…

PART 1: NUMBERS ARE MALLEABLE

On the first day, we discussed climate science at length. We (a very self aware room of liberal, number-crunching, data-visualization-making, coastal-living, self-ascribed nerds) attempted to break down the problems with human psychology. We looked at the facts, stats, charts, and graphs; then investigated the human power of denial, dissonance, disincentivization, and the hurdles of behavioral change. After 6 hours of discussion, ideation, and reflection, feeling a bit helpless, we ended with questions that I kept with me throughout the next 3 days of lectures:

Why don’t people believe statistics?

Are stories more powerful than numbers?

Why is denial more powerful than behavioral change?

Why do lies travel faster than truth?

…And what should we do about this?

The next day, Amanda Cox enlightened us with her talk These Lines Are The Same. She showed us that data, even in simple bar graphs, can be misinterpreted depending on the viewer’s own bias. She bravely revealed to us that in her department The Upshot at The New York Times they struggle with how to best represent datasets objectively. They experiment in meaningful and educational ways. In one example she showed data from the US unemployment report. The article allows readers to look at the chart with ‘Democratic Goggles’ and ‘Republican Goggles.’

The numbers are the same, but they can easily be bent to the will of anyone with an agenda.

Then she humorously showed us our flaws in clinging to round numbers. She drove the point home with a series of charts, one here showing the likelihood that someone in the ER gets checked for a heart attack, according to their age. As Amanda points out, “nothing radical changes from the age of 39-and-three-quarters and 40, yet here is the data:",https://cdn-images-1.medium.com/max/1200/1*bJ58aYiSmkeNYJY73AQN3w.jpeg,[],https://medium.com/@evejweinberg/in-2018-numbers-lie-and-fictions-paint-truth-ea1f5cdc9abe?source=topic_page---8------0----------------,2018-06-08 22:01:41.763000+00:00

Data,The Art of Ethereal: Bringing Cellarius to Life – Genesis Thought – Medium,['Mally Anderson'],"The Art of Ethereal: Bringing Cellarius to Life

Whose future is it? Hers, and his, and theirs, and ours.

A sampling of the Cellarius faction portraits from our Ethereal Summit pop-up.

On May 11 and 12, our parent company ConsenSys hosted the third Ethereal Summit at the Knockdown Center in Queens, New York and invited Cellarius to participate, along with many other spokes from our Mesh. The creators of Ethereal wanted to build a different kind of crypto conference. Since this one explored the intersection of blockchain and the arts, we wanted to showcase that aspect of our project and spread the word in an unexpected way. We set up shop in “The Crypt,” a semi-outdoor concrete space with a distinctive patina that felt perfect for the Cellarius blockpunk aesthetic.

The Knockdown Center’s very blockpunk Crypt space. We displayed some not-yet-published art commissions.

We teamed with some artists from a group called Drawn Together NYC: Boris Rasin, Michael Scarola, Derrick Dent, and Rosalind Bunting. Drawn Together’s talented roster of artists creates design concepts, multimedia experiences, and fine art solutions for a wide range of projects and businesses, and they understood what we are going for right away.

The artists of Drawn Together NYC, from left to right: Boris Rasin, Rosalind Bunting, Derrick Dent, and Michael Scarola.

Boris, Michael, and Derrick created custom, in-universe faction portraits of Ethereal attendees. The CX Universe Guide imagines that nation-states and traditional economies will break down after the Cellarius AI seizes control of Earth’s energy sources and communication channels in 2084. In the absence of familiar institutions and technologies, people will begin to form factions according to their allegiance to Cellarius. We wanted to get attendees thinking about their own relationships to technology and start dreaming up characters to explore in the Cellarius universe. So we posed the question: which faction do you think you would be?

Boris drew background art for four different factions:

The 4 faction backgrounds, clockwise from top left: Bucolic, Elite, Ad-Hoc, Homotranscendus.

Bucolic: Bucolics are AI skeptics who reject technology and live on the peripheries of megacities, observing from the outside and farming small pockets of fertile soil. Though their process is completely manual and their harvests are meager, they feel a great satisfaction from working with their own hands, in stark contrast to the highly automated farming processes elsewhere.

Ad-Hoc: Ad-Hocs live off the Cellarius grid and make their own augmentations and tools with scrap pieces they scavenge and rework. Comprised of mostly poor and marginalized groups, they use ingenuity and what little tech they can access to get by.

Elite: The crypto-Elites of the future are pro-Cellarius and experiment with AI and aesthetic enhancements. Living in the highest levels of the megacities, Elites have access to bleeding-edge technology. They are known for having lifespans beyond the normal range of humans, and enjoy the neural boost that comes with AI coupling.

Homotranscendus: During the Reformation, it wasn’t just the home habitat that was transformed forever, but also humankind itself. The campaign was more than just re-imagining the economic machinery of the planet Earth, but also a re-imagining of the of the human brain and body. Through Cellarius-engineered advancements, the next evolution of humanity was born: Homotranscendus. Homotranscendi are fully integrated with AI and no longer depend on their human forms to express consciousness and gather information.

We even got a portrait of ConsenSys’s own Joe Lubin, who wore a custom Cellarius Ethereal t-shirt design during his keynote address (thanks, Joe!). Something tells us that Joe would be a Homotranscendus.

Future Homotranscendus Joe Lubin on Mars.

Reimagining how familiar scenarios from your own life play out in a future setting or speculating about how you might react to a superintelligent AI’s takeover of the world is a great place to start inventing your own ideas in the world of Cellarius. We hope some attendees will be inspired to start making art and stories based on their portraits!

Every single Ethereal portrait, as arranged by our designer, Octavian.

As we’ve mentioned in previous posts, we are also commissioning works from artists we admire to create the first round of content for the Cellarius universe. We decided to commission a mural that would take shape over the two days of the Summit and give attendees a behind-the-scenes look at the process of making a large-scale landscape painting. The design depicts what the Knockdown Center might look like a century from now, in 2118. Visitors to the Crypt got a chance to watch Rosalind transform the canvas from a faint pencil sketch into an impressive and detailed final product:

Rosalind’s “Knockdown Center in 2118” painting took shape over two days.

Rosalind & Boris outlined the sketch first, then Rosalind added color, starting with the future-NYC background.

We hope that the Cellarius platform will allow experienced artists and creators to get directly in touch with their fan bases and share some glimpses of their artistic process, just as Rosalind did with her live painting.

The Drawn Together NYC artists got to learn more about the possibilities of blockchain and decentralization for creatives in the process of chatting with the attendees. Michael noted, “There were so many passionate and interesting people from all over the world that came through. And they had as much fun as we did learning about and playing in the Cellarius world.” Rosalind agreed: “Probably my favorite thing I learnt about over the Summit was how Cellarius involves the creative talents of so many more artists in their company, and loved seeing some of their amazing artwork. Can’t wait to see more!”

We were also excited that the long-term goals of the Cellarius project resonated with the Drawn Together NYC artists. Derrick said, “This was probably the coolest on-site portrait job I’ve ever worked on. I had a great time learning about the Cellarius project and the potential for a sprawling, community-shaped open sci-fi world. It was even cooler to have our portrait work used as an onboarding tool for visitors. People immediately took to creating their own story within this world, and that says a lot about how exciting this could be for folks who are creatively inclined.” We couldn’t have said it better ourselves.

As Boris told us, “The more I spoke to the pop-up team and event attendees about the concept behind this project, the more it occurred to me that this is a game changer. Cellarius and the other projects from ConsenSys are sure to revolutionize our ecosystem in ways we can’t even begin to comprehend. It’s a challenge to explain exactly what this project is, because the underlying platform allows for limitless opportunities of invention, inspiration, and collaboration. Cellarius is whatever its contributors will it to be, and frankly, that’s a fundamentally crazy idea!”

That’s just the point: blockchain enthusiasts can become artists and use storytelling to push the conceptual limits of technology. Artists can use the platform to explore the possibilities of decentralization and blockchain for sharing and protecting their work. We can build it together. Cellarius is whatever our community of contributors wills it to be.",https://cdn-images-1.medium.com/max/1200/1*vL8856P7cdV84CYM_SkF0A.jpeg,[],https://medium.com/genesis-thought/the-art-of-ethereal-bringing-cellarius-to-life-ba4ae31811e7?source=topic_page---8------1----------------,2018-06-08 16:46:47.896000+00:00

Data,A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what…,['Rowan Trollope'],"A recent post on ycombinator titled “Chatbots were supposed to be the next “big thing”: what happened?” Has gotten some fun responses.

The most popular comment being one that says “not surprised, this was never going to be a big thing”…

The first thing to point out is that people are conflating the specific of a chatbot with the generic “conversational user interface” (CUI) of which a chatbot is a specific modality. The real discussion here is about the CUI.

And the last month has certainly showed us that the CUI has made dramatic strides with Google demonstrating Duplex.

So what happened to the explosion of chatbots people predicted?

Among other things, Developers figured out just how hard it is to make a really good conversational user interface. Product folks were tricked by the trio of Alexa/Siri/Google Assistant into the belief that a conversational interface is easy.

Turns out it’s really hard, requires a ton of data and is highly domain specific.

In other words, training a CUI to be really great at getting sports scores doesn’t translate at all to a chatbot that can help you with a billing problem or ordering a pizza.

Google was careful to point out that Duplex was trained for only two very specific use cases : book a salon or a restaurant appointment.

Tim Tuttle at Mindmeld figured this out and built a company to solve it, but it still required heavy lifting and tons of data specific to the domain.

My belief is that the conversational interface is inevitable.

Technology evolution is exponential not linear. Our tendency is to project the future in a linear fashion, which causes us to overestimate what’s possible in 1 year and underestimate what’s possible in 10 years.

This makes tech progress feel gradual or slow, and then sudden and surprising.

Last week Salesforce’s chief scientist, Richard Socher, spoke publicly about the future of chatbots and asserted that in 5 years we would begin to see this start to pay off.

We are early days on the conversational interface, but as with all tech progress most folks will be disappointed until one year, 5–10 years from now when they’ll be shocked and amazed and wonder how it happened so fast.",https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico,[],https://medium.com/@rowantrollope/chatbots-were-supposed-to-be-the-next-big-thing-what-happened-5a4e416308e1?source=topic_page---8------2----------------,2018-06-08 21:06:45.446000+00:00

Data,"Beethoven, Picasso, and Artificial Intelligence – Towards Data Science",['Chris Kalahiki'],"Beethoven, Picasso, and Artificial Intelligence

Introduction

When people think of the greatest artists who’ve ever lived, they probably think of names like Beethoven or Picasso. No one would ever think of a computer as a great artist. But what if one day, that was indeed the case. Could computers learn to create incredible drawings like the Mona Lisa? Perhaps one day a robot will be capable of composing the next great symphony. Some experts believe this to be the case. In fact, some of the greatest minds in artificial intelligence are diligently working to develop programs that can create drawing and music independently from humans. The use of artificial intelligence in the field of art has even been picked up by tech giants the likes of Google.

The projects that are included in this paper could have drastic implications in our everyday lives. They may also change the way we view art. They also showcase the incredible advancement that has been made in the field of artificial intelligence. Image recognition is not as far as the research goes. Nor is the ability to generate music in the styling of the great artists of our past. Although these topics will be touched upon, we will focus on several more advanced achievements such as text descriptions being turned into images and generating art and music that is totally original. Each of these projects bring something new and innovative to the table and show us exactly how the art space is a great place to further explore applications of artificial intelligence. We will be discussing problems that have been faced in these projects and how they have been overcome. The future of AI looks bright. Let’s look at what the future may hold. In doing this, we may be able to better understand the impact that artificial intelligence can have in an area that is driven by human creativity.

GAN and Its Evolved Forms

Machines must be educated. They learn from instruction. How do we lead machines away from emulating what already exists, and have them create new techniques? “No creative artist will create art today that tries to emulate the Baroque or Impressionist style, or any other traditional style, unless trying to do so ironically” [4]. This problem isn’t limited to paintings either. Music can be very structured in some respects, but is also a form of art that requires vast creativity. So how do we go about solving such a problem? The first concept we will discuss is something called GAN (Generative Adversarial Networks). GANs, although quite complex, are becoming an outdated model. If artificial intelligence in the art space is to advance, researchers and developers will have to work to find better methods to allow machines to generate art and music. Two of these such methods are presented in the form of Sketch-RNN and CAN (Creative Adversarial Networks). Each of these methods have their advantages over GANs.

First, let’s explore what exactly a GAN is. Below is a small excerpt explaining how a GAN works:

Generative Adversarial Network (GAN) has two sub networks, a generator and a discriminator. The discriminator has access to a set of images (training images). The discriminator tries to discriminate between “real” images (from the training set) and “fake” images generated by the generator. The generator tries to generate images similar to the training set without seeing the images [4].

The more images the generator creates, the closer they get to the images from the training set. The idea is that after a certain number of images are generated, the GAN will create images that are very similar to what we consider art. This is a very impressive accomplishment to say the least. But what if we take it a step further?

Many issues associated with the GAN are simply limitations on what it can do. The GAN is powerful, but can’t do quite as much as we would like. For example, the generator in the model described above will continue to create images closer and closer to the images given to the discriminator that it isn’t producing original art. Could a GAN be trained to draw alongside a user? It’s not likely. The model wouldn’t be able to turn a text-based description of an image into an actual picture either. As impressive as the GAN may be, we would all agree that it can be improved. Each of the shortcoming mentioned have actually been addressed and, to an extent, solved. Let’s look at how this is done.

Sketch-RNN is a recurrent neural network model developed by Google. The goal of Sketch-RNN is to help machines learn to create art in a manner similar to the way a human may learn. It has been used in a Google AI Experiment to be able to sketch alongside a user. While doing so, it can provide the users with suggestions and even complete the user’s sketch when they decide to take a break. Sketch-RNN is exposed to a massive number of sketches provided through a dataset of vector drawings obtained through another Google application that we will discuss later. Each of these sketches are tagged to let the program know what object is in the sketch. The data set represents the sketch as a set of pen strokes. This allows Sketch-RNN to then learn what aspects each sketch of a certain object has in common. If a user begins to draw a cat, Sketch-RNN could then show the user other common features that could be on the cat. This model could have many new creative applications. “The decoder-only model trained on various classes can assist the creative process of an artist by suggesting many possible ways of finishing a sketch” [3]. The Sketch-RNN team even believes that, given a more complex dataset, the applications could be used in an educational sense to teach users how to draw. These applications of Sketch-RNN couldn’t be nearly as easily achieved with GAN alone.

Another method used to improve upon GAN is the Creative Adversarial Network. In their paper regarding adversarial networks generating art, several researchers discuss a new way of generating art through CANs. The idea is that the CAN has two adversary networks. One, the generator, has no access to any art. It has no basis to go off of when generating images. The other network, the discriminator, is trained to classify the images generated as being art or not. When an image is generated, the discriminator gives the generator two pieces of information. The first is whether it believes the generated image comes from the same distributor as the pieces of art it was trained on, and the other being how the discriminator can fit the generated image into one of the categories of art it was taught. This technique is fantastic in that it helps the generator create images that are both emulative of past works of art in the sense that it learns what was good about those images and creative in a sense that it is taught to produce new and different artistic concepts. This is a big difference from GAN creating art that emulated the training images. Eventually, the CAN will learn how to produce only new and innovative artwork.

One final future for the vanilla GAN is StackGAN. StackGAN is a text to photo-realistic image synthesizer that uses stacked generative adversarial networks. Given a text description, the StackGAN is able to create images that are very much related to the given text. This wouldn’t be doable with a normal GAN model as it would be much too difficult to generate photo-realistic images from a text description even with a state-of-the-art training database. This is where StackGAN comes in. It breaks the problem down into 2 parts. “Low-resolution images are generated by our Stage-I GAN. On the top of our Stage-I GAN, we stack Stage-II GAN to generate realistic high-resolution images conditioned on Stage-I results and text descriptions” [7]. It is through the conditioning on Stage-I results and text descriptions that Stage-II GAN can find details that Stage-I GAN may have missed and create higher resolution images. By breaking the problem down into smaller subproblems, the StackGAN can tackle problems that aren’t possible with a regular GAN. On the next page is an image showing the difference between a regular GAN and each step of the StackGAN.

This image came from the StackGAN paper [7].

It is through advancements like these that have been made in recent years that we can continue to push the boundaries of what AI can do. We have just seen three ways to improve upon a concept that was already quite complex and innovative. Each of these advancements have a practical, everyday use. As we continue to improve on artificial intelligence techniques, we will able to do more and more in regard to, not just art and music, but a wide variety of tasks to improve our lives.

DeepBach, Magenta, and NSynth

Images aren’t the only type of art that artificial intelligence can impact though. Its effect on music is being explored as we speak. We will now explore some specific cases and their impact on both music and artificial intelligence. In doing this, we should be able to see how art can do as much for AI as AI does for it. Both fields benefit heavily from the types of projects that we are exploring here.

Could a machine ever be able to create a piece of music the likes of Johann Sebastian Bach? In a project known as DeepBach, several researchers looked to create pieces similar to Bach’s chorales. The beauty of DeepBach is that it “is able to generate coherent musical phrases and provides, for instance, varied reharmonizations of melodies without plagiarism” [6]. What this means it that DeepBach can create music with correct structure and be original. It is just in the style of Bach. It isn’t just a mashup of his works. DeepBach is creating new content. The developers of DeepBach went on to test whether their product could actually fool listeners.

As part of the experiment, over 1,250 people were asked to vote whether pieces presented to them were in fact composed by Bach. The subjects had varying degrees of musical expertise. The results showed that as the model for DeepBach’s complexity increased, the subjects had more and more trouble distinguishing the chorales of Bach from those of DeepBach. This experiment shows us that through the use of artificial intelligence and machine learning, it is quite possible to recreate original works in the likeness of the greats. But is that the limit to what artificial intelligence can do in the field of art and music?

DeepBach has achieved something that would have been unheard of in the not so distant past, but it certainly isn’t the fullest extent of what AI can do to benefit the field of music. What if we want to create new and innovative music? Maybe AI can change the way music is created all together. There must be projects that do more to push the envelope. As a matter of fact, that is exactly what the team behind Magenta look to do.

Magenta is a project being conducted by the Google Brain team and lead by Douglas Eck. Eck has been working for Google since 2010, but that isn’t where his interest in Music began. Eck helped found Brain Music and Sound, an international laboratory for brain, music, and sound research. He was also involved at the McGill Centre for Interdisciplinary Research in Music Media and Technology, and was an Associate Professor in Computer Science at the University of Montreal.

Magenta’s goal is to be “a research project to advance the state of the art in machine intelligence for music and art generation” [2]. It is an open source project that uses TensorFlow. Magenta aims to learn how to generate art and music in a way that is indeed generative. It must go past just emulating existing music. This is distinctly different that projects along the line of DeepBach which set out to emulate existing music in a way that wasn’t plagiarizing existing pieces of music. Eck and company realize that art is about capturing elements of surprise and drawing attention to certain aspects. “This leads to perhaps the biggest challenge: combining generation, attention and surprise to tell a compelling story. So much of machine-generated music and art is good in small chunks, but lacks any sort of long-term narrative arc” [2]. Such a perspective gives computer-generated music more substance, and helps it to become less of a gimmick.

One of the projects the magenta team has developed is called NSynth. The idea behind NSynth is to be able to create new sounds that have never been heard before, but beyond that, to reimagine how music synthesis can be done. Unlike ordinary synthesizers that focus on “a specific arrangement of oscillators or an algorithm for sample playback, such as FM Synthesis or Granular Synthesis” [5], NSynth generates sounds on an individual level. To do this, it uses deep neural networks. Google has even launched an experiment that allows users to really see what NSynth can do by allowing them to fuse together the sounds of existing instruments to create new hybrid sounds that have never been heard before. As an example, users can take two instruments such as a banjo and a tuba, and take parts of each of their sounds to create a totally new instrument. The experiment also allowed users to decide what percentage of each instrument would be used.

Projects like Magenta go above and beyond in showing us the full extent of what artificial intelligence can do in the way of generating music. They explore new applications of artificial intelligence that can generate new ideas independent of humans. It is the closest we have come to machine creativity. Although machines aren’t yet able to truly think and express creativity, they may soon be able to generate new and unique art and music for us to enjoy. Don’t worry though. Eck doesn’t intend to replace artists with AI. Instead he looks to provide artists with tools to create music in an entirely new way.

Deep Dream and Quick, Draw!

As we look ahead to a few more of the ways that AI has been used to accomplish new and innovative ideas in the art space, we look at projects like Quick, Draw! and Deep Dream. These projects showcase amazing progress in the space while pointing out some issues that researchers in AI will have to work out in the years to come.

Quick, Draw! is an application from the Google Creative Lab, trained to recognize quick drawings much like one would see in a game of Pictionary. The program can recognize simple objects such as cats and apples based on common aspects of the many pictures it was given before. Although the program will not get every picture right each time it is used, it continues to learn from the similarities in the picture drawn and the hundreds of pictures before it.

The science behind Quick, Draw! “uses some of the same technology that helps Google Translate recognize your handwriting. To understand handwritings or drawings, you don’t just look at what the person drew. You look at how they actually drew it” [1]. It is presented in the form of a game, with the user drawing a picture of an object chosen by the application. The program then has 20 seconds to recognize the image. In each session, the user is given a total of 6 objects. The images are then stored to the database used to train application. This happens to be the same database we saw earlier in the Sketch-RNN application. This image recognition is a very practical use of artificial intelligence in the realm of art and music. It can do a lot to benefit us in our everyday lives. But this only begins to scratch the surface of what artificial intelligence can do in this field. Although this is very impressive, we might point out that the application doesn’t truly understand what is being drawn. It is just picking up on patterns. In fact, this distinction is part of the gap between simple AI techniques and true artificial general intelligence. Machines that truly understand what the objects in images are don’t appear to be coming in the near future.

Another interesting project in the art space is Google’s Deep Dream project, which uses AI to create new and unique images. Unfortunately, the Deep Dream Generator Team wouldn’t go into too much detail about the technology itself (mostly fearing it would be too long for an email) [8]. They did, however, explain that convolutional neural networks train on the famous ImageNet dataset. Those neural networks are then used to create art-like images. Essentially, Deep Dream takes the styling of one image and uses it to modify another image. The results can be anything from a silly fusion to an artistic masterpiece. This occurs when the program identifies the unique stylings of an image provided by the user and imposes those stylings onto another image that the user provides. What can easily be observed through the use of Deep Dream is that computers aren’t yet capable of truly understanding what they are doing with respect to art. They can be fed complex algorithms to generate images, but don’t fundamentally understand what it is they are generating. For example, a computer may see a knife cutting through an onion and assume the knife and onion are one object. The lack of an ability to truly understand the contents of an image is one dilemma that researchers have yet to solve.

Perhaps as we continue to make advances in artificial intelligence we will be able to have machines that do truly understand what objects are in an image and even the emotions evoked by their music. The only way for this to be achieved is by reaching true artificial general intelligence (AGI). IN the meantime, the Deep Dream team believes that generative models will be able to create some really interesting pieces of art and digital content.

Where Do We Go From Here?

For this section, we will consider where artificial intelligence could be heading in the art space. We will take a look at how AI has impacted the space and in what ways it can continue to do so. We will also look at ways art and music could continue to impact AI in the years to come.

Although I don’t feel that we have completely mastered the ability to emulate the great artists of our past, it is just a matter of time before that problem is solved. The real task to be solved is that of creating new innovations in art and music. We need to work towards creation without emulation. It is quite clear that we are headed in that direction through projects like CAN and Magenta. Artificial general intelligence (AGI) is not the only way to complete this task. As a matter of fact, even those who dispute the possibility of AGI would have a hard time disputing the creation of unique works of art by a machine.

One path that may be taken to further improve art and music through AI is to create more advanced datasets to use in training the complex networks like Sketch-RNN and Deep Dream. AI needs to be trained to be able to perform as expected. That training has a huge impact on the results we get. Shouldn’t we want to train our machines in the most beneficial way possible. Even developing software like Sketch-RNN to use the ImageNet dataset used in Deep Dream could be huge in educating artists on techniques for drawing complex, realistic images. Complex datasets could very well be our answer to more efficient training. Until our machines can think and learn like we do, we will need to be very careful what data is used to train them.

One of the ways that art and music can help to impact AI is by providing another method of Turing Testing machines. For those who dream of creating AGI, what better way to test the machine’s ability that to create something that tests the full extent of human-like creativity? Art is the truest representation of human creativity. That is, in fact, its essence. Although art is probably not the ultimate end game for artificial intelligence, it could be one of the best ways to test the limits of what a machine can do. The day that computers can create original musical composition and create images based on descriptions given by a user could very well be the day that we stop being able to distinguish man from machine.

Conclusion

There are many benefits to using artificial intelligence in the music space. Some of them have already been seen in the projects we have discussed so far. We have seen how artificial intelligence could be used for image recognition as well as their ability to turn our words into fantastic images. We have also seen how AI can be used to synthesize new sounds that have never been heard. We know that artificial intelligence can be used to create art alongside us as well as independently from us. It can be taught to mimic music from the past and can create novel ideas. All of these accomplishments are a part of what will drive AI research into the future. Who knows? Perhaps one day we will achieve artificial general intelligence and machines will be able to understand what is really in the images it is given. Maybe our computers will be able to understand how their art makes us feel. There is a clear path showing us where to go from here. I firmly believe that it is up to us to continue this research and test the limits of what artificial intelligence can do, both in the field of art and in our everyday lives.

References",https://cdn-images-1.medium.com/max/1200/0*pIGHko-OCo1usW2c,[],https://towardsdatascience.com/beethoven-picasso-and-artificial-intelligence-caf644fc72f9?source=topic_page---8------3----------------,2018-06-08 21:34:58.310000+00:00

Data,The curious case of the vanishing & exploding gradient,['Eniola Alese'],"The curious case of the vanishing & exploding gradient

Understanding why gradients explode or vanish and methods for dealing with the problem.

Photo by SpaceX on Unsplash

In the last post, we introduced a step by step walkthrough of RNN training and how to derive the gradients of the network weights using back propagation and the chain rule. But it turns out that during this training the RNN can suffer greatly from two problems: 1. Vanishing gradients or 2. Exploding gradients.

Why Gradients Explode or Vanish

Recall the many-to-many architecture for text generation shown below and in the introduction to RNN post, lets assume the input sequence to the network is a 20 word sentence: “I grew up in France,…….. I speak French fluently.

We can see from the example above that for the RNN to predict the word “French” which comes at the end of the sequence, it would need information from the word “France”, which occurs further back at the beginning of the sentence. This kind of dependence between sequence data is called long-term dependencies because the distance between the relevant information “France” and the point where it is needed to make a prediction “French” is very wide. Unfortunately, in practice as this distance becomes wider, RNNs have a hard time learning these dependencies because it encounters either a vanishing or exploding gradient problem.

These problems arise during training of a deep network when the gradients are being propagated back in time all the way to the initial layer. The gradients coming from the deeper layers have to go through continuous matrix multiplications because of the the chain rule, and as they approach the earlier layers, if they have small values (<1), they shrink exponentially until they vanish and make it impossible for the model to learn , this is the vanishing gradient problem. While on the other hand if they have large values (>1) they get larger and eventually blow up and crash the model, this is the exploding gradient problem

Dealing with Exploding Gradients",https://cdn-images-1.medium.com/max/1200/0*UCn2LUkacEHQxgZW,[],https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb?source=topic_page---8------5----------------,2018-06-05 22:33:57.437000+00:00

Data,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------,2018-06-08 22:25:33.341000+00:00

Data,"How my app grew by 5,800% in one month with no branding or marketing",['Assaf Elovic'],"How my app grew by 5,800% in one month with no branding or marketing

All it took was this simple weekly approach and patience.

Building and promoting a new consumer product is one of the most challenging things you can do as an entrepreneur. While there are many approaches on how to design, test, build and promote apps, usually they don’t seem to bring real results.

Then you start wondering, maybe it’s the product? Maybe there’s not enough market fit? Or is it bad execution? Or maybe we should grow the marketing and branding budget! Maybe we’re not targeting the right audience? Maybe we should build more features!

When you start questioning everything, things usually get even worse. You start defocusing from the main goal and start wasting energy and money on all kinds of wide approaches.

The worst is when you think it’s all a matter of growing your marketing or branding budget.

Your goal should always be one: improving customer retention. For those who are not familiar with what customer retention is, click here.

A case study: why it’s important to keep your customers around

To make my point clear, I’ll let you in on a story I heard from a friend of mine, who’s the Co-founder and CTO of a very successful productivity B2C company.

In 2012, they released the first version of their app to the Android Google store, and a crazy thing happened. Within a few days after the launch, 500K users worldwide had downloaded the app. The reason for that crazy growth was mainly because there were no good apps in the productivity space back then. Over the next few months, they had grown to a few million users and raised over $5M from VCs.

Four years later, however, they still couldn’t reach a decent business model. He realized that despite the big numbers, there were very few users who were actually using the product long term.

So he decided to dig into the data and look for the reason. He found out that retention was very low. Even worse, he discovered that it hadn’t improved much in four years! That’s when it hit him to focus on retention instead of user growth.

Back then, VC’s poured millions of dollars into companies with large user growth because they didn’t know how to deal with or measure the crazy scale that mobile app stores and websites brought with them.

Today the case is different. The first thing you’ll need in order to raise money in B2C is to show retention growth. And there’s a very good reason for that.

Back to my friend’s story: with no retention, it didn’t matter how many users had downloaded their app. After a week, 95% of users stopped using the product. So even if they had a billion users, after a few weeks it would only be a number in their database.

Here’s a thought: if you have 100K users using your product every day, it’s 100X more valuable than having 100M users using your product once a month.

Most importantly, once you’ve reached a decent retention rate, you can be sure that your marketing budget will lead to the sustainable growth of your product and business.

The Lean Startup approach

Too many startups begin with an idea for a product that they think people want. They then spend months, sometimes years, perfecting that product without ever showing the product, even in a very rudimentary form, to the prospective customer. This is where the Lean startup comes in.

In short, the Lean Startup is a methodology that posits that every startup is a grand experiment that attempts to answer one main question — “Should this product be built?”

A core component of Lean Startup methodology is the build-measure-learn feedback loop.

The first step is figuring out the problem that needs to be solved, and then developing a minimum viable product (MVP) to begin the process of learning as quickly as possible.

Once the MVP is established, a startup can work on tuning the engine. This will involve measurement and learning, and must include actionable metrics that can demonstrate the cause and effect question.

Whenever my team and I are working on a product, here are the steps we’ve:

Define the most important product assumption Design and build an MVP of how this assumption should be tested Target early adopters to test the MVP Apply the test results Repeat

This is how our growth looked in the first year (2017) of iterations:

User activity from March 2017 to January 2018

Slowly but surely right? Now let’s look at an example together and see what happened after enough iterations.

The process

Define the most important assumption

I’ll use my team as an example. We believed that there were no decent reminder apps that people actually like to use. The main reason, in our opinion, was that there is a lot of friction in setting a single reminder. Either you need to fill out a long form on a mobile app, or naturally ask an assistant like Siri — realizing that she doesn’t understand 50% of your requests.

So that’s when we defined our most important product assumption: if we could achieve understanding for almost every reminder request in natural language, users would use such a product long term.

Design and build an MVP

Since our assumption was focused on NLU (natural language understanding), we decided to focus solely on that. No branding, UX, or other features.

First, we hired data scientists to build a state of the art NLU algorithm for understanding complex reminder requests.

Secondly, since all we were validating was this assumption, we decided to build the MVP as a chatbot on Facebook Messenger, instead of going through the long and annoying process of building a mobile app.

Please note: If we were to build a mobile app, this would not add anything to testing our assumption, and would make our MVP longer and more complicated to design and build. Moreover, it might even defocus us from the main assumption. For example, what if users just don’t like to use new apps anymore? We might’ve concluded that our assumption was wrong, even though it was for a whole other reason.

It’s important to narrow your MVP as much as possible, so there are no distractions from your main assumption.

Target early adopters

We needed English speakers, since our NLU algorithms only supported it. Also, we believed that millennial moms would eagerly want a product like this, since they’re always on the move and very busy, while constantly needing to remember things. So we targeted some Facebook pages (with no budget) which were based on a community of moms, and successfully brought onboard a few hundred beta testers to try it out.

Apply the test results on the product

After our first iteration, we learned the following:

There were many more ways to ask for reminders than we thought. But users really enjoyed the ease of setting reminders with a simple request. Users don’t always ask for reminders in a single request but break it down into a few steps. When working with chatbots, users would like the assistance of buttons to make it faster and easier to handle.

With these results, we prioritized and went on to our next assumption, which was to add buttons to the flow of setting a reminder (conclusion three). And guess what? That assumption also turned out to be true. For more proven assumptions, you can read my article on How to improve your chatbot.

Little by little, we improved our overall product and retention rate on a weekly basis.

We never tackled more than one assumption at a time.

Suddenly, we started discovering users who were with us for over six months! After a year of weekly iterations, we finally decided it was time to launch our product. We reached a Week 1 retention rate of 92% and Week 4 of 19%. It was way above the market standard, which was enough for us.

We published our chatbot on FB Messenger in mid Feb 2018, and within a month we grew by over 5,800%, as you can see below.

Daily new users from Feb 17 to March 17

This was mostly due to delivering a lean product that we knew people enjoyed and would recommend to others. Since then, we’ve grown to over 1M users worldwide and are growing by tens of thousands of users a day.

User activity from Jan 01 to May 01

We’re continuing to work with this methodology, and it’s proven a success every day.

Also, we try to make as many data driven decisions as possible. Try collecting user data for improving user experience, and do A/B tests when there is no definitive answer. For example, if you’re not sure where a button should be placed or which title would attract more clicks, try placing it on one side for half the users, and on another side for the second half. Then, see which placement led to more clicks.

Final thoughts

Not only does this methodology help us focus solely on what’s the most important set of features users want, but it also helps us filter out features we believe are valuable, but that are actually not.

As they say in customer service: the customer is always right. The same goes for product development. Trust your customers, listen to them and engage with them, and you’ll understand what they want and don’t want. Never build things out of your own intuition, unless it’s to challenge your assumptions. At the end of the road, you’ll reach one of two conclusions:

The product does not have enough market fit, time to move on. You have a product people want. Good job, you’re on the way to building a company!

Either way, you win.",https://cdn-images-1.medium.com/max/1200/1*oXGlgC187951ecRdVkHhlQ.jpeg,[],https://medium.freecodecamp.org/how-my-app-grew-by-5-800-in-one-month-with-no-branding-or-marketing-d0bafb93108?source=collection_home---6------0----------------#--responses,2018-06-08 22:25:33.341000+00:00

Data,How to build a range slider component in React from scratch using only <div> and <span>,['Rajesh Pillai'],"How to build a range slider component in React from scratch using only <div> and <span>

In this article we will build a React range slider component step by step using only <div>. We will enable it with touch support.

What can you do with a piece of about 50 <div’s>?

Build a slider control from scratch. If this sounds interesting, then follow along.

The final output will look like the below animation.

Please do note that I have developed this component as a teaching exercise for my students of ReactJS — Beyond the Basics course on Udemy, so it may have some edge cases (which I will fix as and when encountered).

You could use an HTML5 range control and customize it. But I wanted to take a different approach and build something from scratch. And the result is what you see here.

Our slider component will be composed of the below three elements:

A slider range

The actual slider controls

The current selection range

Defining the state for our component

Let us begin by defining our state. I am only showing you the important part of the code. For the full source code, please refer to the link at the end of the article.

state = {

slots: 24,

start: 0,

end: 10,

labelMode: ""mid"", // mid, long

}

The state contains the following properties.

slots: Total slots to be drawn (in this case I am using it as a time selector, so it will have 24 hour slots)

start: The start value of the selection

end: The end value of the selection

labelMode: Currently unused. But can be used to customize the scale label rendering.

The return part of the render method

Let us now take a look at the return part of the render method. The render() method will be slowly composed of small pieces of functionality.

return (

<div>

<h2>React Slider</h2>

<div className=""example-1"">

<div className=""slider-container"">

<div className=""slider-scale"">

{scale}

</div>

<div className=""slider"">

{slider}

</div>

<div className=""slider-selected-scale"">

{currentScale}

</div>

</div>

</div>

</div>

);

For those reading on mobile, the below image may be handy, as sometimes Medium breaks the code formatting.

If you take a look at the code, there are only three important pieces:

scale variable

slider variable

currentScale variable

The three variables above will be responsible for rendering the correct parts of the overall slider.

Dissecting the render () method

Let us initialize some variables. The scale , slider and currentScale JSX will be created within the for loop defined below.

render () {

let scale = [];

let slider=[];

let currentScale = [];

let minThumb = null;

let maxThumb = null

..... // rest of the code

}

Create the JSX for the ‘scale’ variable

Creating the JSX for the scale variable is quite simple. We just loop through the slots value in the state and push a <div> to the scale array with the required CSS class for styling.

The if condition ensures that we are only printing the label for i = 0, i = 12, or i = 24 (kind of mid range). Please feel free to customize this.

for (let i = 0; i <= this.state.slots;i++) {

let label = """";



if (i == 0 || i == 12 || i == 24) {

label = i;

}



scale.push(

<div

key={i}

className=""slot-scale"">

{label}

</div>

);

Here’s the code in image format:

Create the JSX for the ‘currentScale’ variable

Let us now continue with the same for loop and create the ‘currentScale’ JSX. We are still within the same for loop, so about 24 divs will be created as per the value in this.state.slots value.

The currentScale has a class of ‘slot-scale-selected’.

let currentLabel = """";



if (i === this.state.start || i === this.state.end) {

currentLabel = i;

}



currentScale.push(

<div

key={i}

className=""slot-scale-selected"">

{currentLabel}

</div>

);

The code is pretty similar to the ‘scale’ JSX that we created.

Create the JSX for the ‘slider’ variable

Let us write a function to render the ‘slider’ jsx. The slider needs two thumbs, one for min, and one for max.

Let us first initialize the thumb variable depending on the ‘i’ value. If ‘i’ is the same as this.state.start, then we set the minThumb variable. Else if the value of ‘i’ is the same as this.state.end, then we initialize the maxThumb variable.

if (i === this.state.start) {

minThumb = <this.MinSlider />

} else if (i === this.state.end) {

maxThumb = <this.MaxSlider />

} else {

minThumb = null;

maxThumb = null;

}

Create the JSX for the ‘slider’

The important code piece here is the dragover event. This is required for the HTML drop to work correctly.

let lineClass = ""line"";



if (i >= this.state.start && i < this.state.end) {

lineClass += "" line-selected"";

}

slider.push(

<div

data-slot={i}

onDragOver={this.onDragOver}

onTouchMove = {this.onDragOver}

onTouchEnd = {this.onDrop}

onDrop = {this.onDrop}

key={i}

className=""slot"">

<div data-slot={i} className={lineClass}/>

<span className=""scale-mark""></span>

{minThumb}

{maxThumb}

</div>

);

The slider variable needs two additional pieces of features to represent the min and the max thumb on the slider.

The slider JSX has additional event handlers to deal with handling the drop event/touchend event. We will take a look at the event handlers shortly.

The ‘lineClass’ styles/renders the line on the slider, and the ‘line-selected’ class styles the currently selected range.

Let us now write the MinSlider and MaxSlider function outside the render method.

The MinSlider () function to render the min thumb

Let’s take a look at the code. The important props are the events related to drag and the draggable attribute. The draggable attribute will make this element draggable.

We are also adding the touch event handler. Refer to the link at the bottom of the article to add touch support polyfill for the HTML5 API.

MinSlider=()=> {

return (

<div data-slider=""min""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-min"">

</div>

);

}

The MaxSlider () function to render the min thumb

The MaxSlider is almost the same as the MinSlider except for the data and the className.

MaxSlider=()=> {

return (

<div data-slider=""max""

onDragStart={this.onDragStart}

onTouchStart={this.onDragStart}

draggable className=""slider-thumb slider-thumb-max"">

</div>

);

}

The code image is given below for reference.

Event Handling

Let us now look at the drag/touch event handlers defined within our <div> to control the movement of the slider element.

dragover:

The dragover event is required to support the drop zone when using the HTML5 drag/drop API. The only thing we need to do here is to invoke the preventDefault on the event object.

onDragOver = (e) => {

e.preventDefault();

}

dragstart:

The dragstart enables us to store which slider is being dragged. Please note that I am not using the dataTransfer object here, but simply using an instance variable to store this.

onDragStart = (e) => {

let slider = e.target.dataset.slider;

this.sliderType = slider;

}

The value of e.target.dataset.slider is either “min” or “max,” indicating which slider is being dragged.

ondrop:

The ondrop event captures where the thumb is being dropped (on which scale).

This is the important flow in the ondrop event:

Grab the source (whether min/max thumb)

Get the slot (where the drop happens)

Validations

Update the slot (in the state)

Reset the sliderType.

onDrop = (e, target) => {

let source = this.sliderType;

let slot = Number(e.target.dataset.slot);



if (isNaN(slot)) return;



if (source === ""min"") {

if (slot >= this.state.end) return;

this.setState({

start: slot

},()=>{

console.log(this.state);

})

} else if (source === ""max"") {

if (slot <= this.state.start) return;

this.setState({

end: slot

},()=>{

console.log(this.state);

})

}

this.sliderType = null;

}

The complete source code/and demo can be seen here http://jsbin.com/remodat/edit?output

Since I am using HTML5 drag and drop features to add touch, support please add this polyfill reference to your html file.

Todos

Extract the logic to a separate Component class

Test it and and add customization.

History

21-May-2018 — First release

P.S: This component is a result of a very quick coding attempt. This will be refactored.

Promotion: If you would like to support our open source curriculum Mastering Full Stack Engineering in 12 to 20 weeks then here is a special 10$ coupon for medium readers for my upcoming live ReactJS-Beyond the basicscourse on udemy (MEDIUM_500 is the coupon code, which is already tagged in the above URL)",https://cdn-images-1.medium.com/max/1200/1*iSkeoPHBQubtAL4fV4h9xQ.png,[],https://medium.freecodecamp.org/how-to-build-a-range-slider-component-in-react-from-scratch-using-only-div-and-span-d53e1a62c4a3?source=collection_home---6------1----------------,2018-06-08 21:41:33.808000+00:00

Data,The well-kept secret behind great UX: Usability Testing,['Anant Jain'],"The well-kept secret behind great UX: Usability Testing

Whether you only have a prototype or a full-fledged product, it’s a really good idea to run monthly usability tests. These make sure that whatever you’re working on is usable and the user experience is excellent.

If you’re wondering what you can do to make your usability tests more structured and organized, this guide is for you. Let’s get started!

First off, always keep the two Golden Rules of Usability Testing in mind:

Any testing is better than no testing (with no one!) A little testing earlier is better than a lot of testing later.

In this post, I will introduce you to the kind of lightweight usability testing described in Steve Krug’s books, “Don’t Make Me Think” and “Rocket Surgery Made Easy.” Steve calls this kind of testing “Do-It-Yourself Usability Testing” since it’s supposed to be cheap, easy-to-do and takes just a morning a month.

A quick intro to usability testing

The idea behind this is to:

Find a few participants

Ask them to come in and go through a list of user flows you want to test

Observe the problems they run into

Finally, make a list of issues to fix

Sounds simple enough, but very few of us actually do it. The goal of this post is to make you confident enough to run at least one usability test session this month. I ran my first usability test only a year ago, and I must say it’s actually a lot of fun!

Before we get to the test itself, here are a few things to note:

Reserve one morning a month (say the third Thursday every month) for a round of testing, debriefing, and deciding what to fix. Test with three participants each round. Recruit loosely, and grade on a curve. You don’t need to find someone who fits the exact mould of your ideal user, since most usability problems can be uncovered by testing with just about anyone. If you are part of a big company and have the budget, you can recruit via Craigslist and offer a $50 gift card for an hour of the participant’s time. If you don’t have those kind of resources, don’t worry — you can ask your friends, your existing users, or even go to a café and ask strangers for 15 minutes of their time in exchange for buying them a coffee. If you’re doing this as part of a bigger team, get as many observers as possible to observe the tests in a separate observation room. These will be the designers, engineers, project managers, executives, etc. Or, in case of side projects, it’ll be just be you later in your room!

What happens during the test?

During a usability test, you will record the participant’s voice and their computer screen, and share both these streams live with observers in another room. A typical one-hour test can be broken down into:

Welcome (4 mins): Explain how the test will work so that the participant will know what to expect. The questions (2 mins): Ask the participant a few questions about themselves. This helps put them at ease and gives you an idea of how computer-savvy they are. The Homepage tour (3 mins): Open the Home page of your site, and ask the participant to look around and tell you what they think. This will give you an idea of how easy it is to understand your home page, as well as how familiar the participant is with your domain. The tasks (35 minutes): Watch the participant perform a series of tasks you have prepared for them beforehand. If you’re building a SaaS product and you’re testing out your subscription flow, a typical task could be to find the Pricing page, compare various plans, and Subscribe to one of the plans with a provided test credit card number. Encourage the participant to think out loud as they perform the task (see the video at the end of the post for a sample test.) It’s crucial that you let them work on their own and not ask them any leading questions, or give out any clues or assistance. Probing (5 mins): Ask the participant any questions you may have about anything that happened during the test and about any issues that people in the observation room may have. Also, answer any questions that the participant may have at this point (don’t answer them during the actual tasks since you’re testing how they’ll perform with no one around.) Wrapping Up (5 mins): Thank them for their help, and give them their gift card if you promised one while recruiting them.

The debrief

During the breaks between successive tests, ask the observers to write down the top 3 usability problems that they saw. During the debriefing, focus ruthlessly on deciding to fix the most severe problems first. Here are a few other recommendations:

Keep a separate list of low-hanging fruit. These are the problems you can typically fix with one-line code changes, but have a huge impact on task completion rates. Joel Califa calls them “tiny wins”. Here’s an example:

Resist the impulse to add things — instead, try to tweak your existing design to fix the problem.

to fix the problem. Take “new feature” requests with a grain of salt. Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature.

Participants will often suggest new features, but when you probe them further, they will admit that they will likely not use the features they are proposing. Instead, try to get to the root of the problem that the participant faced and was trying to fix on their own by suggesting that new feature. Ignore the problems where the user goes astray for a bit but comes back on track by themselves. These are usually not worth investing much time unless you see a pattern across multiple participants.

Good design is a delicate balance, so when fixing a problem, ensure that you aren’t introducing new ones.

Remote testing and unmoderated user testing

Remote testing is very similar to an in-person usability test, except that the participant is at their home/office and you conduct the testing via screen sharing and voice call.

Unmoderated user testing is another way to test, where you specify your website, the tasks you want the users to do, and get back video recordings of people trying to accomplish those tasks. Usertesting.com is the leader in this space, but note that a single 30-minute test costs about $50.

Resources

You can download checklists, interview script, consent form, and a demo video at Steve Krug’s site here: Downloads for Rocket Surgery Made Easy.

Here’s a Usability Test demo video from Google Ventures:

I want to thank you for reading this quick guide. This was originally published as part of the UX Design course on Commonlounge, a platform that has courses with small bite-sized lessons like these on topics ranging from Project Management to Machine Learning that deliver the most value for the time you put in.

You learn by working on real-world projects and getting feedback from industry mentors. You should check it out here!",https://cdn-images-1.medium.com/max/1200/0*UWxJWKKNLXR5c1cm,[],https://medium.freecodecamp.org/the-well-kept-secret-behind-great-ux-usability-testing-b788178a64c3?source=collection_home---6------2----------------,2018-06-08 21:25:31.335000+00:00

Data,An introduction to part-of-speech tagging and the Hidden Markov Model,['Divya Godayal'],"Let’s go back into the times when we had no language to communicate. The only way we had was sign language. That’s how we usually communicate with our dog at home, right? When we tell him, “We love you, Jimmy,” he responds by wagging his tail. This doesn’t mean he knows what we are actually saying. Instead, his response is simply because he understands the language of emotions and gestures more than words.

We as humans have developed an understanding of a lot of nuances of the natural language more than any animal on this planet. That is why when we say “I LOVE you, honey” vs when we say “Lets make LOVE, honey” we mean different things. Since we understand the basic difference between the two phrases, our responses are very different. It is these very intricacies in natural language understanding that we want to teach to a machine.

What this could mean is when your future robot dog hears “I love you, Jimmy”, he would know LOVE is a Verb. He would also realize that it’s an emotion that we are expressing to which he would respond in a certain way. And maybe when you are telling your partner “Lets make LOVE”, the dog would just stay out of your business 😛.

This is just an example of how teaching a robot to communicate in a language known to us can make things easier.

The primary use case being highlighted in this example is how important it is to understand the difference in the usage of the word LOVE, in different contexts.

Part-of-Speech Tagging

From a very small age, we have been made accustomed to identifying part of speech tags. For example, reading a sentence and being able to identify what words act as nouns, pronouns, verbs, adverbs, and so on. All these are referred to as the part of speech tags.

Let’s look at the Wikipedia definition for them:

In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging or word-category disambiguation, is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its definition and its context — i.e., its relationship with adjacent and related words in a phrase, sentence, or paragraph. A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.

Identifying part of speech tags is much more complicated than simply mapping words to their part of speech tags. This is because POS tagging is not something that is generic. It is quite possible for a single word to have a different part of speech tag in different sentences based on different contexts. That is why it is impossible to have a generic mapping for POS tags.

As you can see, it is not possible to manually find out different part-of-speech tags for a given corpus. New types of contexts and new words keep coming up in dictionaries in various languages, and manual POS tagging is not scalable in itself. That is why we rely on machine-based POS tagging.

Before proceeding further and looking at how part-of-speech tagging is done, we should look at why POS tagging is necessary and where it can be used.

Why Part-of-Speech tagging?

Part-of-Speech tagging in itself may not be the solution to any particular NLP problem. It is however something that is done as a pre-requisite to simplify a lot of different problems. Let us consider a few applications of POS tagging in various NLP tasks.

Text to Speech Conversion

Let us look at the following sentence:

They refuse to permit us to obtain the refuse permit.

The word refuse is being used twice in this sentence and has two different meanings here. refUSE (/rəˈfyo͞oz/)is a verb meaning “deny,” while REFuse(/ˈrefˌyo͞os/) is a noun meaning “trash” (that is, they are not homophones). Thus, we need to know which word is being used in order to pronounce the text correctly. (For this reason, text-to-speech systems usually perform POS-tagging.)

Have a look at the part-of-speech tags generated for this very sentence by the NLTK package.

>>> text = word_tokenize(""They refuse to permit us to obtain the refuse permit"")

>>> nltk.pos_tag(text)

[('They', 'PRP'), ('refuse', 'VBP'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'),

('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]

As we can see from the results provided by the NLTK package, POS tags for both refUSE and REFuse are different. Using these two different POS tags for our text to speech converter can come up with a different set of sounds.

Similarly, let us look at yet another classical application of POS tagging: word sense disambiguation.

Word Sense Disambiguation

Let’s talk about this kid called Peter. Since his mother is a neurological scientist, she didn’t send him to school. His life was devoid of science and math.

One day she conducted an experiment, and made him sit for a math class. Even though he didn’t have any prior subject knowledge, Peter thought he aced his first test. His mother then took an example from the test and published it as below. (Kudos to her!)

Word-sense Disambiguation example — My son Peter’s first Maths problem.

Words often occur in different senses as different parts of speech. For example:

She saw a bear.

Your efforts will bear fruit.

The word bear in the above sentences has completely different senses, but more importantly one is a noun and other is a verb. Rudimentary word sense disambiguation is possible if you can tag words with their POS tags.

Word-sense disambiguation (WSD) is identifying which sense of a word (that is, which meaning) is used in a sentence, when the word has multiple meanings.

Try to think of the multiple meanings for this sentence:

Time flies like an arrow

Here are the various interpretations of the given sentence. The meaning and hence the part-of-speech might vary for each word.

Part-of-speech tags define the meaning of a sentence based on the context

As we can clearly see, there are multiple interpretations possible for the given sentence. Different interpretations yield different kinds of part of speech tags for the words.This information, if available to us, can help us find out the exact version / interpretation of the sentence and then we can proceed from there.

The above example shows us that a single sentence can have three different POS tag sequences assigned to it that are equally likely. That means that it is very important to know what specific meaning is being conveyed by the given sentence whenever it’s appearing. This is word sense disambiguation, as we are trying to find out THE sequence.

These are just two of the numerous applications where we would require POS tagging. There are other applications as well which require POS tagging, like Question Answering, Speech Recognition, Machine Translation, and so on.

Now that we have a basic knowledge of different applications of POS tagging, let us look at how we can go about actually assigning POS tags to all the words in our corpus.

Types of POS taggers

POS-tagging algorithms fall into two distinctive groups:

Rule-Based POS Taggers

Stochastic POS Taggers

E. Brill’s tagger, one of the first and most widely used English POS-taggers, employs rule-based algorithms. Let us first look at a very brief overview of what rule-based tagging is all about.

Rule-Based Tagging

Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods.

Typical rule-based approaches use contextual information to assign tags to unknown or ambiguous words. Disambiguation is done by analyzing the linguistic features of the word, its preceding word, its following word, and other aspects.

For example, if the preceding word is an article, then the word in question must be a noun. This information is coded in the form of rules.

Example of a rule:

If an ambiguous/unknown word X is preceded by a determiner and followed by a noun, tag it as an adjective.

Defining a set of rules manually is an extremely cumbersome process and is not scalable at all. So we need some automatic way of doing this.

The Brill’s tagger is a rule-based tagger that goes through the training data and finds out the set of tagging rules that best define the data and minimize POS tagging errors. The most important point to note here about Brill’s tagger is that the rules are not hand-crafted, but are instead found out using the corpus provided. The only feature engineering required is a set of rule templates that the model can use to come up with new features.

Let’s move ahead now and look at Stochastic POS tagging.

Stochastic Part-of-Speech Tagging

The term ‘stochastic tagger’ can refer to any number of different approaches to the problem of POS tagging. Any model which somehow incorporates frequency or probability may be properly labelled stochastic.

The simplest stochastic taggers disambiguate words based solely on the probability that a word occurs with a particular tag. In other words, the tag encountered most frequently in the training set with the word is the one assigned to an ambiguous instance of that word. The problem with this approach is that while it may yield a valid tag for a given word, it can also yield inadmissible sequences of tags.

An alternative to the word frequency approach is to calculate the probability of a given sequence of tags occurring. This is sometimes referred to as the n-gram approach, referring to the fact that the best tag for a given word is determined by the probability that it occurs with the n previous tags. This approach makes much more sense than the one defined before, because it considers the tags for individual words based on context.

The next level of complexity that can be introduced into a stochastic tagger combines the previous two approaches, using both tag sequence probabilities and word frequency measurements. This is known as the Hidden Markov Model (HMM).

Before proceeding with what is a Hidden Markov Model, let us first look at what is a Markov Model. That will better help understand the meaning of the term Hidden in HMMs.

Markov Model

Say that there are only three kinds of weather conditions, namely

Rainy

Sunny

Cloudy

Now, since our young friend we introduced above, Peter, is a small kid, he loves to play outside. He loves it when the weather is sunny, because all his friends come out to play in the sunny conditions.

He hates the rainy weather for obvious reasons.

Every day, his mother observe the weather in the morning (that is when he usually goes out to play) and like always, Peter comes up to her right after getting up and asks her to tell him what the weather is going to be like. Since she is a responsible parent, she want to answer that question as accurately as possible. But the only thing she has is a set of observations taken over multiple days as to how weather has been.

How does she make a prediction of the weather for today based on what the weather has been for the past N days?

Say you have a sequence. Something like this:

Sunny, Rainy, Cloudy, Cloudy, Sunny, Sunny, Sunny, Rainy

So, the weather for any give day can be in any of the three states.

Let’s say we decide to use a Markov Chain Model to solve this problem. Now using the data that we have, we can construct the following state diagram with the labelled probabilities.",https://cdn-images-1.medium.com/max/1200/1*f6e0uf5PX17pTceYU4rbCA.jpeg,[],https://medium.freecodecamp.org/an-introduction-to-part-of-speech-tagging-and-the-hidden-markov-model-953d45338f24?source=collection_home---6------3----------------,2018-06-08 19:31:14.123000+00:00

Data,A deep dive into part-of-speech tagging using the Viterbi algorithm,['Sachin Malhotra'],"Welcome back, Caretaker!

In case you’ve forgotten the problem we were trying to tackle in the previous article, let us revise it for you.

So there’s this naughty kid Peter and he’s going to pester his new caretaker, you!

As a caretaker, one of the most important tasks for you is to tuck Peter in bed and make sure he is sound asleep. Once you’ve tucked him in, you want to make sure that he’s actually asleep and not up to some mischief.

You cannot, however, enter the room again, as that would surely wake Peter up. All you can hear are the noises that might come from the room.

Either the room is quiet or there is noise coming from the room. These are your states.

All you have as the caretaker are:

a set of observations, which is basically a sequence containing noise or quiet over time, and

or over time, and A state diagram provided by Peter’s mom — who happens to be a neurological scientist — that contains all the different sets of probabilities that you can use to solve the problem defined below.

The problem

Given the state diagram and a sequence of N observations over time, we need to tell the state of the baby at the current point in time. Mathematically, we have N observations over times t0, t1, t2 .... tN . We want to find out if Peter would be awake or asleep, or rather which state is more probable at time tN+1 .

In case any of this seems like Greek to you, go read the previous article to brush up on the Markov Chain Model, Hidden Markov Models, and Part of Speech Tagging.

The state diagram that Peter’s mom gave you before leaving.

In that previous article, we had briefly modeled the problem of Part of Speech tagging using the Hidden Markov Model.

The problem of Peter being asleep or not is just an example problem taken up for a better understanding of some of the core concepts involved in these two articles. At the core, the articles deal with solving the Part of Speech tagging problem using the Hidden Markov Models.

So, before moving on to the Viterbi Algorithm, let’s first look at a much more detailed explanation of how the tagging problem can be modeled using HMMs.

Generative Models and the Noisy Channel Model

A lot of problems in Natural Language Processing are solved using a supervised learning approach.

Supervised problems in machine learning are defined as follows. We assume training examples (x(1), y(1)) . . . (x(m) , y(m)) , where each example consists of an input x(i) paired with a label y(i) . We use X to refer to the set of possible inputs, and Y to refer to the set of possible labels. Our task is to learn a function f : X → Y that maps any input x to a label f(x).

In tagging problems, each x(i) would be a sequence of words X1 X2 X3 …. Xn(i) , and each y(i) would be a sequence of tags Y1 Y2 Y3 … Yn(i) (we use n(i)to refer to the length of the i’th training example). X would refer to the set of all sequences x1 . . . xn, and Y would be the set of all tag sequences y1 . . . yn. Our task would be to learn a function f : X → Y that maps sentences to tag sequences.

An intuitive approach to get an estimate for this problem is to use conditional probabilities. p(y | x) which is the probability of the output y given an input x. The parameters of the model would be estimated using the training samples. Finally, given an unknown input x we would like to find

f(x) = arg max(p(y | x)) ∀y ∊ Y

This here is the conditional model to solve this generic problem given the training data. Another approach that is mostly adopted in machine learning and natural language processing is to use a generative model.

Rather than directly estimating the conditional distribution p(y|x) , in generative models we instead model the joint probability p(x, y) over all the (x, y) pairs.

We can further decompose the joint probability into simpler values using Bayes’ rule:

p(y) is the prior probability of any input belonging to the label y.

is the prior probability of any input belonging to the label y. p(x | y) is the conditional probability of input x given the label y.

We can use this decomposition and the Bayes rule to determine the conditional probability.

Remember, we wanted to estimate the function

f(x) = arg max( p(y|x) ) ∀y ∊ Y

f(x) = arg max( p(y) * p(x | y) )

The reason we skipped the denominator here is because the probability p(x) remains the same no matter what the output label being considered. And so, from a computational perspective, it is treated as a normalization constant and is normally ignored.

Models that decompose a joint probability into terms p(y) and p(x|y) are often called noisy-channel models. Intuitively, when we see a test example x, we assume that it has been generated in two steps:

first, a label y has been chosen with probability p(y) second, the example x has been generated from the distribution p(x|y). The model p(x|y) can be interpreted as a “channel” which takes a label y as its input, and corrupts it to produce x as its output.

Generative Part of Speech Tagging Model

Let us assume a finite set of words V and a finite sequence of tags K. Then the set S will be the set of all sequence, tags pairs <x1, x2, x3 ... xn, y1, y2, y3, ..., yn> such that n > 0 ∀x ∊ V and ∀y ∊ K .

A generative tagging model is then the one where

2.

Given a generative tagging model, the function that we talked about earlier from input to output becomes

Thus for any given input sequence of words, the output is the highest probability tag sequence from the model. Having defined the generative model, we need to figure out three different things:

How exactly do we define the generative model probability p(<x1, x2, x3 ... xn, y1, y2, y3, ..., yn>) How do we estimate the parameters of the model, and How do we efficiently calculate

Let us look at how we can answer these three questions side by side, once for our example problem and then for the actual problem at hand: part of speech tagging.

Defining the Generative Model

Let us first look at how we can estimate the probability p(x1 .. xn, y1 .. yn) using the HMM.

We can have any N-gram HMM which considers events in the previous window of size N.

The formulas provided hereafter are corresponding to a Trigram Hidden Markov Model.

Trigram Hidden Markov Model

A trigram Hidden Markov Model can be defined using

A finite set of states.

A sequence of observations.

q(s|u, v)

Transition probability defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations.

defined as the probability of a state “s” appearing right after observing “u” and “v” in the sequence of observations. e(x|s)

Emission probability defined as the probability of making an observation x given that the state was s.

Then, the generative model probability would be estimated as

As for the baby sleeping problem that we are considering, we will have only two possible states: that the baby is either awake or he is asleep. The caretaker can make only two observations over time. Either there is noise coming in from the room or the room is absolutely quiet. The sequence of observations and states can be represented as follows:

Observations and States over time for the baby sleeping problem

Coming on to the part of speech tagging problem, the states would be represented by the actual tags assigned to the words. The words would be our observations. The reason we say that the tags are our states is because in a Hidden Markov Model, the states are always hidden and all we have are the set of observations that are visible to us. Along similar lines, the sequence of states and observations for the part of speech tagging problem would be

Observations and States over time for the POS tagging problem

Estimating the model’s parameters

We will assume that we have access to some training data. The training data consists of a set of examples where each example is a sequence consisting of the observations, every observation being associated with a state. Given this data, how do we estimate the parameters of the model?

Estimating the model’s parameters is done by reading various counts off of the training corpus we have, and then computing maximum likelihood estimates:

Transition probability and Emission probability for a Trigram HMM

We already know that the first term represents transition probability and the second term represents the emission probability. Let us look at what the four different counts mean in the terms above.

c(u, v, s) represents the trigram count of states u, v and s. Meaning it represents the number of times the three states u, v and s occurred together in that order in the training corpus. c(u, v) following along similar lines as that of the trigram count, this is the bigram count of states u and v given the training corpus. c(s → x) is the number of times in the training set that the state s and observation x are paired with each other. And finally, c(s) is the prior probability of an observation being labelled as the state s.

Let us look at a sample training set for the toy problem first and see the calculations for transition and emission probabilities using the same.

The BLUE markings represent the transition probability, and RED is for emission probability calculations.

Note that since the example problem only has two distinct states and two distinct observations, and given that the training set is very small, the calculations shown below for the example problem are using a bigram HMM instead of a trigram HMM.

Peter’s mother was maintaining a record of observations and states. And thus she even provided you with a training corpus to help you get the transition and emission probabilities.

Transition Probability Example:

Training Corpus

Calculations for Awake appearing after Awake

Emission Probability Example:

Training corpus

Calculations for observing ‘Quiet’ when the state is ‘Awake’

That was quite simple, since the training set was very small. Let us look at a sample training set for our actual problem of part of speech tagging. Here we can consider a trigram HMM, and we will show the calculations accordingly.

We will use the following sentences as a corpus of training data (the notation word/TAG means word tagged with a specific part-of-speech tag).

The training set that we have is a tagged corpus of sentences. Every sentence consists of words tagged with their corresponding part of speech tags. eg:- eat/VB means that the word is “eat” and the part of speech tag in this sentence in this very context is “VB” i.e. Verb Phrase. Let us look at a sample calculation for transition probability and emission probability just like we saw for the baby sleeping problem.

Transition Probability

Let’s say we want to calculate the transition probability q(IN | VB, NN). For this, we see how many times we see a trigram (VB,NN,IN) in the training corpus in that specific order. We then divide it by the total number of times we see the bigram (VB,NN) in the corpus.

Emission Probability

Let’s say we want to find out the emission probability e(an | DT). For this, we see how many times the word “an” is tagged as “DT” in the corpus and divide it by the total number of times we see the tag “DT” in the corpus.

So if you look at these calculations, it shows that calculating the model’s parameters is not computationally expensive. That is, we don’t have to do multiple passes over the training data to calculate these parameters. All we need are a bunch of different counts, and a single pass over the training corpus should provide us with that.

Let’s move on and look at the final step that we need to look at given a generative model. That step is efficiently calculating

We will be looking at the famous Viterbi Algorithm for this calculation.

Finding the most probable sequence — Viterbi Algorithm

Finally, we are going to solve the problem of finding the most likely sequence of labels given a set of observations x1 … xn. That is, we are to find out

The probability here is expressed in terms of the transition and emission probabilities that we learned how to calculate in the previous section of the article. Just to remind you, the formula for the probability of a sequence of labels given a sequence of observations over “n” time steps is

Before looking at an optimized algorithm to solve this problem, let us first look at a simple brute force approach to this problem. Basically, we need to find out the most probable label sequence given a set of observations out of a finite set of possible sequences of labels. Let’s look at the total possible number of sequences for a small example for our example problem and also for a part of speech tagging problem.

Say we have the following set of observations for the example problem.

Noise Quiet Noise

We have two possible labels {Asleep and Awake}. Some of the possible sequence of labels for the observations above are:

Awake Awake Awake

Awake Awake Asleep

Awake Asleep Awake

Awake Asleep Asleep

In all we can have ²³ = 8 possible sequences. This might not seem like very many, but if we increase the number of observations over time, the number of sequences would increase exponentially. This is the case when we only had two possible labels. What if we have more? As is the case with part of speech tagging.

For example, consider the sentence

the dog barks

and assuming that the set of possible tags are {D, N, V}, let us look at some of the possible tag sequences:

D D D

D D N

D D V

D N D

D N N

D N V ... etc

Here, we would have ³³ = 27 possible tag sequences. And as you can see, the sentence was extremely short and the number of tags weren’t very many. In practice, we can have sentences that might be much larger than just three words. Then the number of unique labels at our disposal would also be too high to follow this enumeration approach and find the best possible tag sequence this way.

So the exponential growth in the number of sequences implies that for any reasonable length sentence, the brute force approach would not work out as it would take too much time to execute.

Instead of this brute force approach, we will see that we can find the highest probable tag sequence efficiently using a dynamic programming algorithm known as the Viterbi Algorithm.

Let us first define some terms that would be useful in defining the algorithm itself. We already know that the probability of a label sequence given a set of observations can be defined in terms of the transition probability and the emission probability. Mathematically, it is

Let us look at a truncated version of this which is

and let us call this the cost of a sequence of length k.

So the definition of “r” is simply considering the first k terms off of the definition of probability where k ∊ {1..n} and for any label sequence y1…yk.

Next we have the set S(k, u, v) which is basically the set of all label sequences of length k that end with the bigram (u, v) i.e.

Finally, we define the term π(k, u, v) which is basically the sequence with the maximum cost.

The main idea behind the Viterbi Algorithm is that we can calculate the values of the term π(k, u, v) efficiently in a recursive, memoized fashion. In order to define the algorithm recursively, let us look at the base cases for the recursion.

π(0, *, *) = 1

π(0, u, v) = 0

Since we are considering a trigram HMM, we would be considering all of the trigrams as a part of the execution of the Viterbi Algorithm.

Now, we can start the first trigram window from the first three words of the sentence but then the model would miss out on those trigrams where the first word or the first two words occurred independently. For that reason, we consider two special start symbols as * and so our sentence becomes

* * x1 x2 x3 ...... xn

And the first trigram we consider then would be (*, *, x1) and the second one would be (*, x1, x2).

Now that we have all our terms in place, we can finally look at the recursive definition of the algorithm which is basically the heart of the algorithm.",https://cdn-images-1.medium.com/max/1200/1*x-5ZBtUvlD78BOMuMnMAbg.png,[],https://medium.freecodecamp.org/a-deep-dive-into-part-of-speech-tagging-using-viterbi-algorithm-17c8de32e8bc?source=collection_home---6------4----------------,2018-06-08 19:05:31.518000+00:00

Data,A quick introduction to OAuth using Passport.js – freeCodeCamp,['Arun Kumar'],"A quick introduction to OAuth using Passport.js

What is OAuth?

OAuth (Open Authorization) is an authorization protocol. A third party application can use it to access user data from a site (like Google or Twitter) without revealing their password. Sites like Quora, Medium, AirBnb and many others offer authentication using OAuth.

OAuth really makes our lives simpler by eliminating the need to remember the password of every account you create on almost any site. You just have to remember your OAuth provider’s main account password.

What is Passport.js?

Passport is a middleware which implements authentication on Express-based web applications. It provides over 500+ strategies. What are these strategies? Strategies are used to authenticate requests. Each strategy has its own npm package (such as passport-twitter, passport-google-oauth20). A strategy must be configured before usage.

Why use Passport.js?

Here are six reasons stating why you should use Passport:

It is lightweight

Easily configurable

Supports persistent sessions

Offers OAuth

Provides separate modules for each strategy

Gives you the ability to implement custom strategies

Let’s build something

To get started, we need to install passport from NPM:

npm install passport

We are going to build a simple app which grants the user access to a secret route only if they log in. I’m going to be using the passport-google-oauth20 strategy in this tutorial. Feel free to use any other strategy you prefer, but make sure to check the docs to see how it is configured.

Before continuing, we need a clientID and clientSecret. To get one, head over to https://console.developers.google.com and create a new project. Then go to Enable APIs and Services and enable the Google+ API. Select the API and click on create credentials.

Fill out the form and use the same callback URL on both the form and on your file. Make sure to read the comments on the code to figure out how everything fits together.

app.js

index.ejs

As you can see, we’ve created a /secret route, and only grant access to it if the user is authenticated. To verify whether the user is authenticated, we’ve created a middleware which checks if the request has the user object in it. Finally, to log out we used the req.logout() method provided by passport to clear the session.

Here are some resources to learn more about passport

Complete Passport.js tutorial series

Conclusion

We only saw one strategy here. There are 500+ more. I highly recommend that you skim through Passport’s official documentation and find out what else they offer. Thank you for taking your time to read this. Feel free to connect with me on LinkedIn, Twitter and GitHub. I wish you good luck!

“Do what is great, written on a computer monitor.” by Martin Shreder on Unsplash

Previous article",https://cdn-images-1.medium.com/max/1200/0*gWsdm7w5PSZNR08L,[],https://medium.freecodecamp.org/a-quick-introduction-to-oauth-using-passport-js-65ea5b621a?source=collection_home---6------5----------------,2018-06-07 22:11:44.925000+00:00

Data,How to control your randomizer in R – freeCodeCamp,['Michelle Jones'],"What happens when you need a particular type of randomization?

Overview of random number generation in R

R has at least 20 random number generator functions. Each uses a specific probability distribution to create the numbers. All require you to specify the number of random numbers you want (the above image shows 200). All are available in base R — no packages required.

Common random number generator distributions are:

normal (rnorm): default mean of 0 and standard deviation of 1

binomial (rbinom): no defaults, specify the number of trials and the probability of success on each trial

uniform (runif): default minimum value of 0 and maximum value of 1

Of the three above, only the binomial random number generator creates integers.

Why create random numbers?

Problems involving random numbers are very common — there are around 50,000 questions relating to random numbers on Stack Exchange.

But why use them?

Random numbers have many practical applications. They are used in Monte Carlo simulations. They are used in cryptography. They have been used to produce CAPTCHA content. They are used in slot machines. They have also been used for more mundane tasks such as creating a random sort order for an array of ordered data.

Problems with random numbers

Common questions include “are my random numbers actually random?” and “how can I generate non-repeated random numbers?”

Note: the latter decreases randomness, because the population of possible random numbers is decreased by one each time a random number is drawn. The method is appropriate in situations such as lotteries or bingo, where each ticket or ball can only be drawn once.

This problem brings in another problem! The randomly generated, sampling without replacement numbers must be integers. No one has ticket 5.6932 or bingo ball 0.18967.

A practical example of random number problems

Let’s take the example that I have 20 female students of the same age. I have four teaching methods that I want to trial. I only want to trial one teaching method for each student. Easy math— I need five students in each group.

But how do I do this so that each student is randomly assigned?

And how do I make sure that I only have integers produced?

And how do I do all this while using randomly generated numbers without replacement? I don’t want, for example, six students in one group, and four students in another.

First, I need to create some dummy data, in R. Let’s create that list of mock female students.

FemaleStudents <- data.frame(Names=c(""Alice"", ""Betty"", ""Carol"", ""Denise"", ""Erica"", ""Frances"", ""Gina"", ""Helen"", ""Iris"", ""Julie"", ""Katherine"",

""Lisa"", ""Michelle"", ""Ngaire"", ""Olivia"", ""Penelope"", ""Rachel"", ""Sarah"", ""Trudy"", ""Uma""))

Now we have a one-dimensional dataset of our 20 students.

We know that the runif() function doesn’t create integers. Why don’t we round the random numbers so that we only get integers and use this function? We can wrap the random number in a rounding function.

Question 1: why am I using the random uniform distribution and not another one, such as the random normal distribution?

There are five types of rounding functions in R. We will use round() .

So that we get the same results, I will set a seed for the random number generation. Each time we generate random numbers, we will use the same seed. I’ve decided on 5 as the seed. If you do not set a seed, or if you set a seed other than 5, your results will be different than mine.

set.seed(5)

FemaleStudents$Group <- round(runif(20, 1, 5))

Well, that seemed to work. We have each student allocated to a group numbered between 1 and 5.

Let’s double check our allocation.

table(FemaleStudents$Group)

1 2 3 4 5

2 6 5 4 3

Darn. Only one of the five groups has the correct number of students (Group 4). Why did this happen?

We can check the numbers actually output by runif() without rounding, and letting the output print to the console. Here, the output prints because I have not assigned the function to an object (for example, to a data.frame variable).

set.seed(5)

runif(20,1,5)

[1] 1.800858 3.740874 4.667503 2.137598 1.418601 3.804230 3.111840 4.231741 4.826001 1.441812 2.093140 2.962053 2.273616 3.236691 2.050373

[16] 1.807501 2.550103 4.551479 3.219690 4.368718

As we can see, the rounding caused our problem. But if we hadn’t rounded, each student would have been assigned to a different group.

What do we do?

sample()

sample() is now one of my favourite functions in R. Let’s see how it works.

Randomly allocate to equally sized groups (counts matter)

How can we use it to randomly assign our 20 students to four equally sized groups?

What happens if we try sample() normally?

set.seed(5)

FemaleStudents$Sample <- sample(1:5, nrow(FemaleStudents), replace=TRUE)

Question 2: what output did you get when you used table(FemaleStudents$Sample) ?

We can fix this problem by creating a vector of group numbers, and then using sampling without replacement from this vector. The rep command is used to create a range of repeated values. You can use it to repeat each number in the series, as I have used here. Number 1 is repeated four times, then number 2 is repeated four times, and so forth. You can also use it to repeat a sequence of numbers, if you use this code instead: rep(1:5,4)

OurGroups <- rep(1:5, each=4)

set.seed(5)

FemaleStudents$Sample <- sample(OurGroups, nrow(FemaleStudents), replace=FALSE)

We used our vector of numbers ( OurGroups ) to allocate our students to groups. We used sampling without replacement ( replace=FALSE ) from OurGroups because we need to use each value in that vector. We need to remove each value as we use it.

And we get the result we wanted!

table(FemaleStudents$Sample)

1 2 3 4 5

4 4 4 4 4

Question 3: why did I still set a seed?

Another advantage of sample() is that it doesn’t care about type. We can repeat the allocation using a vector of strings. This can be useful if you don’t want to keep referring back to what “1” means.

OurNamedGroups <- rep(c(""Up"", ""Down"", ""Charmed"", ""Strange"", ""Top""), each=4)

set.seed(5)

FemaleStudents$Sample2 <- sample(OurNamedGroups, nrow(FemaleStudents), replace=FALSE)

table(FemaleStudents$Sample2)

Charmed Down Strange Top Up

4 4 4 4 4

Because we used the same seed, we can see that the same student allocation was performed, irrespective of whether we used numeric or character data for the assignment.

table(FemaleStudents$Sample,FemaleStudents$Sample2)



Charmed Down Strange Top Up

1 0 0 0 0 4

2 0 4 0 0 0

3 4 0 0 0 0

4 0 0 4 0 0

5 0 0 0 4 0

Randomly allocate when group size is not restricted

Sometimes we want to randomly allocate to groups, but we don’t have a vector of groups. We are still only allocating each unit (person, sheep, block of cheese) to a single group, and we use completely random allocation.

Let’s say that our school has a new, special library room. It’s been constructed to be soundproof to give students a better studying environment. The chief librarian would like to know about the experiences of students in that room. The only problem is that the room is limited in size. The chief librarian thinks that around four students is a large enough group to provide the initial feedback.

Again, we can use sample() to pick our student groups. In this case, we have “students who will test the room” and “students who won’t test the room”. I’m going to call them “Test” and “Not test”. These labels have been chosen for being 1. short and 2. easily distinguished.

Because we did sampling without replacement earlier, we didn’t specify probabilities of assignment to groups — we simply pulled out an assignment from a vector. Now we are going to use sampling with replacement. With replacement refers to the group, not to the students.

We need to sample with replacement as we only have two groups (“Test”, “Not test”) and 20 students. If we tried to sample without replacement, our code would error.

Our code is very similar:

set.seed(5)

FemaleStudents$Library <- sample(c(""Test"", ""Not test""), nrow(FemaleStudents), replace=TRUE, prob=c(4/20,16/20))

table(FemaleStudents$Library)

Not test Test

15 5

As you can see, we allocated five students to test the room, not four. This type of result is expected when dealing with small samples. However, our allocation of students is completely random. Each student had exactly the same probability of being assigned to test the room. Whether previous students were testers or not had no impact on the allocation of the next student.

Let’s walk through some of that code.

I’ve constructed a new variable in the data.frame to collect the allocation ( Library ).

Instead of dealing with numbers for group names, I’ve used the strings I mentioned earlier. Because I’ve used strings, the c() must wrap the group names ( “Test”, “Not test” ) and each group name is separated by a comma.

Replacement has been set to TRUE .

The probability of assignment to either group must be provided. This is the prob=c(4/20,16/20) part of the sample() function. Again, note how c() is used to contain the probabilities. Also of interest is that the probabilities can be expressed as fractions, rather than decimals.

Hooray for sample()

I use sample() all the time for the work I am doing. The ability to use strings, as well as to restrict numeric output to integers (and define the desired integer range), provides me with more control than trying to use one of the random number functions.

Answers

Answer 1: I used a random uniform distribution because I wanted each value to be equally probable.

Answer 2: I got this output:

1 2 3 4 5

2 7 4 2 5

Answer 3: If we don’t set a seed value, or we use a different one, the allocation of specific students will be different. For example, when the seed is 5, Alice is allocated to group 2. If the seed is 7, Alice is allocated to group 5. Replication is important when code needs to be re-run (for example, in testing).",https://cdn-images-1.medium.com/max/1200/1*aI6mpoboOmJMKqvEU593xA.png,[],https://medium.freecodecamp.org/how-to-control-your-randomizer-in-r-852ae7d8f80c?source=collection_home---6------6----------------,2018-06-07 20:10:57.677000+00:00

Data,How to style your webpage or markdown like a Medium article — or however you want,[],"View the respective pages at: https://github.com/ryandav/link-formatter/ and https://ryandav.github.io/link-formatter/

Get started with Sass at https://sass-lang.com/guide",https://cdn-images-1.medium.com/max/1200/1*L8PQs8ubyxZVIr1EC-cZ6Q.png,[],https://medium.freecodecamp.org/style-webpage-or-markdown-like-medium-article-using-html-css-sass-bootstrap-c6f9e64c0955?source=collection_home---6------7----------------,2018-06-07 19:32:27.295000+00:00

Data,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------,2018-06-07 17:57:40.375000+00:00

Data,Learn how to use the Vue.js CLI – freeCodeCamp,['Flavio Copes'],"Learn how to use the Vue.js CLI Image source. Vue is a very impressive project. In addition to the core of the framework, it maintains a lot of utilities that make a Vue programmer’s life easier. One of them is the Vue Command Line Interface (CLI). Note: There is a huge rework of the CLI going on right now, going from version 2 to 3. While not yet stable, I will describe version 3 because it’s a huge improvement over version 2, and quite different. Installation The Vue CLI is a command line utility, and you install it globally using npm: npm install -g @vue/cli or using yarn: yarn global add @vue/cli Once you do so, you can invoke the vue command.

What does the Vue CLI provide? The CLI is essential for rapid Vue.js development. Its main goal is to make sure all the tools you need are working along, to perform what you need. It abstracts away all the nitty-gritty configuration details that using each tool in isolation would require. It can perform an initial project setup and scaffolding. It’s a flexible tool. Once you create a project with the CLI, you can go and tweak the configuration, without having to eject your application (like you’d do with create-react-app ). You can configure anything and still be able to upgrade with ease. After you create and configure the app, it acts as a runtime dependency tool, built on top of webpack. The first encounter with the CLI is when creating a new Vue project. How to use the CLI to create a new Vue project The first thing you’re going to do with the CLI is to create a Vue app: vue create example The cool thing is that it’s an interactive process. You need to pick a preset. By default, there is one preset that’s providing Babel and ESLint integration: I’m going to press the down arrow ⬇️ and manually choose the features I want: Press space to on each feature you need, and then press enter to go on. Since I chose “Linter/Formatter”, Vue CLI prompts me for the configuration. I chose “ESLint + Prettier” since that’s my favorite setup: The next step is choosing how to apply linting. I chose “Lint on save”. Next up: testing. I picked testing, and Vue CLI offers me the two most popular solutions to choose from: “Mocha + Chai” vs “Jest”. Vue CLI asks me where to put all the configuration. The choices are in the “package.json” file, or in dedicated configuration files, one for each tool. I chose the latter. Next, Vue CLI asks me if I want to save these presets, and allows me to pick them as a choice the next time I use Vue CLI to create a new app. It’s a very convenient feature. Having a quick setup with all my preferences is a complexity reliever: Vue CLI then asks me if I prefer using yarn or npm: and it’s the last thing it asks me. It then it goes on to download the dependencies and create the Vue app: How to start the newly created Vue CLI application Vue CLI has created the app for us, and we can go in the “example” folder and run yarn serve to start up our first app in development mode:

The starter example application source contains a few files, including “package.json”:",https://cdn-images-1.medium.com/max/1200/1*tAKfoNTaWdTFxxFgOlXHfg.png,[],https://medium.freecodecamp.org/learn-how-to-use-the-vue-js-cli-8349fb23a566?source=collection_home---6------8----------------#--responses,2018-06-07 17:57:40.375000+00:00

Data,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------,2018-06-07 15:39:54.084000+00:00

Data,How to avoid the shameful look your site has on Twitter and Facebook,['Ohans Emmanuel'],"How to avoid the shameful look your site has on Twitter and Facebook

Photo by Hannes Wolf on Unsplash

If you already understand what Facebook Open Graph and Twitter Cards are, this article is not aimed at you. Please pass it on to someone who doesn’t understand what those are. Introduction According to Mashable, 52% of shared links on Twitter are articles and images, with images taking about 36% of the pie. On the average, people are sharing about 30 million unique images per day. From Mashable Did you gasp? I did. Tweets with image links get 2x the engagement rate of those without, says Buffer. Now, these stats are just for Twitter. The combined stats for other popular social media platforms will blow your mind. Bottom line is: humans are visual beings. If your site is shared on social media, and it looks like a boring sour stew, the engagement will be low. Share a link that appears nicely in people’s timeline, and you are more likely to get the kind of engagement you seek. Not taking these into consideration when building your site? You’re definitely doing something wrong. What exactly is the shaming look? Well, not all links are created equal. Consider the graphics below. They represent the appearance of two different links shared on Twitter. One is from Medium, the other from a website of mine.

This is a shared medium article, and it definitely looks good!

The previous graphic has a large image, title, description, and looks good generally.

Here’s my own website link shared and this doesn’t look as good. Sad stuff :(

This just doesn’t look as good. So, what’s Medium doing under the hood to make their shared URLs look great? Going from zero to hero Let’s take a step-by-step approach to taking a site from “shaming look” to “freaking awesome”. For our considerations, I’ll be using one of my sites, TheReduxJSBooks.com , as the lab rat. First, to preview how your link preview will be displayed on Twitter and Facebook, both companies provide debuggers where you paste in your link and have a look for yourself. Here’s the link for the Facebook Sharing debugger, and this for Twitter. Starting at “zero”, let’s see what TheReduxJSBooks.com looks like when shared now. Here’s what we’ve got on facebook: The poor look when shared on Facebook (FB). As simulated on the FB sharing debugger, FB managed to display the URL and the first bit of text on the website And this on Twitter: So bad — no previews are shown :( Twitter doesn’t pull out any info from the site. You gotta do the work. Those don’t look impressive at the moment, but we will fix that shortly. To have some control over how your links look when shared, Facebook developed the technology called Open Graph. It’s nearly becoming a standard across other services, and not just Facebook. Twitter calls theirs something different, Twitter Cards. Let’s see how these work. Facebook Open Graph In the simplest of terms, the Facebook Open Graph is all about including certain meta tags to the head of your html . These metadata will be read from your site, and they affect how your link is previewed when shared. Now, have a look at the final results we will achieve when the link is shared on Facebook.

The final result we’re gunning for.

What’s different now?

Here’s what is different.

Now, that looks beautiful. With a custom image, title, and description, you totally control how your link preview is displayed. Now, here’s the code that yielded the preview you see above: <!-- Facebook Opengraph -->

<meta property=""og:url"" content=""https://thereduxjsbooks.com"" />

<meta property=""og:type"" content=""website"" />

<meta property=""og:title"" content=""The ReduxJS Books"" />

<meta property=""og:description"" content=""What you ar about to view is a complete guide to mastering Redux from total novice to badass, and with every skill level catered for. Ready?""/> <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" />

<meta property=""og:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta property=""og:image:type"" content=""image/png"" />

<meta property=""og:image:width"" content=""1200"" />

<meta property=""og:image:height"" content=""630"" /> I know it feels like a lot of code, but it isn’t. These are placed in the head of your html page. For example <head>

<!-- put them here -->

</head> Now, let’s go over each Open Graph meta tag one after the other. Here’s the first: <meta property=""og:url"" content=""https://thereduxjsbooks.com"" /> What you have there is a meta tag with two attributes, property and content . property defines the property of the meta tag in question. In this case, it has the value, og:url . As you may have guessed, og is short for Open Graph and url denotes that this describes the url of the shared link. The content then holds the value for the url , i.e “https://thereduxjsbooks.com”. That was easy. Now, the same goes for the type , title , and description tags. You see those? The type, title and description tags. The next set of meta tags are those that describe the image preview. The first has a property, og:image , and the content is the URL to the image. <meta property=""og:image"" content=""https://thereduxjsbooks.com/images/redux-trio-1200x630.png"" /> An important thing to note is that, for Facebook Open Graph, you must provide the width and height of the image — preferably 1200px by 630px The other tags just further describe the image’s alt text, type , width , and height . The image’s alt text, type, width and height! Great! Now you know the most important bits of the Facebook Open Graph. Twitter Cards Like Facebook, you also have total control over how your link is displayed when shared on Twitter. If you share your link on Twitter, assuming you already have the Facebook Open Graph meta tags set, you’ll actually get some preview. It may look something like this:

Some basic description is pulled from the Facebook Open Graph meta tags. Not so bad, actually.

Not bad, but not great either. When we are done, here’s what we’ll have on Twitter:

The better result to aim for on Twitter.

As you can see, the preview image is much larger, and the description isn’t as lengthy. Facebook takes in more characters — but not Twitter. So, here are the basic tags you need. <!-- Twitter Card -->

<meta name=""twitter:card"" content=""summary_large_image"" />

<meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" />

<meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

/> Simple! The first meta tag is super important. <meta name=""twitter:card"" content=""summary_large_image"" /> Unlike Facebook Open Graph with the property and content attributes, Twitter cards use name and content attributes. Here, the name is twitter:card and the content, summary_large_image . This describes the type of Twitter card you want. There are many different types of Twitter cards available, but summary_large_image gives you the large image preview you saw earlier. Unlike Facebook, you do not need to describe the image’s width and height Just having the name, twitter:image and content URL will do! <meta name=""twitter:image"" content=""https://thereduxjsbooks.com/images/redux-trio-560x300.png"" /> Finally, just include the image alt text and a shorter description for Twitter. <meta name=""twitter:image:alt"" content=""3 books on ReduxJS. A sequel that takes you from beginner to pro."" />

<meta name=""twitter:description"" content=""For every book you buy, we will send a free copy to a developer in India, Nigeria, and Tunisia who can't afford the cost.""

'' /> And that is it! What’s even more beautiful is that setting this up means other services can equally look up this metadata and display your links beautifully!



Here’s a preview for when the link is shared on Slack.

The same link shared on Slack. That looks good!",https://cdn-images-1.medium.com/max/1200/1*R5gAdbWi_wTP1_zSBjBtYA.jpeg,[],https://medium.freecodecamp.org/how-to-avoid-the-shaming-look-your-site-has-on-twitter-and-facebook-f2e8f4be568d?source=collection_home---6------9----------------#--responses,2018-06-07 15:39:54.084000+00:00

Data,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------,2018-06-06 21:43:33.288000+00:00

Data,How to create a real-world Node CLI app with Node – freeCodeCamp,[],"How to create a real-world Node CLI app with Node

The command line is a user interface that doesn’t get enough attention in the world of JavaScript development. The reality is that most dev tools should have a CLI to be utilized by nerds like us, and the user experience should be on par with that of your meticulously-created web app. This includes a nice design, helpful menus, clean error messages and outputs, loading indicators and progress bars, and so on.

There aren’t many real-world tutorials out there when it comes to building command-line interfaces with Node, so this is the first of a series that will go beyond a basic “hello world” CLI app. We’ll be creating an app called outside-cli , which will give you the current weather and 10-day forecast for any location.

Note: There are several libraries out there which aid in creating complex CLI’s such as oclif, yargs and commander, but we’ll be keeping our dependencies slim for the sake of this example so you can better understand how things are working under the hood. This tutorial assumes you have a basic working knowledge of JavaScript and Node.

Getting started

As with all JavaScript projects, creating a package.json and an entry file is the best way to kick things off. We can keep it simple — no dependencies are needed yet.

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

index.js

module.exports = () => {

console.log('Welcome to the outside!')

}

We’ll need a way to invoke our newly minted app and show the welcome message, as well as add it to the system path so it can be called from anywhere. A bin file is the way to do that.

#!/usr/bin/env node

require('../')()

Never seen #!/usr/bin/env node before? It's called a shebang. It basically tells the system this isn't a shell script and it should use a different interpreter.

It’s important to keep the binary file slim, as it’s only purpose is to invoke the app. All our code should live outside the binary so it can remain modular and testable. It will also help if we want to provide programatic access to our library in the future.

In order to run the bin file directly, we’ll need to give it the correct filesystem permissions. If you’re on UNIX, this is as easy as running chmod +x bin/outside . If you're on Windows, do yourself a favor and use the Linux Subsystem.

Next, we’ll add our binary to the package.json file. This will automatically place it onto the user’s system path when they install our package as a global ( npm install -g outside-cli ).

package.json

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""license"": ""MIT"",

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {}

}

We can now call our bin file directly by running ./bin/outside . You should see the welcome message. Running npm link in the root of your project will symlink your binary file to the system path, making it accessible from anywhere by running outside .

When you run a CLI app, it consists of arguments and commands. Arguments (or “flags”) are the values prepended with one or two hyphens (such as -d , --debug or --env production ) and are useful for passing options to our app. Commands are all the other values that don't have a flag.

Unlike commands, arguments don't need to be specified in any particular order. For example, we could run outside today Brooklyn and just assume that the second command will always be the location--but wouldn't it be better to run outside today --location Brooklyn in case we want to add more options in the future?

In order for our app to be useful at all, we’ll need to parse those commands and arguments, and turn them into an object. We could always jump into process.argv and try to do it ourselves, but let's install our first dependency called minimist to take care of this one for us.

npm install --save minimist

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

console.log(args)

}

Note: The reason we remove the first two arguments with .slice(2) is because the first arg will always be the interpreter followed by the name of the file being interpreted. We only care about the arguments after that.

Now running outside today should output { _: ['today'] } . If you run outside today --location ""Brooklyn, NY"" , it should output { _: ['today'], location: 'Brooklyn, NY' } . We'll go more in-depth with arguments later when we actually use the location, but for now this is enough to set up our first command.

Argument Syntax

To better understand how argument syntax works, you can read this. Basically, a flag can be single or double hyphened, and will take the value immediately following in the command or will equal true when there is no value. Single-hyphen flags can also be combined for short-handed booleans ( -a -b -c or -abc would give you { a: true, b: true, c: true } .)

It’s important to remember that values must be quoted if they contain special characters or a space. Running --foo bar baz would give you `{ : ['baz'], foo: 'bar' } , but running --foo ""bar baz"" would give you { foo: 'bar baz' }`._

It’s a good idea to split up the code for each command and only load it into memory when it is called. This creates faster startup times and prevents unnecessary modules from loading. Easy enough with a switch statement on the main command given to us by minimist. Using this setup, each command file should export a function, and in this case, we’re passing the arguments to each command so we can use them later.

index.js

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))

const cmd = args._[0]



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break

default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

cmds/today.js

module.exports = (args) => {

console.log('today is sunny')

}

Now if you run outside today , you'll see the message ""today is sunny"", and if you run outside foobar , it will tell you that ""foobar"" is not a valid command. We do still need to query a weather API to get real data, but this is a good start.

There are a few commands and arguments that are expected to be in every CLI: help , --help and -h , which should show help menus, and version , --version and -v which should output the current app version. We should also default to a main help menu if no command is specified.

This can be easily implemented in our current setup by adding two cases to our switch statement, a default value for the cmd variable, and implementing some if statements for the help and version argument flags. Minimist automatically parses arguments to key/values, so running outside --version will make args.version equal true.

const minimist = require('minimist')



module.exports = () => {

const args = minimist(process.argv.slice(2))



let cmd = args._[0] || 'help'



if (args.version || args.v) {

cmd = 'version'

}



if (args.help || args.h) {

cmd = 'help'

}



switch (cmd) {

case 'today':

require('./cmds/today')(args)

break



case 'version':

require('./cmds/version')(args)

break



case 'help':

require('./cmds/help')(args)

break



default:

console.error(`""${cmd}"" is not a valid command!`)

break

}

}

To implement our new commands, follow the same format as the today command.

cmds/version.js

const { version } = require('../package.json')



module.exports = (args) => {

console.log(`v${version}`)

}

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,

}



module.exports = (args) => {

const subCmd = args._[0] === 'help'

? args._[1]

: args._[0]



console.log(menus[subCmd] || menus.main)

}

Now if you run outside help today or outside today -h , you should see the help menu for the today command. Running outside or outside -h should show you the main help menu.

This project setup is really awesome because if you need to add a new command, all you need to do is create a new file in the cmds folder, add it to the switch statement, and add a help menu if it has one.

cmds/forecast.js

module.exports = (args) => {

console.log('tomorrow is rainy')

}

index.js

// ...

case 'forecast':

require('./cmds/forecast')(args)

break

// ...

cmds/help.js

const menus = {

main: `

outside [command] <options>



today .............. show weather for today

forecast ........... show 10-day weather forecast

version ............ show package version

help ............... show help menu for a command`,



today: `

outside today <options>



--location, -l ..... the location to use`,



forecast: `

outside forecast <options>



--location, -l ..... the location to use`,

}



// ...

Sometimes a command can take a long time to run. If you’re fetching data from an API, generating content, writing files to the disk, or any other process that takes more than a few milliseconds, you want to give the user some feedback that your app hasn’t frozen and is simply working hard. Sometimes you can measure the progress of your operation and it makes sense to show a progress bar, but other times it’s more variable and makes sense to show a loading indicator instead.

For our app, we can’t measure the progress of our API requests, so we’ll use a basic spinner to show something is happening. Install two more dependencies for our network requests and our spinner:

npm install --save axios ora

Fetching data from the API

Now let’s create a utility that will make a request to the Yahoo weather API for the current conditions and forecast of a location.

Note: The Yahoo API uses “YQL” syntax, and it’s a little funky — don’t try to understand it, just copy and paste. This was the only weather API I could find that didn’t require an API key.

utils/weather.js

const axios = require('axios')



module.exports = async (location) => {

const results = await axios({

method: 'get',

url: 'https://query.yahooapis.com/v1/public/yql',

params: {

format: 'json',

q: `select item from weather.forecast where woeid in

(select woeid from geo.places(1) where text=""${location}"")`,

},

})



return results.data.query.results.channel.item

}

cmds/today.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Current conditions in ${location}:`)

console.log(`\t${weather.condition.temp}° ${weather.condition.text}`)

} catch (err) {

spinner.stop()



console.error(err)

}

}

Now if you run outside today --location ""Brooklyn, NY"" , you'll see a quick spinner while it makes the request, followed by the current weather conditions.

Since the request happens so fast, it can be difficult to see the loading indicator. If you want to manually slow it down for the purpose of seeing it, you can add this line to the beginning of your weather util function: await new Promise(resolve => setTimeout(resolve, 5000)) .

Great! Now let’s copy that code over to our forecast command, and change the formatting a bit.

cmds/forecast.js

const ora = require('ora')

const getWeather = require('../utils/weather')



module.exports = async (args) => {

const spinner = ora().start()



try {

const location = args.location || args.l

const weather = await getWeather(location)



spinner.stop()



console.log(`Forecast for ${location}:`)

weather.forecast.forEach(item =>

console.log(`\t${item.date} - Low: ${item.low}° | High: ${item.high}° | ${item.text}`))

} catch (err) {

spinner.stop()



console.error(err)

}

}

You can now see a 10-day weather forecast when you run outside forecast --location ""Brooklyn, NY"" . Looks good! Let's add one more utility to automatically get our location based off our IP address if no location is specified in the command.

utils/location.js

const axios = require('axios')



module.exports = async () => {

const results = await axios({

method: 'get',

url: 'https://api.ipdata.co',

})



const { city, region } = results.data

return `${city}, ${region}`

}

cmds/today.js & cmds/forecast.js

// ...

const getLocation = require('../utils/location')



module.exports = async (args) => {

// ...

const location = args.location || args.l || await getLocation()

const weather = await getWeather(location)

// ...

}

Now if you simply run outside forecast without a location, you'll see the forecast for your current location.

Error handling

I didn’t go into a lot of detail on how to best handle errors (this will come in a later tutorial), but the most important thing to remember is to use the correct exit codes.

If your CLI ever has a critical error, you should exit with process.exit(1) . This lets the terminal know that the program did not exit cleanly, which will notify you from a CI service, for example.

Let's create a quick utility that does this for us, so we can get the correct exit code when a non-existant command is run.

utils/error.js

module.exports = (message, exit) => {

console.error(message)

exit && process.exit(1)

}

index.js

// ...

const error = require('./utils/error')



module.exports = () => {

// ...

default:

error(`""${cmd}"" is not a valid command!`, true)

break

// ...

}

Finishing up

The last step to getting our library out into the wild is to publish it to a package manager. Since our app is written in JavaScript, it makes sense to publish to NPM. Let’s fill out our package.json a bit more:

{

""name"": ""outside-cli"",

""version"": ""1.0.0"",

""description"": ""A CLI app that gives you the weather forecast"",

""license"": ""MIT"",

""homepage"": ""https://github.com/timberio/outside-cli#readme"",

""repository"": {

""type"": ""git"",

""url"": ""git+https://github.com/timberio/outside-cli.git""

},

""engines"": {

""node"": "">=8""

},

""keywords"": [

""weather"",

""forecast"",

""rain""

],

""preferGlobal"": true,

""bin"": {

""outside"": ""bin/outside""

},

""scripts"": {},

""devDependencies"": {},

""dependencies"": {

""axios"": ""^0.18.0"",

""minimist"": ""^1.2.0"",

""ora"": ""^2.0.0""

}

}

Setting engine will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above.

will ensure anyone installing our app has an updated version of Node. Since we are using async/await syntax without transpilation, we are requiring Node 8.0 or above. Setting preferGlobal will warn the user if installing with npm install --save rather than npm install --global .

That’s it! You can now run npm publish and your app will be available for download. If you want to take this a step further and release on other package managers (such as Homebrew), you can check out pkg or nexe, which help you bundle your app into a self-contained binary.

Summary

This is the structure we follow for all of our CLI apps here at Timber, and it helps keep things organized and modular.

Some key takeaways from this tutorial for those who only skimmed it:

Bin files are the entry point for any CLI app, and should only invoke the main function

Command files shouldn’t be required until they are needed

Always include help and version commands

and commands Keep command files slim — their main purpose is to call functions and show user messages

Always show some kind of activity indicator

Exit with the correct error codes

I hope you now have a better understanding of how to create and organize CLI apps in Node. This is the first part of a series of tutorials, so come back later as we go more in-depth on adding design, ascii art and color, accepting user input, writing integration tests, and more. You can see all the source code we wrote today on GitHub.

We’re a cloud-based logging company here @ Timber. We’d love it if you tried out our product (it’s seriously great! — you can create a free account here), but that’s all we’re going to advertise our product … you guys came here to learn about building a CLI App in Node and hopefully this guide helped you get started.",https://cdn-images-1.medium.com/max/1200/0*2mHsgB-JH_yxlRev.png,[],https://medium.freecodecamp.org/how-to-create-a-real-world-node-cli-app-with-node-391b727bbed3?source=collection_home---6------10----------------#--responses,2018-06-06 21:43:33.288000+00:00

Data,Follow these steps to solve any Dynamic Programming interview problem,['Nikola Otasevic'],"Follow these steps to solve any Dynamic Programming interview problem

Despite having significant experience building software products, many engineers feel jittery at the thought of going through a coding interview that focuses on algorithms. I’ve interviewed hundreds of engineers at Refdash, Google, and at startups I’ve been a part of, and some of the most common questions that make engineers uneasy are the ones that involve Dynamic Programming (DP).

Many tech companies like to ask DP questions in their interviews. While we can debate whether they’re effective in evaluating someone’s ability to perform in an engineering role, DP continues to be an area that trips engineers up on their way to finding a job that they love.

Dynamic Programming — Predictable and Preparable

One of the reasons why I personally believe that DP questions might not be the best way to test engineering ability is that they’re predictable and easy to pattern match. They allow us to filter much more for preparedness as opposed to engineering ability.

These questions typically seem pretty complex on the outside, and might give you an impression that a person who solves them is very good at algorithms. Similarly, people who may not be able to get over some mind-twisting concepts of DP might seem pretty weak in their knowledge of algorithms.

The reality is different, and the biggest factor in their performance is preparedness. So let’s make sure everyone is prepared for it. Once and for all.

7 Steps to solve a Dynamic Programming problem

In the rest of this post, I will go over a recipe that you can follow to figure out if a problem is a “DP problem”, as well as to figure out a solution to such a problem. Specifically, I will go through the following steps:

How to recognize a DP problem Identify problem variables Clearly express the recurrence relation Identify the base cases Decide if you want to implement it iteratively or recursively Add memoization Determine time complexity

Sample DP Problem

For the purpose of having an example for abstractions that I am going to make, let me introduce a sample problem. In each of the sections, I will refer to the problem, but you could also read the sections independently of the problem.

Problem statement:

In this problem, we’re on a crazy jumping ball, trying to stop, while avoiding spikes along the way.

Here are the rules:

1) You’re given a flat runway with a bunch of spikes in it. The runway is represented by a boolean array which indicates if a particular (discrete) spot is clear of spikes. It is True for clear and False for not clear.

Example array representation:

2) You’re given a starting speed S. S is a non-negative integer at any given point, and it indicates how much you will move forward with the next jump.

3) Every time you land on a spot, you can adjust your speed by up to 1 unit before the next jump.

4) You want to safely stop anywhere along the runway (does not need to be at the end of the array). You stop when your speed becomes 0. However, if you land on a spike at any point, your crazy bouncing ball bursts and it’s game over.

The output of your function should be a boolean indicating whether we can safely stop anywhere along the runway.

Step 1: How to recognize a Dynamic Programming problem

First, let’s make it clear that DP is essentially just an optimization technique. DP is a method for solving problems by breaking them down into a collection of simpler subproblems, solving each of those subproblems just once, and storing their solutions. The next time the same subproblem occurs, instead of recomputing its solution, you simply look up the previously computed solution. This saves computation time at the expense of a (hopefully) modest expenditure in storage space.

Recognizing that a problem can be solved using DP is the first and often the most difficult step in solving it. What you want to ask yourself is whether your problem solution can be expressed as a function of solutions to similar smaller problems.

In the case of our example problem, given a point on the runway, a speed, and the runway ahead, we could determine the spots where we could potentially jump next. Furthermore, it seems that whether we can stop from the current point with the current speed depends only on whether we could stop from the point we choose to go to next.

That is a great thing, because by moving forward, we shorten the runway ahead and make our problem smaller. We should be able to repeat this process all the way until we get to a point where it is obvious whether we can stop.

Recognizing a Dynamic Programming problem is often the most difficult step in solving it. Can the problem solution be expressed as a function of solutions to similar smaller problems?

Step 2: Identify problem variables

Now we have established that there is some recursive structure between our subproblems. Next, we need to express the problem in terms of the function parameters and see which of those parameters are changing.

Typically in interviews, you will have one or two changing parameters, but technically this could be any number. A classic example of a one-changing-parameter problem is “determine an n-th Fibonacci number”. Such an example for a two-changing-parameters problem is “Compute edit distance between strings”. If you’re not familiar with these problems, don’t worry about it.

A way to determine the number of changing parameters is to list examples of several subproblems and compare the parameters. Counting the number of changing parameters is valuable to determine the number of subproblems we have to solve. It’s also important in its own right in helping us strengthen the understanding of the recurrence relation from step 1.

In our example, the two parameters that could change for every subproblem are:

Array position (P) Speed (S)

One could say that the runway ahead is changing as well, but that would be redundant considering that the entire non-changing runway and the position (P) carry that information already.

Now, with these 2 changing parameters and other static parameters, we have the complete description of our sub-problems.

Identify the changing parameters and determine the number of subproblems.

Step 3: Clearly express the recurrence relation

This is an important step that many rush through in order to get into coding. Expressing the recurrence relation as clearly as possible will strengthen your problem understanding and make everything else significantly easier.

Once you figure out that the recurrence relation exists and you specify the problems in terms of parameters, this should come as a natural step. How do problems relate to each other? In other words, let’s assume that you have computed the subproblems. How would you compute the main problem?

Here is how we think about it in our sample problem:

Because you can adjust your speed by up to 1 before jumping to the next position, there are only 3 possible speeds, and therefore 3 spots in which we could be next.

More formally, if our speed is S, position P, we could go from (S, P) to:

(S, P + S); # if we do not change the speed (S — 1, P + S — 1); # if we change the speed by -1 (S + 1, P + S + 1); # if we change the speed by +1

If we can find a way to stop in any of the subproblems above, then we can also stop from (S, P). This is because we can transition from (S, P) to any of the above three options.

This is typically a fine level of understanding of the problem (plain English explanation), but you sometimes might want to express the relation mathematically as well. Let’s call a function that we’re trying to compute canStop. Then:

canStop(S, P) = canStop(S, P + S) || canStop(S — 1, P + S — 1) || canStop(S + 1, P + S + 1)

Woohoo, it seems like we have our recurrence relation!

Recurrence relation: Assuming you have computed the subproblems, how would you compute the main problem?

Step 4: Identify the base cases

A base case is a subproblem that doesn’t depend on any other subproblem. In order to find such subproblems, you typically want to try a few examples, see how your problem simplifies into smaller subproblems, and identify at what point it cannot be simplified further.

The reason a problem cannot be simplified further is that one of the parameters would become a value that is not possible given the constraints of the problem.

In our example problem, we have two changing parameters, S and P. Let’s think about what possible values of S and P might not be legal:

P should be within the bounds of the given runway P cannot be such that runway[P] is false because that would mean that we’re standing on a spike S cannot be negative, and a S==0 indicates that we’re done

Sometimes it can be a little challenging to convert assertions that we make about parameters into programmable base cases. This is because, in addition to listing the assertions if you want to make your code look concise and not check for unnecessary conditions, you also need to think about which of these conditions are even possible.

In our example:

P < 0 || P >= length of runway seems like the right thing to do. An alternative could be to consider making P == end of runway a base case. However, it is possible that a problem splits into a subproblem which goes beyond the end of the runway, so we really need to check for inequality. This seems pretty obvious. We can simply check if runway[P] is false. Similar to #1, we could simply check for S < 0 and S == 0. However, here we can reason that it is impossible for S to be < 0 because S decreases by at most 1, so it would have to go through S == 0 case beforehand. Therefore S == 0 is a sufficient base case for the S parameter.

Step 5: Decide if you want to implement it iteratively or recursively

The way we talked about the steps so far might lead you to think that we should implement the problem recursively. However, everything that we’ve talked about so far is completely agnostic to whether you decide to implement the problem recursively or iteratively. In both approaches, you would have to determine the recurrence relation and the base cases.

To decide whether to go iteratively or recursively, you want to carefully think about the trade-offs.

Stack overflow issues are typically a deal breaker and a reason why you would not want to have recursion in a (backend) production system. However, for the purposes of the interview, as long as you mention the trade-offs, you should typically be fine with either of the implementations. You should feel comfortable implementing both.

In our particular problem, I implemented both versions. Here is python code for that:

A recursive solution: (original code snippets can be found here)

An iterative solution: (original code snippets can be found here)

Step 6: Add memoization

Memoization is a technique that is closely associated with DP. It is used for storing the results of expensive function calls and returning the cached result when the same inputs occur again.

Why are we adding memoization to our recursion? We encounter the same subproblems which, without memoization, are computed repeatedly. Those repetitions very often lead to exponential time complexities.

In recursive solutions, adding memoization should feel straightforward. Let’s see why. Remember that memoization is just a cache of the function results. There are times when you want to deviate from this definition in order to squeeze out some minor optimizations, but treating memoization as a function result cache is the most intuitive way to implement it.

This means that you should:

Store your function result into your memory before every return statement Look up the memory for the function result before you start doing any other computation

Here is the code from above with added memoization (added lines are highlighted): (original code snippets can be found here)

In order to illustrate the effectiveness of memoization and different approaches, let’s do some quick tests. I will stress test all three methods that we have seen so far. Here is the set up:

I created a runway of length 1000 with spikes in random places (I chose to have a probability of a spike being in any given spot to be 20%) initSpeed = 30 I ran all functions 10 times and measured the average time of execution

Here are the results (in seconds):

You can see that the pure recursive approach takes about 500x more time than the iterative approach and about 1300x more time than the recursive approach with memoization. Note that this discrepancy would grow rapidly with the length of the runway. I encourage you to try running it yourself.

Step 7: Determine Time complexity

There are some simple rules that can make computing time complexity of a dynamic programming problem much easier. Here are two steps that you need to do:

Count the number of states — this will depend on the number of changing parameters in your problem Think about the work done per each state. In other words, if everything else but one state has been computed, how much work do you have to do to compute that last state?

In our example problem, the number of states is |P| * |S|, where

P is the set of all positions (|P| indicates the number of elements in P)

S is the set of all speeds

The work done per each state is O(1) in this problem because, given all other states, we simply have to look at 3 subproblems to determine the resulting state.

As we noted in the code before, |S| is limited by length of the runway (|P|), so we could say that the number of states is |P|² and because work done per each state is O(1), then the total time complexity is O(|P|²).

However, it seems that |S| can be further limited, because if it were really |P|, it is very clear that stopping would not be possible because you would have to jump the length of the entire runway on the first move.

So let’s see how we can put a tighter bound on |S|. Let’s call maximum speed S. Assume that we’re starting from position 0. How quickly could we stop if we were trying to stop as soon as possible and if we ignore potential spikes?

In the first iteration, we would have to come at least to the point (S-1), by adjusting our speed at zero by -1. From there we would at a minimum go by (S-2) steps forward, and so on.

For a runway of length L, the following has to hold:

=> (S-1) + (S-2) + (S-3) + ….+ 1 < L

=> S*(S-1) / 2 < L

=> S < sqrt(2L + 1)

That is the maximum speed that we could possibly have on a runway of a length L. If we had a speed higher than that, we could not stop even theoretically, irrespective of the position of the spikes.

That means that the total time complexity depends only on the length of the runway L in the following form:

O(L * sqrt(L)) which is better than O(L²)

O(L * sqrt(L)) is the upper bound on the time complexity

Awesome, you made it through! :)

The 7 steps that we went through should give you a framework for systematically solving any dynamic programming problem. I highly recommend practicing this approach on a few more problems to perfect your approach.

Here are some next steps that you can take

Extend the sample problem by trying to find a path to a stopping point. We solved a problem that tells you whether you can stop, but what if you wanted to also know the steps to take in order to stop eventually along the runway? How would you modify the existing implementation to do that? If you want to solidify your understanding of memoization, and understand that it is just a function result cache, you should read about decorators in Python or similar concepts in other languages. Think about how they would allow you to implement memoization in general for any function that you want to memoize. Work on more DP problems by following the steps we went through. You can always find a bunch of them online (ex. LeetCode or GeeksForGeeks). As you practice, keep in mind one thing: learn ideas, don’t learn problems. The number of ideas is significantly smaller and it’s an easier space to conquer which will also serve you much better.

When you feel like you’ve conquered these ideas, check out Refdash where you are interviewed by a senior engineer and get a detailed feedback on your coding, algorithms, and system design.",https://cdn-images-1.medium.com/max/1200/0*DpsbrfUM89M_LHKY.jpg,[],https://medium.freecodecamp.org/follow-these-steps-to-solve-any-dynamic-programming-interview-problem-cc98e508cd0e?source=collection_home---6------11----------------,2018-06-06 19:32:36.335000+00:00

Data,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------,2018-06-06 17:23:02.015000+00:00

Data,What I learned building three services in three months while working full-time,['Taira Lee'],"What I learned building three services in three months while working full-time

Photo by Lost Co on Unsplash

To give you a bit of a context, I’ll start off with a little bit about me. I’m a self-taught developer currently working in Japan. I’m not special in any way, I don’t have any Internet celebrity friends, but I do love coding and have a positive can-do attitude.

At the end of last year, I decided to launch an experimental project, to try to create one service per month in 2018 in my spare time. I wanted to see if I, an Indie-hacker-wanna-be, could work something out. And here’s my story so far.

I’ll break my discussion of each service into these sections:

How the idea came about

What the service is

Tech stack

How much $ I spent

Lessons learned

January: scratch my own itch.

How the idea came about

The first thing that came to my mind was to build something that I’d use heavily. In the worst case scenario, if my service attracted no one, it would still help me.

I started to look into my day-to-day flow. I realized that I spent quite a lot of time every day going to a variety of websites. So wouldn’t it be nice to have a web service to keep eyes on those sites for me, and send me updates via email? This would help me focus on the important things.

What the service is

Keep Me PPPosted is what I ended up building. To make the service even more user-friendly, I built a Chrome extension as well, which allowed the user to subscribe to updates for any website right on the spot. You can check out the detailed user stories and design decisions on the About page.

Tech stack

I went with what I’m most comfortable with: front-end Vue.js and back-end AWS Lambda Serverless combo. I have been working with these in my current company on a daily basis for the last year and a half. Serverless fits my design very well, considering most parts of my service follow the event-sourcing pattern.

How much I spent

$22 in total: $7 for the domain, $10 for the Sendgrid subscription (100,000 emails per month, I could use it for my other services as well), and a $5 one-time fee for publishing the extension on the Chrome web store. Everything else was covered by the AWS free tier plan.

Lessons learned

It was definitely a valuable learning experience, since it was my very first full-scale web service. I posted it on Indie hackers and got a couple of users. But more importantly, I got the chance to talk directly with my users, working as a developer in the company.

In my job, I never get to talk with my end users to get instant feedback and have full control over the product that I build. That alone was worth the time and effort I put into it.

February: leverage my resources.

How the idea came about

January was pretty tense, so I decided to take it easy. I thought about what else I could offer, besides my half box of chicken wings in my fridge. Something that others might need.

I’m in Japan, and working here might be something developers would be interested in. On top of that, I often get recruiters sending me job opportunities. Connecting developers and recruiters might be something I could work on.

What the service is

Instead of jumping right into coding, I created a mailing list using MailChimp. I started to share my experience in developer communities whenever I got the chance. It worked, and my mailing list grew to 500+ subscribers within a month.

In the meantime, whenever a recruiter reached out to me, I would casually mention my mailing list, and ask if I could share that with my subscribers.

How much I spent

$0. The outgoing mails are covered by the same Sendgrid account, and the backend cron job which was built with AWS Lambda was again covered by my AWS free tier plan.

Lesson learned

It seems that the less time I spent on coding, and the more time on promoting my service, the more potential users I’d get. Two weeks after I started, I got an email from one of my subscribers thanking me for what I did.

He hadn’t gotten a job using the service yet, he just wanted to thank me for sharing that information. That email just warmed my heart, knowing that what I’m doing actually helps others. That’s just the best feeling ever!

March: get ideas from others.

How the idea came about

At this point, I’d kinda run out of ideas. That’s when I started to talk with my non-developer friends. I tried to understand what their day to day life is like, and if there were pain points they have that I could help with.

As part of his job, one of my friends receives CSV files from clients, and then imports those files into an internal system. Often times, the files he receives does not match the requirements, are missing columns, or contain incompatible data types — and so on.

He often has to go back and ask his client to redo and re-send the files. He has tried using Excel to automate the process, but failed because most of the files were really big (300+ MB with 1M+ rows). That sure sounded like something that I could help with.

What the service is

I created CSV Lint, a CSV file validation service for businesses, that allows a user to create a schema easily for validating CSV files once the schema is created. It can be shared with others (who could use it without having an account). This means that once my friend created the schema, he could ask his clients to use it to validate their files before sending them to him.

Tech stack

Instead of AWS, I went with Google Cloud Platform, Firebase for hosting and database, and Google Cloud Functions to handle the backend logic. Once again, their free tier covered everything.

How much I spent

$17 in total. I spent $7 for the domain — and it is a pretty awesome domain, I have to say, patting myself on the back. And another $10 on Udemy for a how to make demo video using a Keynote course. It was money well spent, another new skill learned. 😄

Lessons learned

Ideas that I come up with lead to nothing 9 out of 10 times. Talking with others, especially people outside my normal circle, often helps me get new ideas. However, the sad part is I don’t really have a lot of friends that I can talk to — looks like I’ll need to work on that as well. 😂

Wrapping up

So, that’s my journey so far. None of my projects have succeeded big time, and I’m currently making $0 out of them. But each one of those services is helping people one way or another, and that puts a big smile on my face every day as I go to sleep. Also, they cost me close to nothing, there’s still some chicken wings left in my fridge. All good, all good.

What’s next? I have couple more ideas, and I like to try something different every time. One of the ideas is to create a hands-on online course on building production quality web services / apps using a Serverless stack (both AWS Lambda and Google Cloud Functions). My goal is to show people the whole process, from idea to launch, covering all aspects of creating web services with minimal cost. If that sounds like something you might be interested, sign up to this mailing list to stay informed.",https://cdn-images-1.medium.com/max/1200/1*gxHw9bxhEY-ezPeMC26kOQ.jpeg,[],https://medium.freecodecamp.org/what-i-learned-building-three-services-in-three-months-while-working-full-time-5cf1bbf207d0?source=collection_home---6------12----------------#--responses,2018-06-06 17:23:02.015000+00:00

Data,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------,2018-06-06 16:42:46.938000+00:00

Data,Machine Learning: how to go from Zero to Hero – freeCodeCamp,['Gant Laborde'],"Machine Learning: how to go from Zero to Hero Start with “Why?” and end with “I’m ready!”

If your understanding of A.I. and Machine Learning is a big question mark, then this is the blog post for you. Here, I gradually increase your Awesomenessicity™ by gluing inspirational videos together with friendly text.

Sit down and relax. These videos take time, and if they don’t inspire you to continue to the next section, fair enough.

However, if you find yourself at the bottom of this article, you’ve earned your well-rounded knowledge and passion for this new world. Where you go from there is up to you.

Understanding Why Machine Learning is so HOT Right Now

A.I. was always cool, from moving a paddle in Pong to lighting you up with combos in Street Fighter.

A.I. has always revolved around a programmer’s functional guess at how something should behave. Fun, but programmers aren’t always gifted in programming A.I. as we often see. Just Google “epic game fails” to see glitches in A.I., physics, and sometimes even experienced human players.

Regardless, A.I. has a new talent. You can teach a computer to play video games, understand language, and even how to identify people or things. This tip-of-the-iceberg new skill comes from an old concept that only recently got the processing power to exist outside of theory.

I’m talking about Machine Learning.

You don’t need to come up with advanced algorithms anymore. You just have to teach a computer to come up with its own advanced algorithm.

So how does something like that even work? An algorithm isn’t really written as much as it is sort of… bred. I’m not using breeding as an analogy. Watch this short video, which gives excellent commentary and animations to the high-level concept of creating the A.I.

Wow! Right? That’s a crazy process!

Now how is it that we can’t even understand the algorithm when it’s done? One great visual was when the A.I. was written to beat Mario games. As a human, we all understand how to play a side-scroller, but identifying the predictive strategy of the resulting A.I. is insane.

Impressed? There’s something amazing about this idea, right? The only problem is we don’t know Machine Learning, and we don’t know how to hook it up to video games.

Fortunately for you, Elon Musk already provided a non-profit company to do the latter. Yes, in a dozen lines of code you can hook up any A.I. you want to countless games/tasks!

Why Should You Use Machine Learning?

I have two good answers on why you should care. Firstly, Machine Learning (ML) is making computers do things that we’ve never made computers do before. If you want to do something new, not just new to you, but to the world, you can do it with ML.

Secondly, if you don’t influence the world, the world will influence you.

Right now significant companies are investing in ML, and we’re already seeing it change the world. Thought-leaders are warning that we can’t let this new age of algorithms exist outside of the public eye. Imagine if a few corporate monoliths controlled the Internet. If we don’t take up arms, the science won’t be ours. I think Christian Heilmann said it best in his talk on ML.

“We can hope that others use this power only for good. I — for one, don’t consider this a good bet. I’d rather play and be part of this revolution. And so can you.”

OK, now I’m interested…

The concept is useful and cool. We understand it at a high level, but what the heck is actually happening? How does this work?

If you want to jump straight in, I suggest you skip this section and move on to the next “How Do I Get Started” section. If you’re motivated to be a DOer in ML, you won’t need these videos.

If you’re still trying to grasp how this could even be a thing, the following video is perfect for walking you through the logic, using the classic ML problem of handwriting.",https://cdn-images-1.medium.com/max/1200/1*B8sHUXpYMX7xqiAfVTaAUg.jpeg,[],https://medium.freecodecamp.org/machine-learning-how-to-go-from-zero-to-hero-40e26f8aa6da?source=collection_home---6------13----------------#--responses,2018-06-06 16:42:46.938000+00:00

Data,How to process textual data using TF-IDF in Python – freeCodeCamp,[],"How to process textual data using TF-IDF in Python

Computers are good with numbers, but not that much with textual data. One of the most widely used techniques to process textual data is TF-IDF. In this article, we will learn how it works and what are its features.

From our intuition, we think that the words which appear more often should have a greater weight in textual data analysis, but that’s not always the case. Words such as “the”, “will”, and “you” — called stopwords — appear the most in a corpus of text, but are of very little significance. Instead, the words which are rare are the ones that actually help in distinguishing between the data, and carry more weight.

An introduction to TF-IDF

TF-IDF stands for “Term Frequenct — Inverse Data Frequency”. First, we will learn what this term means mathematically.

Term Frequency (tf): gives us the frequency of the word in each document in the corpus. It is the ratio of number of times the word appears in a document compared to the total number of words in that document. It increases as the number of occurrences of that word within the document increases. Each document has its own tf.

Inverse Data Frequency (idf): used to calculate the weight of rare words across all documents in the corpus. The words that occur rarely in the corpus have a high IDF score. It is given by the equation below.

Combining these two we come up with the TF-IDF score (w) for a word in a document in the corpus. It is the product of tf and idf:

Let’s take an example to get a clearer understanding.

Sentence 1 : The car is driven on the road.

Sentence 2: The truck is driven on the highway.

In this example, each sentence is a separate document.

We will now calculate the TF-IDF for the above two documents, which represent our corpus.

From the above table, we can see that TF-IDF of common words was zero, which shows they are not significant. On the other hand, the TF-IDF of “car” , “truck”, “road”, and “highway” are non-zero. These words have more significance.

Using Python to calculate TF-IDF

Lets now code TF-IDF in Python from scratch. After that, we will see how we can use sklearn to automate the process.",https://cdn-images-1.medium.com/max/1200/1*JTk6iVMiZCQCr8duiaKlHQ.png,[],https://medium.freecodecamp.org/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3?source=collection_home---6------15----------------,2018-06-06 16:07:18.115000+00:00

Data,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------,2018-06-06 01:10:32.658000+00:00

Data,Let’s talk about whiteboarding interviews and the possible alternatives,['Sun-Li Beatteay'],"Let’s talk about whiteboarding interviews and the possible alternatives

It’s not news to anyone that many engineers hate whiteboard-based interview questions.

Whether it’s on Twitter, Medium, or LinkedIn, it’s easy to find someone venting. The phrase “the hiring process is broken” is used so often it’s become a cliché.

Unfortunately, much of this frustration is falling on deaf ears.

Despite the chorus of ire surrounding it, “whiteboarding” is still a staple in software engineering interviews. Part of that is due to the fact that developers are quick to voice their resentment, but slow to offer better alternatives.

Are there better alternatives?

This question has been on my mind a lot recently. Four weeks ago, I landed my first full-time software engineering job. While I’m not involved in the hiring process yet, I will be eventually.

Having been on the other side of the table just a month ago, I understand how imprecise interviewing can be. When it’s my turn to ask the questions, I want to make sure that I evaluate my potential colleagues with accuracy and fairness.

This predicament has led me to two questions:

Are whiteboarding interviews the best choice? If not, what are the better alternatives?

In this post, I’m going to attempt to answer these questions. Keep in mind, these are my personal opinions that have been shaped by my own interviewing experience.

I will try to be as objective as possible by approaching this task in true software engineering fashion: examining all the options and weighing their tradeoffs.

Are whiteboarding interviews the worst?

The first step in this process is to scrutinize whiteboarding.

Pros:

Fast and low effort Not language or domain dependent You know (generally) what to expect Community support (Glassdoor, LeetCode, Pramp, and so on)

Cons:

Luck is a big factor (algorithm lottery) Doesn’t necessarily test engineering aptitude Favors young engineers and recent grads

For companies who require engineers to have a strong grasp on CS fundamentals, low level algorithms, and aren’t dependent on libraries, the whiteboarding interview is perfect.

SpaceX, MacOS/Windows, and Facebook’s React were all built by engineers with such knowledge. To get a whiteboarding interview from one of these companies is to be expected.

As a job candidate, I love whiteboarding interviews. I know what to expect. Most algorithm questions fall under these general topics:

Arrays/Strings

Binary Trees

Linked Lists

DFS/BFS

Backtracking

Dynamic programming

Knowing this ahead of time means I can study for it. And there’s a plethora of studying tools to choose from. Technical interview preparation is an entire industry of its own.

It’s for that reason that whiteboarding interviews aren’t the best option for every company. So much of it comes down to luck, memorization, and whoever has spent the most time studying.

Not everyone can study for long swathes of time to master algorithms.

I was lucky that I could and outcompeted other engineers who couldn’t. Am I a better engineer than all of them? Maybe, but I’m not sure a whiteboarding interview is the best means of revealing it.

So if there’s doubt that the whiteboarding interview is the best tool for the job, what could be better?

Let’s take a look at some of the alternatives.

Coding challenges via computer

Pros:

Get to use a computer and familiar dev environment Can be done remotely via screen share All of the other advantages of whiteboarding interviews

Cons:

More strict about syntax and run-ability. Programming environment and plugins can play a big factor Same disadvantages of whiteboarding interviews

Coding Challenges on a laptop are the less rigorous cousin of the whiteboarding interview.

Candidates have the benefit of using their own computers. They can be done remotely or in a pair programming environment.

One nice thing I’ve noticed about these is that they will usually be easier than whiteboarding questions. Most of the questions I got involved string manipulation, or simple algorithms that any experienced engineer wouldn’t need to study for.

The drawback to this is that there is much greater emphasis on functionality.

During my job hunt, I was asked the Coin Change problem twice. One as a whiteboard challenge and the other on an editor.

For the whiteboard challenge, I got away with mainly explaining my solution. On my laptop, I was expected to write edge case tests and guarantee that my solution worked.

Part of the reason I like whiteboarding is due to the leniency. No one is going to run your written function through a compiler. As long as the interviewer understands what you’re thinking and the writing looks good enough, you get full credit.

Not so with code challenges.

Some may argue that the emphasis on functionality is better, because we’re paid to write working code. That’s true, but we aren’t getting paid to do it in 30–45 minute sprints.

Let’s just hope you don’t get nervous during interviews. One small bug that causes failing tests and several minutes of debugging could be the difference between a “strong hire” or a pass.

Code challenges still suffer from the same short comings as whiteboarding because many of them are algorithm-based.

With the added pressure of functionality, it can make the questions even more difficult despite the comfortable environment. If you already dislike algorithm problems, code challenges won’t be much better.

Take home assessments

Pros:

Can work on it in your pajamas Usually given upwards of a week to work on assignment Get to use your own editor and dev environment Can be a new addition to portfolio Usually more fun than whiteboarding

Cons:

Level of difficulty can range drastically Much more effort and time consuming than coding challenges Can be domain dependent Can lead to feature creep due to competition Doesn’t represent day to day work

A lot of engineers prefer take home assignments. The timelines for turning them in are usually flexible, and candidates get to actually code. It’s no shock programmers prefer this to standing in front of a whiteboard while being silently judged.

However, take home tests have some major drawbacks.

Firstly, they’re easy to manipulate.

Many companies host their tests on GitHub. Type in “Challenge” or “Test” into GitHub search and you’ll find plenty. This will give the savvy candidate plenty of time to preemptively research the challenge.

That’s not really a complaint. Just more of a pro-tip.

What is an issue is that it’s easy enough to find other people’s answers to these challenges and copy them. Plenty of engineers keep the answers to take home challenges on their GitHub profiles.

You can even test it yourself. Type “<Company Name> Challenge” into GitHub search and see what you find.

I live next to the Etsy headquarters in Brooklyn and was curious if I could find the answers to some of their tests. “Etsy Challenge” revealed four. There were even more under “Etsy Test”.

It’s true that companies can change their assessments. However, it can be a hassle to change an interview process every couple months due to details being leaked.

Secondly, the level of difficulty and time it takes to finish these challenges varies widely.

During my last job hunt, I was given four take home assignments. Three of the companies said they should only take 3–5 hours to finish.

They all took me multiple days.

The main reason for this was because the challenges were often domain specific. They required several hours of researching API docs and new technologies.

The fourth company took a challenge that could easily take a week and gave me two days. I had to build a functioning chat app that supported slash commands.

It was a fun and interesting project, but it required me to drop everything I was doing for two days in order to complete it.

If a candidate is fortunate enough to interview with multiple companies at once, it can become a full time job just working on these challenges.

Additionally, professional developers have to work on legacy codebases and deal with deadlines. A week long greenfield project isn’t going to assess how well the interviewee works in a fast paced environment.

Overall, I like take home assignments as an initial screen of a candidate’s ability. With that said, they should be related to the job the candidate is applying for, and shouldn’t take an obscene amount of time to finish.

Project Based/Contract-to-Hire

Pros:

Get a chance to work with candidate/team Get paid to work Get to work on real projects Are evaluated on how well you work with team and ship code

Cons:

Long time commitment Working without a guarantee of employment No health benefits as a contractor Can put candidate in bad negotiating position Language dependent

Project-based interviews are rare. But quite a few companies stand by them, such as Basecamp and Automatic. I can understand why.

They interviews are probably the most accurate way to assess someone’s skill and evaluate them as a team member. The company gets to work with them directly and see how they handle tasks in a team.

The candidate also gets a chance to evaluate the company and determine if it is the type of environment they would like to work in.

Win-win. Or so it seems.

With all of that said, as a job candidate, I would never partake in project-based interviews or contract-to-hire roles. The negatives far outweigh the positives.

The first couple months of any job are typically the toughest. You’re acclimatizing to a new team, culture, codebase. Now imagine working on a project not knowing if you’ll have a job by the end.

A good friend of mine recently interviewed at Automatic and confirmed how stressful it can be. Everything from the way you interact with coworkers to the questions you ask are judged. In these environments, there is such thing as a “stupid question.”

What’s worse is that he was let go after the three month contract. Luckily, he hasn’t let it impact his self-esteem. He knows his ability and is charging ahead. I’m not sure if I, or many other engineers, could do the same so easily.

Furthermore, contracts put the job seeker in an awful negotiating position. Strength in negotiations comes from the willingness to walk away.

By the end of a contract-to-hire period, the potential candidate won’t have any bargaining chips. They won’t have any other offers and they’ve already poured dozens or hundreds of hours into their projects depending on the contract length.

They would be incentivized to take the position even if it’s not their preferred choice. The alternative is to join the job market back at square one.

The Sunk Cost Fallacy at its finest.

While whiteboarding interviews may not be ideal, I would do a hundred of them before I ever did a project-based interview.

So which is the best?

As you might’ve guessed: It Depends™.

The tradeoffs seem to be between speed and effort versus accuracy. Each method sacrifices one for the other. It is up to each company to judge those tradeoffs for themselves. SpaceX is most likely going to have a different process than small New York startup.

What is true is that a SaaS company should only ask candidates to write out dynamic programming algorithms if it helps them determine the engineer’s skill. Not simply because Google does it.

If I were designing the interview process for my team at DigitalOcean, I would use a mixture of take home assessments and code challenges/pairing exercises. I would also gauge their understanding of availability and distributed systems through a Q&A session and system design challenge.

The good news is that my team already does this. DigitalOcean’s tough yet fair interview process was one of the reasons I accepted their offer. It proved to me that they had already gone through this self-examination process and found out how to fairly evaluate their candidates.

Please let me know what your preferred interview method in the comments below!

Finally, for all you engineers who want to see the interview process change, start coming up with ideas. I’ve seen too many engineers rant about whiteboarding interviews only to continue the process once they get hired because it’s too much work to change it.

Don’t be that person.

Stop complaining.

Find solutions.",https://cdn-images-1.medium.com/max/1200/0*PbKAbM5J891Qldc2,[],https://medium.freecodecamp.org/lets-talk-about-whiteboarding-interviews-fed040e20cc9?source=collection_home---6------16----------------#--responses,2018-06-06 01:10:32.658000+00:00

Data,"Ode to the tutorial — or, how I regained my motivation",['Linea Brink Andersen'],"Ode to the tutorial — or, how I regained my motivation

The internet is full of well-meaning advice for people learning to code. There are tons of blog-posts with recipes for success.

One piece of advice I have seen a lot lately is: “Build something.” It often comes together with a warning: “Don’t get stuck with tutorials.” The essence seems to be: Building, good. Tutorials, bad!

I had internalized this advice. I was living by it myself, and passing it on to others. I started building “real” things, not “just” things from tutorials. And it was awesome. You can read about the open source project I recently started. But building stuff was not all smooth sailing.

Getting stuck

For the last couple of weeks, I have been working on a silly little project that generates random band names following certain patterns. I wanted it to be a web-app, and I had a very particular idea about how it was supposed to look. I have little to no experience with front-end and web development. The name generator required both, so I figured that building it would be a good way to learn.

However, my focus on building was causing me not to build anything at all. With my pre-existing skills, a lot of googling, and a touch of stubbornness, I was getting pretty far with the name generator. But not far enough. I kept running into walls. Most of the time, I could get myself across the wall with a lot of work. But before I knew it, I was facing yet another wall.

Suddenly, I wasn’t coding anymore. I had to take a few days away from code because I was busy with midterms. But when midterms were over, and I had time on my hands again, I still wasn’t coding. I was making all sorts of excuses for why I would start tomorrow.

Tomorrow became the next day, and the next day, and the next day, and a week had passed, and I was still not coding. Just a few weeks prior you could barely pull me away from the screen. I had been spending all my free time coding. And now — I was avoiding it.

Back to the source

That’s when I realized — constantly running into walls was demotivating me. I had to do something different. My obsession with building was keeping me from progressing. Sure, when I ran into a problem, I could work to get myself unstuck. But I was solving small isolated problems. I needed to understand how all the individual pieces I was working on were going to fit together. I needed a bigger picture.

I found this tutorial online. It is a solid introduction to web development using Flask. The tutorial walked me through building a microblog. It was pretty interesting in itself, but I also saw many ways that I could use what I learned in my name generator, when I return to it.

To get started, I had to shut out that voice inside my head that said: “You’ll learn so much more from building your own project, instead of passively following a tutorial.” In the end, for me, it wasn’t true — I wasn’t really learning anything from building, because I was doing all I could to avoid having to try. I needed to get my motivation back, and the tutorial was helping me do just that.

Balance is key

I still believe that building my own projects is an important part of becoming a better programmer. But for me, building works best as a way to crystalize knowledge I already have. Sometimes I will learn something new in that process, but it is not the main focus. It is very satisfying to see how well I have understood something after studying it and then explore all the things I can do with my new skills. But when I need to learn something new, I prefer getting an overview.

By working through tutorials, I gain a surface understanding and an overview of the new skills I am trying to learn, and I see examples of how other people are applying them.

There are many ups and downs when learning to code. Next time a lack of motivation hits (I am sure it will happen again), I will use it as an opportunity to step back and reflect. Do I need to change something? Is there a reason why I keep getting stuck? Is there some gap in my skills, and how can I best fill it?

Shifting between the two different approaches, building and working through tutorials, I hope I can stay motivated and keep getting better and better. Building is not better or more important.

Sure, doing tutorials might be passive learning, but it is also about gearing up and learning new skills I can apply later when building. It is all part of the process.",https://cdn-images-1.medium.com/max/1200/0*yoRQAXhOXGU7tGy7,[],https://medium.freecodecamp.org/ode-to-the-tutorial-or-how-i-regained-my-motivation-3ff142ea0237?source=collection_home---6------17----------------#--responses,2018-06-06 00:59:12.072000+00:00

Data,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------,2018-06-06 00:20:56.870000+00:00

Data,How to write bulletproof code in Go: a workflow for servers that can’t fail,['Tal Kol'],"How to write bulletproof code in Go: a workflow for servers that can’t fail

From time to time you may find yourself facing a daunting task: building a server that really isn’t allowed to fail, a project where the cost of error is extraordinarily high. What is the methodology for approaching such a task?

Does your server really need to be bulletproof?

Before diving into this excessive workflow, you should ask yourself — does my server really need to be bulletproof? There’s a lot of overhead involved in preparing for the worst, and it’s not always worth it.

If the cost of error isn’t extraordinarily high, a perfectly valid approach is to make a reasonable best effort for things to work, and if your server breaks, just deal with it. Monitoring tools today and modern workflows of continuous delivery allow us to spot problems in production quickly and fix them almost immediately. For many cases, this is good enough.

In the project I’m working on today, it isn’t. I’m working on implementing a blockchain — a distributed server infrastructure for executing code securely under consensus in a low trust environment. One of the applications of this technology is digital currencies. This is a textbook example where the cost of error is literally high. We naturally want its implementation to be as bulletproof as possible.

There are other cases though, even when not dealing with currencies, where bulletproof code makes sense. The cost of maintenance skyrockets quickly for a codebase that fails frequently. Being able to identify problems earlier in the development cycle, when the cost of fixing them is still low, has a good chance of paying back the upfront investment in a bulletproof methodology.

Is TDD the magic answer?

Test Driven Development (TDD) is often hailed as the silver bullet against malfunctioning code. It is a puristic development methodology where new code isn’t added unless it satisfies a failing test. This process guarantees test coverage of 100 percent and often gives the illusion that your code is tested against every possible scenario.

This isn’t the case. TDD is a great methodology that works well for some, but by itself it still isn’t enough. Even worse, TDD instills false confidence in code and may make developers lazy when considering paranoid edge cases. I’ll show a good example of this later on.

Tests are important — they are the key

It doesn’t matter if you write tests before the fact or after, using a technique like TDD or not. All that matters is that you have tests. Tests are the best line of defense for protecting your code against breaking in production.

Since we’re going to run our entire test suite very frequently — after every new line of code if possible — tests must be automated. No part of our confidence in our code can result from a manual QA process. Humans make mistakes. Human attention to detail deteriorates after doing the same mind-numbing task a hundred times in a row.

Tests must be fast. Blazingly fast.

If a test suite takes more than a few seconds to run, developers are likely going to become lazy, pushing code without running it. This is one of the great things about Go — it has one of the fastest toolchains out there. It compiles, rebuilds, and tests in seconds.

Tests are also important enablers for open-source projects. Blockchains, for example, are almost religiously open-source. The codebase must be open to establish trust — expose itself for audit and create a decentralized atmosphere where no single governing entity controls the project.

It is unreasonable to expect massive external contributions in an open-source project without a thorough test suite. External contributors need a quick way to check if their contribution breaks any existing behavior. The entire test suite, in fact, must run automatically on every pull request and fail automatically if the PR broke anything.

Full test coverage is a misleading metric, but it is important. It may feel excessive to reach 100% coverage, but when you think about it, it makes no sense to ship code to production that was never executed beforehand.

Full test coverage doesn’t necessarily mean that we have enough tests and it doesn’t mean that our tests are meaningful. What is certain is that if we don’t have 100% coverage, we don’t have enough to consider ourselves bulletproof, since parts of our code were never tested.

Nevertheless, there is such a thing as too many tests. Ideally, every bug we encounter should break a single test. If we have redundant tests — different tests that check the same thing — modifying existing code and breaking existing behavior in the process will incur too much overhead in fixing failed tests.

Why is Go a great choice for bulletproof code?

Go is statically typed. Types provide a contract between various pieces of code running together. Without automatic type checking during build, if we wanted to adhere to our strict coverage rules, we would have to implement these contract tests ourselves. This is the case with environments like Node.js and JavaScript. Writing comprehensive contract tests manually is a lot of extra work we prefer to avoid.

Go is simple and dogmatic. Go is known for being stripped of many traditional language features like classic OOP inheritance. Complexity is the worst enemy of bulletproof code. Problems tend to creep up in the seams. While the common case is easy to test, it’s the strange edge case you haven’t thought of that will eventually get you.

Dogma is also helpful in this sense. There’s often only one way to do something in Go. This may inhibit the free spirit of man, but when there’s one way to do something, it’s more difficult to get this one thing wrong.

Go is concise yet expressive. Readable code is easier to review and audit. If the code is too verbose, its core purpose may be drowned by the noise of boilerplate. If the code is too concise, it becomes hard to follow and understand.

Go strikes a nice balance between the two. There’s not a lot of language boilerplate like in Java or C++, but the language is still very explicit and verbose in areas like error handling — making it easy to verify that you’ve checked every possible route.

Go has clear paths of error and recovery. Dealing gracefully with errors in runtime is a cornerstone for bulletproof code. Go has a strict convention of how errors are returned and propagated. Environments like Node.js — where multiple flavors of control flow like callbacks, promises, and async are mixed together — often result in leakage like unhandled promise rejections. Recovering from these is almost impossible.

Go has an extensive standard library. Dependencies add risk, especially when coming from sources that aren’t necessarily well-maintained. When shipping your server, you ship all of your dependencies with it. You are responsible for their malfunctions as well. Environments overflowing with fragmented dependencies, like Node.js, are harder to keep bulletproof.

This is also risky from a security standpoint, as you are as vulnerable as your weakest dependency. Go’s extensive standard library is well-maintained and reduces reliance on external dependencies.

Development velocity is still rapid. The main appeal of environments like Node.js is an extremely rapid development cycle. Code just takes less time to write and you become more productive.

Go preserves these benefits quite well. The build toolchain is fast enough to make feedback immediate. Compilation time is negligible, and code seems to run like it’s interpreted. The language has enough abstractions like garbage collection to focus engineering efforts on core functionality.

Let’s play with a working example

Now, with the introductions over, it’s time to dive into some code. We need an example that is simple enough so we can focus on methodology, but complicated enough to have substance. I find it’s easiest to take something from my day to day, so let’s build a server that processes currency-like transactions. Users will be able to check the balance for an account. Users will also be able to transfer funds from one account to another.

We’ll keep things very simple. Our system will only have a single server. We’re also not going to deal with user authentication or cryptography. These are product features, whereas we want to focus on building the bulletproof software foundation.

Breaking down complexity to manageable parts

Complexity is the worst enemy of bulletproof code. One of the best ways to deal with complexity is divide and conquer — split the problem into smaller problems and solve each one separately. How do we split? We’ll follow the principle of separation of concerns. Every part should deal with a single concern.

This goes hand in hand with the popular architecture of microservices. Our server will be comprised of services. Each service will be mandated a clear responsibility and given a well defined interface for communication with the other services.

Once we’ve structured our server this way, we’ll be free to decide how each service is running. We can run all services together in the same process, make each service its own separate server and communicate via RPC, or split services to run on different machines.

Since we’re just starting out, we’ll keep things simple — all services will share the same process and communicate directly as libraries. We’ll be able to change this decision easily in the future.

So which services should we have? Our server is a little too simple for splitting up, but to demonstrate this principle we’ll do so anyways. We need to respond to HTTP requests from clients for checking balances and making transactions. One service can deal with the client HTTP interface — we’ll call it PublicApi. Another service will own the state — the ledger of all balances —so we’ll call it StateStorage. The third service will connect the two and implement our business logic of the “contract” for changing balances. Since blockchains usually allow these contracts to be deployed by application developers, the third service will be charged with running them — we’ll call it VirtualMachine.

We’ll place the code for services in our project under /services/publicapi , /services/virtualmachine and /services/statestorage .

Defining service boundaries clearly

When implementing services, we’ll want to be able to work on each one separately. Possibly even assign different services to different developers. Since services are dependent on one another and we’re going to parallelize work on their implementation, we’ll have to start by defining clear interfaces between them. Using this interface, we’ll be able to test a service individually and mock everything else.

How can we define the interface? One option is to document it, but documentation tends to grow stale and out of sync with the code. We could use Go interface declarations. This makes sense, but it’s nicer to define the interface in a language agnostic way. Our server isn’t limited to Go only. We may decide down the road to reimplement one of the services in a different language more appropriate to its requirements.

One approach is to use protobuf — a simple language-agnostic syntax by Google to define messages and service endpoints.

Let’s start with StateStorage. We’ll structure state as a key-value store:

Although PublicApi is accessed via client HTTP, it’s still a good practice to give it a clear interface in the same way:

This will require us to define Transaction and Address data structures:

We’ll place the .proto definitions for services in our project under /types/services and general data structures under /types/protocol . Once the definitions are ready, they can be compiled to Go code. The benefit of this approach is that code which doesn’t meet the contract will simply not compile. Alternate methods would require us to write contract tests explicitly.

The complete definitions, generated Go files, and compilation instructions are available here. Kudos to Square Engineering for making goprotowrap.

Note that we’re not integrating an RPC transport layer yet, and calls between services will currently be regular library calls. When we’re ready to split services to different servers, we can add a transport layer like gRPC.

The types of tests in our project

Since tests are the key to bulletproof code, let’s discuss first which types of tests we’ll be writing:

Unit tests

This is the base of the testing pyramid. We’ll test every unit in isolation. What’s a unit? In Go, we can define a unit to be every file in a package. If we have /services/publicapi/handlers.go , we’ll place its unit test in the same package under /services/publicapi/handlers_test.go .

It’s preferable to place unit tests in the same package as the tested code so the tests have access to non-exported variables and functions.

Service / integration / component tests

The next type of tests has multiple names that all refer to the same thing — taking several units and testing them together. This is one level up the pyramid. In our case, we’ll focus on an entire service. These tests define the specifications for a service. For the StateStorage service for example, we’ll place them in /services/statestorage/spec .

It’s preferable to place these tests in a different package than the tested code to enforce access through exported interfaces only.

End-to-end tests

This is the top of the testing pyramid, where we test our entire system together with all services combined. These tests define the end-to-end specifications for the system, therefore we’ll place them in our project under /e2e/spec .

These tests as well should be placed in a different package than the tested code to enforce access through exported interfaces only.

Which tests should we write first? Do we start at the base and work our way up? Or go top-down? Both approaches are valid. The benefit of the top-down approach is for building specifications. It’s usually easier to reason about the specifications for the entire system first. Even if we split our system to services the wrong way, the system spec would remain the same. This would also help us understand that.

The drawback of starting top-down is that our end-to-end tests will be the last ones to pass (only after the entire system has been implemented). This means they’ll remain failing for a long time.

End-to-end tests

Before writing tests, we need to consider whether we’re going to write everything bare-boned or use a framework. Relying on frameworks for dev dependencies is less dangerous than relying on frameworks for production code. In our case, since the Go standard library doesn’t have great support for BDD and this format is excellent for defining specs, we’ll opt for a framework.

There are many excellent candidates like GoConvey and Ginkgo. My personal preference is Ginkgo with Gomega (terrible names, but what can you do) which use syntax like Describe() and It() .

So what does a test look like? Checking user balance:

Since our server provides public HTTP interface to the world, we access this web API using http.Get. What about making a transaction?

The test is very descriptive and can even replace documentation. As you can see above, we’re allowing accounts to reach a negative balance. This is a product choice. If this weren’t allowed, the test would reflect that.

The complete test file is available here.

Service integration / component tests

Now that we’re done with end-to-end tests, we go down the pyramid and implement service tests. This is done for every service separately. Let’s choose a service which has a dependency on another service, because this case is more interesting.

We’ll start with VirtualMachine. The protobuf interface for this service is available here. Because VirtualMachine relies on service StateStorage and makes calls to it, we’re going to have to mock StateStorage in order to test VirtualMachine in isolation. The mock object will allow us to control StateStorage’s responses during the test.

How can we implement mock objects in Go? We can simply create a bare-boned stub implementation, but using a mocking library will also provide us with useful assertions during the test. My preference is go-mock.

We’ll place the mock for StateStorage in /services/statestorage/mock.go . It’s preferable to place mocks in the same package as the mocked code to provide access to non-exported variables and functions. The mock is pretty much just boilerplate at this point, but as our services get more complicated, we may find ourselves adding some logic here. This is the mock:

If you assign different services to different developers, it makes sense to implement the mocks first and share them between the team.

Let’s get back to writing our service test for VirtualMachine. Which scenario should we test here exactly? It’s best to follow the interface for the service and design tests for each endpoint. We’ll implement the test for the endpoint CallContract() with the method argument of ""GetBalance"" first:

Notice that the service we’re testing, VirtualMachine, receives a pointer to its dependency StateStorage in its Start() method via simple dependency injection. That’s where we pass the mocked instance. Also notice on line 23 where we instruct the mock with how to respond when accessed. When its ReadKey method is called, it should return the value 100 . We then verify that it indeed was called exactly once in line 28.

These tests become the specifications for the service. The full suite for service VirtualMachine is available here. The suites for the other services are available here and here.

Let’s implement a unit, finally

Implementing the contract for method ""GetBalance"" is a bit too simple, so let’s move instead to the slightly more complicated implementation for method ""Transfer” . The transfer contract needs to read the balances of both the sender and recipient, calculate their new balances, and write them back to state. The service integration test for it is very similar to the one we just implemented:

We’ll finally get down to business and create a unit called processor.go that contains the actual implementation for the contract. This is what our initial implementation turns out:

This satisfies the service integration test, but the integration test only contains a common case scenario. What about edge cases and potential failures? As you can see, any of the calls we make to StateStorage may fail. If we’re aiming for 100-percent coverage, we need to check all of these cases. A unit test would be a great place to do that.

Since we’re going to have to run the function multiple times with different inputs and mock settings to reach all flows, a table driven test would make this process a little more efficient. The convention in Go is to avoid fancy frameworks in unit tests. We can drop Ginkgo, but we should probably keep Gomega so our matchers look similar to our previous tests. This is the test:

If you’re weirded out by the “Ω” symbol don’t worry, it’s just a regular variable name (holding a pointer to Gomega). You’re welcome to rename it to anything you like.

For the sake of time, we didn’t show the strict methodology of TDD where a new line of code would only be written to resolve a failing test. Using this methodology, the unit test and implementation for processTransfer() would be implemented over several iterations.

The full suite of unit tests in the VirtualMachine service is available here. The unit tests for the other services are available here and here.

We’ve reached 100% coverage, our end-to-end tests are passing, our service integration tests are passing and our unit tests are passing. The code fulfills its requirements to the letter and is thoroughly tested.

Does that mean that everything is working? Unfortunately not. We still have several nasty bugs hiding in plain sight in our simple implementation.

The importance of stress tests

All of our tests so far tested a single request being handled at any given time. What about synchronization issues? Every HTTP request in Go is handled in its own goroutine. Since these goroutines run concurrently, potentially on different OS threads on different CPU cores, we face synchronization problems. These are very nasty bugs that aren’t easy to track down.

One of the approaches for finding synchronization issues is stressing the system with many requests in parallel and making sure everything still works. This should be an end-to-end test because we want to test synchronization issues across our entire system with all services. We’ll place stress tests in our project under /e2e/stress .

This is what a stress test looks like:

Notice that the stress test includes random data. It’s recommended to use a constant seed (see line 39) to make the test deterministic. Running a different scenario every time we run our tests isn’t a good idea. Flakiness by tests that sometimes pass and sometimes fail reduces developer confidence in the suite.

The tricky part about stress tests over HTTP is that most machines have a hard time simulating thousands of concurrent users and opening thousands of concurrent TCP connections (you’ll see strange failures like “maximum file descriptors” or “connection reset by peer”). The code above tries to deal with this gracefully by limiting concurrent connections to batches of 200 and using IdleConnection Transport settings to recycle TCP sessions between batches. If this test is flaky on your machine, try reducing the batch size to 100.

Oh no…the test fails:

What happens here? StateStorage is implemented as simple in-memory map. It seems we’re trying to write to this map in parallel from different threads. It may seem at first that we should just replace the regular map with the thread-safe sync.map but our problem runs a little deeper.

Take a look at the processTransfer() implementation. It reads twice from the state and then writes twice. The set of reads and writes isn’t an atomic transaction, so if another thread changes the state after one thread read from it, we’re going to have data corruption. The fix is to make sure only one instance of processTransfer() can run concurrently — you can see it here.

Let’s try to run the stress test again. Oh no, another failure!

This one requires a little more debugging to understand. It seems that it happens when a user tries to transfer an amount to themselves (the same user is both the sender and recipient). Looking at the implementation, it’s easy to see why this happens.

This one is a little disturbing. We’ve followed a TDD-like workflow and we still hit a hard business logic bug. How can that be? Isn’t our code tested against every scenario with 100% coverage?! Well…this bug is the result of a faulty product requirement, not a faulty implementation. The requirements for processTransfer() should have clearly stated that if a user transfers an amount to themselves, nothing happens.

When we discover a business logic bug, we should always reproduce it first in our unit tests. It’s very easy to add this case to our table driven test from before. The fix is also simple — you can see it here.

Are we finally home free?

After adding the stress tests and making sure everything passes, is our system finally working as intended? Is it finally bulletproof?

Unfortunately not.

We still have some nasty bugs that even the stress test did not uncover. Our “simple” function processTransfer() is still at risk. Consider what happens if we ever reach this line. The first write to state succeeded but the second fails. We’re about to return an error, but we’ve already corrupted our state by writing to it half-baked data. If we’re going to return an error, we’ll have to undo the first write.

This is a little more complicated to fix. The best solution is probably to change our interface altogether. Instead of having an endpoint in StateStorage named WriteKey that we call twice, we should probably rename it to WriteKeys — an endpoint that we’ll call once to write both keys together in one transaction.

There’s a bigger lesson here: a methodical test suite is not enough. Dealing with complex bugs requires critical thinking and paranoid creativity by developers. It’s recommended to have someone else look at your code and perform code reviews in your team. Even better, open sourcing your code and encouraging the community to audit it is one of the best ways to make your code more bulletproof.",https://cdn-images-1.medium.com/max/1200/1*rATDejNGIZtqzLtB-LhJEQ.jpeg,[],https://medium.freecodecamp.org/how-to-write-bulletproof-code-in-go-a-workflow-for-servers-that-cant-fail-10a14a765f22?source=collection_home---6------18----------------#--responses,2018-06-06 00:20:56.870000+00:00

Data,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------,2018-06-05 20:08:25.488000+00:00

Data,A comprehensive guide to coding a blockchain-powered online community,['Sandeep Panda'],"A comprehensive guide to coding a blockchain-powered online community

At Hashnode we have been experimenting a lot with blockchain and its use-cases. We have been running a developers’ community ourselves, and the idea behind “decentralized communities” fascinates me a lot. The fact that everyone owns the data and controls the platform can give rise to new types of social apps and disrupt the traditional way of building online communities.

Platforms like Steemit have proven that it’s possible to build such communities and reward users for their contributions. But how should someone go about replicating it and launching their own decentralized social platform powered by blockchain?

To answer the question, I took up the challenge of building a decentralized version of HackerNews.

During the process, I evaluated multiple platforms and finally zeroed in on a protocol called Tendermint. Using Tendermint, I have built a prototype called “Mint” which can serve as a boilerplate for building blockchain-powered social apps.

The codebase is on GitHub. You can check out the following links for code and demo:

So what does it take to build a blockchain-powered social community where the user-generated data is decentralized? If you are looking for an answer, you have come to the right place. Read on.

Preliminary Observations

Initially, I thought of utilizing an existing platform to build the app. Smart Contract platforms like Ethereum, NEM, NEO, and so on offer storage of assets, but these are not designed to store large amount of data.

HyperLedger Fabric is compelling, but it’s designed to be deployed in private blockchain networks. Hashgraph sounds interesting, but it’s experimental as of now.

Other potential solutions were: Lisk Sidechains, Loom Network, and BigChainDB. The first two are in private alpha (invite-only), while BigChainDB is powered by Tendermint.

So, instead of using BigChainDB, I decided to play around with Tendermint directly and see what was possible.

Why Tendermint

Tendermint is a protocol that takes care of the consensus layer using BFT algorithm while you just focus on writing the business logic.

The beauty of the protocol is that you are literally free to choose any programming language to build an interface (Application Blockchain Interface or simply ABCI) that interacts with the blockchain.

Tendermint handles the most complex aspects of a blockchain such as block production rounds, peer to peer connectivity, gossiping about new blocks, transaction handling, and more. It stores the transactions on the disk using LevelDB and also delivers the confirmed transaction to your ABCI server so that you can create a global state out of it.

Sounds interesting? Let’s see how to create a blockchain app that stores data on chain using Tendermint.

What’s Needed?

Here is what you are going to need:

Macbook / Ubuntu server

Golang

Tendermint

MongoDB

And beer… (Coffee lovers can replace this with coffee)

Setting up the Machine

Tendermint is written in Go. So, we need to install the Go language first. Visit this link to check out a few download options. If you are on Ubuntu, you can follow this guide.

By default, Go chooses $HOME/go as your workspace. If you want to use a different location as your workspace, you can set GOPATH variable in ~/.profile . From now on, we’ll refer to this location as GOPATH .

Here is how ~/.profile file looks on my machine:

export GOPATH=""$HOME/go""

export PATH=~/.yarn/bin:$GOPATH/bin:$PATH

export GOBIN=""$GOPATH/bin""

Remember to set GOBIN variable as shown above. This is where the Go binaries will be installed.

Don’t forget to run source ~/.profile after updating the file.

Now we can install Tendermint. Here are the steps:

cd $GOPATH/src/github.com

mkdir tendermint

cd tendermint

And finally,

git clone https://github.com/tendermint/tendermint

This will install the latest version of Tendermint. As I have tested my code against v0.19.7 , let’s check out the specific release.

cd tendermint

git checkout v0.19.7

This will put you on v0.19.7. To proceed with the installation, run the following commands:

make get_tools

make get_vendor_deps

make install

Congrats! You have installed Tendermint successfully. If everything was installed as intended, the command tendermint version will print out the Tendermint version.

Now, you should go ahead and install MongoDB.

Coding the Blockchain

If you want to understand how Tendermint works, go through this guide. You may also find the following diagram helpful.

I’ll outline a few important concepts here:

Tendermint core handles the consensus part.

You need to write an ABCI server that handles the business logic, validations, and so on. Although you can write this in any language, our language of choice will be Go.

Tendermint core will interact with your ABCI server via socket connections.

The ABCI server has many methods (JS developers can think of them as callbacks) that will be invoked by Tendermint core on various events.

Two important methods are: CheckTx and DeliverTx . The first one is called to validate a transaction, while the latter is called when the Tx is confirmed.

and . The first one is called to validate a transaction, while the latter is called when the is confirmed. DeliverTx helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB.

helps you take necessary actions based on the confirmed transactions. In our case, we’ll use this to create and update our global state stored in MongoDB. Tendermint uses BFT consensus. This means more than 2/3 of the validators need to have consensus in order to commit a transaction. So, even if 1/3 of the validators go rogue, the blockchain will still work.

In a real world scenario (at least in a public deployment), you will most likely add some sort of consensus such as PoS (Proof of State) in addition to BFT consensus. In this case, we’ll just go ahead with simple BFT consensus. I’ll leave adding PoS up to you.

I suggest that you clone the blockchain ABCI server (code-named mint) from GitHub. But before we go ahead, we need to install a dependency management tool called dep.

If you are on a Mac, you can just run brew install dep . For Ubuntu, run the following command.

curl https://raw.githubusercontent.com/golang/dep/master/install.sh | sh

Now you can clone the codebase of mint.

cd $GOPATH/src

git clone https://github.com/Hashnode/mint

cd mint

dep ensure

go install mint

Sweet! You have now installed mint, which is an ABCI server and works along with Tendermint core.

Now, let me walk you through the whole set-up and all the code.

Entry Point

You can find the code (and entry point) on GitHub here.

The entry point of the app is mint.go . The most important part of the file is the following section:

app = jsonstore.NewJSONStoreApplication(db)

srv, err := server.NewServer(""tcp://0.0.0.0:46658"", ""socket"", app) if err != nil { return err }

All the business logic, methods, and so on are defined in the package jsonstore . The above code simply creates a TCP server on port 46658 that accepts socket connections from Tendermint core.

Now let’s look at jsonstore package.

Business Logic

Here’s the jsonstore repo.

Our ABCI server does two important things:

Validates incoming transactions. If a transaction is invalid, it returns an error code and the transaction is rejected.

Once a transaction is committed (confirmed by > 2/3 of the validators) and stored in LevelDB, the ABCI server updates its global state stored in MongoDB.

We’re going to use mgo for interacting with MongoDB. So, jsonstore.go defines 5 models that correspond to 5 different MongoDB collections.

The code looks like the following:

// Post ...

type Post struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Title string `bson:""title"" json:""title""`

URL string `bson:""url"" json:""url""`

Text string `bson:""text"" json:""text""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Date time.Time `bson:""date"" json:""date""`

Score float64 `bson:""score"" json:""score""`

NumComments int `bson:""numComments"" json:""numComments""`

AskUH bool `bson:""askUH"" json:""askUH""`

ShowUH bool `bson:""showUH"" json:""showUH""`

Spam bool `bson:""spam"" json:""spam""`

}

// Comment ...

type Comment struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Content string `bson:""content"" json:""content""`

Author bson.ObjectId `bson:""author"" json:""author""`

Upvotes int `bson:""upvotes"" json:""upvotes""`

Score float64 `bson:""score"" json:""score""`

Date time.Time

PostID bson.ObjectId `bson:""postID"" json:""postID""`

ParentCommentID bson.ObjectId `bson:""parentCommentId,omitempty"" json:""parentCommentId""`

}

// User ...

type User struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

Name string `bson:""name"" json:""name""`

Username string `bson:""username"" json:""username""`

PublicKey string `bson:""publicKey"" json:""publicKey""`

}

// UserPostVote ...

type UserPostVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

PostID bson.ObjectId `bson:""postID"" json:""postID""`

}

// UserCommentVote ...

type UserCommentVote struct {

ID bson.ObjectId `bson:""_id"" json:""_id""`

UserID bson.ObjectId `bson:""userID"" json:""userID""`

CommentID bson.ObjectId `bson:""commentID"" json:""commentID""`

}

We also define a few utility functions such as the following:

func byteToHex(input []byte) string {

var hexValue string

for _, v := range input {

hexValue += fmt.Sprintf(""%02x"", v)

}

return hexValue

}

func findTotalDocuments(db *mgo.Database) int64 {

collections := [5]string{""posts"", ""comments"", ""users"", ""userpostvotes"", ""usercommentvotes""}

var sum int64

for _, collection := range collections {

count, _ := db.C(collection).Find(nil).Count()

sum += int64(count)

}

return sum

}

func hotScore(votes int, date time.Time) float64 {

gravity := 1.8

hoursAge := float64(date.Unix() * 3600)

return float64(votes-1) / math.Pow(hoursAge+2, gravity)

}

// FindTimeFromObjectID ... Convert ObjectID string to Time

func FindTimeFromObjectID(id string) time.Time {

ts, _ := strconv.ParseInt(id[0:8], 16, 64)

return time.Unix(ts, 0)

}

These will be used subsequently in the code.

Inside CheckTx

Now let’s come to the validation part. How do we accept or reject a transaction? Let’s say someone is trying to sign up, but doesn’t choose a valid username. How can our app validate this?

It’s done via CheckTx function. The signature looks like the following:

func (app *JSONStoreApplication) CheckTx(tx []byte) types.ResponseCheckTx {

// ... Validation logic

}

When a Tendermint node receives a transaction, it invokes CheckTx of ABCI server and passes tx data as a byte array argument. If CheckTx returns a non-zero code, the transaction is rejected.

In our case, clients send Base64 encoded stringified JSON objects to the Tendermint node via an RPC request. So, it is our job to decode the tx and unmarshall the string into a JSON object.

It’s done like this:

var temp interface{}

err := json.Unmarshal(tx, &temp)



if err != nil {

panic(err)

}



message := temp.(map[string]interface{})

message object typically looks like the following:

{

body: {... Message body},

publicKey: <Public Key of Sender>,

signature: <message.body is signed with the Private Key>

}

First, we need to make sure that said person has indeed submitted the transaction to the blockchain, not someone else claiming to be that person.

The best way to validate is to ask clients to sign the message body with the user’s private key and attach both the public key and the signature to the payload. We’ll use ed25519 algorithm to generate the keys and sign the message in the browser and hit the RPC endpoint. In the CheckTx function we’ll again use ed25519 and verify the message with the help of the user’s public key.

It’s done like this:

pubKeyBytes, err := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

sigBytes, err := hex.DecodeString(message[""signature""].(string))

messageBytes := []byte(message[""body""].(string))



isCorrect := ed25519.Verify(pubKeyBytes, messageBytes, sigBytes)



if isCorrect != true {

return types.ResponseCheckTx{Code: code.CodeTypeBadSignature}

}

In the above example, we use the ed25519 package to validate the message. Various codes such as code.CodeTypeBadSignature are defined inside code package. These are just integers. Just remember that if you want to reject a transaction, you have to return a non-zero code. In our case, if we detect that the message signature is not valid, we return CodeTypeBadSignature which is 4 .

The next section of CheckTx deals with various data validations, such as:

If the user is sending any transaction other than “createUser (Sign up)”, we first check that the user’s public key is present in our database.

If the user is trying to create a post or comment, it should have valid data such as non-empty title , content , and so on.

, , and so on. If the user is trying to sign up, the username should have acceptable characters.

The code looks like the following:

// ==== Does the user really exist? ======

if body[""type""] != ""createUser"" {

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

count, _ := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).Count()

if count == 0 {

return types.ResponseCheckTx{Code: code.CodeTypeBadData}

}

}

// ==== Does the user really exist? ======

codeType := code.CodeTypeOK

// ===== Data Validation =======

switch body[""type""] {

case ""createPost"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""]. (string)) != true) {

codeType = code.CodeTypeBadData

break

}

if entity[""title""] == nil || strings.TrimSpace(entity[""title""].(string)) == """" {

codeType = code.CodeTypeBadData

break

}

if (entity[""url""] != nil) && (strings.TrimSpace(entity[""url""].(string)) != """") {

_, err := url.ParseRequestURI(entity[""url""].(string))

if err != nil {

codeType = code.CodeTypeBadData

break

}

}

case ""createUser"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

r, _ := regexp.Compile(""^[A-Za-z_0-9]+$"")

if (entity[""username""] == nil) || (strings.TrimSpace(entity[""username""].(string)) == """") || (r.MatchString(entity[""username""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""name""] == nil) || (strings.TrimSpace(entity[""name""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

case ""createComment"":

entity := body[""entity""].(map[string]interface{})

if (entity[""id""] == nil) || (bson.IsObjectIdHex(entity[""id""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""postId""] == nil) || (bson.IsObjectIdHex(entity[""postId""].(string)) != true) {

codeType = code.CodeTypeBadData

break

}

if (entity[""content""] == nil) || (strings.TrimSpace(entity[""content""].(string)) == """") {

codeType = code.CodeTypeBadData

break

}

}

// ===== Data Validation =======

return types.ResponseCheckTx{Code: codeType}

The code is really simple and pretty self-explanatory. So, I won’t go into the details, and will leave it up to you to read and explore further.

Inside DeliverTx

Once a transaction is confirmed and applied to the blockchain, Tendermint core calls DeliverTx and passes the transaction as a byte array. The function signature looks like the following:

func (app *JSONStoreApplication) DeliverTx(tx []byte) types.ResponseDeliverTx {

// ... Code goes here

}

We’ll use this function to construct a MongoDB-based global state. We do this so that our website users can read the data easily.

This function is big and has multiple cases. In this section I’ll just cover only one case which is “Post Creation”. As the rest of the code is similar, I’ll leave it up to you to dig deeper and explore the full code.

Firstly, we’ll go ahead and unmarshall the tx data into a JSON object:

var temp interface{}

err := json.Unmarshal(tx, &temp)

if err != nil {

panic(err)

}

message := temp.(map[string]interface{})

var bodyTemp interface{}

errBody := json.Unmarshal([]byte(message[""body""].(string)), &bodyTemp)

if errBody != nil {

panic(errBody)

}

body := bodyTemp.(map[string]interface{})

For post creation, the message object looks like the following:

{

body: {

type: ""createPost"",

entity: {

id: id,

title: title,

url: url,

text: text,

author: author

}

},

signature: signature,

publicKey: publicKey

}

And here is how DeliverTx function creates a new entry in the database when a “createPost” transaction is committed:

entity := body[""entity""].(map[string]interface{})

var post Post

post.ID = bson.ObjectIdHex(entity[""id""].(string))

post.Title = entity[""title""].(string)

if entity[""url""] != nil {

post.URL = entity[""url""].(string)

}

if entity[""text""] != nil {

post.Text = entity[""text""].(string)

}

if strings.Index(post.Title, ""Show UH:"") == 0 {

post.ShowUH = true

} else if strings.Index(post.Title, ""Ask UH:"") == 0 {

post.AskUH = true

}

pubKeyBytes, errDecode := base64.StdEncoding.DecodeString(message[""publicKey""].(string))

if errDecode != nil {

panic(errDecode)

}

publicKey := strings.ToUpper(byteToHex(pubKeyBytes))

var user User

err := db.C(""users"").Find(bson.M{""publicKey"": publicKey}).One(&user)

if err != nil {

panic(err)

}

post.Author = user.ID

post.Date = FindTimeFromObjectID(post.ID.Hex())

post.Upvotes = 1

post.NumComments = 0

// Calculate hot rank

post.Score = hotScore(post.Upvotes, post.Date)

// While replaying the transaction, check if it has been marked as spam

spamCount, _ := db.C(""spams"").Find(bson.M{""postID"": post.ID}).Count()

if spamCount > 0 {

post.Spam = true

}

dbErr := db.C(""posts"").Insert(post)

if dbErr != nil {

panic(dbErr)

}

var document UserPostVote

document.ID = bson.NewObjectId()

document.UserID = user.ID

document.PostID = post.ID

db.C(""userpostvotes"").Insert(document)

The actual code block has a switch statement that handles each type of transaction differently. Feel free to check out the code and play around. If something is unclear, feel free to write your queries in the comments below.

Now that we’ve examined two important aspects of the ABCI server, let’s try to run both Tendermint core and our server and see how to send transactions.

In order to run the app, run the following commands from two different terminals.

First, run:

mint

If the command succeeds, you will see the following output in the terminal:

Mint Output

Make sure MongoDB is already running before starting mint . If your terminal is unable to recognize mint command, be sure to run source ~/.profile .

Then start Tendermint in a different terminal:

tendermint node --consensus.create_empty_blocks=false

By default, Tendermint produces new blocks every 3 seconds, even if there are no transactions.

To prevent that we use the flag:

consensus.create_empty_blocks=false

Now that Tendermint is running you can start sending the transactions to it. You need a client that can generate ed25519 keys, sign your requests, and hit the RPC endpoint exposed by Tendermint.

An example request (Node.js) looks like this:

const base64Data = req.body.base64Data;

let headers = {

'Content-Type': 'text/plain',

'Accept':'application/json-rpc'

}

let options = {

url: ""http://localhost:46657"",

method: 'POST',

headers: headers,

json: true,

body: {""jsonrpc"":""2.0"",""method"":""broadcast_tx_commit"",""params"": { ""tx"" : base64Data } ,""id"":""something""}

}

request(options, function (error, response, body) {

res.json({ body: response.body });

});

Note that the RPC endpoint is exposed on port 46657 .

Forming and signing the requests manually can be tedious. So, I suggest that you use Uphack (a HackerNews style website that interacts with the blockchain) to get the full picture.

To install Uphack, follow the steps below:

git clone https://github.com/Hashnode/Uphack

cd Uphack

yarn

gulp less // make sure gulp is installed globally

node server.js

You can access the website on http://localhost:3000 . It looks like this on my machine:

Uphack

As you don’t have any data yet, it will look empty initially. Feel free to register an account and submit some posts to visualize the process.",https://cdn-images-1.medium.com/max/1200/1*1h7x469AFYKuUveSj7ZlOA.jpeg,[],https://medium.freecodecamp.org/a-comprehensive-guide-to-coding-a-blockchain-powered-online-community-f938792dbcb4?source=collection_home---6------19----------------#--responses,2018-06-05 20:08:25.488000+00:00

Data,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------,2018-06-05 16:44:13.144000+00:00

Data,When (and why) you should use ES6 arrow functions — and when you shouldn’t,['Cynthia Lee'],"When (and why) you should use ES6 arrow functions — and when you shouldn’t

Arrow functions (also called “fat arrow functions”) are undoubtedly one of the more popular features of ES6. They introduced a new way of writing concise functions.

Here is a function written in ES5 syntax:

function timesTwo(params) {

return params * 2

}

timesTwo(4); // 8

Now, here is the same function expressed as an arrow function:

var timesTwo = params => params * 2

timesTwo(4); // 8

It’s much shorter! We are able to omit the curly braces and the return statement due to implicit returns (but only if there is no block — more on this below).

It is important to understand how the arrow function behaves differently compared to the regular ES5 functions.

Variations

Variety is the spice of life

One thing you will quickly notice is the variety of syntaxes available in arrow functions. Let’s run through some of the common ones:

1. No parameters

If there are no parameters, you can place an empty parentheses before => .

() => 42

In fact, you don’t even need the parentheses!

_ => 42

2. Single parameter

With these functions, parentheses are optional:

x => 42 || (x) => 42

3. Multiple parameters

Parentheses are required for these functions:

(x, y) => 42

4. Statements (as opposed to expressions)

In its most basic form, a function expression produces a value, while a function statement performs an action.

With the arrow function, it is important to remember that statements need to have curly braces. Once the curly braces are present, you always need to write return as well.

Here is an example of the arrow function used with an if statement:

var feedTheCat = (cat) => {

if (cat === 'hungry') {

return 'Feed the cat';

} else {

return 'Do not feed the cat';

}

}

5. “Block body”

If your function is in a block, you must also use the explicit return statement:

var addValues = (x, y) => {

return x + y

}

6. Object literals

If you are returning an object literal, it needs to be wrapped in parentheses. This forces the interpreter to evaluate what is inside the parentheses, and the object literal is returned.

x =>({ y: x })

Syntactically anonymous

It is important to note that arrow functions are anonymous, which means that they are not named.

This anonymity creates some issues:

Harder to debug

When you get an error, you will not be able to trace the name of the function or the exact line number where it occurred.

2. No self-referencing

If your function needs to have a self-reference at any point (e.g. recursion, event handler that needs to unbind), it will not work.

Main benefit: No binding of ‘this’

Photo by davide ragusa on Unsplash

In classic function expressions, the this keyword is bound to different values based on the context in which it is called. With arrow functions however, this is lexically bound. It means that it uses this from the code that contains the arrow function.

For example, look at the setTimeout function below:

// ES5

var obj = {

id: 42,

counter: function counter() {

setTimeout(function() {

console.log(this.id);

}.bind(this), 1000);

}

};

In the ES5 example, .bind(this) is required to help pass the this context into the function. Otherwise, by default this would be undefined.

// ES6

var obj = {

id: 42,

counter: function counter() {

setTimeout(() => {

console.log(this.id);

}, 1000);

}

};

ES6 arrow functions can’t be bound to a this keyword, so it will lexically go up a scope, and use the value of this in the scope in which it was defined.

When you should not use Arrow Functions

After learning a little more about arrow functions, I hope you understand that they do not replace regular functions.

Here are some instances where you probably wouldn’t want to use them:

Object methods

When you call cat.jumps , the number of lives does not decrease. It is because this is not bound to anything, and will inherit the value of this from its parent scope.

var cat = {

lives: 9,

jumps: () => {

this.lives--;

}

}

2. Callback functions with dynamic context

If you need your context to be dynamic, arrow functions are not the right choice. Take a look at this event handler below:

var button = document.getElementById('press');

button.addEventListener('click', () => {

this.classList.toggle('on');

});

If we click the button, we would get a TypeError. It is because this is not bound to the button, but instead bound to its parent scope.

3. When it makes your code less readable

It is worth taking into consideration the variety of syntax we covered earlier. With regular functions, people know what to expect. With arrow functions, it may be hard to decipher what you are looking at straightaway.

When you should use them

Arrow functions shine best with anything that requires this to be bound to the context, and not the function itself.

Despite the fact that they are anonymous, I also like using them with methods such as map and reduce , because I think it makes my code more readable. To me, the pros outweigh the cons.

Thanks for reading my article, and clap if you liked it! Check out my other articles like How I built my Pomodoro Clock app, and the lessons I learned along the way, and Let’s demystify JavaScript’s ‘new’ keyword.",https://cdn-images-1.medium.com/max/1200/1*GRUP3Ml4piJhZQ8EOHkFDA.jpeg,[],https://medium.freecodecamp.org/when-and-why-you-should-use-es6-arrow-functions-and-when-you-shouldnt-3d851d7f0b26?source=collection_home---6------20----------------#--responses,2018-06-05 16:44:13.144000+00:00

Data,A deeply detailed but never definitive guide to mobile development architecture,['Jose Berardo Cunha'],"A deeply detailed but never definitive guide to mobile development architecture

Native, Web, PWA, hybrid, Cross-Compiled… what is “the best” way to develop for Android and iOS platforms? What looks reasonable? And how are you supposed to choose among the options? In this article, I’ll lay it all out so you can make an informed decision.

First things first, let me provide you with a bit of context. I am an IT senior consultant, and the idea of putting together this guide was born from discussions with one of our clients about what could be the best approach for them. Yes, just for them. And we realized that we did not have a well-defined strategy, a solid and reliable foundation, to help us come up with the right answer.

And you know what? I could not find such a guide easily anywhere on the Internet, either. Although there are several articles about this topic, none of those I came across were reasonably complete. Unfortunately the majority overlook a lot of concepts or, even worse, are essentially wrong.

Now, I’d like to take a wider look. And while I’m potentially helping someone make their own decisions, I’m also asking around the community for more thoughts on the subject.

This guide has two parts:

Mobile Development Architectural Tiers (this) How to make your decision

It's also available on YouTube as a series of 10 videos and as a free course on Udemy. There, you’ll find the same written material as here, the same videos from the YouTube series, as well as quizzes to fix all the topics and a final certification.

So let’s get started.

Introduction

When it comes to mobile platforms, it's arguable that there are just two big players: Android and iOS. Other technologies like Tizen, Blackberry, or Windows Phone are either dead or have been around for a while and have no prospects of reaching any significative market share.

A quick look at this massive duopoly might make you think that developers do not have many options when creating mobile apps. This idea can't be further from the truth, though. You can quickly spot a fistful of programming languages being used out there: C/C++, Java, Kotlin, Objective-C, Swift, JavaScript, TypeScript, C#, Dart, Ruby, and I'm pretty sure I’ve missed a few more.

The same is true of mobile development frameworks. Unless you are not a developer, or have somehow been unaware of new technologies for the last 10 years, you’ve probably heard about Cordova/PhoneGap, React Native, Xamarin, Ionic, Nativescript, or Flutter, just to name a few cross-platform solutions for mobile apps.

So let’s look at all these pieces of the architecture and break things down a bit.

TL;DR

There's no clear winner. All approaches have pros and cons, and might be either the best fit or the worst fit for your next project. In this guide, I'm classifying many different solutions into various tiers according to the distance their architectures are from the native platform.

Native Apps

To start, let's go straight to the metal. Our first architectural tier is Native Apps.

Native Apps Tier — Where you develop for each specific platform (it might be even more specific when considering NDK)

This is the tier where you must be aware of the idiosyncrasies of each platform. It’s not my intention to dig into them, I just want to mention a few things in a bit of context.

You can watch this first part on Youtube.

iOS

Starting on the iOS side, just because it's simpler, there's only Apple ruling the world. Originally, developers needed to learn Objective-C, a proprietary object-oriented variation of C with some inspiration from SmallTalk (and an insanely long-named API).

In 2014, Apple announced Swift, a multi-paradigm language, which was a lot easier than its predecessor. It's still possible to deal with Objective-C legacy code, but Swift has reached high maturity levels. So, if you're planning to learn how to natively develop for iOS, Swift is definitely where you should start.

Android

On the Android side, there are a number of different manufacturers. The vast majority of them rely upon ARM processors. But generally speaking, Android apps lay on virtual machine instances (instances of ART) to help deal with potential underlying specificities (not without many amazing tricks).

That's why, originally, the language of choice was Java. It’s not only been the most popular language in the World for almost two decades (with a few position swaps with C), but it’s also notable for its Java Virtual Machine (JVM). This empowered developers to compile their code down to an intermediate bytecode that could be read and run by the JVM.

With the Android Native Development Kit (NDK), it's also possible to develop critical parts of the app directly in native code, writing in C/C++. In this case, you have to be aware of underlying platform quirks.

Kotlin is a language unveiled by JetBrains in 2011. When it first came out, despite its flexibility and conciseness, it wasn't more than yet another JVM language with more successful competitors like Scala, Clojure, or Groovy. However, after its first major release in 2016, it rapidly started to stand out from the crowd, especially after Google announced that it would be officially supported on the Android platform at Google I/O 2017.

Kotlin is becoming Google's first class language (currently Kotlin and Java — in this order — are used throughout Android's official documentation). A total Java replacement is expected even more so now that the US Federal Appeals Court has ruled on the endless lawsuit filed by Oracle accusing Google of violating Java copyrights.

Native components

Developing in this tier, you can also leverage all native APIs and, in particular, the native components. This saves your app from having to reinvent the wheel.

I've published a video demo of how to create a simple project on Xcode (iOS) and Android Studio. If you want to check it out:

Demo of iOS and Android basic projects.

Native Apps advantages

Best performance and top user engagement

Bleeding edge native features

Notably good IDEs Android Studio / Xcode

Modern high-level languages Kotlin / Swift

Very low-level approach with NDK

Native Apps disadvantages

Two codebases to maintain

Require installation (except Android Instant Apps)

Hard to analyze SEO

Very expensive to get users to download the app

Web Apps

On the other side of the spectrum, we have Web Apps. Web Apps are essentially apps run by the browser. You don't write code targeting the platform, but rather any browser running on top of it.

Web Apps Tier — clearly on top of a browser bar targeting a beast sitting in between Android and iOS.

In this tier you’ll find an insane number of contenders jumping at each other's throats. But they all use an arsenal consisting of the same weapons: HTML, CSS, and Javascript.

Web frameworks and libraries, even when leveraging CSS pre-compilers like LESS or SASS, even Javascript pre-compiled languages like TypeScript, CoffeeScript or Flow, even symbiosis like JSX or Elm, leaving alone tools like Babel used to transpile everything to Javascript with different configurable levels of conformance with ECMAScript yearly specifications (ES6 / ES7 / ES8, or if you prefer ES2015 / ES2016 / ES2017 / ES2018).

At the end of the day, they all are HTML, CSS, and JavaScript rendered and run by the browser. There's no direct access to native APIs like camera, vibration, battery status, or file system, but some of them can be achieved via Web API's:

The big issue with Web APIs is their maturity level. Many of them are not supported by some browsers. There are differences in implementations, especially across mobile browsers.

Web App advantages

Shared code between platforms and desktop browsers

Do not require previous installations, just navigate and use

Tons of frameworks and libraries to go with them

Best for SEO

Web App disadvantages

Lower performance

Hard to get a native user experience

Require an internet connection

Not available on official app stores

API not as mature and reliable as native API

Frameworks and Web components

Angular, React, and Vue are probably the most popular web frameworks as of 2018. To be precise, however, React is considered just a library due to its flexible and less opinionated nature. Angular, on the other hand, is a strongly opinionated framework. Vue lives at some point in between them.

Angular vs React vs Vue

Angular, originally called AngularJS, was presented to the world in 2010 by Google. It quickly started to shine, due to its inversion of paradigms in comparison with other libraries from that time (like jQuery, the most popular back then). Instead of directly talking to HTML elements to manipulate the UI state, with AngularJS, templates were magically updated whenever the JavaScript model was updated.

As AngularJS became more and more popular, it also grew in purpose. It turned into a complete and opinionated framework that was one of the first that took SPAs (Single Page Apps) seriously. This growth (in both aspects) was responsible for some API bloats and performance issues.

React was created by Facebook to solve their own needs on the presentation layer. It introduced many aspects that suddenly became very popular, like virtual DOM, one-way data flow (originally named Flux, especially popular through an implementation library called Redux), and a mixture of HTML and JavaScript called JSX.

Only in 2016, after long debates and unexpected big changes, Google launched version two of its popular web framework. They called it Angular, instead of AngularJS. But, as many people already called the first version “Angular” (without the ""JS"" suffix), people started calling the new version Angular 2. That turned into a naming problem, as Google also announced that it would release new major versions every 6 months.

In my opinion, that was a mammoth mistake. I've seen this before (with Struts vs Struts 2/WebWork, for example). They have a massively popular product that appears to have reached its plateau, and it has started to be more criticized than praised. If Google decides to rebuild it from the ground up, they should never, by any means, just change its major version. How will people trust that they will not repeat it every new major version release? Version two is supposed to present breaking changes, but it doesn't mean it can be totally revamped.

Angular is a spectacular web framework, and I really feel passionate about it. However, it's a completely new beast. It does not have much to do with AngularJS. Even Vue, which is another amazing framework (probably one of the most pleasant to work with, by the way) looks more similar to AngularJS from a bird's-eye view. I believe this caused a significant movement away from Angular and contributed substantially to React's popularity.

Vue is the only one of the three most popular web frameworks that is not backed by a big company. It was actually started by a former Google developer. Due to its formidable simplicity and tiny footprint, it got attention from a massive and enthusiastic community.

Although there are more complete solutions, they all work on top of the concept of web components. There's an open specification about them currently in progress in W3C, and some interesting implementations like Polymer, Stencil and X-Tag.

In the third video of the series, I don't spend too much time discussing frameworks but discuss web component libraries:

The Web Apps tier is discussed in Part 3 of the series

Mobile Apps vs Web Apps

I’m not sure if you’ve noticed, but the order of tiers I'm presenting here follows what I think is the easiest path to learn all approaches. I started from the Native Tier, the most genuinely mobile development. Then I decided to fly directly to the other extreme to present the Web Tier, which is the tier that has been available since the first smartphones.

Only now, after elaborating on a comparison between the two edges of my diagram, will I start talking about many of the cross-platform approaches to build mobile apps.

There's a long debate between Mobile Apps vs Web Apps. Everything I say about Mobile Apps is not exclusive to the Native Tier. It is also applicable to all cross-platform tiers I present later on.

The user behavior dilemma

Users spend more time on Mobile Apps (87%) than on Mobile Websites (13%)

According to a Comscore survey in 2017, a user's fidelity to a mobile app is way more relevant than it is to mobile websites. According to an aligned article on Forbes, this is usually because of convenience (for example, home screen buttons, widgets, top notifications), speed (for example, smoother interfaces, almost instant start ups), and stored settings (for example, offline content).

Mobile Websites reach more people (8.9M monthly unique visitors against 3.3M of Mobile Apps)

On the other hand, in the same Comscore data, we learn that customers can be reached more easily from mobile websites, as they are not as much tied to their few apps of preference. If you compare the most popular websites versus the most downloaded apps, it's estimated that an average of 8.9 million unique web visitors per month access the top 1000 websites. That's almost three times more than the average unique users of the top 1000 most downloaded apps.

Distribution (Web App) x Engagement (Mobile App)

That's all about distribution vs engagement. Your web app has a higher chance of being accessed, as users are more likely to try new things when navigating through their mobile browsers. But Mobile Apps have been proven to be more engaging, and catch the users attention for much longer periods.

Now that you understand the dilemma, let's have a look at Progressive Web Apps. This is an approach so tied to the Web Apps tier that I classify it as just an addendum to Web Apps. But it's a big disruptor and a serious candidate for the most prominent new and cool thing in web and mobile development.

Progressive Web Apps

Progressive Web Apps (PWAs) are a set of tools used to give Web App users the same experience they are accustomed to when they run Mobile Apps. This means that Web Apps can leverage the potentially higher levels of distribution with more decent levels of engagement.

Progressive Web Apps addendum to Web Apps tier

Google defined three main qualifications for PWAs: they must be Reliable, Fast, and Engaging.

Features called Service Workers and the App Shell are the foundation of Progressive Web Apps. They were created to promote apps’ reliability as they are now designed to work regardless of the device’s connection status. That includes offline mode, as well as poor connections. They also provide significant perceived performance boost, as apps launch using locally cached data, which eliminates delays for synchronous content downloads.

You could consider reliability an indirect vector of engagement. Users are not affected while commuting by train, for example. They can stay engaged.

The same applies to speed. According to Google:

53% of users will abandon a site if it takes longer than 3 seconds to load!

However, being exclusively reliable and fast on load doesn't necessarily guarantee high engagement. PWAs leverage mobile-related features that used to be exclusive to mobile apps, like an “Add to Home Screen” option and Push Notifications.

When it comes to to the “Add to Home Screen” feature, you might notice that Apple has had a similar feature since the very first iPhone. Some people even argue that Progressive Web Apps are Google's fancy new name for an original Apple idea.

And you really can’t completely disagree. Some ideas are actually cycling. They come, go away, and then come back with a new name and some enhancements (for instance, Service Workers), so they can finally stick around.

On the other hand, it’s hard to completely agree. Steve Jobs’ speech about Web 2.0 + AJAX and the memorable announcement of the iPhone back in WWDC 2007 are not convincing enough to call him as the father, or even the prophet, of PWAs.

To be fair, the Add to Home Screen capability on iPhone has been nothing more than a subtle, almost hidden, feature to generate desktop icons that just start up Web Apps in fullscreen mode. It has all the burden of HTTP request-response cycles and no clear path around caches.

PWAs start from the right point. They explore how previous installations of Web Apps aren’t necessary without losing the client-side bootstrap of Mobile Apps. This means that everything a user needs for their first interaction following startup might be locally cached (read: App Shell) and kept available as soon as they hit “Add to Home Screen.”

Moving onto another well-known characteristic of PWAs, let’s talk about the super engaging (or re-engaging) feature of the Mobile Apps world: Push Notifications. They are alert-style messages that appear on the top notification bar / area, as well as on lock screens. They have the power of pulling users back to your app once they receive the notification.

To reinforce the appeal of PWAs, Google has been pulling all modern Web APIs under the PWA umbrella. So expect to see things like Payment Requests, Credential Management, WebVR, Sensors, WebAssembly, and WebRTC in the context of Progressive Web Apps. But these feature are not necessarily tied to PWAs, and some were even born before the term PWA was coined.

PWA and Apple

Apple, on the other hand, announced their first solid milestones towards PWAs only in March 2018. Although there are still some limitations, the progress is appreciable. Some of the limitations might be related to the fact that Safari has fallen behind its competitors. Others could be attributed to Apple's philosophy of tight control.

Still, Apple has a more profitable App Store than Google. Apple's asserts that more criteria on app publications brings more overall reliability, and PWAs are bound to hurt the App Store's revenue. This suggests that some limitations that seem to be intentionally imposed (like 50Mb of PWA maximum cache size) will cost more to be revoked.

Unfortunately PWAs are not perfect

Web solutions and, on different levels, all cross-platform solutions struggle to attain the excellence and comprehensiveness of Native Apps. Every new feature, and every detail particular to Android or iOS makes that native feel harder and harder to access as you distance your app from the native tier.

Overall, PWAs fix some issues in the Web Apps tier. But there are other issues that can’t be fixed by a solution working on top of a browser.

What PWAs fix

More “native” experience

Faster load times

Do not require an internet connection

Force web developers to be aware of situations where there’s no connection as well as a bad connection

Incorporate features from Mobile Apps like Push Notifications, Geolocation, or Speech Recognition

What they don’t

Inherent slowness

Not available on app stores (just yet)

Still not fully supported by all browsers

Still lack mobile features like NFC, Ambient Light, Geofencing

Also lack support for peculiarities of Android or iOS like PiP, smart app banners, launch screen widgets, and 3D touch

In the video below, I do a brief overview of PWAs.

Progressive Web Apps are introduced in the Part 4 of the series

Hybrid Apps

At this level, we begin to dive into the Mobile App world. We’ll start from the most distant tier: Hybrid Apps.

The term Hybrid is also commonly applied to all cross-platform solutions. Here, however, I’m restricting it to Apps that work inside mobile components, called WebViews.

The Hybrid Apps tier. Below the browser's line but on top of WebViews

In the demos in the second video, my purpose for adding WebView as the Hello World example was to make clear that there's a native component for each platform that is able to perform like an actual browser.

Cordova/PhoneGap

Solutions like Cordova/PhoneGap close the gap (sorry for the uninspired pun) between Web and Mobile Apps. They provide tools to package developer's HTML, JavaScript, and CSS code (as well as any extra assets like images or videos) and transform them into Mobile Apps (yes, real Android or iOS apps). These apps have their WebView exclusively to interpret and run the original web code, starting with the “index.html” file in the app’s main folder (normally called “www”). They also bridge the JavaScript code to native APIs through plugins which are partially implemented in JavaScript and partially in a native language.

So, let's make things clearer. Hybrid Apps are able to access native APIs (instead of Web APIs), but they are enclosed by the WebView. A button with Cordova must be an HTML button rendered by a WebView instead of a mobile native button.

This is the magical tier that allows companies to port their Web Apps to Mobile Apps to be shipped by app stores. So any web framework is allowed here.

Ionic

Frameworks like Ionic wrap Cordova into their own solutions. With Ionic, you don't need to use Cordova’s command line interface (CLI), because all of its commands are wrapped by the Ionic CLI.

Recently, the Ionic team decided to take the reins of the entire stack of Hybrid Apps. So they launched a proposed replacement for Cordova called Capacitor. Capacitor has support for Cordova plugins, and can also be used by a non-Ionic project.

You can watch me going through a Cordova Hello World sample in the fifth video of the series:

Hybrid Apps are in Part 5 of the series.

Hybrid Apps advantages

They are essentially web apps that are shippable to official app stores

Can be used along with any JavaScript framework / library

The code is still highly shareable across platforms

Access to native features (for instance, camera, accelerometer, contact list)

Hybrid Apps disadvantages

Struggle with performance issues and memory consumption, as web views are responsible for rendering everything on screen

Have to mimic all native UI components on top of a single web view

Harder to be accepted and published on App Store

Usually take longer to have native features available for these environments

Web Native

Web Native is a relatively new and often misunderstood tier. That's where Web Apps meet native components. Although Appcelerator (Axway) Titanium has been around a long time, there are some relatively new competitors that justify making this a completely separate category of mobile apps.

Web Native Apps don't need WebView as they talk directly to other native components

As you can see above, there's no web view to render and run your application. So, how is your JavaScript executed? Is it compiled? Well, if you consider transpilation (compilation from one language to another — for example TypeScript to JavaScript), bundling, minification, mangling, and obfuscation all together as a compilation, yes JavaScript is compiled.

But the problem is, this doesn't make your JavaScript something directly understood by Android or iOS operational systems. And, in theory, there's no native component that only serves as a JavaScript engine without the bloat of the HTML layout engine.

The strategy is to ship JavaScript engines (normally V8 for Android and JavaScriptCore for iOS) along with your code. Although they have small footprints and are very fast, they are something external that must be provided by your app.

On the other hand, this approach tends to have better UI performance, as all the components are the same (or are based on the same thing for React Native, for example) as the ones used by Native Apps.

Web Native Apps advantages

Reach both platforms with one single codebase

Roughly the same performance as native apps, as they also deal with native UI components

Tweaks are necessary, but the code is still shareable with web development

Web Native Apps disadvantages

Even with one single codebase, the developer must be aware of native components

Steeper learning curve than Hybrid / Web Apps for web developers, especially when it comes to layout

React Native

In part 6 of the series, I do a quick Hello World in React Native. This shows, on Android Studio's Layout Inspector, what components were rendered in the emulator. I compare with the previous examples, ensuring that there's no WebView whatsoever.

Web Native Apps presentation with focus on React Native in Part 6 of the series.

Nativescript

Another amazing framework that I've been particularly interested in over the last two years (I have a course on Udemy about it — in Portuguese), is Nativescript. It’s similar to React Native but is not tied to the React world (there's an unofficial integration, Nativescript-Preact, though).

With Nativescript, you can develop using vanilla JavaScript, TypeScript, Angular and, more recently, Vue. Of course you can use other frameworks, but those are the ones officially supported. It’s fairly well documented too, by the way.

Nativescript has tools like Nativescript Sidekick and Nativescript Playground, as well as project structures based on templates that can be provided by the community. This should help you in project creation, giving you the ability to start, deploy, test, and run on simulators on the cloud and iPhone devices even when you are not developing using a Mac.

In the seventh part of the series, I do a Hello World using Sidekick along with another project started from the CLI and a WhatsApp clone template I created for learning purposes.

Web Native Apps with Nativescript in Part 7 of the series.

It's important to have a look at the Layout Inspector when your app is running on an Android emulator. With Nativescript, it shows the native components (again, no WebView), and direct instances of common Android classes like TextView. This is different than React Native, which has its own classes to wrap the native components.

That's probably why Nativescript claims that there’s no delay between when a new feature is available on iOS and Android and when you can use it in a Nativescript project. For example, they posted on their blog an AR project on the same day iOS 11 was officially released with the new ARKit API.

Weex

Another framework worth mentioning in this category is Weex. It's a project developed by Alibaba, and is currently incubated at Apache Sofware Foundation (ASF). It uses common HTML tags like <div> and CSS commands inside <style> tags to call native components instead. From their documentation:

Although components in Weex look like HTML tags, you are not able to use all of them. Instead, you can only use the built-in components and your custom components.

Cross Compiled

At this level, it’s time to jump off the Web bandwagon. This is the closest tier to native development, but has the advantage of using one single codebase to target Android and iOS.

Development tiers now complete with Cross Compiled Apps

RubyMotion and Xamarin

There are solutions like RubyMotion. This is a way to write mobile apps using Ruby and compile directly to the targeted platform (as it was created using any ""native"" language).

Another option is Xamarin, where you write in C#, compile to an intermediate bytecode, and deploy your app along with an instance of the Mono common language runtime. This approach has the same drawback as Web Native (where V8 and JavaScriptCore are delivered by your app), but can also rely upon JIT compilations to optimize the app at runtime.

Flutter

Last but not least, I'd like to bring up Flutter. It’s Google's newest cool initiative for mobile development. It fits in the Cross Compiled tier because you write apps using the Dart language and compile them down to the native platform.

Flutter has innovated in some aspects. Probably the most outstanding one is the fact that it provides its own set of components.

What? Own set of components?

Yes, Flutter provides a number of different components so you can completely skip the ones from the platform. It has generic components as well as Material Design components for Android, and Cupertino components for iOS.

Rather than .Net virtual machine (as Xamarin) or JavaScript engines (as Web Native frameworks), with Flutter your app will deliver the components you decide to use.

Are they native components?

Yes, they are. Your app is native, too. Everything is compiled to the native architecture. However, bear in mind they are not the pre-existing native components.

What's the point of that?

Well, in my opinion, this solution is clever and audacious. I've been waiting to talk about advantages and disadvantages, but as it's just one particular technology, let me address them now.

One of the biggest challenges for Web Native and Cross Compiled solutions (remember, above Native but below the WebView in our tiers) is how to deal with native components. For example, an important problem is how to lay them out. That's because they were not created to be used by those external resources. Also, they were not created with a counterpart in the other platform in mind. The Android NavBar doesn't work like iOS UINavBar, for example.

With Flutter, components are created with cross-platform always in mind. So let's have a look at the pros and cons of the Cross Compiled Apps tier:

Cross Compiled Apps advantages

Reach both platforms with one single language

Roughly the same performance as native apps, as they also deal with native UI components

Cross Compiled Apps disadvantages

Slightly delayed support for the latest platform updates

Code not shareable with web development

Even with one single codebase, the developer must be aware of native components

PS: With Flutter, you’ll provide your own set of widgets along with your app's code

Mobile Apps runtime architecture",https://cdn-images-1.medium.com/max/1200/1*kHze88HBCkKt8Tw4MESC9Q.png,[],https://medium.freecodecamp.org/a-deeply-detailed-but-never-definitive-guide-to-mobile-development-architecture-6b01ce3b1528?source=collection_home---6------21----------------,2018-06-05 16:34:24.241000+00:00

Data,How to deliver a React Native app to the client – freeCodeCamp,[],"How to deliver a React Native app to the client

If you have written some React Native apps, you’ve probably noticed that the process of beta-release version generation requires many repeatable steps. This happens especially for multi-platform apps.

Let’s look at sample action steps you need to perform to deliver the beta version app to the client or tester:

Download the proper branch from the repository

Android:

Insert the APK signing key into the ./android/app/ directory

directory Build the release version

Send the app, for example via e-mail

iOS:

Launch Xcode

Change the scheme to Release

Change the jsCodeLocation value to a static main.jsbundle file path

value to a static file path Archive

Upload the app to TestFlight

As you can see, the above list contains a large number of repeatable steps. Since they are repeatable, we can automate them, right?

Possible solutions

There are several solutions for automating beta release version generation and delivering the app to the client.

Visual Studio App Center

The first solution that came to our minds at Brainhub was the use of the Visual Studio App Center. A project built by Microsoft seems to be really attractive — in addition to building the app in the cloud (free 240 minutes / month of building) and distribution among testers and the client, it also provides a platform for testing apps on many real devices, giving access to reports and screenshots of every step of the process.

However, it quickly turned out that this was not the appropriate solution for our particular project. VS App Center has limited configuration abilities, and the app’s code needs to be downloaded from the Git repository hosted on GitHub, Bitbucket, or VSTS. Due to the fact that we use GitLab, we had to rule out this solution (but it could work for your project).

HockeyApp (with Fastlane)

The next option was to use HockeyApp — a tool for app distribution and collecting crash reports and users’ feedback. The service was initially created for distribution of iOS apps using the ‘ad hoc’ method (outside of App Store), but currently it works for Android also.

HockeyApp works well as a delivery platform of software testing versions, but does not give the functionality of building the app. However, we can also use Fastlane — a tool for mobile app building process automation built by fabric.io.

Preparations

Before you start building and deploying the app, you should prepare the environment. This section describes the steps you should take first.

Automatic jsCodeLocation change

React Native documentation says that you should change jsCodeLocation to the static js bundle for the iOS release version in AppDelegate.m file. But there’s no need to do that manually every time you release the app — you can use the #ifdef DEBUG macro to do it automatically. Just replace the line containing jsCodeLocation = … with the following code.

#ifdef DEBUG

// DEV

jsCodeLocation = [[RCTBundleURLProvider sharedSettings] jsBundleURLForBundleRoot:@”index” fallbackResource:nil];

#else

// PROD

jsCodeLocation = [[NSBundle mainBundle] URLForResource:@”main” withExtension:@”jsbundle”];

#endif

Ignore helper files

During the process of building the app, there will be some helper files created. There’s no need to commit them to the repository, so just add them to the following “.gitignore” file.

# Deployment

*.cer

*.jsbundle

*.jsbundle.meta

*dSYM.zip

*.keystore

*.mobileprovision

fastlane/report.xml

APK signing key

To release an Android app, you need a signing key. To learn more about this process, look here.

When you have your key generated, move it to the “android/app” directory and remember to add *.keystore to “.gitignore”.

Fastlane + HockeyApp + Testflight

You will learn how to automatically generate an app written in React Native for Android and iOS platforms, and send it to HockeyApp (Android) and Testflight (iOS).

First, let’s install Fastlane. Make sure you have the newest version of Xcode command line tools installed.

xcode-select — install

Install Fastlane.

[sudo] gem install fastlane -NV` or `brew cask install fastlane`

Init Fastlane.

fastlane init

The command above will create the “fastlane” directory in current directory with a file called “Fastfile” that contains the Fastlane configuration.

Appfile

In the “fastlane” directory, create a file called “Appfile”, which stores data that is used across all fastlane tools, for example AppleID. It is required for the iOS build and deployment to Testflight.

Add your AppleID to “Appfile”.

Fastfile

Your beta release Fastfile might look like this.

# More documentation about how to customize your build

# can be found here:

# https://docs.fastlane.tools

# fastlane_version “2.68.0”

# Fastfile actions accept additional configuration, but

# don’t worry, fastlane will prompt you for required

# info which you can add here later

platform :ios do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

get_certificates

get_provisioning_profile(

app_identifier: “org.you.yourProject”

)

# build your iOS app

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

# TestFlight

pilot()

end

end

platform :android do

lane :beta do

ensure_git_branch(

branch: “master”

)

git_pull

# build the release variant

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

# upload to HockeyApp

hockey(

api_token: “YOUR_TOKEN”

)

end

end

Let’s analyze our “Fastfile” step-by-step.

The code block below will be executed after typing fastlane ios beta into the console.

platform :ios do

lane :beta do

# …

end

end

For Android , type fastlane android beta .

platform :android do

lane :beta do

# …

end

end

Ensure that the current branch is master and perform git pull to sync with the remote repository.

ensure_git_branch(

branch: “master”

)

git_pull

iOS only

Let’s increment the build number (works for iOS only). The application that is being sent to Testflight has to have a higher build number than the previous version.

increment_build_number(

xcodeproj: “./ios/yourProject.xcodeproj”

)

Testflight and Ad Hoc distribution require the proper certificate and provisioning profile. There are several methods of signing apps:

match

cert and sigh

Xcode’s code signing feature

manually

In this article, cert and sigh was used. For further reading about codesigning using Fastlane, visit this site.

get_certificates

get_provisioning_profile( app_identifier: “org.you.yourProject” )

Next, there is the step of building the iOS version where we pass the params such as project path, scheme , and export_method . Export_method contains one of the following values: app-store , ad-hoc , package , enterprise , development , or developer-id .

build_ios_app(

project: “./ios/yourProject.xcodeproj”,

scheme: “yourProjectRelease”,

export_method: “app-store”

)

The last step for iOS is sending the app to Testflight.

pilot()

Android only

Now let’s look at the Android version. There are two gradle steps: cleaning, and building the release version.

gradle(task: “clean”, project_dir: “android/”)

gradle(task: “assemble”, build_type: “Release”, project_dir: “android/”)

Now you can send the generated app to HockeyApp.

hockey(

api_token: “YOUR_TOKEN”

)

If you don’t add some required parameter, for example no iTunes Connect user in Fastfile, Fastlane will ask you for that data in the console.

HockeyApp Configuration

After signing up and signing in to HockeyApp, you will see the blue “New App” button.",https://cdn-images-1.medium.com/max/1200/1*153T3TpCccNK7hs11oRNpA.png,[],https://medium.freecodecamp.org/how-to-deliver-a-react-native-app-to-the-client-e58421e7272e?source=collection_home---6------22----------------,2018-06-05 01:26:27.937000+00:00

Data,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------,2018-06-05 00:59:03.212000+00:00

Data,Here are some practical JavaScript objects that have encapsulation,['Cristi Salcescu'],"Here are some practical JavaScript objects that have encapsulation

Photo by Jon Tyson on Unsplash

Encapsulation means information hiding. It’s about hiding as much as possible of the object’s internal parts and exposing a minimal public interface.

The simplest and most elegant way to create encapsulation in JavaScript is using closures. A closure can be created as a function with private state. When creating many closures sharing the same private state, we create an object.

I’m going to build a few objects that can be useful in an application: Stack, Queue, Event Emitter, and Timer. All will be built using factory functions.

Let’s start.

Stack

Stack is a data structure with two principal operation: push for adding an element to the collection, and pop for removing the most recent element added. It adds and removes elements according to the Last In First Out (LIFO) principle.

Look at the next example:

let stack = Stack();

stack.push(1);

stack.push(2);

stack.push(3);

stack.pop(); //3

stack.pop(); //2

Let’s implement the stack using a factory function.

function Stack(){

let list = [];



function push(value){ list.push(value); }

function pop(){ return list.pop(); }



return Object.freeze({

push,

pop

});

}

The stack object has two public methods push() and pop() . The internal state can only be changed through these methods.

stack.list; //undefined

I can’t modify directly the internal state:

stack.list = 0;//Cannot add property list, object is not extensible

Stack using class

If I do the same implementation using class I don’t have encapsulation.

let stack = new Stack();

stack.push(1);

stack.push(2);

stack.list = 0; //corrupt the private state

console.log(stack.pop()); //this.list.pop is not a function

Here is the implementation of the stack using a class:

class Stack {

constructor(){

this.list = [];

}



push(value) { this.list.push(value); }

pop() { return this.list.pop(); }

}

For a more in-depth comparison, take a look at Class vs Factory function: exploring the way forward

Queue

Queue is a data structure with two principal operations: enqueue for adding an element to the collection, and dequeue for removing the first element from the collection. It adds and removes elements according to the First In First Out (FIFO) principle.

Here is an example of using the queue:

let queue = Queue();

queue.enqueue(1);

queue.enqueue(2);

queue.enqueue(3);

queue.dequeue(); //1

queue.dequeue(); //2

Below is the implementation of the queue :

function Queue(){

let list = [];



function enqueue(value){ list.push(value); }

function dequeue(){ return list.shift(); }



return Object.freeze({

enqueue,

dequeue

});

}

As we saw before, the internal state of the object can't be accessed from the outside:

queue.list; //undefined

Event emitter

An event emitter is an object with a publish/subscribe API. It’s used to communicate between different parts in an application.

Look at the next example:

let eventEmitter = EventEmitter();

eventEmitter.subscribe(""update"", doSomething);

eventEmitter.subscribe(""update"", doSomethingElse);

eventEmitter.subscribe(""add"", doSomethingOnAdd);

eventEmitter.publish(""update"", {});

function doSomething(value) { }

function doSomethingElse(value) { }

function doSomethingOnAdd(value) { }

First, I subscribe with two functions for the update event, and with one function for the add event. When the event emitter publishes the update event, doSomething and doSomethingElse will be called.

Here is an implemention of a simple Event Emitter:

function EventEmitter(){

let subscribers = [];



function subscribe(type, callback){

subscribers[type] = subscribers[type] || [];

subscribers[type].push(callback);

}



function notify(value, fn){

try {

fn(value);

}

catch(e) { console.error(e); }

}



function publish(type, value){

if(subscribers[type]){

let notifySubscriber = notify.bind(null, value);

subscribers[type].forEach(notifySubscriber);

}

}



return Object.freeze({

subscribe,

publish

});

}

The subscribers state and the notify method are private.

Timer

JavaScript has two well known timer functions : setTimeout and setInterval . I would like to work with timers in a object-oriented way and do something like:

let timer = Timer(doSomething, 6000);

timer.start();

function doSomething(){}

But the setInterval() function has some limitations. It does not wait for the previous call to finish before making a new call. A new call will be made even if the previous one has not finished yet. Even worse, in the case of AJAX calls, the response callbacks may get out of order.

The recursive setTimeout pattern can solve this situation. Using this pattern, a new call is made only when the previous one has finished. (Here is an example.)

Let’s create the Timer object:

function Timer(fn, interval){

let timerId;

function startRecursiveTimer(){

fn().then(function makeNewCall(){

timerId = setTimeout(startRecursiveTimer, interval);

});

}

function stop(){

if(timerId){

clearTimeout(timerId);

timerId = 0;

}

}

function start(){

if(!timerId){

startRecursiveTimer();

}

}

return Object.freeze({

start,

stop

});

}

let timer = Timer(getTodos, 2000);

timer.start();

Only the start and stop methods are public. Everything else is private. There are no this losing context problems when calling setTimeout(startRecursiveTimer, interval) , as factory functions don’t use this .

The timer works with a callback that returns a promise.

Now, we can easily do something like stopping the timer when the browser tab is hidden, and then starting it back when the tab is visible:

document.addEventListener(""visibilitychange"", toggleTimer);

function toggleTimer(){

if(document.visibilityState === ""hidden""){

timer.stop();

}

if(document.visibilityState === ""visible""){

timer.start();

}

}

Conclusion

JavaScript offers a unique way for creating encapsulated objects using factory functions. Objects encapsulate state.

Stack and Queue can be created as wrappers around the basic array functionality.

Event emitter is an object that communicates between different parts in an application.

The timer object is easy to use. It has a clear interface start() and stop() . You don’t have to deal with the internals parts of managing the timer token.

More on improving JavaScript code:

How point-free composition will make you a better functional programmer

How to make your code better with intention-revealing function names

Why you should give the Closure function another chance

Make your code easier to read with Functional Programming",https://cdn-images-1.medium.com/max/1200/1*mCEgL1FUi8SoVeMSJrQ9pA.jpeg,[],https://medium.freecodecamp.org/here-are-some-practical-javascript-objects-that-have-encapsulation-fc4c1a79c655?source=collection_home---6------23----------------#--responses,2018-06-05 00:59:03.212000+00:00

Data,A coffee-break introduction to time complexity of algorithms,['Vicky Lai'],"A coffee-break introduction to time complexity of algorithms

Just like writing your very first for loop, understanding time complexity is an integral milestone to learning how to write efficient complex programs. Think of it as having a superpower that allows you to know exactly what type of program might be the most efficient in a particular situation — before even running a single line of code.

The fundamental concepts of complexity analysis are well worth studying. You’ll be able to better understand how the code you’re writing will interact with the program’s input, and as a result, you’ll spend a lot less wasted time writing slow and problematic code.

It won’t take long to go over all you need to know in order to start writing more efficient programs — in fact, we can do it in about fifteen minutes. You can go grab a coffee right now (or tea, if that’s your thing) and I’ll take you through it before your coffee break is over. Go ahead, I’ll wait.

All set? Let’s do it!

What is “time complexity” anyway?

The time complexity of an algorithm is an approximation of how long that algorithm will take to process some input. It describes the efficiency of the algorithm by the magnitude of its operations. This is different than the number of times an operation repeats. I’ll expand on that later. Generally, the fewer operations the algorithm has, the faster it will be.

We write about time complexity using Big O notation, which looks something like O(n). There’s rather a lot of math involved in its formal definition, but informally we can say that Big O notation gives us our algorithm’s approximate run time in the worst case, or in other words, its upper bound. It is inherently relative and comparative.

We’re describing the algorithm’s efficiency relative to the increasing size of its input data, n. If the input is a string, then n is the length of the string. If it’s a list of integers, n is the length of the list.

It’s easiest to picture what Big O notation represents with a graph:

Lines made with the very excellent Desmos graph calculator. You can play with this graph here.

Here are the main important points to remember as you read the rest of this article:

Time complexity is an approximation

An algorithm’s time complexity approximates its worst case run time

Determining time complexity

There are different classes of complexity that we can use to quickly understand an algorithm. I’ll illustrate some of these classes using nested loops and other examples.

Polynomial time complexity

A polynomial, from the Greek poly meaning “many,” and Latin nomen meaning “name,” describes an expression comprised of constant variables, and addition, multiplication, and exponentiation to a non-negative integer power. That’s a super math-y way to say that it contains variables usually denoted by letters, and symbols that look like these:

The below classes describe polynomial algorithms. Some have food examples.

Constant

A constant time algorithm doesn’t change its running time in response to the input data. No matter the size of the data it receives, the algorithm takes the same amount of time to run. We denote this as a time complexity of O(1).

Here’s one example of a constant algorithm that takes the first item in a slice.

func takeCupcake(cupcakes []int) int {

return cupcakes[0]

}

Choice of flavours are: vanilla cupcake, strawberry cupcake, mint chocolate cupcake, lemon cupcake, and “wibbly wobbly, timey wimey” cupcake.

With this contant-time algorithm, no matter how many cupcakes are on offer, you just get the first one. Oh well. Flavours are overrated anyway.

Linear

The running duration of a linear algorithm is constant. It will process the input in n number of operations. This is often the best possible (most efficient) case for time complexity where all the data must be examined.

Here’s an example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

}

Here’s another example of code with time complexity of O(n):

func eatChips(bowlOfChips int) {

for chip := 0; chip <= bowlOfChips; chip++ {

// double dip chip

}

}

It doesn’t matter whether the code inside the loop executes once, twice, or any number of times. Both these loops process the input by a constant factor of n, and thus can be described as linear.

Don’t double dip in a shared bowl.

Quadratic

Now here’s an example of code with time complexity of O(n2):

func pizzaDelivery(pizzas int) {

for pizza := 0; pizza <= pizzas; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

Because there are two nested loops, or nested linear operations, the algorithm process the input n2times.

Cubic

Extending on the previous example, this code with three nested loops has time complexity of O(n3):

func pizzaDelivery(boxesDelivered int) {

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

}

Seriously though, who delivers unsliced pizza??

Logarithmic

A logarithmic algorithm is one that reduces the size of the input at every step. We denote this time complexity as O(log n), where log, the logarithm function, is this shape:

One example of this is a binary search algorithm that finds the position of an element within a sorted array. Here’s how it would work, assuming we’re trying to find the element x:

If x matches the middle element m of the array, return the position of m. If x doesn’t match m, see if m is larger or smaller than x. If larger, discard all array items greater than m. If smaller, discard all array items smaller than m. Continue by repeating steps 1 and 2 on the remaining array until x is found.

I find the clearest analogy for understanding binary search is imagining the process of locating a book in a bookstore aisle. If the books are organized by author’s last name and you want to find “Terry Pratchett,” you know you need to look for the “P” section.

You can approach the shelf at any point along the aisle and look at the author’s last name there. If you’re looking at a book by Neil Gaiman, you know you can ignore all the rest of the books to your left, since no letters that come before “G” in the alphabet happen to be “P.” You would then move down the aisle to the right any amount, and repeat this process until you’ve found the Terry Pratchett section, which should be rather sizable if you’re at any decent bookstore, because wow did he write a lot of books.

Quasilinear

Often seen with sorting algorithms, the time complexity O(n log n) can describe a data structure where each operation takes O(log n) time. One example of this is quick sort, a divide-and-conquer algorithm.

Quick sort works by dividing up an unsorted array into smaller chunks that are easier to process. It sorts the sub-arrays, and thus the whole array. Think about it like trying to put a deck of cards in order. It’s faster if you split up the cards and get five friends to help you.

Non-polynomial time complexity

The below classes of algorithms are non-polynomial.

Factorial

An algorithm with time complexity O(n!) often iterates through all permutations of the input elements. One common example is a brute-force search, seen in the traveling salesman problem. It tries to find the least costly path between a number of points by enumerating all possible permutations and finding the ones with the lowest cost.

Exponential

An exponential algorithm often also iterates through all subsets of the input elements. It is denoted O(2n) and is often seen in brute-force algorithms. It is similar to factorial time except in its rate of growth, which, as you may not be surprised to hear, is exponential. The larger the data set, the more steep the curve becomes.

In cryptography, a brute-force attack may systematically check all possible elements of a password by iterating through subsets. Using an exponential algorithm to do this, it becomes incredibly resource-expensive to brute-force crack a long password versus a shorter one. This is one reason that a long password is considered more secure than a shorter one.

There are further time complexity classes less commonly seen that I won’t cover here, but you can read about these and find examples in this handy table.

Recursion time complexity

As I described in my article explaining recursion using apple pie, a recursive function calls itself under specified conditions. Its time complexity depends on how many times the function is called and the time complexity of a single function call. In other words, it’s the product of the number of times the function runs and a single execution’s time complexity.

Here’s a recursive function that eats pies until no pies are left:

func eatPies(pies int) int {

if pies == 0 {

return pies

}

return eatPies(pies - 1)

}

The time complexity of a single execution is constant. No matter how many pies are input, the program will do the same thing: check to see if the input is 0. If so, return, and if not, call itself with one fewer pie.

The initial number of pies could be any number, and we need to process all of them, so we can describe the input as n. Thus, the time complexity of this recursive function is the product O(n).

This function’s return value is zero, plus some indigestion.

Worst case time complexity

So far, we’ve talked about the time complexity of a few nested loops and some code examples. Most algorithms, however, are built from many combinations of these. How do we determine the time complexity of an algorithm containing many of these elements strung together?

Easy. We can describe the total time complexity of the algorithm by finding the largest complexity among all of its parts. This is because the slowest part of the code is the bottleneck, and time complexity is concerned with describing the worst case for the algorithm’s run time.

Say we have a program for an office party. If our program looks like this:

package main



import ""fmt""



func takeCupcake(cupcakes []int) int {

fmt.Println(""Have cupcake number"",cupcakes[0])

return cupcakes[0]

}



func eatChips(bowlOfChips int) {

fmt.Println(""Have some chips!"")

for chip := 0; chip <= bowlOfChips; chip++ {

// dip chip

}

fmt.Println(""No more chips."")

}



func pizzaDelivery(boxesDelivered int) {

fmt.Println(""Pizza is here!"")

for pizzaBox := 0; pizzaBox <= boxesDelivered; pizzaBox++ {

// open box

for pizza := 0; pizza <= pizzaBox; pizza++ {

// slice pizza

for slice := 0; slice <= pizza; slice++ {

// eat slice of pizza

}

}

}

fmt.Println(""Pizza is gone."")

}



func eatPies(pies int) int {

if pies == 0 {

fmt.Println(""Someone ate all the pies!"")

return pies

}

fmt.Println(""Eating pie..."")

return eatPies(pies - 1)

}



func main() {

takeCupcake([]int{1, 2, 3})

eatChips(23)

pizzaDelivery(3)

eatPies(3)

fmt.Println(""Food gone. Back to work!"")

}

We can describe the time complexity of all the code by the complexity of its most complex part. This program is made up of functions we’ve already seen, with the following time complexity classes:

To describe the time complexity of the entire office party program, we choose the worst case. This program would have the time complexity O(n3).

Here’s the office party soundtrack, just for fun.

Have cupcake number 1

Have some chips!

No more chips.

Pizza is here!

Pizza is gone.

Eating pie...

Eating pie...

Eating pie...

Someone ate all the pies!

Food gone. Back to work!

P vs NP, NP-complete, and NP-hard

You may come across these terms in your explorations of time complexity. Informally, P (for Polynomial time), is a class of problems that is quick to solve. NP, for Nondeterministic Polynomial time, is a class of problems where the answer can be quickly verified in polynomial time. NP encompasses P, but also another class of problems called NP-complete, for which no fast solution is known. Outside of NP, but still including NP-complete, is yet another class called NP-hard, which includes problems that no one has been able to verifiably solve with polynomial algorithms.

P vs NP Euler diagram, by Behnam Esfahbod, CC BY-SA 3.0

P versus NP is an unsolved, open question in computer science.

Anyway, you don’t generally need to know about NP and NP-hard problems to begin taking advantage of understanding time complexity. They’re a whole other Pandora’s box.

Approximate the efficiency of an algorithm before you write the code

So far, we’ve identified some different time complexity classes and how we might determine which one an algorithm falls into. So how does this help us before we’ve written any code to evaluate?

By combining a little knowledge of time complexity with an awareness of the size of our input data, we can take a guess at an efficient algorithm for processing our data within a given time constraint. We can base our estimation on the fact that a modern computer can perform some hundreds of millions of operations in a second. The following table from the Competitive Programmer’s Handbook offers some estimates on required time complexity to process the respective input size in a time limit of one second.

Keep in mind that time complexity is an approximation, and not a guarantee. We can save a lot of time and effort by immediately ruling out algorithm designs that are unlikely to suit our constraints, but we must also consider that Big O notation doesn’t account for constant factors. Here’s some code to illustrate.

The following two algorithms both have O(n) time complexity.

func makeCoffee(scoops int) {

for scoop := 0; scoop <= scoops; scoop++ {

// add instant coffee

}

}

func makeStrongCoffee(scoops int) {

for scoop := 0; scoop <= 3*scoops; scoop++ {

// add instant coffee

}

}

The first function makes a cup of coffee with the number of scoops we ask for. The second function also makes a cup of coffee, but it triples the number of scoops we ask for. To see an illustrative example, let’s ask both these functions for a cup of coffee with a million scoops.

Here’s the output of the Go test:

Benchmark_makeCoffee-4 1000000000 0.29 ns/op

Benchmark_makeStrongCoffee-4 1000000000 0.86 ns/op

Our first function, makeCoffee , completed in an average 0.29 nanoseconds. Our second function, makeStrongCoffee , completed in an average of 0.86 nanoseconds. While those may both seem like pretty small numbers, consider that the stronger coffee took nearly three times longer to make. This should make sense intuitively, since we asked it to triple the scoops. Big O notation alone wouldn’t tell you this, since the constant factor of the tripled scoops isn’t accounted for.

Improve time complexity of existing code

Becoming familiar with time complexity gives us the opportunity to write code, or refactor code, to be more efficient. To illustrate, I’ll give a concrete example of one way we can refactor a bit of code to improve its time complexity.

Let’s say a bunch of people at the office want some pie. Some people want pie more than others. The amount that everyone wants some pie is represented by an int > 0:

diners := []int{2, 88, 87, 16, 42, 10, 34, 1, 43, 56}

Unfortunately, we’re bootstrapped and there are only three forks to go around. Since we’re a cooperative bunch, the three people who want pie the most will receive the forks to eat it with. Even though they’ve all agreed on this, no one seems to want to sort themselves out and line up in an orderly fashion, so we’ll have to make do with everybody jumbled about.

Without sorting the list of diners, return the three largest integers in the slice.

Here’s a function that solves this problem and has O(n2) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// loop over three forks

for i := 1; i <= 3; i++ {

// variables to keep track of the highest integer and where it is

var max, maxIndex int

// loop over the diners slice

for n := range diners {

// if this integer is higher than max, update max and maxIndex

if diners[n] > max {

max = diners[n]

maxIndex = n

}

}

// remove the highest integer from the diners slice for the next loop

diners = append(diners[:maxIndex], diners[maxIndex+1:]...)

// keep track of who gets a fork

withForks = append(withForks, max)

}

return withForks

}

This program works, and eventually returns diners [88 87 56] . Everyone gets a little impatient while it’s running though, since it takes rather a long time (about 120 nanoseconds) just to hand out three forks, and the pie’s getting cold. How could we improve it?

By thinking about our approach in a slightly different way, we can refactor this program to have O(n) time complexity:

func giveForks(diners []int) []int {

// make a slice to store diners who will receive forks

var withForks []int

// create variables for each fork

var first, second, third int

// loop over the diners

for i := range diners {

// assign the forks

if diners[i] > first {

third = second

second = first

first = diners[i]

} else if diners[i] > second {

third = second

second = diners[i]

} else if diners[i] > third {

third = diners[i]

}

}

// list the final result of who gets a fork

withForks = append(withForks, first, second, third)

return withForks

}

Here’s how the new program works:

Initially, diner 2 (the first in the list) is assigned the first fork. The other forks remain unassigned.

Then, diner 88 is assigned the first fork instead. Diner 2 gets the second one.

Diner 87 isn’t greater than first which is currently 88 , but it is greater than 2 who has the second fork. So, the second fork goes to 87 . Diner 2 gets the third fork.

Continuing in this violent and rapid fork exchange, diner 16 is then assigned the third fork instead of 2 , and so on.

We can add a print statement in the loop to see how the fork assignments play out:

0 0 0

2 0 0

88 2 0

88 87 2

88 87 16

88 87 42

88 87 42

88 87 42

88 87 42

88 87 43

[88 87 56]

This program is much faster, and the whole epic struggle for fork domination is over in 47 nanoseconds.

As you can see, with a little change in perspective and some refactoring, we’ve made this simple bit of code faster and more efficient.

Well, it looks like our fifteen minute coffee break is up! I hope I’ve given you a comprehensive introduction to calculating time complexity. Time to get back to work, hopefully applying your new knowledge to write more effective code! Or maybe just sound smart at your next office party. :)

Sources

“If I have seen further it is by standing on the shoulders of Giants.” –Isaac Newton, 1675",https://cdn-images-1.medium.com/max/1200/1*_YsSsyFQ5sgS8F0kiZ1USA.png,[],https://medium.freecodecamp.org/a-coffee-break-introduction-to-time-complexity-of-algorithms-64df7dd8338e?source=collection_home---6------24----------------,2018-06-04 23:44:40.970000+00:00

